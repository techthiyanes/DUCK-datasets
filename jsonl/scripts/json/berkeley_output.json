{
    "1.3.3": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Let $x_{0}=1$ and\n\n$$\nx_{n+1}=\\frac{3+2 x_{n}}{3+x_{n}}, \\quad n \\geqslant 0 .\n$$\n\nProve that $x_{\\infty}=\\lim _{n \\rightarrow \\infty} x_{n}$ exists, and find its value.\n\n",
        "Solution": " Obviously, $x_{n} \\geqslant 1$ for all $n$; so, if the limit exists, it is $\\geqslant 1$, and we can pass to the limit in the recurrence relation to get\n\n$$\nx_{\\infty}=\\frac{3+2 x_{\\infty}}{3+x_{\\infty}} \\text {; }\n$$\n\nin other words, $x_{\\infty}^{2}+x_{\\infty}-3=0$. So $x_{\\infty}$ is the positive solution of this quadratic equation, that is, $x_{\\infty}=\\frac{1}{2}(-1+\\sqrt{13})$.\n\nTo prove that the limit exists, we use the recurrence relation to get\n\n$$\n\\begin{aligned}\nx_{n+1}-x_{n} &=\\frac{3+2 x_{n}}{3+x_{n}}-\\frac{3+2 x_{n-1}}{3+x_{n-1}} \\\\\n&=\\frac{3\\left(x_{n}-x_{n-1}\\right)}{\\left(3+x_{n}\\right)\\left(3+x_{n+1}\\right)}\n\\end{aligned}\n$$\n\nHence, $\\left|x_{n+1}-x_{n}\\right| \\leqslant \\frac{1}{3}\\left|x_{n}-x_{n-1}\\right|$. Iteration gives\n\n$$\n\\left|x_{n+1}-x_{n}\\right| \\leqslant 3^{-n}\\left|x_{1}-x_{0}\\right|=\\frac{1}{3^{n} \\cdot 4} .\n$$\n\nThe series $\\sum_{n=1}^{\\infty}\\left(x_{n+1}-x_{n}\\right)$, of positive terms, is dominated by the convergent series $\\frac{1}{4} \\sum_{n=1}^{\\infty} 3^{-n}$ and so converges. We have $\\sum_{n=1}^{\\infty}\\left(x_{n+1}-x_{n}\\right)=\\lim x_{n}-x_{1}$ and we are done.\n\n",
        "Final Answer": "$\\frac{1}{2}(-1 + \\sqrt{13})$"
    },
    "3.2.3": {
        "Topic": "Second Order Equations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Find all solutions of the differential equation\n\n$$\n\\frac{d^{2} x}{d t^{2}}-2 \\frac{d x}{d t}+x=\\sin t\n$$\n\nsubject to the condition $x(0)=1$ and $x^{\\prime}(0)=0$.\n\n",
        "Solution": "The characteristic polynomial of the associated homogeneous equation is\n\n$$\nr^{2}-2 r+1=(r-1)^{2}\n$$\n\nso the general solution of the homogeneous equation\n\n$$\n\\frac{d^{2} x}{d t^{2}}-2 \\frac{d x}{d t}+x=0\n$$\n\nis\n\n$$\nA e^{t}+B t e^{t} \\quad(A, B \\in \\mathbb{R}) .\n$$\n\n$(\\cos t) / 2$ is easily found to be a particular solution of the original equation, so the general solution is\n\n$$\nA e^{t}+B t e^{t}+\\frac{\\cos t}{2} \\text {. }\n$$\n\nThe initial conditions give $A=-\\frac{1}{2}$ and $B=\\frac{1}{2}$, so the solution is\n\n$$\n\\frac{1}{2}\\left(e^{t}-t e^{t}+\\cos t\\right) \\text {. }\n$$\n\n",
        "Final Answer": "$\\frac{1}{2}\\left(e^{t}-t e^{t}+\\cos t\\right)$"
    },
    "1.5.23": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Compute\n\n$$\n\\int_{0}^{\\infty} \\frac{\\log x}{x^{2}+a^{2}} d x\n$$\n\nwhere $a>0$ is a constant. ",
        "Solution": "$\\log x$ is integrable near zero, and near infinity it is dominated by $\\sqrt{x}$, so the given integral exists finitely. Making the change of variables $x=a / t$, it becomes \n\n$$\n\\begin{aligned}\n\\int_{0}^{\\infty} \\frac{\\log x}{x^{2}+a^{2}} d x &=\\frac{\\log a}{a} \\int_{0}^{\\infty} \\frac{d t}{1+t^{2}}-\\frac{1}{a} \\int_{0}^{\\infty} \\frac{\\log t}{1+t^{2}} d t \\\\\n&=\\left.\\frac{\\log a}{a} \\arctan t\\right|_{0} ^{\\infty}-J \\\\\n&=\\frac{\\pi \\log a}{2 a}-J .\n\\end{aligned}\n$$\n\nIf we treat $J$ in a similar way, we get $J=-J$, so $J=0$ and the given integral equals\n\n$$\n\\frac{\\pi \\log a}{2 a}\n$$\n\n",
        "Final Answer": "$\\frac{\\pi \\log a}{2 a}$"
    },
    "1.1.11": {
        "Topic": "Elementary Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Suppose that $f$ is a twice differentiable real function such that $f^{\\prime \\prime}(x)>0$ for all $x \\in[a, b]$. Find all numbers $c \\in[a, b]$ at which the area between the graph $y=f(x)$, the tangent to the graph at $(c, f(c))$, and the lines $x=a, x=b$, attains its minimum value.\n\n",
        "Solution": " Let $A(c)$ denote the area the problem refers. The condition on $f^{\\prime \\prime}$ implies the convexity of $f$, so the graph of $f$ is always above any tangent to it, and we have\n\n$$\nA(c)=\\int_{a}^{b}\\left(f(x)-f(c)-f^{\\prime}(c)(x-c)\\right) d x .\n$$\n\nThe derivative of $A$ is given by\n\n$$\n\\begin{aligned}\nA^{\\prime}(c) &=-\\int_{a}^{b} f^{\\prime \\prime}(c)(x-c) d x \\\\\n&=-f^{\\prime \\prime}(c) \\frac{b^{2}-a^{2}}{2}+(b-a) c f^{\\prime}(c) \\\\\n&=f^{\\prime \\prime}(c)(b-a)\\left(c-\\frac{a+b}{2}\\right)\n\\end{aligned}\n$$\n\nso the minimum occurs at $c=(a+b) / 2$. As $A^{\\prime}$ is an increasing function, $A$ is convex, so its minimum in $[a, b]$ corresponds to the only critical point in $(a, b)$.\n\n",
        "Final Answer": "$\\frac{a+b}{2}$"
    },
    "1.1.18": {
        "Topic": "Elementary Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Find all pairs of integers $a$ and $b$ satisfying $0<a<b$ and $a^{b}=b^{a}$.\n\n",
        "Solution": "Consider the function $f(x)=\\log x / x$. We have $a^{b}=b^{a}$ iff $f(a)=f(b)$. Now $f^{\\prime}(x)=(1-\\log x) / x^{2}$, so $f$ is increasing for $x<e$ and decreasing for $x>e$. For the above equality to hold, we must have $0<a<e$, so $a$ is either 1 or 2 , and $b>e$. For $a=1$, clearly there are no solutions, and for $a=2$ and $b=4$ works; since $f$ is decreasing for $x>e$, this is the only solution. ",
        "Final Answer": "$(a, b) = (2, 4)$"
    },
    "2.3.6": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\mathcal{S}=\\left\\{(x, y, z) \\in \\mathbb{R}^{3} \\mid x^{2}+y^{2}+z^{2}=1\\right\\}$ denote the unit sphere in $\\mathbb{R}^{3}$. Evaluate the surface integral over $\\mathcal{S}$ :\n\n$$\n\\iint_{\\mathcal{S}}\\left(x^{2}+y+z\\right) d A .\n$$\n\n",
        "Solution": " Using the change of variables\n\n$$\n\\begin{cases}x=\\sin \\varphi \\cos \\theta & 0<\\theta<2 \\pi \\\\ y=\\sin \\varphi \\sin \\theta & 0<\\varphi<\\pi \\\\ z=\\cos \\varphi & \\end{cases}\n$$\n\nwe have\n\n$$\nd A=\\sin \\varphi d \\theta d \\varphi\n$$\n\nand\n\n$$\n\\iint_{\\mathcal{S}}\\left(x^{2}+y+z\\right) d A=\\int_{0}^{\\pi} \\int_{0}^{2 \\pi}\\left(\\sin ^{2} \\varphi \\cos ^{2} \\theta+\\sin \\varphi \\sin \\theta+\\cos \\varphi\\right) \\sin \\varphi d \\theta d \\varphi .\n$$\n\nBreaking the integral in three terms, we get\n\n$$\n\\begin{aligned}\n\\int_{0}^{\\pi} \\int_{0}^{2 \\pi} \\sin \\varphi \\cos \\varphi d \\theta d \\varphi=2 \\pi \\cdot \\frac{1}{2} \\int_{0}^{\\pi} \\sin 2 \\varphi d \\varphi=0 \\\\\n\\int_{0}^{\\pi} \\int_{0}^{2 \\pi} \\sin ^{2} \\varphi \\sin \\theta d \\theta d \\varphi=\\left(\\int_{0}^{\\pi} \\sin ^{2} \\varphi d \\varphi\\right) \\int_{0}^{2 \\pi} \\sin \\theta d \\theta=0 \\\\\n\\int_{0}^{\\pi} \\int_{0}^{2 \\pi} \\sin ^{3} \\varphi \\cos ^{2} \\theta d \\theta d \\varphi &=\\left(\\int_{0}^{\\pi} \\sin ^{3} \\varphi d \\varphi\\right)\\left(\\int_{0}^{2 \\pi} \\cos ^{2} \\theta d \\theta\\right) \\\\\n&=\\int_{0}^{\\pi} \\frac{1}{4}\\left(3 \\sin \\varphi-\\sin ^{3} \\varphi\\right) d \\varphi \\int_{0}^{2 \\pi} \\cos ^{2} \\theta d \\theta \\\\\n&=\\frac{1}{4}\\left(-3 \\cos \\varphi+\\left.\\frac{1}{3} \\cos ^{3} \\varphi\\right|_{0} ^{\\pi}\\right)\\left(\\int_{0}^{2 \\pi} \\frac{1+\\cos 2 \\theta}{2} d \\theta\\right) \\\\\n&=\\frac{1}{4}\\left(-3(-2)+\\frac{1}{3}(-2)\\right) \\pi \\\\\n&=\\frac{1}{4}\\left(6-\\frac{2}{3}\\right) \\pi=\\frac{4}{3} \\pi .\n\\end{aligned}\n$$\n\nTherefore,\n\n$$\n\\iint_{\\mathcal{S}}\\left(x^{2}+y+z\\right) d A=\\frac{4}{3} \\pi\n$$\n\n",
        "Final Answer": "$\\frac{4}{3} \\pi$"
    },
    "1.1.35": {
        "Topic": "Elementary Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Define\n\n$$\nF(x)=\\int_{\\sin x}^{\\cos x} e^{\\left(t^{2}+x t\\right)} d t .\n$$\n\nCompute $F^{\\prime}(0)$.\n\n",
        "Solution": " Let\n\n$$\nG(u, v, x)=\\int_{v}^{u} e^{t^{2}+x t} d t .\n$$\n\nThen $F(x)=G(\\cos x, \\sin x, x)$, so\n\n$$\n\\begin{aligned}\nF^{\\prime}(x) &=\\frac{\\partial G}{\\partial u} \\frac{\\partial u}{\\partial x}+\\frac{\\partial G}{\\partial v} \\frac{\\partial v}{\\partial x}+\\frac{\\partial G}{\\partial x} \\\\\n&=e^{u^{2}+x u}(-\\sin x)-e^{\\left(v^{2}+x v\\right)} \\cos x+\\int_{v}^{u} t e^{t^{2}+x t} d t\n\\end{aligned}\n$$\n\nand\n\n$$\nF^{\\prime}(0)=-1+\\int_{0}^{1} t e^{t^{2}} d t=\\frac{1}{2}(e-3) .\n$$\n\n",
        "Final Answer": "$\\frac12(e - 3)$"
    },
    "5.7.4": {
        "Topic": "Cauchy's Theorem ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " For $0<a<b$, evaluate the integral\n\n$$\nI=\\frac{1}{2 \\pi} \\int_{0}^{2 \\pi} \\frac{1}{\\left|a e^{i \\theta}-b\\right|^{4}} d \\theta .\n$$\n\n",
        "Solution": " The integrand equals\n\n$$\n\\frac{1}{\\left(a e^{i \\theta}-b\\right)^{2}\\left(a e^{-i \\theta}-b\\right)^{2}}=\\frac{e^{2 i \\theta}}{\\left(a e^{i \\theta}-b\\right)^{2}\\left(a-b e^{i \\theta}\\right)^{2}}\n$$\n\nThus, I can be written as a complex integral,\n\n$$\nI=\\frac{1}{2 \\pi i} \\int_{|z|=1} \\frac{z}{(a z-b)^{2}(a-b z)^{2}} d z=\\frac{1}{2 \\pi i b^{2}} \\int_{|z|=1} \\frac{z}{(a z-b)^{2}\\left(z-\\frac{a}{b}\\right)^{2}} d z\n$$\n\nBy Cauchy's Theorem for derivatives, we have\n\n$$\nI=\\left.\\frac{1}{b^{2}} \\frac{d}{d z}\\left(\\frac{z}{(a z-b)^{2}}\\right)\\right|_{z=\\frac{a}{b}}=\\frac{a^{2}+b^{2}}{\\left(b^{2}-a^{2}\\right)^{3}}\n$$\n\n",
        "Final Answer": "$\\frac{a^{2}+b^{2}}{\\left(b^{2}-a^{2}\\right)^{3}}$"
    },
    "5.7.2": {
        "Topic": "Cauchy's Theorem ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Evaluate\n\n$$\n\\int_{0}^{2 \\pi} e^{\\left(e^{i \\theta}-i \\theta\\right)} d \\theta .\n$$\n\n",
        "Solution": " By Cauchy's Integral Formula for derivatives, we have\n\ntherefore,\n\n$$\n\\left.\\frac{d}{d z} e^{z}\\right|_{z=0}=\\frac{1}{2 \\pi i} \\int_{|z|=1} \\frac{e^{z}}{z^{2}} d z=\\frac{1}{2 \\pi} \\int_{0}^{2 \\pi} e^{e^{i \\theta}-i \\theta} d \\theta\n$$\n\n$$\n\\int_{0}^{2 \\pi} e^{e^{i \\theta}-i \\theta} d \\theta=2 \\pi .\n$$\n\n",
        "Final Answer": "$2\\pi$"
    },
    "7.4.26": {
        "Topic": "Linear Transformations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $e=(a, b, c)$ be a unit vector in $\\mathbb{R}^{3}$ and let $T$ be the linear transformation on $\\mathbb{R}^{3}$ of rotation by $180^{\\circ}$ about e. Find the matrix for $T$ with respect to the standard basis. ",
        "Solution": " Let $x=\\left(x_{1}, x_{2}, x_{3}\\right)$ in the standard basis of $\\mathbb{R}^{3}$. The line joining the points $x$ and $T x$ intersects the line containing $e$ at the point $f=\\langle e, x\\rangle e$ and is perpendicular to it. We then have $T x=2(f-x)+x=2 f-x$, or, in the standard basis, $T x=\\left(2\\langle e, x\\rangle a-x_{1}, 2\\langle e, x\\rangle b-x_{2}, 2\\langle e, x\\rangle c-x_{3}\\right)$. With respect to the standard basis for $\\mathbb{R}^{3}$, the columns of the matrix of $T$ are $T e_{1}, T e_{2}$, and $T e_{3}$. Applying our formula and noting that $\\left\\langle e, e_{1}\\right\\rangle=a,\\left\\langle e, e_{2}\\right\\rangle=b$, and $\\left\\langle e, e_{3}\\right\\rangle=c$, we get that the matrix for $T$ is\n\n$$\n\\left(\\begin{array}{ccc}\n2 a^{2}-1 & 2 a b & 2 a c \\\\\n2 a b & 2 b^{2}-1 & 2 b c \\\\\n2 a c & 2 b c & 2 c^{2}-1\n\\end{array}\\right)\n$$\n\n",
        "Final Answer": "$$\n\\left(\\begin{array}{ccc}\n2 a^{2}-1 & 2 a b & 2 a c \\\\\n2 a b & 2 b^{2}-1 & 2 b c \\\\\n2 a c & 2 b c & 2 c^{2}-1\n\\end{array}\\right)\n$$"
    },
    "1.3.11": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $f(x)=\\frac{1}{4}+x-x^{2}$. For any real number $x$, define a sequence $\\left(x_{n}\\right)$ by $x_{0}=x$ and $x_{n+1}=f\\left(x_{n}\\right)$. If the sequence converges, let $x_{\\infty}$ denote the limit.\n\n1. For $x=0$, show that the sequence is bounded and nondecreasing, and find $x_{\\infty}=\\lambda$.\n\n\n",
        "Solution": " 1. We have\n\n$$\nf(x)=\\frac{1}{2}-\\left(x-\\frac{1}{2}\\right)^{2}\n$$\n\nso $x_{n}$ is bounded by $1 / 2$ and, by the Induction Principle, nondecreasing. Let $\\lambda$ be its limit. Then\n\n$$\n\\lambda=\\frac{1}{2}-\\left(\\lambda-\\frac{1}{2}\\right)^{2}\n$$\n\nand, as the sequence takes only positive values,\n\n$$\n\\lambda=\\frac{1}{2} \\text {. }\n$$\n\n",
        "Final Answer": "$\\lambda=\\frac12$"
    },
    "7.6.40": {
        "Topic": "Canonical Forms ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $A$ be the $3 \\times 3$ matrix\n\n$$\n\\left(\\begin{array}{rrr}\n1 & -1 & 0 \\\\\n-1 & 2 & -1 \\\\\n0 & -1 & 1\n\\end{array}\\right)\n$$\n\nDetermine all real numbers $a$ for which the limit $\\lim _{n \\rightarrow \\infty} a^{n} A^{n}$ exists and is nonzero (as a matrix).\n\n",
        "Solution": " An easy calculation shows that $A$ has eigenvalues $\\{0,1,3\\}$ , so $A$ is similar to the diagonal matrix with entries $0,1,3$ . Since clearly the problem does not change when $A$ is replaced by a similar matrix, we may replace $A$ by that diagonal matrix. Then the condition on $a$ is that each of the sequences $\\left(0^{n}\\right),\\left(a^{n}\\right)$, and $\\left((3 a)^{n}\\right)$ has a limit, and that at least one of these limits is nonzero. This occurs if and only if $a=1 / 3$.\n\n",
        "Final Answer": "$a=\\frac13$"
    },
    "7.8.3": {
        "Topic": "Bilinear, Quadratic Forms, and Inner Product Spaces ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the infimum and supremum of the set of real numbers $t$ for which the quadratic form $Q_{t}$ on $\\mathbb{R}^{3}$, defined by\n\n$$\nQ_{t}\\left(x_{1}, x_{2}, x_{3}\\right)=2 x_{1}^{2}+x_{2}^{2}+3 x_{3}^{2}+2 t x_{1} x_{2}+2 x_{1} x_{3},\n$$\n\nis positive definite.\n\n",
        "Solution": " We have\n\n$$\n2 x_{1}^{2}+x_{2}^{2}+3 x_{3}^{2}+2 t x_{1} x_{2}+2 x_{1} x_{3}=\\left(x_{1}, x_{2}, x_{3}\\right)\\left(\\begin{array}{lll}\n2 & t & 1 \\\\\nt & 1 & 0 \\\\\n1 & 0 & 3\n\\end{array}\\right)\\left(\\begin{array}{l}\nx_{1} \\\\\nx_{2} \\\\\nx_{3}\n\\end{array}\\right)\n$$\n\nThe form is positive definite if and only if the determinants\n\n$$\n\\left|\\begin{array}{lll}\n2 & t & 1 \\\\\nt & 1 & 0 \\\\\n1 & 0 & 3\n\\end{array}\\right|>0 \\quad \\text { and } \\quad\\left|\\begin{array}{ll}\n2 & t \\\\\nt & 1\n\\end{array}\\right|>0\n$$\n\nthat is, when $-1+3\\left(2-t^{2}\\right)=5-3 t^{2}>0$ and $2-t^{2}>0$.\n\nBoth conditions hold iff $|t|<\\sqrt{\\frac{5}{3}}$. For these values of $t$ the form is positive definite.\n\n",
        "Final Answer": "$\\left(-\\sqrt{\\frac53}, \\sqrt{\\frac53}\\right)$"
    },
    "5.8.8": {
        "Topic": "Zeros and Singularities ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the number of roots of\n\n$$\nz^{7}-4 z^{3}-11=0\n$$\n\nwhich lie between the two circles $|z|=1$ and $|z|=2$.\n\n",
        "Solution": " Let $p(z)=z^{7}-4 z^{3}-11$. For $z$ in the unit circle, we have\n\n$$\n|p(z)-11|=\\left|z^{7}-4 z^{3}\\right| \\leqslant 5<11\n$$\n\nso, by Rouch\u00e9's Theorem, the given polynomial has no zeros in the unit disc. For $|z|=2$,\n\n$$\n\\left|p(z)-z^{7}\\right|=\\left|4 z^{3}+11\\right| \\leqslant 43<128=\\left|z^{7}\\right|\n$$\n\nso there are seven zeros inside the disc $\\{z|| z \\mid<2\\}$ and they are all between the two given circles.\n\n",
        "Final Answer": "$7$"
    },
    "6.5.7": {
        "Topic": "S_{n}, A_{n}, D_{n}, ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $S_{9}$ denote the group of permutations of nine objects and let $A_{9}$ be the subgroup consisting of all even permutations. Denote by $1 \\in S_{9}$ the identity permutation. Determine the minimum of all positive integers $m$ such that every $\\sigma \\in S_{9}$ satisfies $\\sigma^{m}=1$. Determine also the minimum of all positive integers $m$ such that every $\\sigma \\in A_{9}$ satisfies $\\sigma^{m}=1$.\n\n",
        "Solution": " The order of a $k$-cycle is $k$, so the smallest $m$ which simultaneously annihilates all 9-cycles, 8-cycles, 7-cycles, and 5-cycles is $2^{3} \\cdot 3^{2} \\cdot 5 \\cdot 7= 2520$. Any $n$-cycle, $n \\leqslant 9$, raised to this power is annihilated, so $n=2520$.\n\nTo compute $n$ for $A 9$, note that an 8-cycle is an odd permutation, so no 8-cycles are in $A_{9}$. Therefore, $n$ need only annihilate 4-cycles (since a 4-cycle times a transposition is in A9), 9-cycles, 7-cycles, and 5-cycles. Thus, $n=2520 / 2= 1260$.\n\n",
        "Final Answer": "$(2520, 1260)$"
    },
    "2.2.4": {
        "Topic": "Differential Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $f: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$ be defined by:\n\n$$\nf(x, y)=\\left\\{\\begin{array}{lll}\nx^{4 / 3} \\sin (y / x) & \\text { if } & x \\neq 0 \\\\\n0 & \\text { if } & x=0\n\\end{array}\\right.\n$$\n\nDetermine all points at which $f$ is differentiable.\n\n",
        "Solution": " The function $f$ is differentiable at the point $z=\\left(x_{0}, y_{0}\\right) \\in U$ if there is a linear transformation $f^{\\prime}(z) \\in L\\left(\\mathbb{R}^{2}, \\mathbb{R}^{1}\\right)$ such that\n\n$$\n\\lim _{h \\rightarrow 0} \\frac{\\left|f(z+h)-f(z)-f^{\\prime}(z) h\\right|}{\\|h\\|}=0 .\n$$\n\nContinuity of the partial derivatives is a sufficient condition for differentiability. A calculation gives\n\n$$\n\\begin{gathered}\n\\frac{\\partial f}{\\partial x}(x, y)= \\begin{cases}(4 / 3) x^{1 / 3} \\sin y / x-y x^{-2 / 3} \\cos y / x & \\text { if } x \\neq 0 \\\\\n0 & \\text { if } x=0\\end{cases} \\\\\n\\frac{\\partial f}{\\partial y}(x, y)= \\begin{cases}x^{1 / 3} \\cos (y / x) & \\text { if } x \\neq 0 \\\\\n0 & \\text { if } x=0\\end{cases}\n\\end{gathered}\n$$\n\nwhich are continuous on $\\mathbb{R}^{2} \\backslash\\{(0, y) \\mid y \\in \\mathbb{R}\\}$. Thus, $f$ is differentiable there. At any point $(0, y)$, we have\n\n$$\n\\frac{f(h, k)-f(0, y)}{\\|(h, k)\\|}=O\\left(|h|^{1 / 3}\\right)=o(1) \\quad(h \\rightarrow 0)\n$$\n\nso $f$ is differentiable at these points also.\n\n",
        "Final Answer": "$\\mathbb{R}^2$"
    },
    "2.3.5": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\varphi(x, y)$ be a function with continuous second order partial derivatives such that\n\n1. $\\varphi_{x x}+\\varphi_{y y}+\\varphi_{x}=0$ in the punctured plane $\\mathbb{R}^{2} \\backslash\\{0\\}$,\n\n2. $r \\varphi_{x} \\rightarrow \\frac{x}{2 \\pi r}$ and $r \\varphi_{y} \\rightarrow \\frac{y}{2 \\pi r}$ as $r=\\sqrt{x^{2}+y^{2}} \\rightarrow 0$.\n\nLet $C_{R}$ be the circle $x^{2}+y^{2}=R^{2}$. Show that the line integral\n\n$$\n\\int_{C_{R}} e^{x}\\left(-\\varphi_{y} d x+\\varphi_{x} d y\\right)\n$$\n\nis independent of $R$, and evaluate it.\n\n",
        "Solution": "Consider the annular region $\\mathcal{A}$ between the circles of radius $r$ and $R$, then by Green's Theorem\n\n$$\n\\begin{aligned}\n&\\int_{R} e^{x}\\left(-\\varphi_{y} d x+\\varphi_{x} d y\\right)-\\int_{r} e^{y}\\left(-\\varphi_{y} d x+\\varphi_{x} d y\\right)= \\\\\n&=\\int_{\\partial \\mathcal{A}} e^{x}\\left(-\\varphi_{x} d x+\\varphi_{x} d y\\right) \\\\\n&=\\iint_{\\mathcal{A}} d\\left(e^{x}\\left(-\\varphi_{y} d x+\\varphi_{x} d y\\right)\\right) \\\\\n&=\\iint_{\\mathcal{A}}-e^{x} \\varphi_{y y} d y \\wedge d x+\\left(e^{x} \\varphi_{x}+e^{x} \\varphi_{x x}\\right) d x \\wedge d y \\\\\n&=\\iint_{\\mathcal{A}} e^{x}\\left(\\varphi_{x x}+e^{x} \\varphi_{x x}+\\varphi_{x}\\right) d x \\wedge d y=0\n\\end{aligned}\n$$\n\nshowing that the integral does not depend on the radius $r$. Now, parametrizing the circle of radius $r$\n\n$$\n\\begin{aligned}\n&\\int_{C_{r}} e^{x}\\left(-\\varphi_{y} d x+\\varphi_{x} d y\\right)= \\\\\n&=\\int_{0}^{2 \\pi} e^{r \\cos \\theta}\\left(\\varphi_{y}(r \\cos \\theta, r \\sin \\theta) \\sin \\theta+\\varphi_{x}(r \\cos \\theta, r \\sin \\theta) \\cos \\theta\\right) r d \\theta\n\\end{aligned}\n$$\n\nbut when $r \\rightarrow 0$ the integrand converges uniformly to\n\n$$\n\\frac{\\sin \\theta}{2 \\pi} \\cdot \\sin \\theta+\\frac{\\cos \\theta}{2 \\pi} \\cdot \\cos \\theta=\\frac{1}{2 \\pi}\n$$\n\nso the integral approaches $1$ when $r \\rightarrow 0$ and that is the value of the integral.\n\n",
        "Final Answer": "$1$"
    },
    "7.9.19": {
        "Topic": "General Theory of Matrices ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " 1. Determine the commutant of the $n \\times n$ Jordan matrix\n\n$$\nA B=\\left(\\begin{array}{cccccc}\n\\lambda & 1 & 0 & \\ldots & 0 & 0 \\\\\n0 & \\lambda & 1 & \\ldots & 0 & 0 \\\\\n0 & 0 & \\lambda & \\ldots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & \\ldots & \\lambda & 1 \\\\\n0 & 0 & 0 & \\ldots & 0 & \\lambda\n\\end{array}\\right)\n$$\n\nIn particular, find the dimension of the commutant as a complex vector space.",
        "Solution": " 1. Assume without loss of generality that $\\lambda=0$ (otherwise replace $J$ by $J-\\lambda I)$. Let $e_{1}, \\ldots, e_{n}$ be the standard basis vectors for $\\mathbb{C}^{n}$, so that $J e_{k}=e_{k-1}$ for $k=2, \\ldots, n, J e_{1}=0$. Suppose $A J=J A$. Then, for $k=1, \\ldots, n-1$,\n\n$$\nA e_{k}=A J^{n-k} e_{n}=J^{n-k} A e_{n},\n$$\n\nso $A$ is completely determined by $A e_{n}$. If $A e_{n}=\\left(\\begin{array}{c}c_{n} \\\\ \\vdots \\\\ c_{1}\\end{array}\\right)$, then\n\n$$\nA=\\left(\\begin{array}{cccccc}\nc_{1} & c_{2} & c_{3} & \\ldots & c_{n-1} & c_{n} \\\\\n0 & c_{1} & c_{2} & \\ldots & c_{n-2} & c_{n-1} \\\\\n0 & 0 & c_{1} & \\ldots & c_{n-3} & c_{n-2} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & \\ldots & c_{1} & c_{2} \\\\\n0 & 0 & 0 & \\ldots & 0 & c_{1}\n\\end{array}\\right) .\n$$\n\nIn other words, $A$ has zero entries below the main diagonal, the entry $c_{1}$ at each position on the main diagonal, the entry $c_{2}$ at each position immediately above the main diagonal, the entry $c_{3}$ at each position two slots above the main diagonal, etc. From (*) it follows that every matrix of this form commutes with $J$. The commutant of $J$ thus has dimension $n$.\n\n",
        "Final Answer": "$n$"
    },
    "1.3.1": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $A_{1} \\geqslant A_{2} \\geqslant \\cdots \\geqslant A_{k} \\geqslant 0$. Evaluate\n\n$$\n\\lim _{n \\rightarrow \\infty}\\left(A_{1}^{n}+A_{2}^{n}+\\cdots+A_{k}^{n}\\right)^{1 / n} .\n$$\n\n",
        "Solution": " $A_{1}^{n} \\leqslant A_{1}^{n}+\\cdots+A_{k}^{n} \\leqslant k A_{1}^{n}$, so we have\n\n$$\nA_{1}=\\lim _{n \\rightarrow \\infty}\\left(A_{1}^{n}\\right)^{1 / n} \\leqslant \\lim _{n \\rightarrow \\infty}\\left(A_{1}^{n}+\\cdots+A_{k}^{n}\\right)^{1 / n} \\leqslant \\lim _{n \\rightarrow \\infty}\\left(k A_{1}^{n}\\right)^{1 / n}=A_{1} .\n$$\n\nshowing that the limit equals $A_{1}$.\n\n",
        "Final Answer": "$A_1$"
    },
    "5.7.1": {
        "Topic": "Cauchy's Theorem ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": "Evaluate\n\n$$\n\\int_{0}^{2 \\pi} e^{e^{i \\theta}} d \\theta .\n$$\n\n\n\n",
        "Solution": " By Cauchy's Integral Formula, we have\n\n$$\ne^{0}=\\frac{1}{2 \\pi i} \\int_{|z|=1} \\frac{e^{z}}{z} d z=\\frac{1}{2 \\pi} \\int_{0}^{2 \\pi} e^{e^{i \\theta}} d \\theta\n$$\n\ntherefore,\n\n$$\n\\int_{0}^{2 \\pi} e^{e^{i \\theta}} d \\theta=2 \\pi .\n$$\n\n",
        "Final Answer": "$2\\pi$"
    },
    "1.3.5": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\alpha$ be a number in $(0,1)$. Prove that any sequence $\\left(x_{n}\\right)$ of real numbers satisfying the recurrence relation\n\n$$\nx_{n+1}=\\alpha x_{n}+(1-\\alpha) x_{n-1}\n$$\n\nhas a limit, and find an expression for the limit in terms of $\\alpha, x_{0}$ and $x_{1}$.\n\n",
        "Solution": " By the given relation $x_{n+1}-x_{n}=(\\alpha-1)\\left(x_{n}-x_{n-1}\\right)$. Therefore, by the Induction Principle [MH93, p. 7], we have $x_{n}-x_{n-1}=(\\alpha-1)^{n-1}\\left(x_{1}-x_{0}\\right)$, showing that the sequence is Cauchy and then converges. Hence,\n\n$$\nx_{n}-x_{0}=\\sum_{k=1}^{n}\\left(x_{k}-x_{k-1}\\right)=\\left(x_{1}-x_{0}\\right) \\sum_{k=1}^{n}(\\alpha-1)^{k-1} \\text {. }\n$$\n\nTaking limits, we get\n\n$$\n\\lim _{n \\rightarrow \\infty} x_{n}=\\frac{(1-\\alpha) x_{0}+x_{1}}{2-\\alpha} .\n$$\n\n",
        "Final Answer": "$$\\frac{(1-\\alpha) x_{0}+x_{1}}{2-\\alpha}$$"
    },
    "1.5.15": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Evaluate the integral\n\n$$\nI=\\int_{0}^{1 / 2} \\frac{\\sin x}{x} d x\n$$\n\nto an accuracy of three decimal places; that is, find a number $I^{*}$ such that $\\left|I-I^{*}\\right|<0.0005$.\n\n",
        "Solution": " Using the Maclaurin expansion of $\\sin x$, we get\n\n$$\n\\frac{\\sin x}{x}=\\sum_{0}^{\\infty}(-1)^{n} \\frac{x^{2 n}}{(2 n+1) !} .\n$$\n\nThe series above is alternating for every value of $x$, so we have\n\n$$\n\\left|\\frac{\\sin x}{x}-\\sum_{0}^{k}(-1)^{n} \\frac{x^{2 n+1}}{(2 n+1) !}\\right| \\leqslant \\frac{x^{2 k+2}}{(2 k+3) !} .\n$$\n\nTaking $k=2$, we have\n\n$$\n\\left|I-\\int_{0}^{1 / 2}\\left(1-\\frac{x^{2}}{3 !}\\right) d x\\right| \\leqslant \\int_{0}^{1 / 2} \\frac{x^{4}}{5 !} d x\n$$\n\nwhich gives an approximate value of $71 / 144 \\approx 0.493$ with an error bounded by $0.00013$.\n\n",
        "Final Answer": "$0.493$"
    },
    "1.3.26": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Evaluate the limit\n\n$$\n\\lim _{n \\rightarrow \\infty} \\cos \\frac{\\pi}{2^{2}} \\cos \\frac{\\pi}{2^{3}} \\cdots \\cos \\frac{\\pi}{2^{n}}\n$$\n\n\n\n",
        "Solution": " Using the formula $\\sin 2 x=2 \\sin x \\cos x$, starting with $\\sin \\frac{\\pi}{2}=1$, by induction we see that\n\n$$\n\\cos \\frac{\\pi}{2^{2}} \\cos \\frac{\\pi}{2^{3}} \\cdots \\cos \\frac{\\pi}{2^{n}}=\\frac{1}{2^{n-1} \\sin \\frac{\\pi}{2^{n}}}\n$$\n\nSo we have\n\n$$\n\\frac{1}{2^{n-1} \\sin \\frac{\\pi}{2^{n}}}=\\frac{2}{\\pi} \\frac{\\frac{\\pi}{2^{n}}}{\\sin \\frac{\\pi}{2^{n}}} \\sim \\frac{2}{\\pi} \\quad(n \\rightarrow \\infty)\n$$\n\nsince $\\sin x \\sim x$ when $x \\rightarrow 0$.\n\n\n\n",
        "Final Answer": "$\\frac2\\pi$"
    },
    "5.3.3": {
        "Topic": "Conformal Mappings ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " A fractional linear transformation maps the annulus $r<|z|<1$ (where $r>0$ ) onto the domain bounded by the two circles $\\left|z-\\frac{1}{4}\\right|=\\frac{1}{4}$ and $|z|=1$. Find $r$.\n\n",
        "Solution": " Let $A=\\{z : | z|<1| z-,1 / 4 \\mid>1 / 4\\}, B=\\{z : r<| z \\mid<1\\}$. Let $f(z)=(z-\\alpha) /(\\alpha z-1)$ be a linear fractional transformation mapping $A$ onto $B$, where $-1<\\alpha<1$. We have\n\n$$\nf(\\{z : | z-1 / 4 \\mid=1 / 4\\})=\\{z : | z \\mid=r\\}\n$$\n\nso\n\n$$\n\\{f(0), f(1 / 2)\\}=\\{-r, r\\}\n$$\n\nand\n\n$$\n0=r-r=f(0)+f(1 / 2)=\\alpha+\\frac{1 / 2-\\alpha}{\\alpha / 2-1}\n$$\n\nwhich implies $\\alpha=2-\\sqrt{3}$. Therefore, $r=|f(0)|=2-\\sqrt{3}$.\n\nSuppose now that $g$ is a linear fractional transformation mapping $C=\\{z: s<| z \\mid<1\\}$ onto $A$. Then $g^{-1}(\\mathbb{R})$ is a straight line through the origin, because the real line is orthogonal to the circles $\\{z : | z-1 / 4 \\mid=1 / 4\\}$ and $\\{z : | z \\mid=1\\}$. Multiplying by a unimodular constant, we may assume $g^{-1}(\\mathbb{R})=\\mathbb{R}$. Then $f \\circ g(C)=A$ and $f \\circ g(\\mathbb{R})=\\mathbb{R}$. Replacing, if necessary, $g(z)$ by $g(s / z)$, we may suppose $f \\circ g(\\{z : | z \\mid \\leqslant 1\\})=\\{z : | z \\mid \\leqslant 1\\}$, so\n\n$$\nf \\circ g(z)=\\beta \\frac{z-\\alpha}{\\bar{\\alpha} z-1} \\quad \\text { with } \\quad|\\alpha|<|\\beta|=1 \\text {. }\n$$\n\nUsing the relation $0=f(s)+f(-s)$, we get $\\alpha=0$, so $f \\circ g(z)=\\beta z$ and $s=r=2-\\sqrt{3}$.\n\n",
        "Final Answer": "$2 - \\sqrt{3}$"
    },
    "6.5.5": {
        "Topic": "S_{n}, A_{n}, D_{n}",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $S_{7}$ be the group of permutations of a set of seven objects. Find all $n$ such that some element of $S_{7}$ has order $n$.\n\n",
        "Solution": " We use the notation $1^{\\alpha_{1}} 2^{\\alpha_{2}} \\ldots$ to denote the cycle pattern of a permutation in disjoint cycles form; this means that the permutation is a product of $\\alpha_{1}$ cycles of length $1, \\alpha_{2}$ cycles of length $2, \\ldots$ (Thus the pattern of, say, $(8)(3 4)(56)(271) \\in S_{8}$ is denoted by $1^{1} 2^{2} 3^{1}$.) The order of a permutation in disjoint cycles form is the least common multiple of the orders of its factors. The order of a cycle of length $r$ is $r$. The possible cycle patterns of elements of $S_{7}$ are\n\n$$\n\\begin{aligned}\n& 1^{7} \\\\\n& 1^{5} 2^{1} ; \\quad 1^{3} 2^{2} \\quad 1^{1} 2^{3} ; \\\\\n& 1^{4} 3^{1} ; \\quad 1^{2} 2^{1} 3^{1} ; \\quad 2^{2} 3^{1} ; \\quad 1^{1} 3^{2} ; \\\\\n& 1^{3} 4^{1} ; \\quad 1^{1} 2^{1} 4^{1} ; \\quad 3^{1} 4^{1} \\\\\n& 1^{2} 5^{1} ; \\quad 2^{1} 5^{1} \\text {; } \\\\\n& 1^{1} 6^{1} \\text {; } \\\\\n& 7^{1} \\text {. }\n\\end{aligned}\n$$\n\nWe see that possible orders of elements of $S_{7}$ are $1,2,3,4,5,6,7,10,12$.\n\n",
        "Final Answer": "$\\{1,2,3,4,5,6,7,10,12\\}$"
    },
    "5.6.12": {
        "Topic": "Analytic and Meromorphic Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $s(y)$ and $t(y)$ be real differentiable functions of $y$, $-\\infty<y<\\infty$, such that the complex function\n\n$$\nf(x+i y)=e^{x}(s(y)+i t(y))\n$$\n\nis complex analytic with $s(0)=1$ and $t(0)=0$. Determine $s(y)$ and $t(y)$.\n\n",
        "Solution": " Let $f(x+i y)=u(x, y)+i v(x, y)$, where $u(x, y)=e^{x} s(y)$ and $v(x, y)=e^{x} t(y)$. From the Cauchy-Riemann equations, we get $e^{x} s(y)=e^{x} t^{\\prime}(y)$, so $s(y)=t^{\\prime}(y)$. Similarly, $s^{\\prime}(y)=-t(y)$. This equation has the unique solution $s(y)=\\cos y$ satisfying the initial conditions $s(0)=1$ and $s^{\\prime}(0)=-t(0)=0$, which, in turn, implies that $t(y)=-s^{\\prime}(y)=\\sin y$.\n\n",
        "Final Answer": "$(\\cos y, \\sin y)$"
    },
    "5.2.6": {
        "Topic": "Series and Sequences of Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let the sequence $a_{0}, a_{1}, \\ldots$ be defined by the equation\n\n$$\n1-x^{2}+x^{4}-x^{6}+\\cdots=\\sum_{n=0}^{\\infty} a_{n}(x-3)^{n} \\quad(0<x<1) .\n$$\n\nFind\n\n$$\n\\limsup _{n \\rightarrow \\infty}\\left(\\left|a_{n}\\right|^{\\frac{1}{n}}\\right) .\n$$\n\n",
        "Solution": " As\n\n$$\n1-x^{2}+x^{4}-x^{6}+\\cdots=\\frac{1}{1+x^{2}}\n$$\n\nwhich has singularities at $\\pm i$, the radius of convergence of\n\n$$\n\\sum_{n=0}^{\\infty} a_{n}(x-3)^{n}\n$$\n\nis the distance from $3$ to $\\pm i, and |3 \\mp i|=\\sqrt{10}$. We then have\n\n$$\n\\limsup _{n \\rightarrow \\infty}\\left(\\left|a_{n}\\right|^{\\frac{1}{n}}\\right)=\\frac{1}{\\sqrt{10}} \\cdot\n$$\n\n",
        "Final Answer": "$\\frac1{\\sqrt{10}}$"
    },
    "1.3.7": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let a be a positive real number. Define a sequence $\\left(x_{n}\\right)$ by\n\n$$\nx_{0}=0, \\quad x_{n+1}=a+x_{n}^{2}, \\quad n \\geqslant 0 .\n$$\n\nThe set of all $a$ such that the finite limit $\\lim _{n \\rightarrow \\infty} x_{n}$ exists is an interval on the real line. Find its lower and upper bounds.\n\n",
        "Solution": " If $\\lim x_{n}=x_{\\infty} \\in \\mathbb{R}$, we have $x_{\\infty}=a+x_{\\infty}^{2} ;$ so\n\n$$\nx_{\\infty}=\\frac{1 \\pm \\sqrt{1-4 a}}{2}\n$$\n\nand we must have $a \\leqslant 1 / 4$.\n\nConversely, assume $0<a \\leqslant 1 / 4$. As $x_{n+1}-x_{n}=x_{n}^{2}-x_{n-1}^{2}$, we conclude, by induction, that the given sequence is nondecreasing. Also,\n\n$$\nx_{n+1}=a+x_{n}^{2}<\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}\n$$\n\nif $x_{n}<1 / 2$, which shows that the sequence is bounded. It follows that the sequence converges when $0<a \\leqslant 1 / 4$.\n\n",
        "Final Answer": "$(0, \\frac14]$"
    },
    "7.1.3": {
        "Topic": "Vector Spaces ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\mathrm{F}$ be a finite field with $q$ elements and let $V$ be an $n$-dimensional vector space over $\\mathbf{F}$. Answer the following three subproblems:\n\n1. Find the cardinality of $V$.\n\n2. Let $G L_{n}(\\mathbf{F})$ denote the group of all $n \\times n$ nonsingular matrices over $\\mathbf{F}$. Determine the order of $G L_{n}(\\mathbb{F})$.\n\n3. Let $S L_{n}(\\mathbf{F})$ denote the subgroup of $G L_{n}(\\mathbf{F})$ consisting of matrices with determinant 1. Find the order of $S L_{n}(\\mathrm{~F})$.\n\n",
        "Solution": " 1. Every element of $V$ can be uniquely written in the form $a_{1} v_{1}+\\cdots+a_{n} v_{n}$, where the $v_{i}$ 's form a basis of $V$ and the $a_{i}$ 's are elements of F. Since $\\mathbf{F}$ has $q$ elements it follows that $V$ has $q^{n}$ elements.\n\n2. A matrix $A$ in $G L_{n}(F)$ is nonsingular if and only if its columns are linearly independent vectors in $F^{n}$. Therefore, the first column $A_{1}$ can be any nonzero vector in $\\mathbf{F}^{n}$, so there are $q^{n}-1$ possibilities. Once the first column is chosen, the second column, $A_{2}$, can be any vector which is not a multiple of the first, that is, $A_{2} \\neq c A_{1}$, where $c \\in \\mathbf{F}$, leaving $q^{n}-q$ choices for $A_{2}$. In general, the $i^{t h}$ column $A_{i}$ can be any vector which cannot be written in the form $c_{1} A_{1}+c_{2} A_{2}+\\cdots+c_{i-1} A_{i-1}$ where $c_{j} \\in \\mathbf{F}$. Hence, there are $q^{n}-q^{i-1}$ possibilities for $A_{i}$. By multiplying these together we see that the order of $G L_{n}(F)$ is then $\\left(q^{n}-1\\right)\\left(q^{n}-q\\right) \\cdots\\left(q^{n}-q^{n-1}\\right)$.\n\n3. The determinant clearly induces a homomorphism from $G L_{n}(F)$ onto the multiplicative group $\\mathbf{F}^{*}$, which has $q-1$ elements. The kernel of the homomorphism is $S L_{n}(F)$, and the cosets with respect to this kernel are the elements of $G L_{n}(F)$ which have the same determinant. Since all cosets of a group must have the same order, it follows that the order of $S L_{n}(F)$ is $\\left|G L_{n}(F)\\right| /(q-1)$.\n\n",
        "Final Answer": "$$ \\left(q^n, \\left(q^{n}-1\\right)\\left(q^{n}-q\\right) \\cdots\\left(q^{n}-q^{n-1}\\right), \\frac{\\left(q^{n}-1\\right)\\left(q^{n}-q\\right) \\cdots\\left(q^{n}-q^{n-1}\\right)}{q-1} \\right) $$"
    },
    "6.8.12": {
        "Topic": "Finite Groups ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find (up to isomorphism) all groups of order $2 p$, where $p$ is a prime $(p > 2)$.\n\n",
        "Solution": "Let $G$ have order $2 p$. By Sylow's Theorems, the $p$-Sylow subgroup of $G$ must be normal, since the number of such subgroups must divide $2 p$ and be congruent to $1 \\bmod p$. Since the $p$-Sylow subgroup has order $p$, it is cyclic; let it be generated by $g$. A similar argument shows that the number of 2-Sylow subgroups is odd and divides $2 p$; hence, there is a unique, normal 2-Sylow subgroup, or there are $p$ conjugate 2-Sylow subgroups. Let one of the 2-Sylow subgroups be generated by $h$.\n\nIn the first case, the element $g h g^{-1} h^{-1}$ is in the intersection of the 2-Sylow and the $p$-Sylow subgroups since they are both normal; these are cyclic groups of different orders, so it follows that $g h g^{-1} h^{-1}=1$, or $h g=g h$. Since $g$ and $h$ must generate $G$, we see that $G$ is abelian and isomorphic to $\\mathbb{Z}_{2} \\oplus \\mathbb{Z}_{p}$.\n\nIn the second case, a counting argument shows that all the elements of $G$ can be written in the form $g^{i} h^{j}, 0 \\leqslant i<p, 0 \\leqslant j<2$. Since all the elements of the form $g^{i}$ have order $p$, it follows that all the 2-Sylow subgroups are generated by the elements $g^{i} h$. Hence, all of these elements are of order 2 ; in particular, $g h g h=1$, or $h g=g^{-1} h$. Thus, $G=\\left\\langle g, h \\mid g^{p}=h^{2}=1, h g=g^{-1} h\\right\\rangle$ and so $G$ is the dihedral group $D_{n}$.\n\n",
        "Final Answer": "$\\{\\mathbb{Z}_2 \\oplus \\mathbb{Z}_{p}, D_{2p}\\}$"
    },
    "1.1.12": {
        "Topic": "Elementary Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the maximum area of all triangles that can be inscribed in an ellipse with semiaxes $a$ and $b$, and describe the triangles that have maximum area.\n\n",
        "Solution": " Using the parameterization\n\n$$\nx=a \\cos t, y=b \\sin t,\n$$\n\na triple of points on the ellipse is given by\n\n$$\n\\left(a \\cos t_{i}, b \\sin t_{i}\\right), \\quad i=1,2,3 .\n$$\n\nSo the area of an inscribed triangle is given by\n\n$$\n\\frac{1}{2}\\left|\\begin{array}{lll}\n1 & a \\cos t_{1} & b \\sin t_{1} \\\\\n1 & a \\cos t_{2} & b \\sin t_{2} \\\\\n1 & a \\cos t_{3} & b \\sin t_{3}\n\\end{array}\\right|=\\frac{a b}{2}\\left|\\begin{array}{lll}\n1 & \\cos t_{1} & \\sin t_{1} \\\\\n1 & \\cos t_{2} & \\sin t_{2} \\\\\n1 & \\cos t_{3} & \\sin t_{3}\n\\end{array}\\right|\n$$\n\nwhich is $a b$ times the area of a triangle inscribed in the unit circle. In the case of the circle, among all inscribed triangles with a given base $2 w(0<w \\leqslant 1)$, the one of maximum area is an isosceles triangle whose area equals\n\n$$\ng(w)=w\\left(1+\\sqrt{1-w^{2}}\\right) .\n$$\n\nUsing elementary calculus one finds that the maximum of $g$ on the interval $0 \\leqslant w \\leqslant 1$ occurs at $w=\\sqrt{3} / 2$, corresponding to an equilateral triangle, and equals $3 \\sqrt{3} / 4$. Alternatively, fixing one side of the triangle as the basis, we easily see that among all the inscribed triangles the one with the greatest area is isosceles because of the maximum height, showing that the angle at the basis is the same. Fixing another side we see that the triangle is indeed equilateral. Hence, the area is maximal when\n\n$$\nt_{2}=t_{1}+\\frac{2 \\pi}{3} \\text { and } t_{3}=t_{2}+\\frac{2 \\pi}{3}\n$$\n\nthat is, when the corresponding triangle inscribed in the unit circle is regular.\n\nFor the ellipse with semiaxes $a, b$, this corresponds to an inscribed triangle with maximum area equals $3 a b \\sqrt{3} / 4$.\n\n",
        "Final Answer": "$3 a b \\sqrt{3} / 4$"
    },
    "7.5.6": {
        "Topic": "Eigenvalues and Eigenvectors ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $L$ be a real symmetric $n \\times n$ matrix with 0 as a simple eigenvalue, and let $v \\in \\mathbb{R}^{n}$.\n\n1. Show that for sufficiently small positive real $\\varepsilon$, the equation $L x+\\varepsilon x=v$ has a unique solution $x=x(\\varepsilon) \\in \\mathbb{R}^{n}$.\n\n2. Evaluate $\\lim _{\\varepsilon \\rightarrow 0^{+}} \\varepsilon x(\\varepsilon)$ in terms of $v$, the eigenvectors $e_1, \\ldots, e_n$ of $L$, and the inner product $\\langle \\cdot \\rangle $ on $\\mathbb{R}^{n}$.\n\n",
        "Solution": " 1. Being real and symmetric, $L$ has an orthonormal basis of eigenvectors $e_{1}, \\ldots, e_{n}$. Let $\\lambda_{1}, \\ldots, \\lambda_{n}$ be the associated eigenvalues. We can assume that $\\lambda_{1}=0$ and $\\lambda_{i} \\neq 0$ for $i>1$. Write the two vectors $v=\\sum_{i=1}^{n} v_{i}$ and $x=\\sum_{i=1}^{n} x_{i}$ in terms of its coordinates, then the equation $L x+\\varepsilon=v$ becomes $\\lambda_{i} x_{i}+\\varepsilon x_{i}=v_{i}$ for each $i$, which has the unique solution $x_{i}=v_{i} /\\left(\\lambda_{i}+\\varepsilon\\right)$, provided that $0<\\varepsilon<\\min _{i \\neq 1}\\left|\\lambda_{i}\\right|$.\n\n2. Writing $\\varepsilon x$ in $e_{i}$ coordinates\n\n$$\n\\varepsilon x=\\sum_{i=1}^{n} \\varepsilon x_{i} e_{i}=\\sum_{i=1}^{n} \\frac{\\varepsilon}{\\lambda_{i}+\\varepsilon} v_{i} e_{i}\n$$\n\nas $\\varepsilon \\rightarrow 0$, all terms in the summation on the right tend to 0 , except the first which approaches $v_{1} e_{1}=\\left\\langle v, e_{1}\\right\\rangle e_{1}$.\n\n",
        "Final Answer": "$\\left\\langle v, e_{1}\\right\\rangle e_{1}$"
    },
    "3.2.2": {
        "Topic": "Second Order Equations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the solution of the differential equation\n\n$$\ny^{\\prime \\prime}-2 y^{\\prime}+y=0 .\n$$\n\nsubject to the conditions\n\n$$\ny(0)=1, \\quad y^{\\prime}(0)=1 .\n$$\n\n",
        "Solution": " The characteristic polynomial of the given differential equation is $(r-1)^{2}$ so the general solution is\n\n$$\n\\alpha e^{t}+\\beta t e^{t} \\text {. }\n$$\n\nThe initial conditions give $\\alpha=1$, and $\\beta=0$, so the solution is $y(t)=e^{t}$.\n\n",
        "Final Answer": "$y(t) = e^t$"
    },
    "5.8.33": {
        "Topic": "Zeros and Singularities ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Decide, without too much computation, whether a finite limit\n\n$$\n\\lim _{z \\rightarrow 0}\\left((\\tan z)^{-2}-z^{-2}\\right)\n$$\n\nexists, where $z$ is a complex variable, and if yes, compute the limit.\n\n",
        "Solution": " As\n\n$$\n(\\tan z)^{-2}-z^{-2}=\\frac{z^{2}-(\\tan z)^{2}}{z^{2}(\\tan z)^{2}}\n$$\n\nthe Maclaurin expansion of the numerator has no terms of degree up to 3 , whereas the expansion of the denominator starts with $z^{4}$, therefore, the limit is finite.\n\nAs\n\n$$\n\\tan z=z+\\frac{1}{3} z^{3}+o\\left(z^{4}\\right) \\quad(z \\rightarrow 0)\n$$\n\nwe have\n\n$$\n(\\tan z)^{-2}-z^{-2}=\\frac{z^{2}-z^{2}-\\frac{2}{3} z^{4}+o\\left(z^{4}\\right)}{z^{4}+o\\left(z^{4}\\right)} \\quad(z \\rightarrow 0)\n$$\n\nso the limit at 0 is $-2 / 3$.\n\n",
        "Final Answer": "$-\\frac{2}{3}$"
    },
    "5.7.3": {
        "Topic": "Cauchy's Theorem ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let a be a complex number with $|a|<1$. Evaluate the integral\n\n$$\n\\int_{|z|=1} \\frac{|d z|}{|z-a|^{2}}\n$$\n\n",
        "Solution": " We'll apply Cauchy's Integral Formula to $f(z)=1 /(1-\\bar{a} z)$, which is holomorphic on a neighborhood of $|z| \\leqslant 1$. We have\n\n$$\n\\begin{aligned}\n\\int_{|z|=1} \\frac{|d z|}{|z-a|^{2}} &=\\int_{-\\pi}^{\\pi} \\frac{1}{\\left|e^{i \\theta}-a\\right|^{2}} d \\theta \\\\\n&=\\int_{-\\pi}^{\\pi} \\frac{1}{\\left(e^{i \\theta}-a\\right)\\left(e^{-i \\theta}-\\bar{a}\\right)} d \\theta \\\\\n&=\\int_{-\\pi}^{\\pi} \\frac{e^{i \\theta}}{\\left(e^{i \\theta}-a\\right)\\left(1-\\bar{a} e^{i \\theta}\\right)} d \\theta \\\\\n&=\\frac{1}{i} \\int_{|z|=1} \\frac{1}{(z-a)(1-\\bar{a} z)} d z \\\\\n&=\\frac{2 \\pi}{1-|a|^{2}} .\n\\end{aligned}\n$$\n\n",
        "Final Answer": "$$\\frac{2\\pi}{1 - |a|^2}$$"
    },
    "7.6.5": {
        "Topic": "Canonical Forms ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Compute $A^{10}$ for the matrix\n\n$$\nA=\\left(\\begin{array}{rrr}\n3 & 1 & 1 \\\\\n2 & 4 & 2 \\\\\n-1 & -1 & 1\n\\end{array}\\right)\n$$\n\n",
        "Solution": " The characteristic polynomial of the matrix $A$ is $\\chi_{A}(t)=t^{3}-8 t^{2}+20 t-16=(t-4)(t-2)^{2}$ and the minimal polynomial is $\\mu_{A}(t)=(t-2)(t-4)$. By the Euclidean Algorithm [Her75, p. 155], there is a polynomial $p(t)$ and constants $a$ and $b$ such that\n\n$$\nt^{10}=p(t) \\mu_{A}(t)+a t+b .\n$$\n\nSubstituting $t=2$ and $t=4$ and solving for $a$ and $b$ yields $a=2^{9}\\left(2^{10}-1\\right)$ and $b=-2^{11}\\left(2^{9}-1\\right)$. Therefore, since $A$ is a root of its minimal polynomial,\n\n$$\nA^{10}=a A+b I=\\left(\\begin{array}{ccc}\n3 a+b & a & a \\\\\n2 a & 4 a+b & 2 a \\\\\n-a & -a & a+b\n\\end{array}\\right) \\text {. }\n$$\n\nCalculating everything, we have\n$$A^{10} =\n\\left(\\begin{array}{ccc}\n524800 & 523776 & 523776\\\\\n1047552 & 1048576 & 1047552\\\\\n-523776 & -523776 & -522752\n\\end{array}\\right)\n$$\n",
        "Final Answer": "$$\n\\left(\\begin{array}{ccc}\n524800 & 523776 & 523776\\\\\n1047552 & 1048576 & 1047552\\\\\n-523776 & -523776 & -522752\n\\end{array}\\right)\n$$"
    },
    "7.2.17": {
        "Topic": "Rank and Determinants ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $V$ be the vector space of all real $3 \\times 3$ matrices and let $A$ be the diagonal matrix\n\n$$\n\\left(\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 2 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right) .\n$$\n\nCalculate the determinant of the linear transformation $T$ on $V$ defined by $T(X)=\\frac{1}{2}(A X+X A)$\n\n",
        "Solution": " Let $X=\\left(x_{i j}\\right)$ be any element of $M_{3}(\\mathbb{R})$. A calculation gives\n\n$$\nT(X)=\\left(\\begin{array}{ccc}\nx_{11} & 3 x_{12} / 2 & x_{13} \\\\\n3 x_{21} / 2 & 2 x_{22} & 3 x_{23} / 2 \\\\\nx_{31} & 3 x_{32} / 2 & x_{33}\n\\end{array}\\right) .\n$$\n\nIt follows that the basis matrices $M_{i j}$ are eigenvectors of $T$. Taking the product of their associated eigenvalues, we get $\\operatorname{det} T=2(3 / 2)^{4}=81 / 8$.\n\n",
        "Final Answer": "$\\frac{81}{8}$"
    },
    "5.7.15": {
        "Topic": "Cauchy's Theorem ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Define the function $f$ on $\\mathbb{C} \\backslash[0,1]$ by\n\n$$\nf(z)=\\int_{0}^{1} \\frac{\\sqrt{t}}{t-z} d t .\n$$\n\nProve that $f$ is analytic, and find its Laurent series about $\\infty$.\n\n",
        "Solution": " The analyticity of $f$ can be proved with the aid of Morera's Theorem [MH87, p. 173]. If $\\gamma$ is a rectangle contained with its interior in $\\mathbb{C} \\backslash[0,1]$, then\n\n$$\n\\int_{\\gamma} f(z) d z=\\int_{0}^{1}\\left(\\int_{\\gamma} \\frac{\\sqrt{t}}{t-z} d z\\right) d t=0\n$$\n\nby Cauchy's Theorem. Morera's Theorem thus implies that $f$ is analytic. Alternatively, one can argue directly: for $z_{0}$ in $\\mathbb{C} \\backslash[0,1]$\n\n$$\n\\lim _{z \\rightarrow z_{0}} \\frac{f(z)-f\\left(z_{0}\\right)}{z-z_{0}}=\\lim _{z \\rightarrow z_{0}} \\int_{0}^{1} \\frac{\\sqrt{t}}{\\left(t-z_{0}\\right)(t-z)} d t=\\int_{0}^{1} \\frac{\\sqrt{t}}{\\left(t-z_{0}\\right)^{2}} d t,\n$$\n\nwhere the passage to the limit in the integral is justified by the uniform convergence of the integrands.\n\nTo find the Laurent expansion [MH87, p. 246] about $\\infty$ we assume $|z|>1$ and write\n\n$$\n\\begin{aligned}\nf(z) &=-\\frac{1}{z} \\int_{0}^{1} \\frac{\\sqrt{t}}{1-\\frac{t}{z}} d t \\\\\n&=-\\frac{1}{z} \\int_{0}^{\\infty} \\sum_{n=0}^{\\infty} \\frac{t^{n+\\frac{1}{2}}}{z^{n}} d t\n\\end{aligned}\n$$\n\nThe series converges uniformly on $[0,1]$, so we can integrate term by term to get\n\n$$\nf(z)=-\\sum_{n=0}^{\\infty}\\left(\\int_{0}^{1} t^{n+\\frac{1}{2}} d t\\right) z^{-n-1}=-\\sum_{n=0}^{\\infty} \\frac{z^{-n-1}}{n+\\frac{3}{2}} .\n$$\n\n",
        "Final Answer": "$$\nf(z)=-\\sum_{n=0}^{\\infty} \\frac{z^{-n-1}}{n+\\frac{3}{2}} .\n$$\n"
    },
    "7.2.16": {
        "Topic": "Rank and Determinants ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $M_{2 \\times 2}$ be the vector space of all real $2 \\times 2$ matrices. Let\n\n$$\nA=\\left(\\begin{array}{cc}\n1 & 2 \\\\\n-1 & 3\n\\end{array}\\right) \\quad B=\\left(\\begin{array}{cc}\n2 & 1 \\\\\n0 & 4\n\\end{array}\\right)\n$$\n\nand define a linear transformation $L: M_{2 \\times 2} \\rightarrow M_{2 \\times 2}$ by $L(X)=A X B$. Compute the trace and the determinant of $L$.\n\n",
        "Solution": " Identify $M_{2 \\times 2}$ with $\\mathbb{R}^{4}$ via\n\n$$\n\\left(\\begin{array}{ll}\na & b \\\\\nc & d\n\\end{array}\\right) \\leftrightarrow\\left(\\begin{array}{l}\na \\\\\nb \\\\\nc \\\\\nd\n\\end{array}\\right)\n$$\n\nand decompose $L$ into the multiplication of two linear transformations,\n\n$$\nM_{2 \\times 2} \\simeq \\mathbb{R}^{4} \\stackrel{L_{A}}{\\longrightarrow} \\mathbb{R}^{4} \\stackrel{L_{B}}{\\longrightarrow} \\mathbb{R}^{4} \\simeq M_{2 \\times 2}\n$$\n\nwhere $L_{A}(X)=A X$ and $L_{B}(X)=X B$. is\n\nThe matrices of these two linear transformations on the canonical basis of $\\mathbb{R}^{4}$\n\n$$\nL_{A}=\\left(\\begin{array}{rrrr}\n1 & 0 & 2 & 0 \\\\\n0 & 1 & 0 & 2 \\\\\n-1 & 0 & 3 & 0 \\\\\n0 & -1 & 0 & 3\n\\end{array}\\right) \\quad \\text { and } L_{B}=\\left(\\begin{array}{llll}\n2 & 0 & 0 & 0 \\\\\n1 & 4 & 0 & 0 \\\\\n0 & 0 & 2 & 0 \\\\\n0 & 0 & 1 & 4\n\\end{array}\\right)\n$$\n\nthen $\\operatorname{det} L=\\operatorname{det} L_{A} \\cdot \\operatorname{det} L_{B}=(9+6+2(2+3)) \\cdot(2 \\cdot 32)=2^{6} \\cdot 5^{2}$, and to compute the trace of $L$, we only need the diagonal elements of $L_{A} \\cdot L_{B}$, that is,\n\n$$\n\\operatorname{tr} L=2+4+6+12=24 \\text {. }\n$$\n\n",
        "Final Answer": "$24$"
    },
    "7.1.4": {
        "Topic": "Vector Spaces ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\mathrm{F}$ be a finite field of order $q$, and let $V$ be a two dimensional vector space over $\\mathrm{F}$. Find the number of endomorphisms of $V$ that fix at least one nonzero vector.\n\n",
        "Solution": " Suppose $v \\in V$ is nonzero. Let $S_{v}=\\{A \\in$ End $V \\mid A v=v\\}$. Choose $w \\in V$ so that $\\{v, w\\}$ is a basis. With respect to this basis, $S_{v}$ corresponds\n\n![](https://cdn.mathpix.com/cropped/2022_10_26_a807eeb357d0f35abe4eg-034.jpg?height=75&width=1385&top_left_y=770&top_left_x=370)\n\nif $v$ and $v^{\\prime}$ are $F$-multiples of each other, and otherwise $S_{v} \\cap S_{v^{\\prime}}=\\{I\\}$, since if an endomorphism fixes a basis, it is the identity. There are $\\left(q^{2}-1\\right) /(q-1)=$ $q+1$ nonzero vectors in $V$ modulo the action of $F^{*}$, so the total number of endomorphisms fixing some nonzero vector is $(q+1) q^{2}-q$, where the $-q$ is there to avoid counting the identity $q+1$ times. Thus the answer is $q^{3}+q^{2}-q$.\n\n",
        "Final Answer": "$q^{3}+q^{2}-q$"
    },
    "5.6.30": {
        "Topic": "Analytic and Meromorphic Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Determine the group $Aut(\\mathbb{C})$ of all one-to-one analytic maps of $\\mathbb{C}$ onto $\\mathbb{C}$.\n\n",
        "Solution": " Clearly, entire functions of the form $f(z)=a z+b, a, b \\in \\mathbb{C}$ $a \\neq 0$, are one-to-one maps of $\\mathbb{C}$ onto $\\mathbb{C}$. We will show that these are all such maps by considering the kind of singularity such a map $f$ has at $\\infty$. If it has a removable singularity, then it is a bounded entire function, and, by Liouville's Theorem [MH87, p. 170], a constant.\n\nIf it has an essential singularity, then, by the Casorati-Weierstrass Theorem [MH87, p. 256], it gets arbitrarily close to any complex number in any neighborhood of $\\infty$. But if we look at, say, $f(0)$, we know that for some $\\varepsilon$ and $\\delta$, the disc $|z|<\\delta$ is mapped onto $|f(0)-z|<\\varepsilon$ by $f$. Hence, $f$ is not injective.\n\nTherefore, $f$ has a pole at $\\infty$, so is a polynomial. But all polynomials of degree 2 or more have more than one root, so are not injective.\n\n",
        "Final Answer": "$f(z)=a z+b; a, b \\in \\mathbb{C}, a \\neq 0$"
    },
    "2.3.7": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\vec{i}, \\vec{j}$, and $\\vec{k}$ be the usual unit vectors in $\\mathbb{R}^{3}$. Let $\\vec{F}$ denote the vector field\n\n$$\n\\left(x^{2}+y-4\\right) \\vec{\\imath}+3 x y \\vec{\\jmath}+\\left(2 x z+z^{2}\\right) \\vec{k} .\n$$\n\n1. Compute $\\nabla \\times \\vec{F}$ (the curl of $\\vec{F})$.\n\n2. Compute the integral of $\\nabla \\times \\vec{F}$ over the surface $x^{2}+y^{2}+z^{2}=16, z \\geqslant 0$.\n\n",
        "Solution": " 1 . We have\n\n$$\n\\left|\\begin{array}{ccc}\n\\vec{\\imath} & \\vec{\\jmath} & \\vec{k} \\\\\n\\partial / \\partial x & \\partial / \\partial y & \\partial / \\partial z \\\\\nx^{2}+y-4 & 3 x y & 2 x z+z^{2}\n\\end{array}\\right|=-2 z \\vec{\\jmath}+(3 y-1) \\vec{k} \\text {. }\n$$\n\n2. Let $\\mathcal{H}=\\left\\{(x, y, z) \\in \\mathbb{R}^{3} \\mid x^{2}+y^{2}+z^{2}=16, z \\geqslant 0\\right\\}$, and consider the set $\\mathcal{D}$ given by $\\mathcal{D}=\\left\\{(x, y, 0) \\in \\mathbb{R}^{3} \\mid x^{2}+y^{2} \\leqslant 16\\right\\} . \\mathcal{H}$ and $\\mathcal{D}$ have the same boundary, so, by Stokes' Theorem [Rud87, p. 253]\n\n$$\n\\begin{aligned}\n\\int_{\\mathcal{H}}(\\nabla \\times F) \\cdot \\overrightarrow{d S} &=\\int_{\\partial \\mathcal{H}} F \\cdot \\vec{d} l=\\int_{\\partial \\mathcal{D}} F \\cdot \\overrightarrow{d l} \\\\\n&=\\int_{\\partial \\mathcal{D}}(\\nabla F \\times F) \\cdot d S=\\iint_{\\mathcal{D}}(-2 z \\vec{j}+(3 y-1) \\vec{k}) \\cdot \\vec{k} d x d y \\\\\n&=\\iint_{\\mathcal{D}}(3 y-1) d x d y=-16 \\pi .\n\\end{aligned}\n$$\n\n",
        "Final Answer": "$$\\left(-2 z \\vec{\\jmath}+(3 y-1) \\vec{k}, -16\\pi \\right)$$"
    },
    "7.9.27": {
        "Topic": "General Theory of Matrices ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $A$ and $B$ be $n \\times n$ real matrices, and $k$ a positive integer. Find\n\n$$\n\\lim _{t \\rightarrow 0} \\frac{1}{t}\\left((A+t B)^{k}-A^{k}\\right) .\n$$\n",
        "Solution": " Let $A$ and $B$ be $n \\times n$ real matrices and $k$ a positive integer. We have\n\n$$\n(A+t B)^{k}=A^{k}+t \\sum_{i=0}^{k-1} A^{i} B A^{k-1-i}+O\\left(t^{2}\\right) \\quad(t \\rightarrow 0)\n$$\n\nwhere $O\\left(t^{2}\\right)$ is composed of terms with a power of $t$ higher than 1. Hence\n\n$$\n\\lim _{t \\rightarrow 0} \\frac{1}{t}\\left((A+t B)^{k}-A^{k}\\right)=\\sum_{i=0}^{k-1} A^{i} B A^{k-1-i} .\n$$\n",
        "Final Answer": "$$\\sum_{i=0}^{k-1} A^{i} B A^{k-1-i}\n$$\n"
    },
    "2.2.17": {
        "Topic": "Differential Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " For a real $2 \\times 2$ matrix\n\n$$\nX=\\left(\\begin{array}{ll}\nx & y \\\\\nz & t\n\\end{array}\\right),\n$$\n\nlet $\\|X\\|=x^{2}+y^{2}+z^{2}+t^{2}$, and define a metric by $d(X, Y)=\\|X-Y\\|$. Let $\\Sigma=\\{X \\mid \\operatorname{det}(X)=0\\}$. Let\n\n$$\nA=\\left(\\begin{array}{ll}\n1 & 0 \\\\\n0 & 2\n\\end{array}\\right) \\text {. }\n$$\n\nFind the minimum distance from $A$ to $\\Sigma$.",
        "Solution": "For $X \\in \\Sigma$, we have\n\n$$\n\\begin{aligned}\n\\|A-X\\|^{2} &=(1-x)^{2}+y^{2}+z^{2}+(2-t)^{2} \\\\\n&=y^{2}+z^{2}+1-2 x+x^{2}+(2-t)^{2} \\\\\n& \\geqslant \\pm 2 y z+1-2 x+2|x|(2-t) \\\\\n&=4|x|-2 x+2(\\pm y z-|x| t)+1\n\\end{aligned}\n$$\n\nWe can choose the sign, so $\\pm y z-|x| t=0$ because $\\operatorname{det} X=0$. As $4|x|-2 x \\geqslant 0$, we have $\\|A-X\\| \\geqslant 1$ with equality when $4|x|-2 x=0,|x|=2-t, y=\\pm z$,\n\n![](https://cdn.mathpix.com/cropped/2022_10_26_8d6ad07375e689af3a1cg-089.jpg?height=79&width=846&top_left_y=313&top_left_x=366)\n\n",
        "Final Answer": "$1$"
    },
    "7.6.6": {
        "Topic": "Canonical Forms ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Calculate $A^{100}$ and $A^{-7}$, where\n\n$$\nA=\\left(\\begin{array}{cc}\n3 / 2 & 1 / 2 \\\\\n-1 / 2 & 1 / 2\n\\end{array}\\right) .\n$$\n\n",
        "Solution": " The characteristic polynomial of $A$ is $\\chi_{A}(t)=t^{2}-2 t+1=$ $(t-1)^{2}$. By the Euclidean Algorithm [Her75, p. 155], there is a polynomial $q(t)$ and constants $a$ and $b$ such that $t^{100}=q(t)(t-1)^{2}+a t+b$. Differentiating both sides of this equation, we get $100 t^{99}=q^{\\prime}(t)(t-1)^{2}+2 q(t)(t-1)+a$. Substituting $t=1$ into each equation and solving for $a$ and $b$, we get $a=100$ and $b=-99$. Therefore, since $A$ satisfies its characteristic equation, substituting it into the first equation yields $A^{100}=100 A-991$, or\n\n$$\nA^{100}=\\left(\\begin{array}{cc}\n51 & 50 \\\\\n-50 & -49\n\\end{array}\\right) \\text {. }\n$$\n\nAn identical calculation shows that $A^{7}=7 A-6 I$, so\n\n$$\nA^{7}=\\left(\\begin{array}{cc}\n9 / 2 & 7 / 2 \\\\\n-7 / 2 & -5 / 2\n\\end{array}\\right) \\text {. }\n$$\n\nFrom this it follows immediately that\n\n$$\nA^{-7}=\\left(\\begin{array}{rr}\n-5 / 2 & -7 / 2 \\\\\n7 / 2 & 9 / 2\n\\end{array}\\right) .\n$$\n\n",
        "Final Answer": "$$\n(A^{100}, A^{-7}) = \\left( \\left(\\begin{array}{cc}\n51 & 50 \\\\\n-50 & -49\n\\end{array}\\right), \\left(\\begin{array}{rr}\n-5 / 2 & -7 / 2 \\\\\n7 / 2 & 9 / 2\n\\end{array}\\right) \\right)\n$$"
    },
    "7.8.4": {
        "Topic": "Bilinear, Quadratic Forms, and Inner Product Spaces ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $\\mathbb{R}^{3}$ be three-dimensional space with the usual inner product, and $(a, b, c) \\in \\mathbb{R}^{3}$ a vector of length $1$. Let $W$ be the plane defined by $a x+b y+c z=0$. Find, in the standard basis, the matrix representing the orthogonal projection of $\\mathbb{R}^{3}$ onto $W$.\n\n",
        "Solution": " Every vector in $W$ is orthogonal to $v=(a, b, c)$. Let $Q$ be the orthogonal projection of $\\mathbb{R}^{3}$ onto the space spanned by $v$, identified with its matrix. The columns of $Q$ are $Q e_{j}, 1 \\leqslant j \\leqslant 3$, where the $e_{j}$ 's are the standard basis vectors in $\\mathbb{R}^{3}$. But\n\n$$\n\\begin{aligned}\n&Q e_{1}=\\left\\langle v, e_{1}\\right\\rangle v=\\left(a^{2}, a b, a c\\right) \\\\\n&Q e_{2}=\\left\\langle v, e_{2}\\right\\rangle v=\\left(a b, b^{2}, b c\\right) \\\\\n&Q e_{3}=\\left\\langle v, e_{3}\\right\\rangle v=\\left(a c, b c, c^{2}\\right) .\n\\end{aligned}\n$$\n\nTherefore, the orthogonal projection onto $W$ is given by\n\n$$\nP=I-Q=\\left(\\begin{array}{ccc}\n1-a^{2} & -a b & -a c \\\\\n-a b & 1-b^{2} & -b c \\\\\n-a c & -b c & 1-c^{2}\n\\end{array}\\right) \\text {. }\n$$\n\n",
        "Final Answer": "$$\n\\left(\\begin{array}{ccc}\n1-a^{2} & -a b & -a c \\\\\n-a b & 1-b^{2} & -b c \\\\\n-a c & -b c & 1-c^{2}\n\\end{array}\\right)\n$$"
    },
    "3.4.2": {
        "Topic": "Systems of Differential Equations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find all pairs of $C^{\\infty}$ functions $x(t)$ and $y(t)$ on $\\mathbb{R}$ satisfying\n\n$$\nx^{\\prime}(t)=2 x(t)-y(t), \\quad y^{\\prime}(t)=x(t) .\n$$\n\n",
        "Solution": " Rewritting the system as a liner homogeneous system of equations we have\n\n$$\n\\left(\\begin{array}{c}\nx^{\\prime}(t) \\\\\ny^{\\prime}(t)\n\\end{array}\\right)=\\left(\\begin{array}{cc}\n2 & -1 \\\\\n1 & 0\n\\end{array}\\right)\\left(\\begin{array}{l}\nx(t) \\\\\ny(t)\n\\end{array}\\right)\n$$\n\nso the solutions are of the form\n\n$$\n\\left(\\begin{array}{l}\nx(t) \\\\\ny(t)\n\\end{array}\\right)=e^{A t}\\left(\\begin{array}{l}\nc_{1} \\\\\nc_{2}\n\\end{array}\\right)\n$$\n\nBy the Cayley-Hamilton Theorem [HK61, p. 194], the computation of the exponential of a matrix reduces to a finite sum of terms, in this case two,\n\n$$\ne^{A t}=\\alpha_{1} A t+\\alpha_{0} I\n$$\n\nwhere the $\\alpha_{i}(t)$ are functions of $t$ depending on the matrix $A$. Furthermore, if $r(\\lambda)=\\alpha_{1} \\lambda+\\alpha_{0}$, then for each eigenvalue $\\lambda_{i}$ of $A, r\\left(\\lambda_{i}\\right)=e^{\\lambda_{i}}$ and for each one with multiplicity two\n\n$$\ne^{\\lambda_{i}}=\\left.\\frac{d}{d \\lambda} r(\\lambda)\\right|_{\\lambda=\\lambda_{i}}\n$$\n\nwhich is a way to compute the values of $\\alpha_{0}$ and $\\alpha_{1}$, and then the exponential $e^{A t}$. More generally, if $e^{A t}$ can be computed with the polynomial\n\n$$\ne^{A t}=\\alpha_{n-1} A^{n-1} t^{n-1}+\\alpha_{n-2} A^{n-2} t^{n-2}+\\cdots+\\alpha_{1} A t+\\alpha_{0} I\n$$\n\nthen if we consider the polynomial\n\n$$\nr(\\lambda)=\\alpha_{n-1} \\lambda^{n-1}+\\alpha_{n-2} \\lambda^{n-2}+\\cdots+\\alpha_{1} \\lambda+\\alpha_{0}\n$$\n\nfor each eigenvalue $\\lambda_{i}$ of $A t$\n\n$$\ne^{\\lambda_{i}}=r\\left(\\lambda_{i}\\right)\n$$\n\nand furthermore, if the multiplicity of $\\lambda_{i}$ is $k>1$, the each of the equations is also valid:\n\n$$\ne^{\\lambda_{i}}=\\left.\\frac{d^{j}}{d \\lambda^{j}} r(\\lambda)\\right|_{\\lambda=\\lambda_{i}} \\quad \\text { for } \\quad 1 \\leqslant j \\leqslant k-1 .\n$$\n\nFor more details on this and other interesting ways to compute the exponential of a matrix see [MVL78], specially Section 5, and the references cited there.\n\nThe characteristic polynomial of $A t$ is\n\n$$\n\\chi_{A t}(\\lambda)=\\lambda^{2}-(2 t) \\lambda+t^{2}\n$$\n\nso the eigenvalues are $\\lambda_{1}=\\lambda_{2}=t$, and using the above formulas for the computation of $\\alpha_{i}$, we get\n\n$$\n\\begin{aligned}\nr(\\lambda) &=\\alpha_{1} \\lambda+\\alpha_{0} \\\\\n\\frac{d r(\\lambda)}{d \\lambda} &=\\alpha_{1}\n\\end{aligned}\n$$\n\nand we end up with the system\n\n$$\n\\begin{aligned}\ne^{t} &=t \\alpha_{1}+\\alpha_{0} \\\\\ne^{t} &=\\alpha_{1}\n\\end{aligned}\n$$\n\nTherefore the solutions are $\\alpha_{1}=e^{t}$ and $\\alpha_{0}=e^{t}(1-t)$ so the exponential is\n\n$$\ne^{A t}=e^{t}\\left(\\begin{array}{cc}\n1+t & -t \\\\\nt & 1-t\n\\end{array}\\right)\n$$\n\nThe solutions are then\n\n$$\n\\left(\\begin{array}{l}\nx(t) \\\\\ny(t)\n\\end{array}\\right)=e^{t}\\left(\\begin{array}{cc}\n1+t & -t \\\\\nt & 1-t\n\\end{array}\\right)\\left(\\begin{array}{l}\nc_{1} \\\\\nc_{2}\n\\end{array}\\right)\n$$\n\nthat is,\n\n$$\n\\begin{aligned}\n&x(t)=e^{t}\\left(k_{1}+k_{2} t\\right) \\\\\n&y(t)=e^{t}\\left(k_{1}-k_{2}+k_{2} t\\right)\n\\end{aligned}\n$$\n\n",
        "Final Answer": "$$\n\\begin{aligned}\n&x(t)=e^{t}\\left(k_{1}+k_{2} t\\right) \\\\\n&y(t)=e^{t}\\left(k_{1}-k_{2}+k_{2} t\\right) \\\\\n&k_1, k_2 \\in \\mathbb{R}\n\\end{aligned}\n$$"
    },
    "2.2.7": {
        "Topic": "Differential Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the most general continuously differentiable function $g: \\mathbb{R} \\rightarrow(0, \\infty)$ such that the function $h(x, y)=g(x) g(y)$ on $\\mathbb{R}^{2}$ is constant on each circle with center $(0,0)$.\n\n",
        "Solution": " We have\n\n$$\n\\nabla h(x, y)=\\left(g^{\\prime}(x) g(y), g^{\\prime}(y) g(x)\\right)\n$$\n\nFor the desired condition to hold, $\\nabla h(x, y)$ must be a scalar multiple of $(x, y)$, at least for $(x, y) \\neq(0,0)$. Thus,\n\n$$\n\\frac{g^{\\prime}(x) g(y)}{x}=\\frac{g^{\\prime}(y) g(x)}{y},\n$$\n\nassuming $x y \\neq 0$. This can be written as\n\n$$\n\\frac{g^{\\prime}(x)}{x g(x)}=\\frac{g^{\\prime}(y)}{y g(y)}\n$$\n\nwhich implies that $\\frac{g^{\\prime}(x)}{x g(x)}=A=$ constant. The preceding differential equation for $g$ has the general solution\n\n$$\ng(x)=B e^{A x^{2} / 2}\n$$\n\nwith $B$ a constant, positive because $g$ is positive by assumption. Every such $g$ obviously has the required property.\n\n",
        "Final Answer": "$$\ng(x)=B e^{A x^{2} / 2}, B > 0, A \\in \\mathbb{R} \n$$"
    },
    "2.3.3": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Given the fact that $\\int_{-\\infty}^{\\infty} e^{-x^{2}} d x=\\sqrt{\\pi}$, evaluate the integral\n\n$$\nI=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\left(x^{2}+(y-x)^{2}+y^{2}\\right)} d x d y .\n$$",
        "Solution": " We write\n\n$$\n\\begin{aligned}\nI &=\\int_{-\\infty}^{\\infty} e^{-3 y^{2} / 2}\\left(\\int_{-\\infty}^{\\infty} e^{-2 x^{2}+2 x y-y^{2} / 2} d x\\right) d y \\\\\n&=\\int_{-\\infty}^{\\infty} e^{-3 y^{2} / 2}\\left(\\int_{-\\infty}^{\\infty} e^{-2\\left(x-\\frac{y}{2}\\right)^{2}} d x\\right) d y\n\\end{aligned}\n$$\n\nmaking the substitution $t=\\sqrt{2}\\left(x-\\frac{y}{2}\\right), d t=\\sqrt{2} d x$ on the inner integral, we get\n\n$$\n\\begin{aligned}\nI &=\\frac{1}{\\sqrt{2}} \\int_{-\\infty}^{\\infty} e^{-3 y^{2} / 2}\\left(\\int_{-\\infty}^{\\infty} e^{-t^{2}} d t\\right) d y \\\\\n&=\\sqrt{\\frac{\\pi}{2}} \\int_{-\\infty}^{\\infty} e^{-3 y^{2} / 2} d y\n\\end{aligned}\n$$\n\nnow making the substitution: $s=\\sqrt{\\frac{3}{2}} y, d s=\\sqrt{\\frac{3}{2}} d y$ we obtain\n\n$$\n\\begin{aligned}\nI &=\\sqrt{\\frac{\\pi}{3}} \\int_{-\\infty}^{\\infty} e^{-s^{2}} d s \\\\\n&=\\frac{\\pi}{\\sqrt{3}} .\n\\end{aligned}\n$$\n\n",
        "Final Answer": "$$\\frac{\\pi}{\\sqrt{3}}$$"
    },
    "2.2.19": {
        "Topic": "Differential Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $P_{2}$ denote the set of real polynomials of degree $\\leqslant 2$. Define the map $J: P_{2} \\rightarrow \\mathbb{R}$ by\n\n$$\nJ(f)=\\int_{0}^{1} f(x)^{2} d x .\n$$\n\nLet $Q=\\left\\{f \\in P_{2} \\mid f(1)=1\\right\\}$. Find the polynomial in $Q$ where $J$ attains its minimum value.\n\n",
        "Solution": " Each element of $P_{2}$ has the form $a x^{2}+b x+c$ for $(a, b, c) \\in$ $\\mathbb{R}^{3}$, so we can identify $P_{2}$ with $\\mathbb{R}^{3}$ and $J$ becomes a scalar field on $\\mathbb{R}^{3}$ :\n\n$$\nJ(a, b, c)=\\int_{0}^{1}\\left(a x^{2}+b x+c\\right)^{2} d x=\\frac{a^{2}}{5}+\\frac{a b}{2}+\\frac{2 a c}{3}+\\frac{b^{2}}{3}+b c+c^{2} .\n$$\n\nTo $Q$ corresponds the set $\\{(a, b, c) \\mid a+b+c=1\\}$. If $J$ achieves a minimum value on $Q$, then, by the Method of Lagrange Multipliers [MH93, p. 414], we know that there is a constant $\\lambda$ with $\\nabla J=\\lambda \\nabla g$, where $g(a, b, c)=a+b+c-1$. We have\n\n$$\n\\nabla J=\\left(\\frac{2 a}{5}+\\frac{b}{2}+\\frac{2 c}{3}, \\frac{a}{2}+\\frac{2 b}{3}+c, \\frac{2 a}{3}+b+2 c\\right)\n$$\n\nand $\\nabla g=(1,1,1)$. These and the constraint equation $g(a, b, c)=0$ form the system\n\n$$\n\\left(\\begin{array}{cccc}\n2 / 5 & 1 / 2 & 2 / 3 & -1 \\\\\n1 / 2 & 2 / 3 & 1 & -1 \\\\\n2 / 3 & 1 & 2 & -1 \\\\\n1 & 1 & 1 & 0\n\\end{array}\\right)\\left(\\begin{array}{l}\na \\\\\nb \\\\\nc \\\\\n\\lambda\n\\end{array}\\right)=\\left(\\begin{array}{c}\n0 \\\\\n0 \\\\\n0 \\\\\n1\n\\end{array}\\right)\n$$\n\nwhich has the unique solution $\\lambda=2 / 9,(a, b, c)=(10 / 3,-8 / 3,1 / 3)$. Therefore, if $J$ attains a minimum, it must do so at this point. To see that $J$ does attain a minimum, parameterize the plane $Q$ with the $x y$ coordinates and consider the quadratic surface with a linear $z$ term defined by $z=J(x, y, 1-x-y)$ in $\\mathbb{R}^{3}$. The surface is the graph of the map $J: P_{2} \\rightarrow \\mathbb{R}$. Rotating around the $z$-axis will eliminate the $x y$ cross-terms in the equation, reducing it to the standard equation of either an elliptic paraboloid or a hyperbolic paraboloid. However, $J$ is always nonnegative, so the surface must be an elliptic paraboloid and, as such, has a minimum.\n\n",
        "Final Answer": "$$ \\frac{10}{3}x^2 - \\frac{8}{3}x + \\frac13$$"
    },
    "5.2.2": {
        "Topic": "Series and Sequences of Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Suppose the coefficients of the power series\n\n$$\n\\sum_{n=0}^{\\infty} a_{n} z^{n}\n$$\n\nare given by the recurrence relation\n\n$$\na_{0}=1, a_{1}=-1,3 a_{n}+4 a_{n-1}-a_{n-2}=0, n=2,3, \\ldots .\n$$\n\nFind the radius of convergence $r$ of the series and the function $f$ to which it converges in its disc of convergence.\n\n",
        "Solution": " From the recurrence relation, we see that the coefficients $a_{n}$ grow, at most, at an exponential rate, so the series has a positive radius of convergence. Let $f$ be the function it represents in its disc of convergence, and consider the polynomial $p(z)=3+4 z-z^{2}$. We have\n\n$$\n\\begin{aligned}\np(z) f(z) &=\\left(3+4 z-z^{2}\\right) \\sum_{n=0}^{\\infty} a_{n} z^{n} \\\\\n&=3 a_{0}+\\left(3 a_{1}+4 a_{0}\\right) z+\\sum_{n=0}^{\\infty}\\left(3 a_{n}+4 a_{n-1}-a_{n-2}\\right) z^{n} \\\\\n&=3+z\n\\end{aligned}\n$$\n\nSo\n\n$$\nf(z)=\\frac{3+z}{3+4 z-z^{2}} .\n$$\n\nThe radius of convergence of the series is the distance from 0 to the closest singularity of $f$, which is the closest root of $p$. The roots of $p$ are $2 \\pm \\sqrt{7}$. Hence, the radius of convergence is $\\sqrt{7}-2$.\n\n",
        "Final Answer": "$$(r, f(z)) = \\left( \\sqrt{7}-2, \\frac{3+z}{3+4z-z^2} \\right) $$"
    },
    "5.2.11": {
        "Topic": "Series and Sequences of Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Determine the set $S$ of complex numbers z for which the power series\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{z^{n}}{n^{\\log n}}\n$$\n\nand its term by term derivatives of all orders converge absolutely.",
        "Solution": " Let $R$ denote the radius of convergence of this power series.\n\n$$\nR=\\underset{n}{\\limsup _{n}\\left|n^{\\log n}\\right|^{1 / n}}=\\limsup _{n} e^{(\\log n)^{2} / n}=e^{0}=1 .\n$$\n\nThe series and all term by term derivatives converge absolutely on $|z|<1$ and diverge for $|z|>1$. Let $|z|=1$. For $k \\geqslant 0$ the $k^{t h}$ derivative of the power series is\n\n$$\n\\sum_{n=k}^{\\infty} n(n-1) \\cdots(n-k+1) \\frac{z^{n-k}}{n^{\\log n}} .\n$$\n\nTo see that this converges absolutely, note that\n\n$$\n\\sum_{n=k}^{\\infty} n(n-1) \\cdots(n-k+1) \\frac{1}{n^{\\log n}} \\leqslant \\sum_{n=k}^{\\infty} \\frac{1}{n^{\\log n-k}} .\n$$\n\nSince, for $n$ sufficiently large, $\\log n-k>2$, and $\\sum 1 / n^{2}$ converges, by the Comparison Test [Rud87, p. 60] it follows that the power series converges absolutely on the circle $|z|=1$.\n\n",
        "Final Answer": "$$ S = \\{ z : |z| = 1 \\}$$"
    },
    "5.9.1": {
        "Topic": "Harmonic Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $u: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$ be the function defined by $u(x, y)=x^{3}-3 x y^{2}$. Show that $u$ is harmonic and find $v: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$ such that the function $f: \\mathbb{C} \\rightarrow \\mathbb{C}$ defined by\n\n$$\nf(x+i y)=u(x, y)+i v(x, y)\n$$\n\nis analytic. As there are multiple possible $v$, find the solution with $v(0, 0) = 0$.",
        "Solution": " Derivating twice, we can see that\n\n$$\n\\frac{\\partial^{2} u}{\\partial x^{2}}=6 x=-\\frac{\\partial^{2} u}{\\partial y^{2}},\n$$\n\nso $\\Delta u=0$. The function $f$ is then given by (see [Car63b, pp. 126-127])\n\n$$\nf(z)=2 u\\left(\\frac{z}{2}, \\frac{z}{2 i}\\right)=2\\left(\\frac{z^{3}}{8}-3 \\frac{z}{2} \\frac{z^{2}}{(-4)}\\right)=z^{3} .\n$$\n\nso, up to a constant, $v(x, y)=3 x^{2} y-y^{3}+k$.\n\n",
        "Final Answer": "$$ v(x, y) = 3x^2y - y^3 $$"
    },
    "1.3.2": {
        "Topic": "Sequences, Series, and Products ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Compute\n\n$$\nL=\\lim _{n \\rightarrow \\infty}\\left(\\frac{n^{n}}{n !}\\right)^{1 / n} .\n$$\n\n",
        "Solution": " Let $p_{1}=1, p_{2}=(2 / 1)^{2}, p_{3}=(3 / 2)^{3}, \\ldots, p_{n}=(n /(n-1))^{n}$. Then\n\n$$\n\\frac{p_{1} p_{2} \\cdots p_{n}}{n}=\\frac{n^{n}}{n !},\n$$\n\nand since $p_{n} \\rightarrow e$, we have $\\lim \\left(n^{n} / n !\\right)^{1 / n}=e$ as well (using the fact that $\\left.\\lim n^{1 / n}=1\\right)$.\n\n",
        "Final Answer": "$e$"
    },
    "1.7.2": {
        "Topic": "Fourier Series ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ be the function of period $2 \\pi$ such that $f(x)=x^{3}$ for $-\\pi \\leqslant x<\\pi$.\n\nProve that the Fourier series for $f$ has the form $\\sum_{1}^{\\infty} b_{n} \\sin n x$ and write an\nintegral formula for $b_{n}$ (do not evaluate it). \n\nFind\n$$\n\\sum_{n=1}^{\\infty} b_{n}^{2}\n$$\n\n",
        "Solution": " 1 . Since $f(x)$ is an odd function, the integrals\n\n$$\n\\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x) \\cos n x d x\n$$\n\nvanish for $n \\in \\mathbb{N}$. The Fourier series has only terms in $\\sin n x$ given by\n\n$$\nb_{n}=\\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} x^{3} \\sin n x d x .\n$$\n\n2. As $f$ and $f^{\\prime}$ are sectionally continuous, we have\n\n$$\n\\sum_{n=1}^{\\infty} b_{n} \\sin n x=\\frac{f(x-)+f(x+)}{2}= \\begin{cases}f(x) & \\text { if } x \\neq(2 n+1) \\pi \\\\ 0 & \\text { if } x=(2 n+1) \\pi\\end{cases}\n$$\n\nwhere $n \\in \\mathbb{Z}$.\n\n3. Using Parseval's Identity [MH93, p. 577]\n\n$$\n\\frac{1}{2} a_{0}^{2}+\\sum_{n=1}^{\\infty}\\left(a_{n}^{2}+b_{n}^{2}\\right)=\\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f^{2}(x) d x\n$$\n\nand the fact that all $a_{n}=0$,\n\n$$\n\\sum_{n=1}^{\\infty} b^{2}=\\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} x^{6} d x=\\frac{2}{7} \\pi^{6} .\n$$\n\n",
        "Final Answer": "$$ \\frac{2 \\pi^{6}}{7} $$"
    },
    "5.2.15": {
        "Topic": "Series and Sequences of Functions ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Find the radius of convergence $R$ of the Taylor series about $z=1$ of the function $f(z)=1 /\\left(1+z^{2}+z^{4}+z^{6}+z^{8}+z^{10}\\right)$. Express the answer in terms of real numbers and square roots only.\n\n",
        "Solution": " The rational function\n\n$$\nf(z)=\\frac{1-z^{2}}{1-z^{12}}\n$$\n\nhas poles at all nonreal twelfth roots of unity (the singularities at $z^{2}=1$ are removable). Thus, the radius of convergence is the distance from 1 to the nearest singularity:\n\n$$\nR=|\\exp (\\pi i / 6)-1|=\\sqrt{(\\cos (\\pi / 6)-1)^{2}+\\sin ^{2}(\\pi / 6)}=\\sqrt{2-\\sqrt{3}} .\n$$\n\n",
        "Final Answer": "$$ \\sqrt{2-\\sqrt{3}} $$"
    },
    "3.3.1": {
        "Topic": "Higher Order Equations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $E$ be the set of functions $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ which are solutions to the differential equation $f^{\\prime \\prime \\prime}+f^{\\prime \\prime}-2 f=0$. Then $E$ is a vector space. \n\nLet $E_{0} \\subset E$ be the subspace of solutions $g$ such that $\\lim _{t \\rightarrow \\infty} g(t)=0$. Find $g \\in E_{0}$ such that $g(0)=0$ and $g^{\\prime}(0)=2$.\n\n",
        "Solution": " 1 . Since the differential equation is linear homogeneous with constant coefficients we can build its characteristic equation, which is,\n\n$$\n\\lambda^{3}+\\lambda^{2}-2=0 .\n$$\n\nBy inspection we can easily see that 1 is one of the roots, factoring as\n\n$$\n(\\lambda-1)\\left(\\lambda^{2}+2 \\lambda+2\\right)=0\n$$\n\nso the roots are 1 and $-1 \\pm i$, and the solution to the differential equation has the form\n\n$$\nf(x)=c_{1} e^{x}+c_{2} e^{-x} \\cos x+c_{3} e^{-x} \\sin x\n$$\n\nso the space of solutions has dimension 3.\n\n2. $E_{0}$ is the two-dimensional subspace defined by $c_{1}=0$, that is, the function $g(t)=c_{2} e^{-t} \\cos t+c_{3} e^{-t} \\sin t$, and after the substitution for the initial condition we see that $c_{2}=0$ and $c_{3}=2$, so\n\n$$\ng(t)=2 e^{-t} \\sin t .\n$$\n\n",
        "Final Answer": "$$\ng(t)=2 e^{-t} \\sin t\n$$"
    },
    "2.3.2": {
        "Topic": "Integral Calculus ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Evaluate\n\n$$\n\\iint_{\\mathcal{A}} e^{-x^{2}-y^{2}} d x d y,\n$$\n\nwhere $\\mathcal{A}=\\left\\{(x, y) \\in \\mathbb{R}^{2} \\mid x^{2}+y^{2} \\leqslant 1\\right\\}$.\n\n",
        "Solution": " Using polar coordinates, we have\n\n$$\n\\begin{aligned}\n\\iint_{\\mathcal{A}} e^{-x^{2}-y^{2}} d x d y &=\\int_{0}^{2 \\pi} \\int_{0}^{1} \\rho e^{-\\rho^{2}} d \\rho d \\theta \\\\\n&=-\\frac{1}{2} \\int_{0}^{2 \\pi} \\int_{0}^{1}-2 \\rho e^{-\\rho^{2}} d \\rho d \\theta \\\\\n&=-\\frac{1}{2} \\int_{0}^{2 \\pi}\\left(e^{-1}-1\\right) \\\\\n&=\\pi\\left(e^{-1}-1\\right) .\n\\end{aligned}\n$$\n\n",
        "Final Answer": "$$ \\pi\\left(e^{-1}-1\\right) $$"
    },
    "7.5.22": {
        "Topic": "Eigenvalues and Eigenvectors ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Let $A$ be the $n \\times n$ matrix which has zeros on the main diagonal and ones everywhere else. Compute $\\operatorname{det}(A)$.\n\n",
        "Solution": "\n$$\nA=u u^{t}-I \\quad \\text { where } \\quad u=\\left(\\begin{array}{c}\n1 \\\\\n\\vdots \\\\\n1\n\\end{array}\\right)\n$$\n\nand $I$ is the identity matrix. If $A x=\\lambda x$, where $x \\neq 0$, then\n\n$$\nu u^{t} x-x=\\left(u^{t} x\\right) u-x=\\lambda x\n$$\n\nso $x$ is either perpendicular or parallel to $u$. In the latter case, we can suppose without loss of generality that $x=u$, so $u^{t} u u-u=\\lambda u$ and $\\lambda=n-1$. This gives a 1-dimensional eigenspace spanned by $u$ with eigenvalue $n-1$. In the former case $x$ lies in a $(n-1)$-dimensional eigenspace which is the null space of the rank one matrix $u u^{t}$, so\n\n$$\nA x=\\left(u u^{t}-I\\right) x=-I x=-x\n$$\n\nand the eigenvalue associated with this eigenspace is $-1$, with multiplicity $n-1$. Since the determinant is the product of the eigenvalues, we have $\\operatorname{det}(A)=(-1)^{n-1}(n-1)$.\n\n",
        "Final Answer": "$(-1)^{n-1}(n-1)$"
    },
    "3.2.7": {
        "Topic": "Second Order Equations ",
        "Book": "Berkeley Problems in Mathematics",
        "Problem Statement": " Determine all real numbers $L>1$ so that the boundary value problem\n\n$$\n\\begin{gathered}\nx^{2} y^{\\prime \\prime}(x)+y(x)=0, \\quad 1 \\leqslant x \\leqslant L \\\\\ny(1)=y(L)=0\n\\end{gathered}\n$$\n\nhas a nonzero solution. ",
        "Solution": " Substituting $y(x)=x^{a}$ gives the quadratic equation $a(a-1)+1=0$. The two roots are\n\n$$\n\\frac{1}{2} \\pm \\frac{\\sqrt{3} i}{2},\n$$\n\nso the general solution is\n\n$$\ny(x)=A \\sqrt{x} \\cos \\left(\\frac{\\sqrt{3}}{2} \\log x\\right)+B \\sqrt{x} \\cos \\left(\\frac{\\sqrt{3}}{2} \\log x\\right) .\n$$\n\nThe boundary condition $y(1)=0$ implies $A=0$ and then the boundary condition $y(L)=0$ can be satisfied for nonzero $B$ only if\n\n$$\n\\sin \\left(\\frac{\\sqrt{3}}{2} \\log L\\right)=0 .\n$$\n\n\\section{Equivalently,}\n\n$$\nL=e^{2 n \\pi / \\sqrt{3}}\n$$\n\nwhere $n$ is any positive integer.\n\n",
        "Final Answer": "$$\nL=e^{2 n \\pi / \\sqrt{3}}, n \\in \\mathbb{N}\n$$"
    }
}