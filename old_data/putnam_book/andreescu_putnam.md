\title{
PUTNAM and
}

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-001.jpg?height=47&width=77&top_left_y=181&top_left_x=122)

BEYOND
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-001.jpg?height=150&width=402&top_left_y=214&top_left_x=92)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-001.jpg?height=46&width=65&top_left_y=354&top_left_x=129)
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-001.jpg?height=342&width=462&top_left_y=314&top_left_x=97)

\section{Răzvan Gelca} Titu Andreescu

\section{Springer}



\section{Putnam and Beyond}



\section{Răzvan Gelca Titu Andreescu}

\section{Putnam and Beyond}

\section{(p) Springer}

Răzvan Gelca

Texas Tech University

Department of Mathematics and Statistics

MA 229

Lubbock, TX 79409

USA

rgelca@gmail.com Titu Andreescu

University of Texas at Dallas

School of Natural Sciences and Mathematics

2601 North Floyd Road

Richardson, TX 75080

USA

titu.andreescu@utdallas.edu

Cover design by Mary Burgess.

Library of Congress Control Number: 2007923582

ISBN-13: 978-0-387-25765-5 e-ISBN-13: 978-0-387-68445-1

Printed on acid-free paper.

(c)2007 Springer Science+Business Media, LLC

All rights reserved. This work may not be translated or copied in whole or in part without the written permission of the publisher (Springer Science+Business Media LLC, 233 Spring Street, New York, NY 10013, USA) and the author, except for brief excerpts in connection with reviews or scholarly analysis. Use in connection with any form of information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed is forbidden.

The use in this publication of trade names, trademarks, service marks and similar terms, even if they are not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.

$\begin{array}{llllllll}9 & 8 & 6 & 5 & 4 & 3 & 2 & 1\end{array}$ Life is good for only two things, discovering mathematics and teaching mathematics.

Siméon Poisson 

\section{Contents}

Preface $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

A Study Guide $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

1 Methods of Proof $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$1.1$ Argument by Contradiction $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$1.2$ Mathematical Induction $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$1.3$ The Pigeonhole Principle $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-006.jpg?height=47&width=1267&top_left_y=1273&top_left_x=270)

$1.5$ Invariants and Semi-Invariants $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2 Algebra $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.1$ Identities and Inequalities $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-006.jpg?height=52&width=1195&top_left_y=1501&top_left_x=342)

$2.1 .2 \quad x^{2} \geq 0 \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.1.3 The Cauchy-Schwarz Inequality $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.1.4 The Triangle Inequality $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.1.5 The Arithmetic Mean-Geometric Mean Inequality $\ldots \ldots \ldots \ldots$. . . 39

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-006.jpg?height=49&width=1195&top_left_y=1742&top_left_x=342)

$2.1 .7$ Other Inequalities $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.2$ Polynomials $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.2 .1$ A Warmup $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.2.2 Viète's Relations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-006.jpg?height=52&width=1195&top_left_y=1980&top_left_x=342)

2.2.4 The Location of the Zeros of a Polynomial $\ldots \ldots \ldots$

2.2.5 Irreducible Polynomials $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.2.6 Chebyshev Polynomials $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$ viii Contents

$2.3$ Linear Algebra $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.3.1 Operations with Matrices $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.3.2 Determinants $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=52&width=1195&top_left_y=399&top_left_x=342)

2.3.4 Systems of Linear Equations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

2.3.5 Vector Spaces, Linear Combinations of Vectors, Bases $\ldots \ldots 77$

2.3.6 Linear Transformations, Eigenvalues, Eigenvectors . . . . . . . . 79

2.3.7 The Cayley-Hamilton and Perron-Frobenius Theorems $\ldots \ldots \ldots$

$2.4$ Abstract Algebra $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.4 .1 \quad$ Binary Operations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.4 .2$ Groups $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$2.4 .3$ Rings $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3 Real Analysis $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.1 Sequences and Series $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=48&width=1197&top_left_y=970&top_left_x=343)

3.1.2 Linear Recursive Sequences $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=52&width=1197&top_left_y=1063&top_left_x=343)

3.1.4 More About Limits of Sequences $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=49&width=1195&top_left_y=1159&top_left_x=342)

3.1.6 Telescopic Series and Products $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=50&width=1269&top_left_y=1258&top_left_x=269)

3.2.1 Limits of Functions $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.2.2 Continuous Functions $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.2.3 The Intermediate Value Property . . . . . . . . . . . . . . . . . . . 131

3.2.4 Derivatives and Their Applications . . . . . . . . . . . . . . . . . . . 134

3.2.5 The Mean Value Theorem $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.2.6 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 142

3.2.7 Indefinite Integrals $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.2.8 Definite Integrals $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-007.jpg?height=47&width=1195&top_left_y=1693&top_left_x=342)

3.2.10 Inequalities for Integrals $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.2.11 Taylor and Fourier Series . . . . . . . . . . . . . . . . . . . . . . 159

$3.3$ Multivariable Differential and Integral Calculus . . . . . . . . . . . . . . 167

3.3.1 Partial Derivatives and Their Applications . . . . . . . . . . . . . 167

3.3.2 Multivariable Integrals $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.3.3 The Many Versions of Stokes' Theorem . . . . . . . . . . . . . . . 179

$3.4$ Equations with Functions as Unknowns . . . . . . . . . . . . . . . . . . 185

3.4.1 Functional Equations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

3.4.2 Ordinary Differential Equations of the First Order $\ldots \ldots \ldots \ldots 191$ 3.4.3 Ordinary Differential Equations of Higher Order . . . . . . . . . . 195

3.4.4 Problems Solved with Techniques of Differential Equations ..... 198

4 Geometry and Trigonometry $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=52&width=1271&top_left_y=435&top_left_x=268)

$4.1 .1$ Vectors $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

4.1.2 The Coordinate Geometry of Lines and Circles.............. . 206

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=50&width=1195&top_left_y=578&top_left_x=342)

4.1.4 Coordinate Geometry in Three and More Dimensions ........ . 219

4.1.5 Integrals in Geometry $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

4.1.6 Other Geometry Problems . . . . . . . . . . . . . . . . . . . . . 228

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=48&width=1269&top_left_y=771&top_left_x=269)

4.2.1 Trigonometric Identities $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$4.2 .2$ Euler's Formula $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=50&width=1195&top_left_y=910&top_left_x=342)

4.2.4 Telescopic Sums and Products in Trigonometry ............. 242

5 Number Theory $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.1$ Integer-Valued Sequences and Functions $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=50&width=1195&top_left_y=1138&top_left_x=342)

5.1.2 Fermat's Infinite Descent Principle $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

5.1.3 The Greatest Integer Function $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.2$ Arithmetic $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.2 .1$ Factorization and Divisibility $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.2 .2$ Prime Numbers $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-008.jpg?height=47&width=1195&top_left_y=1422&top_left_x=342)

5.2.4 Fermat's Little Theorem $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.2 .5$ Wilson's Theorem $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.2 .6$ Euler's Totient Function $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

5.2.7 The Chinese Remainder Theorem $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.3$ Diophantine Equations . . . . . . . . . . . . . . . . . . . . . . . . . 270

$5.3 .1$ Linear Diophantine Equations . . . . . . . . . . . . . . . . . . . . 270

5.3.2 The Equation of Pythagoras $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$5.3 .3$ Pell's Equation $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

5.3.4 Other Diophantine Equations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

6 Combinatorics and Probability $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

6.1 Combinatorial Arguments in Set Theory and Geometry ............. . 281

6.1.1 Set Theory and Combinatorics of Sets $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots 281$

$6.1 .2$ Permutations $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

6.1.3 Combinatorial Geometry $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$ $\mathrm{x} \quad$ Contents

6.1.4 Euler's Formula for Planar Graphs $\ldots \ldots \ldots \ldots \ldots$. . . . . . . . 289

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-009.jpg?height=47&width=1195&top_left_y=302&top_left_x=342)

$6.2$ Binomial Coefficients and Counting Methods . . . . . . . . . . . . . . . . . . 294

6.2.1 Combinatorial Identities $\ldots \ldots \ldots \ldots \ldots \ldots$. . . . . . . . . . . . . . 294

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-009.jpg?height=49&width=1195&top_left_y=443&top_left_x=342)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-009.jpg?height=54&width=1195&top_left_y=488&top_left_x=344)

6.2.4 The Inclusion-Exclusion Principle $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$6.3$ Probability $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

$6.3 .1$ Equally Likely Cases $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$. . . . . . . . . 310

6.3.2 Establishing Relations Among Probabilities $\ldots \ldots \ldots \ldots \ldots$. . . . . 314

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-009.jpg?height=52&width=1195&top_left_y=722&top_left_x=344)

\section{Solutions}

Methods of Proof $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

Algebra $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-009.jpg?height=50&width=1339&top_left_y=1100&top_left_x=198)

Geometry and Trigonometry $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

Number Theory $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

Combinatorics and Probability $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

Index of Notation $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$

Index $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$ 

\section{Preface}

A problem book at the college level. A study guide for the Putnam competition. A bridge between high school problem solving and mathematical research. A friendly introduction to fundamental concepts and results. All these desires gave life to the pages that follow.

The William Lowell Putnam Mathematical Competition is the most prestigious mathematics competition at the undergraduate level in the world. Historically, this annual event began in 1938, following a suggestion of William Lowell Putnam, who realized the merits of an intellectual intercollegiate competition. Nowadays, over 2500 students from more than 300 colleges and universities in the United States and Canada take part in it. The name Putnam has become synonymous with excellence in undergraduate mathematics.

Using the Putnam competition as a symbol, we lay the foundations of higher mathematics from a unitary, problem-based perspective. As such, Putnam and Beyond is a journey through the world of college mathematics, providing a link between the stimulating problems of the high school years and the demanding problems of scientific investigation. It gives motivated students a chance to learn concepts and acquire strategies, hone their skills and test their knowledge, seek connections, and discover real world applications. Its ultimate goal is to build the appropriate background for graduate studies, whether in mathematics or applied sciences.

Our point of view is that in mathematics it is more important to understand why than to know how. Because of this we insist on proofs and reasoning. After all, mathematics means, as the Romanian mathematician Grigore Moisil once said, "correct reasoning." The ways of mathematical thinking are universal in today's science.

Putnam and Beyond targets primarily Putnam training sessions, problem-solving seminars, and math clubs at the college level, filling a gap in the undergraduate curriculum. But it does more than that. Written in the structured manner of a textbook, but with strong emphasis on problems and individual work, it covers what we think are the most important topics and techniques in undergraduate mathematics, brought together within the confines of a single book in order to strengthen one's belief in the unitary nature of xii Preface

mathematics. It is assumed that the reader possesses a moderate background, familiarity with the subject, and a certain level of sophistication, for what we cover reaches beyond the usual textbook, both in difficulty and in depth. When organizing the material, we were inspired by Georgia O'Keeffe's words: "Details are confusing. It is only by selection, by elimination, by emphasis that we get at the real meaning of things.",

The book can be used to enhance the teaching of any undergraduate mathematics course, since it broadens the database of problems for courses in real analysis, linear algebra, trigonometry, analytical geometry, differential equations, number theory, combinatorics, and probability. Moreover, it can be used by graduate students and educators alike to expand their mathematical horizons, for many concepts of more advanced mathematics can be found here disguised in elementary language, such as the Gauss-Bonnet theorem, the linear propagation of errors in quantum mechanics, knot invariants, or the Heisenberg group. The way of thinking nurtured in this book opens the door for true scientific investigation.

As for the problems, they are in the spirit of mathematics competitions. Recall that the Putnam competition has two parts, each consisting of six problems, numbered A1 through $\mathrm{A} 6$, and $\mathrm{B} 1$ through $\mathrm{B} 6$. It is customary to list the problems in increasing order of difficulty, with A1 and B1 the easiest, and A6 and B6 the hardest. We keep the same ascending pattern but span a range from $\mathrm{A} 0$ to $\mathrm{B} 7$. This means that we start with some inviting problems below the difficulty of the test, then move forward into the depths of mathematics.

As sources of problems and ideas we used the Putnam exam itself, the International Competition in Mathematics for University Students, the International Mathematical Olympiad, national contests from the United States of America, Romania, Russia, China, India, Bulgaria, mathematics journals such as the American Mathematical Monthly, Mathematics Magazine, Revista Matematică din Timişoara (Timişoara Mathematics Gazette), Gazeta Matematică (Mathematics Gazette, Bucharest), Kvant (Quantum), Középiskolai Matematikai Lapok (Mathematical Magazine for High Schools (Budapest)), and a very rich collection of Romanian publications. Many problems are original contributions of the authors. Whenever possible, we give the historical background and indicate the source and author of the problem. Some of our sources are hard to find; this is why we offer you their most beautiful problems. Other sources are widely circulated, and by selecting some of their most representative problems we bring them to your attention.

Here is a brief description of the contents of the book. The first chapter is introductory, giving an overview of methods widely used in proofs. The other five chapters reflect areas of mathematics: algebra, real analysis, geometry and trigonometry, number theory, combinatorics and probability. The emphasis is placed on the first two of these chapters, since they occupy the largest part of the undergraduate curriculum.

Within each chapter, problems are clustered by topic. We always offer a brief theoretical background illustrated by one or more detailed examples. Several problems are left for the reader to solve. And since our problems are true brainteasers, complete solutions are given in the second part of the book. Considerable care has been taken in selecting the most elegant solutions and writing them so as to stir imagination and stimulate research. We always "judged mathematical proofs," as Andrew Wiles once said, "by their beauty."'

Putnam and Beyond is the fruit of work of the first author as coach of the University of Michigan and Texas Tech University Putnam teams and of the International Mathematical Olympiad teams of the United States and India, as well as the product of the vast experience of the second author as head coach of the United States International Mathematical Olympiad team, coach of the Romanian International Mathematical Olympiad team, director of the American Mathematics Competitions, and member of the Question Writing Committee of the William Lowell Putnam Mathematical Competition.

In conclusion, we would like to thank Elgin Johnston, Dorin Andrica, Chris Jeuell, Ioan Cucurezeanu, Marian Deaconescu, Gabriel Dospinescu, Ravi Vakil, Vinod Grover, V.V. Acharya, B.J. Venkatachala, C.R. Pranesachar, Bryant Heath, and the students of the International Mathematical Olympiad training programs of the United States and India for their suggestions and contributions. Most of all, we are deeply grateful to Richard Stong, David Kramer, and Paul Stanford for carefully reading the manuscript and considerably improving its quality. We would be delighted to receive further suggestions and corrections; these can be sent to rgelca@gmail.com.

May 2007

\author{
Răzvan Gelca \\ Texas Tech University \\ Titu Andreescu \\ University of Texas at Dallas
}



\section{A Study Guide}

The book has six chapters: Methods of Proof, Algebra, Real Analysis, Geometry and Trigonometry, Number Theory, Combinatorics and Probability, divided into subchapters such as Linear Algebra, Sequences and Series, Geometry, and Arithmetic. All subchapters are self-contained and independent of each other and can be studied in any order. In most cases they reflect standard undergraduate courses or fields of mathematics. The sections within each subchapter are best followed in the prescribed order.

If you are an undergraduate student trying to acquire skills or test your knowledge in a certain field, study first a regular textbook and make sure that you understand it very well. Then choose the appropriate chapter or subchapter of this book and proceed section by section. Read first the theoretical background and the examples from the introductory part; then do the problems. These are listed in increasing order of difficulty, but even the very first can be tricky. Don't get discouraged; put effort and imagination into each problem; and only if all else fails, look at the solution from the back of the book. But even if you are successful, read the solution, since many times it gives a new insight and, more important, opens the door toward more advanced mathematics.

Beware! The last few problems of each section can be very hard. It might be a good idea to skip them at the first encounter and return to them as you become more experienced.

If you are a Putnam competitor, then as you go on with the study of the book try your hand at the true Putnam problems (which have been published in three excellent volumes). Identify your weaknesses and insist on those chapters of Putnam and Beyond. Every once in a while, for a problem that you solved, write down the solution in detail, then compare it to the one given at the end of the book. It is very important that your solutions be correct, structured, convincing, and easy to follow.

An instructor can add some of the problems from the book to a regular course in order to stimulate and challenge the better students. Some of the theoretical subjects can also be incorporated in the course to give better insight and a new perspective. Putnam and Beyond can be used as a textbook for problem-solving courses, in which case we recommend beginning with the first chapter. Students should be encouraged to come up with their own original solutions.

If you are a graduate student in mathematics, it is important that you know and understand the contents of this book. First, mastering problems and learning how to write down arguments are essential matters for good performance in doctoral examinations. Second, most of the presented facts are building blocks of graduate courses; knowing them will make these courses natural and easy.

"Don't bother to just be better than your contemporaries or predecessors. Try to be better than yourself'" (W. Faulkner). 

\section{Methods of Proof}

In this introductory chapter we explain some methods of mathematical proof. They are argument by contradiction, the principle of mathematical induction, the pigeonhole principle, the use of an ordering on a set, and the principle of invariance.

The basic nature of these methods and their universal use throughout mathematics makes this separate treatment necessary. In each case we have selected what we think are the most appropriate examples, solving some of them in detail and asking you to train your skills on the others. And since these are fundamental methods in mathematics, you should try to understand them in depth, for "it is better to understand many things than to know many things' (Gustave Le Bon).

\subsection{Argument by Contradiction}

The method of argument by contradiction proves a statement in the following way:

First, the statement is assumed to be false. Then, a sequence of logical deductions yields a conclusion that contradicts either the hypothesis (indirect method), or a fact known to be true (reductio ad absurdum). This contradiction implies that the original statement must be true.

This is a method that Euclid loved, and you can find it applied in some of the most beautiful proofs from his Elements. Euclid's most famous proof is that of the infinitude of prime numbers.

Euclid's theorem. There are infinitely many prime numbers.

Proof. Assume, to the contrary, that only finitely many prime numbers exist. List them as $p_{1}=2, p_{2}=3, p_{3}=5, \ldots, p_{n}$. The number $N=p_{1} p_{2} \cdots p_{n}+1$ is divisible by a prime $p$, yet is coprime to $p_{1}, p_{2}, \ldots, p_{n}$. Therefore, $p$ does not belong to our list of all prime numbers, a contradiction. Hence the initial assumption was false, proving that there are infinitely many primes. We continue our illustration of the method of argument by contradiction with an example of Euler.

Example. Prove that there is no polynomial

$$
P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}
$$

with integer coefficients and of degree at least 1 with the property that $P(0), P(1), P(2)$, $\ldots$ are all prime numbers.

Solution. Assume the contrary and let $P(0)=p, p$ prime. Then $a_{0}=p$ and $P(k p)$ is divisible by $p$ for all $k \geq 1$. Because we assumed that all these numbers are prime, it follows that $P(k p)=p$ for $k \geq 1$. Therefore, $P(x)$ takes the same value infinitely many times, a contradiction. Hence the conclusion.

The last example comes from I. Tomescu's book Problems in Combinatorics (Wiley, 1985).

Example. Let $F=\left\{E_{1}, E_{2}, \ldots, E_{s}\right\}$ be a family of subsets with $r$ elements of some set $X$. Show that if the intersection of any $r+1$ (not necessarily distinct) sets in $F$ is nonempty, then the intersection of all sets in $F$ in nonempty.

Solution. Again we assume the contrary, namely that the intersection of all sets in $F$ is empty. Consider the set $E_{1}=\left\{x_{1}, x_{2}, \ldots, x_{r}\right\}$. Because none of the $x_{i}, i=1,2, \ldots, r$, lies in the intersection of all the $E_{j}$ 's (this intersection being empty), it follows that for each $i$ we can find some $E_{j_{i}}$ such that $x_{i} \notin E_{j_{i}}$. Then

$$
E_{1} \cap E_{i_{1}} \cap E_{i_{2}} \cap \cdots \cap E_{i_{r}}=\emptyset,
$$

since, at the same time, this intersection is included in $E_{1}$ and does not contain any element of $E_{1}$. But this contradicts the hypothesis. It follows that our initial assumption was false, and hence the sets from the family $F$ have a nonempty intersection.

The following problems help you practice this method, which will be used often in the book.

1. Prove that $\sqrt{2}+\sqrt{3}+\sqrt{5}$ is an irrational number.

2. Show that no set of nine consecutive integers can be partitioned into two sets with the product of the elements of the first set equal to the product of the elements of the second set.

3. Find the least positive integer $n$ such that any set of $n$ pairwise relatively prime integers greater than 1 and less than 2005 contains at least one prime number. 

4. Every point of three-dimensional space is colored red, green, or blue. Prove that one of the colors attains all distances, meaning that any positive real number represents the distance between two points of this color.

5. The union of nine planar surfaces, each of area equal to 1 , has a total area equal to 5. Prove that the overlap of some two of these surfaces has an area greater than or equal to $\frac{1}{9}$.

6. Show that there does not exist a function $f: \mathbb{Z} \rightarrow\{1,2,3\}$ satisfying $f(x) \neq f(y)$ for all $x, y \in \mathbb{Z}$ such that $|x-y| \in\{2,3,5\}$.

7. Show that there does not exist a strictly increasing function $f: \mathbb{N} \rightarrow \mathbb{N}$ satisfying $f(2)=3$ and $f(m n)=f(m) f(n)$ for all $m, n \in \mathbb{N}$.

8. Determine all functions $f: \mathbb{N} \rightarrow \mathbb{N}$ satisfying

$$
x f(y)+y f(x)=(x+y) f\left(x^{2}+y^{2}\right)
$$

for all positive integers $x$ and $y$.

9. Show that the interval $[0,1]$ cannot be partitioned into two disjoint sets $A$ and $B$ such that $B=A+a$ for some real number $a$.

10. Let $n>1$ be an arbitrary real number and let $k$ be the number of positive prime numbers less than or equal to $n$. Select $k+1$ positive integers such that none of them divides the product of all the others. Prove that there exists a number among the chosen $k+1$ that is bigger than $n$.

\subsection{Mathematical Induction}

The principle of mathematical induction, which lies at the very heart of Peano's axiomatic construction of the set of positive integers, is stated as follows.

Induction principle. Given $P(n)$, a property depending on a positive integer $n$,

(i) if $P\left(n_{0}\right)$ is true for some positive integer $n_{0}$, and

(ii) iffor every $k \geq n_{0}, P(k)$ true implies $P(k+1)$ true, then $P(n)$ is true for all $n \geq n_{0}$.

This means that when proving a statement by mathematical induction you should (i) check the base case and (ii) verify the inductive step by showing how to pass from an arbitrary integer to the next. Here is a simple example from combinatorial geometry.

Example. Finitely many lines divide the plane into regions. Show that these regions can be colored by two colors in such a way that neighboring regions have different colors. Solution. We prove this by induction on the number $n$ of lines. The base case $n=1$ is straightforward, color one half-plane black, the other white.

For the inductive step, assume that we know how to color any map defined by $k$ lines. Add the $(k+1)$ st line to the picture; then keep the color of the regions on one side of this line the same while changing the color of the regions on the other side. The inductive step is illustrated in Figure 1.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-018.jpg?height=297&width=1036&top_left_y=606&top_left_x=354)

Figure 1

Regions that were adjacent previously still have different colors. Regions that share a segment of the $(k+1)$ st line, which were part of the same region previously, now lie on opposite sides of the line. So they have different colors, too. This shows that the new map satisfies the required property and the induction is complete.

A classical proof by induction is that of Fermat's so-called little theorem.

Fermat's little theorem. Let $p$ be a prime number, and $n$ a positive integer. Then $n^{p}-n$ is divisible by $p$.

Proof. We prove the theorem by induction on $n$. The base case $n=1$ is obvious. Let us assume that the property is true for $n=k$ and prove it for $n=k+1$. Using the induction hypothesis, we obtain

$$
(k+1)^{p}-(k+1) \equiv k^{p}+\sum_{j=1}^{p-1}\left(\begin{array}{l}
p \\
j
\end{array}\right) k^{j}+1-k-1 \equiv \sum_{j=1}^{p-1}\left(\begin{array}{l}
p \\
j
\end{array}\right) k^{j}(\bmod p) .
$$

The key observation is that for $1 \leq j \leq p-1,\left(\begin{array}{l}p \\ j\end{array}\right)$ is divisible by $p$. Indeed, examining

$$
\left(\begin{array}{l}
p \\
j
\end{array}\right)=\frac{p(p-1) \cdots(p-j+1)}{1 \cdot 2 \cdots j},
$$

it is easy to see that when $1 \leq j \leq p-1$, the numerator is divisible by $p$ while the denominator is not. Therefore, $(k+1)^{p}-(k+1) \equiv 0(\bmod p)$, which completes the induction. The third example is a problem from the 5th W.L. Putnam Mathematical Competition, and it was selected because its solution combines several proofs by induction. If you find it too demanding, think of Vincent van Gogh's words: "The way to succeed is to keep your courage and patience, and to work energetically."

Example. For $m$ a positive integer and $n$ an integer greater than 2, define $f_{1}(n)=n$, $f_{2}(n)=n^{f_{1}(n)}, \ldots, f_{i+1}(n)=n^{f_{i}(n)}, \ldots$ Prove that

$$
f_{m}(n)<n ! ! \cdots !<f_{m+1}(n),
$$

where the term in the middle has $m$ factorials.

Solution. For convenience, let us introduce $g_{0}(n)=n$, and recursively $g_{i+1}(n)=$ $\left(g_{i}(n)\right) !$. The double inequality now reads

$$
f_{m}(n)<g_{m}(n)<f_{m+1}(n) .
$$

For $m=1$ this is obviously true, and it is only natural to think of this as the base case. We start by proving the inequality on the left by induction on $m$. First, note that if $t>2 n^{2}$ is a positive integer, then

$$
t !>\left(n^{2}\right)^{t-n^{2}}=n^{t} n^{t-2 n^{2}}>n^{t} .
$$

Now, it is not hard to check that $g_{m}(n)>2 n^{2}$ for $m \geq 2$ and $n \geq 3$. With this in mind, let us assume the inequality to be true for $m=k$. Then

$$
g_{k+1}(n)=\left(g_{k}(n)\right) !>n^{g_{k}(n)}>n^{f_{k}(n)}=f_{k+1}(n),
$$

which proves the inequality for $m=k+1$. This verifies the inductive step and solves half of the problem.

Here we pause for a short observation. Sometimes the proof of a mathematical statement becomes simpler if the statement is strengthened. This is the case with the second inequality, which we replace by the much stronger

$$
g_{0}(n) g_{1}(n) \cdots g_{m}(n)<f_{m+1}(n),
$$

holding true for $m$ and $n$ as above.

As an intermediate step, we establish, by induction on $m$, that

$$
g_{0}(n) g_{1}(n) \cdots g_{m}(n)<n^{g_{0}(n) g_{1}(n) \cdots g_{m-1}(n)},
$$

for all $m$ and all $n \geq 3$. The base case $m=1$ is the obvious $n \cdot n !<n^{n}$. Now assume that the inequality is true for $m=k$, and prove it for $m=k+1$. We have 

$$
\begin{aligned}
g_{0}(n) g_{1}(n) \cdots g_{k+1}(n) &=g_{0}(n) g_{0}(n !) \cdots g_{k}(n !)<g_{0}(n)(n !)^{g_{0}(n !) g_{1}(n !) \cdots g_{k-1}(n !)} \\
&<n(n !)^{g_{1}(n) \cdots g_{k}(n)}<(n \cdot n !)^{g_{1}(n) \cdots g_{k}(n)} \\
&<\left(n^{n}\right)^{g_{1}(n) \cdots g_{k}(n)}=n^{g_{0}(n) g_{1}(n) \cdots g_{k}(n)}
\end{aligned}
$$

completing this induction, and proving the claim.

Next, we show, also by induction on $m$, that $g_{0}(n) g_{1}(n) \cdots g_{m}(n)<f_{m+1}(n)$ for all $n$. The base case $m=1$ is $n \cdot n !<n^{n}$; it follows by multiplying $1 \cdot 2<n$ and $3 \cdot 4 \cdots n<n^{n-2}$. Let's see the inductive step. Using the inequality for the $g_{m}$ 's proved above and the assumption that the inequality holds for $m=k$, we obtain

$$
g_{0}(n) \cdots g_{m}(n) g_{m+1}(n)<n^{g_{0}(n) \cdots g_{m}(n)}<n^{f_{m+1}(n)}=f_{m+2}(n)
$$

which is the inequality for $m=k+1$. This completes the last induction, and with it the solution to the problem. No fewer than three inductions were combined to solve the problem!

Listen and you will forget, learn and you will remember, do it yourself and you will understand. Practice induction with the following examples.

11. Prove for all positive integers $n$ the identity

$$
\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2 n}=1-\frac{1}{2}+\frac{1}{3}-\cdots+\frac{1}{2 n-1}-\frac{1}{2 n} .
$$

12. Prove that $|\sin n x| \leq n|\sin x|$ for any real number $x$ and positive integer $n$.

13. Prove that for any real numbers $x_{1}, x_{2}, \ldots, x_{n}, n \geq 1$,

$$
\left|\sin x_{1}\right|+\left|\sin x_{2}\right|+\cdots+\left|\sin x_{n}\right|+\left|\cos \left(x_{1}+x_{2}+\cdots+x_{n}\right)\right| \geq 1 \text {. }
$$

14. Prove that $3^{n} \geq n^{3}$ for all positive integers $n$.

15. Let $n \geq 6$ be an integer. Show that

$$
\left(\frac{n}{3}\right)^{n}<n !<\left(\frac{n}{2}\right)^{n} .
$$

16. Let $n$ be a positive integer. Prove that

$$
1+\frac{1}{2^{3}}+\frac{1}{3^{3}}+\cdots+\frac{1}{n^{3}}<\frac{3}{2} .
$$

17. Prove that for any positive integer $n$ there exists an $n$-digit number

(a) divisible by $2^{n}$ and containing only the digits 2 and 3 ;

(b) divisible by $5^{n}$ and containing only the digits $5,6,7,8,9$. 

18. Prove that for any $n \geq 1$, a $2^{n} \times 2^{n}$ checkerboard with $1 \times 1$ corner square removed can be tiled by pieces of the form described in Figure 2 .

19. Given a sequence of integers $x_{1}, x_{2}, \ldots, x_{n}$ whose sum is 1 , prove that exactly one of the cyclic shifts

$$
x_{1}, x_{2}, \ldots, x_{n} ; \quad x_{2}, \ldots, x_{n}, x_{1} ; \quad \ldots ; \quad x_{n}, x_{1}, \ldots, x_{n-1}
$$

has all of its partial sums positive. (By a partial sum we mean the sum of the first $k$ terms, $k \leq n$.)

20. Let $x_{1}, x_{2}, \ldots, x_{n}, y_{1}, y_{2}, \ldots, y_{m}$ be positive integers, $n, m>1$. Assume that $x_{1}+x_{2}+\cdots+x_{n}=y_{1}+y_{2}+\cdots+y_{m}<m n$. Prove that in the equality

$$
x_{1}+x_{2}+\cdots+x_{n}=y_{1}+y_{2}+\cdots+y_{m}
$$

one can suppress some (but not all) terms in such a way that the equality is still satisfied.

21. Prove that any function defined on the entire real axis can be written as the sum of two functions whose graphs admit centers of symmetry.

22. Prove that for any positive integer $n \geq 2$ there is a positive integer $m$ that can be written simultaneously as a sum of $2,3, \ldots, n$ squares of nonzero integers.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-021.jpg?height=214&width=203&top_left_y=1352&top_left_x=759)

Figure 2

Even more powerful is strong induction.

Induction principle (strong form). Given $P(n)$ a property that depends on an integer $n$,

(i) if $P\left(n_{0}\right), P\left(n_{0}+1\right), \ldots, P\left(n_{0}+m\right)$ are true for some positive integer $n_{0}$ and nonnegative integer $m$, and

(ii) iffor every $k>n_{0}+m, P(j)$ true for all $n_{0} \leq j<k$ implies $P(k)$ true, then $P(n)$ is true for all $n \geq n_{0}$.

We use strong induction to solve a problem from the 24th W.L. Putnam Mathematical Competition. Example. Let $f: \mathbb{N} \rightarrow \mathbb{N}$ be a strictly increasing function such that $f(2)=2$ and $f(m n)=f(m) f(n)$ for every relatively prime pair of positive integers $m$ and $n$. Prove that $f(n)=n$ for every positive integer $n$.

Solution. The proof is of course by induction on $n$. Monotonicity implies right away that $f(1)=1$. However, the base case is not the given $f(2)=2$, but $f(2)=2$ and $f(3)=3$.

So let us find $f$ (3). Because $f$ is strictly increasing, $f(3) f(5)=f(15)<f(18)=$ $f(2) f(9)$. Hence $f(3) f(5)<2 f(9)$ and $f(9)<f(10)=f(2) f(5)=2 f(5)$. Combining these inequalities, we obtain $f(3) f(5)<4 f(5)$, so $f(3)<4$. But we know that $f(3)>f(2)=2$, which means that $f(3)$ can only be equal to 3 .

The base case was the difficult part of the problem; the induction step is rather straightforward. Let $k>3$ and assume that $f(j)=j$ for $j<k$. Consider $2^{r}(2 m+1)$ to be the smallest even integer greater than or equal to $k$ that is not a power of 2 . This number is equal to either $k, k+1, k+2$, or $k+3$, and since $k>3$, both $2^{r}$ and $2 m+1$ are strictly less than $k$. From the induction hypothesis, we obtain $f\left(2^{r}(2 m+1)\right)=$ $f\left(2^{r}\right) f(2 m+1)=2^{r}(2 m+1)$. Monotonicity, combined with the fact that there are at most $2^{r}(2 m+1)$ values that the function can take in the interval $\left[1,2^{r}(2 m+1)\right]$, implies that $f(l)=l$ for $l \leq 2^{r}(2 m+1)$. In particular, $f(k)=k$. We conclude that $f(n)=n$ for all positive integers $n$.

A function $f: \mathbb{N} \rightarrow \mathbb{C}$ with the property that $f(1)=1$ and $f(m n)=f(m) f(n)$ whenever $m$ and $n$ are coprime is called a multiplicative function. Examples include the Euler totient function and the Möbius function. In the case of our problem, the multiplicative function is also strictly increasing. A more general result of P. Erdós shows that any increasing multiplicative function that is not constant is of the form $f(n)=n^{\alpha}$ for some $\alpha>0$.

23. Show that every positive integer can be written as a sum of distinct terms of the Fibonacci sequence. (The Fibonacci sequence $\left(F_{n}\right)_{n}$ is defined by $F_{0}=0, F_{1}=1$, and $F_{n+1}=F_{n}+F_{n-1}, n \geq 1$.)

24. Prove that the Fibonacci sequence satisfies the identity

$$
F_{2 n+1}=F_{n+1}^{2}+F_{n}^{2}, \quad \text { for } n \geq 0 .
$$

25. Prove that the Fibonacci sequence satisfies the identity

$$
F_{3 n}=F_{n+1}^{3}+F_{n}^{3}-F_{n-1}^{3}, \quad \text { for } n \geq 0 .
$$

26. Show that an isosceles triangle with one angle of $120^{\circ}$ can be dissected into $n \geq 4$ triangles similar to it. 

27. Show that for all $n>3$ there exists an $n$-gon whose sides are not all equal and such that the sum of the distances from any interior point to each of the sides is constant. (An $n$-gon is a polygon with $n$ sides.)

28. The vertices of a convex polygon are colored by at least three colors such that no two consecutive vertices have the same color. Prove that one can dissect the polygon into triangles by diagonals that do not cross and whose endpoints have different colors.

29. Prove that any polygon (convex or not) can be dissected into triangles by interior diagonals.

30. Prove that any positive integer can be represented as $\pm 1^{2} \pm 2^{2} \pm \cdots \pm n^{2}$ for some positive integer $n$ and some choice of the signs.

Now we demonstrate a less frequently encountered form of induction that can be traced back to Cauchy's work, where it was used to prove the arithmetic mean-geometric mean inequality. We apply this method to solve a problem from D. Buşneag, I. Maftei, Themes for Mathematics Circles and Contests (Scrisul Românesc, Craiova, 1983).

Example. Let $a_{1}, a_{2}, \ldots, a_{n}$ be real numbers greater than 1. Prove the inequality

$$
\sum_{i=1}^{n} \frac{1}{1+a_{i}} \geq \frac{n}{1+\sqrt[n]{a_{1} a_{2} \cdots a_{n}}} .
$$

Solution. As always, we start with the base case:

$$
\frac{1}{1+a_{1}}+\frac{1}{1+a_{2}} \geq \frac{2}{1+\sqrt{a_{1} a_{2}}} .
$$

Multiplying out the denominators yields the equivalent inequality

$$
\left(2+a_{1}+a_{2}\right)\left(1+\sqrt{a_{1} a_{2}}\right) \geq 2\left(1+a_{1}+a_{2}+a_{1} a_{2}\right) .
$$

After multiplications and cancellations, we obtain

$$
2 \sqrt{a_{1} a_{2}}+\left(a_{1}+a_{2}\right) \sqrt{a_{1} a_{2}} \geq a_{1}+a_{2}+2 a_{1} a_{2} .
$$

This can be rewritten as

$$
2 \sqrt{a_{1} a_{2}}\left(1-\sqrt{a_{1} a_{2}}\right)+\left(a_{1}+a_{2}\right)\left(\sqrt{a_{1} a_{2}}-1\right) \geq 0,
$$

or

$$
\left(\sqrt{a_{1} a_{2}}-1\right)\left(a_{1}+a_{2}-2 \sqrt{a_{1} a_{2}}\right) \geq 0 .
$$

The inequality is now obvious since $a_{1} a_{2} \geq 1$ and $a_{1}+a_{2} \geq 2 \sqrt{a_{1} a_{2}}$.

Now instead of exhausting all positive integers $n$, we downgrade our goal and check just the powers of 2 . So we prove that the inequality holds for $n=2^{k}$ by induction on $k$. Assuming it true for $k$, we can write

$$
\begin{aligned}
& \sum_{i=1}^{2^{k+1}} \frac{1}{1+a_{i}}=\sum_{i=1}^{2^{k}} \frac{1}{1+a_{i}}+\sum_{i=2^{k}+1}^{2^{k+1}} \frac{1}{1+a_{i}} \\
& \geq 2^{k}\left(\frac{1}{1+\sqrt[2^{k}]{a_{1} a_{2} \cdots a_{2^{k}}}}+\frac{1}{1+\sqrt[2^{k}]{a_{2^{k}+1} a_{2^{k}+2} \cdots a_{2^{k+1}}}}\right) \\
& \geq 2^{k} \frac{2}{1+\sqrt[2^{k+1}]{a_{1} a_{2} \cdots a_{2^{k+1}}}},
\end{aligned}
$$

where the first inequality follows from the induction hypothesis, and the second is just the base case. This completes the induction.

Now we have to cover the cases in which $n$ is not a power of 2 . We do the induction backward, namely, we assume that the inequality holds for $n+1$ numbers and prove it for $n$. Let $a_{1}, a_{2}, \ldots, a_{n}$ be some real numbers greater than 1 . Attach to them the number $\sqrt[n]{a_{1} a_{2} \cdots a_{n}}$. When writing the inequality for these $n+1$ numbers, we obtain

$$
\frac{1}{1+a_{1}}+\cdots+\frac{1}{1+\sqrt[n]{a_{1} a_{2} \cdots a_{n}}} \geq \frac{n+1}{1+\sqrt[n+1]{a_{1} \cdots a_{n} \sqrt[n]{a_{1} a_{2} \cdots a_{n}}}} .
$$

Recognize the complicated radical on the right to be $\sqrt[n]{a_{1} a_{2} \cdots a_{n}}$. After cancelling the last term on the left, we obtain

$$
\frac{1}{1+a_{1}}+\frac{1}{1+a_{2}}+\cdots+\frac{1}{1+a_{n}} \geq \frac{n}{1+\sqrt[n]{a_{1} a_{2} \cdots a_{n}}},
$$

as desired. The inequality is now proved, since we can reach any positive integer $n$ by starting with a sufficiently large power of 2 and working backward.

Try to apply the same technique to the following problems.

31. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a function satisfying $f\left(\frac{x_{1}+x_{2}}{2}\right)=\frac{f\left(x_{1}\right)+f\left(x_{2}\right)}{2}$ for any $x_{1}, x_{2}$. Prove that

$$
f\left(\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}\right)=\frac{f\left(x_{1}\right)+f\left(x_{2}\right)+\cdots+f\left(x_{n}\right)}{n}
$$

for any $x_{1}, x_{2}, \ldots, x_{n}$.

32. Show that if $a_{1}, a_{2}, \ldots, a_{n}$ are nonnegative numbers, then

$$
\left(1+a_{1}\right)\left(1+a_{2}\right) \cdots\left(1+a_{n}\right) \geq\left(1+\sqrt[n]{a_{1} a_{2} \cdots a_{n}}\right)^{n} .
$$



\subsection{The Pigeonhole Principle}

The pigeonhole principle (or Dirichlet's box principle) is usually applied to problems in combinatorial set theory, combinatorial geometry, and number theory. In its intuitive form, it can be stated as follows.

Pigeonhole principle. If $k n+1$ objects ( $k \geq 1$ not necessarily finite) are distributed among $n$ boxes, one of the boxes will contain at least $k+1$ objects.

This is merely an observation, and it was Dirichlet who first used it to prove nontrivial mathematical results. We begin with an easy problem, which was given at the International Mathematical Olympiad in 1972, proposed by Russia.

Example. Prove that every set of 10 two-digit integer numbers has two disjoint subsets with the same sum of elements.

Solution. Let $S$ be the set of 10 numbers. It has $2^{10}-2=1022$ subsets that differ from both $S$ and the empty set. They are the "pigeons." If $A \subset S$, the sum of elements of $A$ cannot exceed $91+92+\cdots+99=855$. The numbers between 1 and 855 , which are all possible sums, are the "holes." Because the number of "pigeons" exceeds the number of "holes," there will be two "pigeons" in the same "hole." Specifically, there will be two subsets with the same sum of elements. Deleting the common elements, we obtain two disjoint sets with the same sum of elements.

Here is a more difficult problem from the 26th International Mathematical Olympiad, proposed by Mongolia.

Example. Given a set $M$ of 1985 distinct positive integers, none of which has a prime divisor greater than 26 , prove that $M$ contains at least one subset of four distinct elements whose product is the fourth power of an integer.

Solution. We show more generally that if the prime divisors of elements in $M$ are among the prime numbers $p_{1}, p_{2}, \ldots, p_{n}$ and $M$ has at least $3 \cdot 2^{n}+1$ elements, then it contains a subset of four distinct elements whose product is a fourth power.

To each element $m$ in $M$ we associate an $n$-tuple $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$, where $x_{i}$ is 0 if the exponent of $p_{i}$ in the prime factorization of $m$ is even, and 1 otherwise. These $n$-tuples are the "objects." The "boxes"' are the $2^{n}$ possible choices of 0 's and 1's. Hence, by the pigeonhole principle, every subset of $2^{n}+1$ elements of $M$ contains two distinct elements with the same associated $n$-tuple, and the product of these two elements is then a square.

We can repeatedly take aside such pairs and replace them with two of the remaining numbers. From the set $M$, which has at least $3 \cdot 2^{n}+1$ elements, we can select $2^{n}+1$ such pairs or more. Consider the $2^{n}+1$ numbers that are products of the two elements of each pair. The argument can be repeated for their square roots, giving four elements $a, b, c, d$ in $M$ such that $\sqrt{a b} \sqrt{c d}$ is a perfect square. Then $a b c d$ is a fourth power and we are done. For our problem $n=9$, while $1985>3 \cdot 2^{9}+1=1537$. The third example comes from the 67th W.L. Putnam Mathematical Competition, 2006.

Example. Prove that for every set $X=\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}$ of $n$ real numbers, there exists a nonempty subset $S$ of $X$ and an integer $m$ such that

$$
\left|m+\sum_{s \in S} s\right| \leq \frac{1}{n+1} .
$$

Solution. Recall that the fractional part of a real number $x$ is $x-\lfloor x\rfloor$. Let us look at the fractional parts of the numbers $x_{1}, x_{1}+x_{2}, \ldots, x_{1}+x_{2}+\cdots+x_{n}$. If any of them is either in the interval $\left[0, \frac{1}{n+1}\right]$ or $\left[\frac{n}{n+1}, 1\right]$, then we are done. If not, we consider these $n$ numbers as the "pigeons" and the $n-1$ intervals $\left[\frac{1}{n+1}, \frac{2}{n+1}\right],\left[\frac{2}{n+1}, \frac{3}{n+1}\right], \ldots,\left[\frac{n-1}{n+1}, \frac{n}{n+1}\right]$ as the "holes." By the pigeonhole principle, two of these sums, say $x_{1}+x_{2}+\cdots+x_{k}$ and $x_{1}+x_{2}+\cdots+x_{k+m}$, belong to the same interval. But then their difference $x_{k+1}+\cdots+x_{k+m}$ lies within a distance of $\frac{1}{n+1}$ of an integer, and we are done.

More problems are listed below.

33. Given 50 distinct positive integers strictly less than 100 , prove that some two of them sum to 99.

34. A sequence of $m$ positive integers contains exactly $n$ distinct terms. Prove that if $2^{n} \leq m$ then there exists a block of consecutive terms whose product is a perfect square.

35. Let $x_{1}, x_{2}, x_{3}, \ldots$ be a sequence of integers such that

$$
1=x_{1}<x_{2}<x_{3}<\cdots \quad \text { and } \quad x_{n+1} \leq 2 n \quad \text { for } n=1,2,3, \ldots
$$

Show that every positive integer $k$ is equal to $x_{i}-x_{j}$ for some $i$ and $j$.

36. Let $p$ be a prime number and $a, b, c$ integers such that $a$ and $b$ are not divisible by $p$. Prove that the equation $a x^{2}+b y^{2} \equiv c(\bmod p)$ has integer solutions.

37. In each of the unit squares of a $10 \times 10$ checkerboard, a positive integer not exceeding 10 is written. Any two numbers that appear in adjacent or diagonally adjacent squares of the board are relatively prime. Prove that some number appears at least 17 times.

38. Show that there is a positive term of the Fibonacci sequence that is divisible by 1000 .

39. Let $x_{1}=x_{2}=x_{3}=1$ and $x_{n+3}=x_{n}+x_{n+1} x_{n+2}$ for all positive integers $n$. Prove that for any positive integer $m$ there is an index $k$ such that $m$ divides $x_{k}$. 

40. A chess player trains by playing at least one game per day, but, to avoid exhaustion, no more than 12 games a week. Prove that there is a group of consecutive days in which he plays exactly 20 games.

41. Let $m$ be a positive integer. Prove that among any $2 m+1$ distinct integers of absolute value less than or equal to $2 m-1$ there exist three whose sum is equal to zero.

42. There are $n$ people at a party. Prove that there are two of them such that of the remaining $n-2$ people, there are at least $\left\lfloor\frac{n}{2}\right\rfloor-1$ of them each of whom knows both or else knows neither of the two.

43. Let $x_{1}, x_{2}, \ldots, x_{k}$ be real numbers such that the set $A=\left\{\cos \left(n \pi x_{1}\right)+\cos \left(n \pi x_{2}\right)+\right.$ $\left.\cdots+\cos \left(n \pi x_{k}\right) \mid n \geq 1\right\}$ is finite. Prove that all the $x_{i}$ are rational numbers.

Particularly attractive are the problems in which the pigeons and holes are geometric objects. Here is a problem from a Chinese mathematical competition.

Example. Given nine points inside the unit square, prove that some three of them form a triangle whose area does not exceed $\frac{1}{8}$.

Solution. Divide the square into four equal squares, which are the "boxes." From the $9=2 \times 4+1$ points, at least $3=2+1$ will lie in the same box. We are left to show that the area of a triangle placed inside a square does not exceed half the area of the square.

Cut the square by the line passing through a vertex of the triangle, as in Figure 3 . Since the area of a triangle is base $\times$ height 2 and the area of a rectangle is base $\times$ height, the inequality holds for the two smaller triangles and their corresponding rectangles. Adding up the two inequalities, we obtain the inequality for the square. This completes the solution.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-027.jpg?height=327&width=332&top_left_y=1603&top_left_x=701)

Figure 3

44. Inside a circle of radius 4 are chosen 61 points. Show that among them there are two at distance at most $\sqrt{2}$ from each other. 

45. Each of nine straight lines divides a square into two quadrilaterals with the ratio of their areas equal to $r>0$. Prove that at least three of these lines are concurrent.

46. Show that any convex polyhedron has two faces with the same number of edges.

47. Draw the diagonals of a 21-gon. Prove that at least one angle of less than $1^{\circ}$ is formed.

48. Let $P_{1}, P_{2}, \ldots, P_{2 n}$ be a permutation of the vertices of a regular polygon. Prove that the closed polygonal line $P_{1} P_{2} \ldots P_{2 n}$ contains a pair of parallel segments.

49. Let $S$ be a convex set in the plane that contains three noncollinear points. Each point of $S$ is colored by one of $p$ colors, $p>1$. Prove that for any $n \geq 3$ there exist infinitely many congruent $n$-gons whose vertices are all of the same color.

50. The points of the plane are colored by finitely many colors. Prove that one can find a rectangle with vertices of the same color.

51. Inside the unit square lie several circles the sum of whose circumferences is equal to 10 . Prove that there exist infinitely many lines each of which intersects at least four of the circles.

\subsection{Ordered Sets and Extremal Elements}

An order on a set is a relation $\leq$ with three properties: (i) $a \leq a$; (ii) if $a \leq b$ and $b \leq a$, then $a=b$; (iii) $a \leq b$ and $b \leq c$ implies $a \leq c$. The order is called total if any two elements are comparable, that is, if for every $a$ and $b$, either $a \leq b$ or $b \leq a$. The simplest example of a total order is $\leq$ on the set of real numbers. The existing order on a set can be found useful when one is trying to solve a problem. This is the case with the following two examples, the second of which is a problem of G. Galperin published in the Russian journal Quantum.

Example. Prove that among any 50 distinct positive integers strictly less than 100 there are two that are coprime.

Solution. Order the numbers: $x_{1}<x_{2}<\cdots<x_{50}$. If in this sequence there are two consecutive integers, they are coprime and we are done. Otherwise, $x_{50} \geq x_{1}+2 \cdot 49=99$. Equality must hold, since $x_{50}<100$, and in this case the numbers are precisely the 50 odd integers less than 100 . Among them 3 is coprime to 7 . The problem is solved.

Example. Given finitely many squares whose areas add up to 1 , show that they can be arranged without overlaps inside a square of area 2. Solution. The guess is that a tight way of arranging the small squares inside the big square is by placing the squares in order of decreasing side length.

To prove that this works, denote by $x$ the side length of the first (that is, the largest) square. Arrange the squares inside a square of side $\sqrt{2}$ in the following way. Place the first in the lower-left corner, the next to its right, and so on, until obstructed by the right side of the big square. Then jump to height $x$, and start building the second horizontal layer of squares by the same rule. Keep going until the squares have been exhausted (see Figure 4).

Let $h$ be the total height of the layers. We are to show that $h \leq \sqrt{2}$, which in turn will imply that all the squares lie inside the square of side $\sqrt{2}$. To this end, we will find a lower bound for the total area of the squares in terms of $x$ and $h$. Let us mentally transfer the first square of each layer to the right side of the previous layer. Now each layer exits the square, as shown in Figure 4.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-029.jpg?height=470&width=549&top_left_y=892&top_left_x=593)

Figure 4

It follows that the sum of the areas of all squares but the first is greater than or equal to $(\sqrt{2}-x)(h-x)$. This is because each newly obtained layer includes rectangles of base $\sqrt{2}-x$ and with the sum of heights equal to $h-x$. From the fact that the total area of the squares is 1 , it follows that

$$
x^{2}+(\sqrt{2}-x)(h-x) \leq 1 .
$$

This implies that

$$
h \leq \frac{2 x^{2}-\sqrt{2} x-1}{x-\sqrt{2}} .
$$

That $h \leq \sqrt{2}$ will follow from

$$
\frac{2 x^{2}-\sqrt{2} x-1}{x-\sqrt{2}} \leq \sqrt{2} .
$$

This is equivalent to

$$
2 x^{2}-2 \sqrt{2} x+1 \geq 0,
$$

or $(x \sqrt{2}-1)^{2} \geq 0$, which is obvious and we are done.

What we particularly like about the shaded square from Figure 4 is that it plays the role of the "largest square" when placed on the left, and of the "smallest square" when placed on the right. Here are more problems.

52. Given $n \geq 3$ points in the plane, prove that some three of them form an angle less than or equal to $\frac{\pi}{n}$.

53. Consider a planar region of area 1 , obtained as the union of finitely many disks. Prove that from these disks we can select some that are mutually disjoint and have total area at least $\frac{1}{9}$.

54. Suppose that $n(r)$ denotes the number of points with integer coordinates on a circle of radius $r>1$. Prove that

$$
n(r)<2 \pi \sqrt[3]{r^{2}}
$$

55. Prove that among any eight positive integers less than 2004 there are four, say $a, b, c$, and $d$, such that

$$
4+d \leq a+b+c \leq 4 d .
$$

56. Let $a_{1}, a_{2}, \ldots, a_{n}, \ldots$ be a sequence of distinct positive integers. Prove that for any positive integer $n$,

$$
a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2} \geq \frac{2 n+1}{3}\left(a_{1}+a_{2}+\cdots+a_{n}\right) .
$$

57. Let $X$ be a subset of the positive integers with the property that the sum of any two not necessarily distinct elements in $X$ is again in $X$. Suppose that $\left\{a_{1}, a_{2}, \ldots, a_{n}\right\}$ is the set of all positive integers not in $X$. Prove that $a_{1}+a_{2}+\cdots+a_{n} \leq n^{2}$.

An order on a finite set has maximal and minimal elements. If the order is total, the maximal (respectively, minimal) element is unique. Quite often it is useful to look at such extremal elements, as is the case with the following problem.

Example. Prove that it is impossible to dissect a cube into finitely many cubes, no two of which are the same size. Solution. For the solution, assume that such a dissection exists, and look at the bottom face. It is cut into squares. Take the smallest of these squares. It is not hard to see that this square lies in the interior of the face, meaning that it does not touch any side of the bottom face. Look at the cube that lies right above this square! This cube is surrounded by bigger cubes, so its upper face must again be dissected into squares by the cubes that lie on top of it. Take the smallest of the cubes and repeat the argument. This process never stops, since the cubes that lie on top of one of these little cubes cannot end up all touching the upper face of the original cube. This contradicts the finiteness of the decomposition. Hence the conclusion.

By contrast, a square can be dissected into finitely many squares of distinct size. Why does the above argument not apply in this case?

And now an example of a more exotic kind.

Example. Given is a finite set of spherical planets, all of the same radius and no two intersecting. On the surface of each planet consider the set of points not visible from any other planet. Prove that the total area of these sets is equal to the surface area of one planet.

Solution. The problem was on the short list of the 22nd International Mathematical Olympiad, proposed by the Soviet Union. The solution below we found in I. Cuculescu's book on the International Mathematical Olympiads (Editura Tehnică, Bucharest, 1984).

Choose a preferential direction in space, which defines the north pole of each planet. Next, define an order on the set of planets by saying that planet $A$ is greater than planet $B$ if on removing all other planets from space, the north pole of $B$ is visible from $A$. Figure 5 shows that for two planets $A$ and $B$, either $A<B$ or $B<A$, and also that for three planets $A, B, C$, if $A<B$ and $B<C$ then $A<C$. The only case in which something can go wrong is that in which the preferential direction is perpendicular to the segment joining the centers of two planets. If this is not the case, then $<$ defines a total order on the planets. This order has a unique maximal element $M$. The north pole of $M$ is the only north pole not visible from another planet.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-031.jpg?height=336&width=822&top_left_y=1770&top_left_x=462)

Figure 5 Now consider a sphere of the same radius as the planets. Remove from it all north poles defined by directions that are perpendicular to the axes of two of the planets. This is a set of area zero. For every other point on this sphere, there exists a direction in space that makes it the north pole, and for that direction, there exists a unique north pole on one of the planets that is not visible from the others. As such, the surface of the newly introduced sphere is covered by patches translated from the other planets. Hence the total area of invisible points is equal to the area of this sphere, which in turn is the area of one of the planets.

58. Complete the square in Figure 6 with integers between 1 and 9 such that the sum of the numbers in each row, column, and diagonal is as indicated.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-032.jpg?height=382&width=461&top_left_y=767&top_left_x=644)

\section{Figure 6}

59. Given $n$ points in the plane, no three of which are collinear, show that there exists a closed polygonal line with no self-intersections having these points as vertices.

60. Show that any polygon in the plane has a vertex, and a side not containing that vertex, such that the projection of the vertex onto the side lies in the interior of the side or at one of its endpoints.

61. In some country all roads between cities are one-way and such that once you leave a city you cannot return to it again. Prove that there exists a city into which all roads enter and a city from which all roads exit.

62. At a party assume that no boy dances with all the girls, but each girl dances with at least one boy. Prove that there are two girl-boy couples $g b$ and $g^{\prime} b^{\prime}$ who dance, whereas $b$ does not dance with $g^{\prime}$, and $g$ does not dance with $b^{\prime}$.

63. The entries of a matrix are real numbers of absolute value less than or equal to 1 , and the sum of the elements in each column is 0 . Prove that we can permute the elements of each column in such a way that the sum of the elements in each row will have absolute value less than or equal to 2 .

64. Find all odd positive integers $n$ greater than 1 such that for any coprime divisors $a$ and $b$ of $n$, the number $a+b-1$ is also a divisor of $n$. 

65. The positive integers are colored by two colors. Prove that there exists an infinite sequence of positive integers $k_{1}<k_{2}<\cdots<k_{n}<\cdots$ with the property that the terms of the sequence $2 k_{1}<k_{1}+k_{2}<2 k_{2}<k_{2}+k_{3}<2 k_{3}<\cdots$ are all of the same color.

66. Let $P_{1} P_{2} \ldots P_{n}$ be a convex polygon in the plane. Assume that for any pair of vertices $P_{i}$ and $P_{j}$, there exists a vertex $P_{k}$ of the polygon such that $\angle P_{i} P_{k} P_{j}=\pi / 3$. Show that $n=3$.

\subsection{Invariants and Semi-Invariants}

In general, a mathematical object can be studied from many points of view, and it is always desirable to decide whether various constructions produce the same object. One usually distinguishes mathematical objects by some of their properties. An elegant method is to associate to a family of mathematical objects an invariant, which can be a number, an algebraic structure, or some property, and then distinguish objects by the different values of the invariant.

The general framework is that of a set of objects or configurations acted on by transformations that identify them (usually called isomorphisms). Invariants then give obstructions to transforming one object into another. Sometimes, although not very often, an invariant is able to tell precisely which objects can be transformed into one another, in which case the invariant is called complete.

An example of an invariant (which arises from more advanced mathematics yet is easy to explain) is the property of a knot to be 3-colorable. Formally, a knot is a simple closed curve in $\mathbb{R}^{3}$. Intuitively it is a knot on a rope with connected endpoints, such as the right-handed trefoil knot from Figure 7.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-033.jpg?height=316&width=511&top_left_y=1489&top_left_x=612)

Figure 7

How can one prove mathematically that this knot is indeed "knotted"? The answer is, using an invariant. To define this invariant, we need the notion of a knot diagram. Such a diagram is the image of a regular projection (all self-intersections are nontangential and are double points) of the knot onto a plane with crossing information recorded at each double point, just like the one in Figure 7. But a knot can have many diagrams (pull the strands around, letting them pass over each other). A deep theorem of Reidemeister states that two diagrams represent the same knot if they can be transformed into one another by the three types of moves described in Figure 8.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-034.jpg?height=462&width=890&top_left_y=434&top_left_x=426)

Figure 8

The simplest knot invariant was introduced by the same Reidemeister, and is the property of a knot diagram to be 3-colorable. This means that you can color each strand in the knot diagram by a residue class modulo 3 such that

(i) at least two distinct residue classes modulo 3 are used, and

(ii) at each crossing, $a+c \equiv 2 b(\bmod 3)$, where $b$ is the color of the arc that crosses over, and $a$ and $c$ are the colors of the other two arcs (corresponding to the strand that crosses under).

It is rather easy to prove, by examining the local picture, that this property is invariant under Reidemeister moves. Hence this is an invariant of knots, not just of knot diagrams.

The trefoil knot is 3-colorable, as demonstrated in Figure 9. On the other hand, the unknotted circle is not 3-colorable, because its simplest diagram, the one with no crossings, cannot be 3-colored. Hence the trefoil knot is knotted.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-034.jpg?height=316&width=511&top_left_y=1651&top_left_x=612)

Figure 9

This 3-colorability is, however, not a complete invariant. We now give an example of a complete invariant from geometry. In the early nineteenth century, F. Bolyai and a less well-known mathematician Gerwin proved that given two polygons of equal area, the first can be dissected by finitely many straight cuts and then assembled to produce the second polygon. In his list of 23 problems presented to the International Congress of Mathematicians, D. Hilbert listed as number 7 the question whether the same property remains true for solid polyhedra of the same volume, and if not, what would the obstruction be.

The problem was solved by M. Dehn, a student of Hilbert. Dehn defined an invariant that associates to a finite disjoint union of polyhedra $P$ the sum $I(P)$ of all their dihedral angles reduced modulo rational multiples of $\pi$ (viewed as an element in $\mathbb{R} / \pi \mathbb{Q}$ ). He showed that two polyhedra $P_{1}$ and $P_{2}$ having the same volume can be transformed into one another if and only if $I\left(P_{1}\right)=I\left(P_{2}\right)$, i.e., if and only if the sums of their dihedral angles differ by a rational multiple of $\pi$.

It is good to know that the quest for invariants dominated twentieth-century geometry. That being said, let us return to the realm of elementary mathematics with a short list problem from the 46th International Mathematical Olympiad.

Example. There are $n$ markers, each with one side white and the other side black, aligned in a row with their white sides up. At each step, if possible, we choose a marker with the white side up (but not one of the outermost markers), remove it, and reverse the two neighboring markers. Prove that one can reach a configuration with only two markers left if and only if $n-1$ is not divisible by 3 .

Solution. We refer to a marker by the color of its visible face. Note that the parity of the number of black markers remains unchanged during the game. Hence if only two markers are left, they must have the same color.

We define an invariant as follows. To a white marker with $t$ black markers to its left we assign the number $(-1)^{t}$. Only white markers have numbers assigned to them. The invariant $S$ is the residue class modulo 3 of the sum of all numbers assigned to the white markers.

It is easy to check that $S$ is invariant under the operation defined in the statement. For instance, if a white marker with $t$ black markers on the left and whose neighbors are both black is removed, then $S$ increases by $-(-1)^{t}+(-1)^{t-1}+(-1)^{t-1}=3(-1)^{t-1}$, which is zero modulo 3 . The other three cases are analogous.

If the game ends with two black markers then $S$ is zero; if it ends with two white markers, then $S$ is 2 . This proves that $n-1$ is not divisible by 3 .

Conversely, if we start with $n \geq 5$ white markers, $n \equiv 0$ or 2 modulo 3 , then by removing in three consecutive moves the leftmost allowed white markers, we obtain a row of $n-3$ white markers. Working backward, we can reach either 2 white markers or 3 white markers. In the latter case, with one more move we reach 2 black markers as desired.

Now try to find the invariants that lead to the solutions of the following problems. 

67. An ordered triple of numbers is given. It is permitted to perform the following operation on the triple: to change two of them, say $a$ and $b$, to $(a+b) / \sqrt{2}$ and $(a-b) / \sqrt{2}$. Is it possible to obtain the triple $(1, \sqrt{2}, 1+\sqrt{2})$ from the triple $(2, \sqrt{2}, 1 / \sqrt{2})$ using this operation?

68. There are 2000 white balls in a box. There are also unlimited supplies of white, green, and red balls, initially outside the box. During each turn, we can replace two balls in the box with one or two balls as follows: two whites with a green, two reds with a green, two greens with a white and red, a white and a green with a red, or a green and red with a white.

(a) After finitely many of the above operations there are three balls left in the box. Prove that at least one of them is green.

(b) Is it possible that after finitely many operations only one ball is left in the box?

69. There is a heap of 1001 stones on a table. You are allowed to perform the following operation: you choose one of the heaps containing more than one stone, throw away a stone from the heap, then divide it into two smaller (not necessarily equal) heaps. Is it possible to reach a situation in which all the heaps on the table contain exactly 3 stones by performing the operation finitely many times?

70. Starting with an ordered quadruple of positive integers, a generalized Euclidean algorithm is applied successively as follows: if the numbers are $x, y, u, v$ and $x>y$, then the quadruple is replaced by $x-y, y, u+v, v$. Otherwise, it is replaced by $x, y-x, u, v+u$. The algorithm stops when the numbers in the first pair become equal (in which case they are equal to the greatest common divisor of $x$ and $y$ ). Assume that we start with $m, n, m, n$. Prove that when the algorithm ends, the arithmetic mean of the numbers in the second pair equals the least common multiple of $m$ and $n$.

71. On an arbitrarily large chessboard consider a generalized knight that can jump $p$ squares in one direction and $q$ in the other, $p, q>0$. Show that such a knight can return to its initial position only after an even number of jumps.

72. Prove that the figure eight knot described in Figure 10 is knotted.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-036.jpg?height=285&width=366&top_left_y=1782&top_left_x=684)

Figure 10 

73. In the squares of a $3 \times 3$ chessboard are written the signs $+$ and $-$ as described in Figure 11(a). Consider the operations in which one is allowed to simultaneously change all signs in some row or column. Can one change the given configuration to the one in Figure 11(b) by applying such operations finitely many times?
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-037.jpg?height=234&width=794&top_left_y=470&top_left_x=468)

Figure 11

74. The number $99 \ldots 99$ (having 1997 nines) is written on a blackboard. Each minute, one number written on the blackboard is factored into two factors and erased, each factor is (independently) increased or decreased by 2 , and the resulting two numbers are written. Is it possible that at some point all of the numbers on the blackboard are equal to 9 ?

75. Four congruent right triangles are given. One can cut one of them along the altitude and repeat the operation several times with the newly obtained triangles. Prove that no matter how we perform the cuts, we can always find among the triangles two that are congruent.

76. For an integer $n \geq 4$, consider an $n$-gon inscribed in a circle. Dissect the $n$-gon into $n-2$ triangles by nonintersecting diagonals. Prove that the sum of the radii of the incircles of these $n-2$ triangles does not depend on the dissection.

In some cases a semi-invariant will do. A semi-invariant is a quantity that, although not constant under a specific transformation, keeps increasing (or decreasing). As such it provides a unidirectional obstruction.

For his solution to the following problem from the 27th International Mathematical Olympiad, J. Keane, then a member of the US team, was awarded a special prize.

Example. To each vertex of a regular pentagon an integer is assigned in such a way that the sum of all of the five numbers is positive. If three consecutive vertices are assigned the numbers $x, y, z$, respectively, and $y<0$, then the following operation is allowed: the numbers $x, y, z$ are replaced by $x+y,-y, z+y$, respectively. Such an operation is performed repeatedly as long as at least one of the five numbers is negative. Determine whether this procedure necessarily comes to an end after a finite number of steps.

Solution. The answer is yes. The key idea of the proof is to construct an integer-valued semi-invariant whose value decreases when the operation is performed. The existence of such a semi-invariant will guarantee that the operation can be performed only finitely many times. Notice that the sum of the five numbers on the pentagon is preserved by the operation, so it is natural to look at the sum of the absolute values of the five numbers. When the operation is performed this quantity decreases by $|x|+|z|-|x+y|-|y+z|$. Although this expression is not always positive, it suggests a new choice. The desired semi-invariant should include the absolute values of pairwise sums as well. Upon testing the new expression and continuing this idea, we discover in turn that the desired semi-invariant should also include absolute values of sums of triples and foursomes. At last, with a pentagon numbered $v, w, x, y, z$ and the semi-invariant defined by

$$
\begin{aligned}
S(v, w, x, y, z)=&|v|+|w|+|x|+|y|+|z|+|v+w|+|w+x|+|x+y| \\
&+|y+z|+|z+v|+|v+w+x|+|w+x+y|+|x+y+z| \\
&+|y+z+v|+|z+v+w|+|v+w+x+y|+|w+x+y+z| \\
&+|x+y+z+v|+|y+z+v+w|+|z+v+w+x|,
\end{aligned}
$$

we find that the operation reduces the value of $S$ by the simple expression $\mid z+v+w+$ $x|-| z+v+w+x+2 y|=| s-y|-| s+y \mid$, where $s=v+w+x+y+z$. Since $s>0$ and $y<0$, we see that $|s-y|-|s+y|>0$, so $S$ has the required property. It follows that the operation can be performed only finitely many times.

Using the semi-invariant we produced a proof based on Fermat's infinite descent method. This method will be explained in the Number Theory chapter of this book. Here the emphasis was on the guess of the semi-invariant. And now some problems.

77. A real number is written in each square of an $n \times n$ chessboard. We can perform the operation of changing all signs of the numbers in a row or a column. Prove that by performing this operation a finite number of times we can produce a new table for which the sum of each row or column is positive.

78. Starting with an ordered quadruple of integers, perform repeatedly the operation

$$
(a, b, c, d) \stackrel{T}{\longrightarrow}(|a-b|,|b-c|,|c-d|,|d-a|) .
$$

Prove that after finitely many steps, the quadruple becomes $(0,0,0,0)$.

79. Several positive integers are written on a blackboard. One can erase any two distinct integers and write their greatest common divisor and least common multiple instead. Prove that eventually the numbers will stop changing.

80. Consider the integer lattice in the plane, with one pebble placed at the origin. We play a game in which at each step one pebble is removed from a node of the lattice and two new pebbles are placed at two neighboring nodes, provided that those nodes are unoccupied. Prove that at any time there will be a pebble at distance at most 5 from the origin. 

\section{Algebra}

It is now time to split mathematics into branches. First, algebra. A section on algebraic identities hones computational skills. It is followed naturally by inequalities. In general, any inequality can be reduced to the problem of finding the minimum of a function. But this is a highly nontrivial matter, and that is what makes the subject exciting. We discuss the fact that squares are nonnegative, the Cauchy-Schwarz inequality, the triangle inequality, the arithmetic mean-geometric mean inequality, and also Sturm's method for proving inequalities.

Our treatment of algebra continues with polynomials. We focus on the relations between zeros and coefficients, the properties of the derivative of a polynomial, problems about the location of the zeros in the complex plane or on the real axis, and methods for proving irreducibility of polynomials (such as the Eisenstein criterion). From all special polynomials we present the most important, the Chebyshev polynomials.

Linear algebra comes next. The first three sections, about operations with matrices, determinants, and the inverse of a matrix, insist on both the array structure of a matrix and the ring structure of the set of matrices. They are more elementary, as is the section on linear systems. The last three sections, about vector spaces and linear transformations, are more advanced, covering among other things the Cayley-Hamilton Theorem and the Perron-Frobenius Theorem.

The chapter concludes with a brief incursion into abstract algebra: binary operations, groups, and rings, really no further than the definition of a group or a ring.

\subsection{Identities and Inequalities}

\subsubsection{Algebraic Identities}

The scope of this section is to train algebraic skills. Our idea is to hide behind each problem an important algebraic identity. We commence with three examples, the first and the last written by the second author of the book, and the second given at a Soviet Union college entrance exam and suggested to us by A. Soifer.

Example. Solve in real numbers the system of equations

$$
\begin{aligned}
(3 x+y)(x+3 y) \sqrt{x y} &=14, \\
(x+y)\left(x^{2}+14 x y+y^{2}\right) &=36 .
\end{aligned}
$$

Solution. By substituting $\sqrt{x}=u, \sqrt{y}=v$, we obtain the equivalent form

$$
\begin{aligned}
u v\left(3 u^{4}+10 u^{2} v^{2}+3 v^{4}\right) &=14, \\
u^{6}+15 u^{4} v^{2}+15 u^{2} v^{4}+v^{6} &=36 .
\end{aligned}
$$

Here we should recognize elements of the binomial expansion with exponent equal to 6 . Based on this observation we find that

$$
36+2 \cdot 14=u^{6}+6 u^{5} v+15 u^{4} v^{2}+20 u^{3} v^{3}+15 u^{2} v^{4}+6 u v^{5}+v^{6}
$$

and

$$
36-2 \cdot 14=u^{6}-6 u^{5} v+15 u^{4} v^{2}-20 u^{3} v^{3}+15 u^{2} v^{4}-6 u v^{5}+v^{6} .
$$

Therefore, $(u+v)^{6}=64$ and $(u-v)^{6}=8$, which implies $u+v=2$ and $u-v=\pm \sqrt{2}$ (recall that $u$ and $v$ have to be positive). So $u=1+\frac{\sqrt{2}}{2}$ and $v=1-\frac{\sqrt{2}}{2}$ or $u=1-\frac{\sqrt{2}}{2}$ and $v=1+\frac{\sqrt{2}}{2}$. The solutions to the system are

$$
(x, y)=\left(\frac{3}{2}+\sqrt{2}, \frac{3}{2}-\sqrt{2}\right) \quad \text { and } \quad(x, y)=\left(\frac{3}{2}-\sqrt{2}, \frac{3}{2}+\sqrt{2}\right) .
$$

Example. Given two segments of lengths $a$ and $b$, construct with a straightedge and a compass a segment of length $\sqrt[4]{a^{4}+b^{4}}$.

Solution. The solution is based on the following version of the Sophie Germain identity:

$$
a^{4}+b^{4}=\left(a^{2}+\sqrt{2} a b+b^{2}\right)\left(a^{2}-\sqrt{2} a b+b^{2}\right) .
$$

Write

$$
\sqrt[4]{a^{4}+b^{4}}=\sqrt{\sqrt{a^{2}+\sqrt{2} a b+b^{2}} \cdot \sqrt{a^{2}-\sqrt{2} a b+b^{2}}} .
$$

Applying the law of cosines, we can construct segments of lengths $\sqrt{a^{2} \pm \sqrt{2} a b+b^{2}}$ using triangles of sides $a$ and $b$ with the angle between them $135^{\circ}$, respectively, $45^{\circ}$.

On the other hand, given two segments of lengths $x$, respectively, $y$, we can construct a segment of length $\sqrt{x y}$ (their geometric mean) as the altitude $A D$ in a right triangle $A B C\left(\angle A=90^{\circ}\right)$ with $B D=x$ and $C D=y$. These two steps combined give the method for constructing $\sqrt[4]{a^{4}+b^{4}}$. Example. Let $x, y, z$ be distinct real numbers. Prove that

$$
\sqrt[3]{x-y}+\sqrt[3]{y-z}+\sqrt[3]{z-x} \neq 0 .
$$

Solution. The solution is based on the identity

$$
a^{3}+b^{3}+c^{3}-3 a b c=(a+b+c)\left(a^{2}+b^{2}+c^{2}-a b-b c-c a\right) .
$$

This identity comes from computing the determinant

$$
D=\left|\begin{array}{lll}
a & b & c \\
c & a & b \\
b & c & a
\end{array}\right|
$$

in two ways: first by expanding with Sarrus' rule, and second by adding up all columns to the first, factoring $(a+b+c)$, and then expanding the remaining determinant. Note that this identity can also be written as

$$
a^{3}+b^{3}+c^{3}-3 a b c=\frac{1}{2}(a+b+c)\left[(a-b)^{2}+(b-c)^{2}+(c-a)^{2}\right] .
$$

Returning to the problem, let us assume the contrary, and set $\sqrt[3]{x-y}=a, \sqrt[3]{y-z}=$ $b, \sqrt[3]{z-x}=c$. By assumption, $a+b+c=0$, and so $a^{3}+b^{3}+c^{3}=3 a b c$. But this implies

$$
0=(x-y)+(y-z)+(z-x)=3 \sqrt[3]{x-y} \sqrt[3]{y-z} \sqrt[3]{z-x} \neq 0,
$$

since the numbers are distinct. The contradiction we have reached proves that our assumption is false, and so the sum is nonzero.

And now the problems.

81. Show that for no positive integer $n$ can both $n+3$ and $n^{2}+3 n+3$ be perfect cubes.

82. Let $A$ and $B$ be two $n \times n$ matrices that commute and such that for some positive integers $p$ and $q, A^{p}=\mathcal{I}_{n}$ and $B^{q}=\mathcal{O}_{n}$. Prove that $A+B$ is invertible, and find its inverse.

83. Prove that any polynomial with real coefficients that takes only nonnegative values can be written as the sum of the squares of two polynomials.

84. Prove that for any nonnegative integer $n$, the number

$$
5^{5^{n+1}}+5^{5^{n}}+1
$$

is not prime. 

85. Show that for an odd integer $n \geq 5$,

$$
\left(\begin{array}{l}
n \\
0
\end{array}\right) 5^{n-1}-\left(\begin{array}{l}
n \\
1
\end{array}\right) 5^{n-2}+\left(\begin{array}{l}
n \\
2
\end{array}\right) 5^{n-3}-\cdots+\left(\begin{array}{c}
n \\
n-1
\end{array}\right)
$$

is not a prime number.

86. Factor $5^{1985}-1$ into a product of three integers, each of which is greater than $5^{100}$.

87. Prove that the number

$$
\frac{5^{125}-1}{5^{25}-1}
$$

is not prime.

88. Let $a$ and $b$ be coprime integers greater than 1. Prove that for no $n \geq 0$ is $a^{2 n}+b^{2 n}$ divisible by $a+b$.

89. Prove that any integer can be written as the sum of five perfect cubes.

90. Solve in real numbers the equation

$$
\sqrt[3]{x-1}+\sqrt[3]{x}+\sqrt[3]{x+1}=0
$$

91. Find all triples $(x, y, z)$ of positive integers such that

$$
x^{3}+y^{3}+z^{3}-3 x y z=p,
$$

where $p$ is a prime number greater than 3 .

92. Let $a, b, c$ be distinct positive integers such that $a b+b c+c a \geq 3 k^{2}-1$, where $k$ is a positive integer. Prove that

$$
a^{3}+b^{3}+c^{3} \geq 3(a b c+3 k) .
$$

93. Find all triples $(m, n, p)$ of positive integers such that $m+n+p=2002$ and the system of equations $\frac{x}{y}+\frac{y}{x}=m, \frac{y}{z}+\frac{z}{y}=n, \frac{z}{x}+\frac{x}{z}=p$ has at least one solution in nonzero real numbers.

\subsection{2 $x^{2} \geq 0$}

We now turn to inequalities. The simplest inequality in algebra says that the square of any real number is nonnegative, and it is equal to zero if and only if the number is zero. We illustrate how this inequality can be used with an example by the second author of the book. Example. Find the minimum of the function $f:(0, \infty)^{3} \rightarrow \mathbb{R}$,

$$
f(x, y, z)=x^{z}+y^{z}-(x y)^{z / 4} .
$$

Solution. Rewrite the function as

$$
f(x, y, z)=\left(x^{z / 2}-y^{z / 2}\right)^{2}+2\left[(x y)^{z / 4}-\frac{1}{4}\right]^{2}-\frac{1}{8} .
$$

We now see that the minimum is $-\frac{1}{8}$, achieved if and only if $(x, y, z)=\left(a, a, \log _{a} \frac{1}{16}\right)$, where $a \in(0,1) \cup(1, \infty)$.

We continue with a problem from the 2001 USA team selection test proposed also by the second author of the book.

Example. Let $\left(a_{n}\right)_{n \geq 0}$ be a sequence of real numbers such that

$$
a_{n+1} \geq a_{n}^{2}+\frac{1}{5}, \quad \text { for all } n \geq 0 .
$$

Prove that $\sqrt{a_{n+5}} \geq a_{n-5}^{2}$, for all $n \geq 5$.

Solution. It suffices to prove that $a_{n+5} \geq a_{n}^{2}$, for all $n \geq 0$. Let us write the inequality for a number of consecutive indices:

$$
\begin{aligned}
&a_{n+1} \geq a_{n}^{2}+\frac{1}{5}, \\
&a_{n+2} \geq a_{n+1}^{2}+\frac{1}{5}, \\
&a_{n+3} \geq a_{n+2}^{2}+\frac{1}{5}, \\
&a_{n+4} \geq a_{n+3}^{2}+\frac{1}{5}, \\
&a_{n+5} \geq a_{n+4}^{2}+\frac{1}{5} .
\end{aligned}
$$

If we add these up, we obtain

$$
\begin{aligned}
a_{n+5}-a_{n}^{2} & \geq\left(a_{n+1}^{2}+a_{n+2}^{2}+a_{n+3}^{2}+a_{n+4}^{2}\right)-\left(a_{n+1}+a_{n+2}+a_{n+3}+a_{n+4}\right)+5 \cdot \frac{1}{5} \\
&=\left(a_{n+1}-\frac{1}{2}\right)^{2}+\left(a_{n+2}-\frac{1}{2}\right)^{2}+\left(a_{n+3}-\frac{1}{2}\right)^{2}+\left(a_{n+4}-\frac{1}{2}\right)^{2} \geq 0 .
\end{aligned}
$$

The conclusion follows. And finally a more challenging problem from the 64th W.L. Putnam Mathematics Competition.

Example. Let $f$ be a continuous function on the unit square. Prove that

$$
\begin{aligned}
&\int_{0}^{1}\left(\int_{0}^{1} f(x, y) d x\right)^{2} d y+\int_{0}^{1}\left(\int_{0}^{1} f(x, y) d y\right)^{2} d x \\
&\quad \leq\left(\int_{0}^{1} \int_{0}^{1} f(x, y) d x d y\right)^{2}+\int_{0}^{1} \int_{0}^{1} f(x, y)^{2} d x d y .
\end{aligned}
$$

Solution. To make this problem as simple as possible, we prove the inequality for a Riemann sum, and then pass to the limit. Divide the unit square into $n^{2}$ equal squares, then pick a point $\left(x_{i}, y_{j}\right)$ in each such square and define $a_{i j}=f\left(x_{i}, y_{j}\right), i, j=1,2, \ldots, n$. Written for the Riemann sum, the inequality becomes

$$
\frac{1}{n^{3}} \sum_{i}\left(\left(\sum_{j} a_{i j}\right)^{2}+\left(\sum_{j} a_{j i}\right)^{2}\right) \leq \frac{1}{n^{4}}\left(\sum_{i j} a_{i j}\right)^{2}+\frac{1}{n^{2}}\left(\sum_{i j} a_{i j}^{2}\right) .
$$

Multiply this by $n^{4}$, then move everything to one side. After cancellations, the inequality becomes

$$
\left(n^{2}-1\right)^{2} \sum_{i j} a_{i j}^{2}+\sum_{i \neq k, j \neq l} a_{i j} a_{k l}-(n-1) \sum_{i j k, j \neq k}\left(a_{i j} a_{i k}+a_{j i} a_{k i}\right) \geq 0 .
$$

Here we have a quadratic function in the $a_{i j}$ 's that should always be nonnegative. In general, such a quadratic function can be expressed as an algebraic sum of squares, and it is nonnegative precisely when all squares appear with a positive sign. We are left with the problem of representing our expression as a sum of squares. To boost your intuition, look at the following tableau:

$$
\begin{array}{ccccccc}
a_{11} & \cdots & \cdots & \cdots & \cdots & \cdots & a_{1 n} \\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
\cdots & \cdots & a_{i j} & \cdots & a_{i l} & \cdots & \cdots \\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
\cdots & \cdots & a_{k j} & \cdots & a_{k l} & \cdots & \cdots \\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
a_{n 1} & \cdots & \cdots & \cdots & \cdots & \cdots & a_{n n}
\end{array}
$$

The expression

$$
\left(a_{i j}+a_{k l}-a_{i l}-a_{k j}\right)^{2}
$$

when expanded gives rise to the following terms:

$$
a_{i j}^{2}+a_{k l}^{2}+a_{i l}^{2}+a_{k j}^{2}+2 a_{i j} a_{k l}+2 a_{i l} a_{k j}-2 a_{i l} a_{i j}-2 a_{i j} a_{k j}-2 a_{k l} a_{i l}-2 a_{k l} a_{k j} .
$$

For a fixed pair $(i, j)$, the term $a_{i j}$ appears in $(n-1)^{2}$ such expressions. The products $2 a_{i j} a_{k l}$ and $2 a_{i l} a_{k j}$ appear just once, while the products $2 a_{i l} a_{i j}, 2 a_{i j} a_{k j}, 2 a_{k l} a_{i l}, 2 a_{k l} a_{k j}$ appear $(n-1)$ times (once for each square of the form $(i, j),(i, l),(k, j),(k, l))$. It follows that the expression that we are trying to prove is nonnegative is nothing but

$$
\sum_{i j k l}\left(a_{i j}+a_{k l}-a_{i l}-a_{k j}\right)^{2},
$$

which is of course nonnegative. This proves the inequality for all Riemann sums of the function $f$, and hence for $f$ itself.

94. Find

$$
\min _{a, b \in \mathbb{R}} \max \left(a^{2}+b, b^{2}+a\right) .
$$

95. Prove that for all real numbers $x$,

$$
2^{x}+3^{x}-4^{x}+6^{x}-9^{x} \leq 1 .
$$

96. Find all positive integers $n$ for which the equation

$$
n x^{4}+4 x+3=0
$$

has a real root.

97. Find all triples $(x, y, z)$ of real numbers that are solutions to the system of equations

$$
\begin{aligned}
&\frac{4 x^{2}}{4 x^{2}+1}=y, \\
&\frac{4 y^{2}}{4 y^{2}+1}=z, \\
&\frac{4 z^{2}}{4 z^{2}+1}=x .
\end{aligned}
$$

98. Find the minimum of

$$
\log _{x_{1}}\left(x_{2}-\frac{1}{4}\right)+\log _{x_{2}}\left(x_{3}-\frac{1}{4}\right)+\cdots+\log _{x_{n}}\left(x_{1}-\frac{1}{4}\right)
$$

over all $x_{1}, x_{2}, \ldots, x_{n} \in\left(\frac{1}{4}, 1\right)$. 

99. Let $a$ and $b$ be real numbers such that

$$
9 a^{2}+8 a b+7 b^{2} \leq 6 .
$$

Prove that $7 a+5 b+12 a b \leq 9$

100. Let $a_{1}, a_{2}, \ldots, a_{n}$ be real numbers such that $a_{1}+a_{2}+\cdots+a_{n} \geq n^{2}$ and $a_{1}^{2}+a_{2}^{2}+$ $\cdots+a_{n}^{2} \leq n^{3}+1$. Prove that $n-1 \leq a_{k} \leq n+1$ for all $k$.

101. Find all pairs $(x, y)$ of real numbers that are solutions to the system

$$
\begin{aligned}
&x^{4}+2 x^{3}-y=-\frac{1}{4}+\sqrt{3}, \\
&y^{4}+2 y^{3}-x=-\frac{1}{4}-\sqrt{3} .
\end{aligned}
$$

102. Let $n$ be an even positive integer. Prove that for any real number $x$ there are at least $2^{n / 2}$ choices of the signs $+$ and $-$ such that

$$
\pm x^{n} \pm x^{n-1} \pm \cdots \pm x<\frac{1}{2} .
$$

\subsubsection{The Cauchy-Schwarz Inequality}

A direct application of the discussion in the previous section is the proof of the CauchySchwarz (or Cauchy-Bunyakovski-Schwarz) inequality

$$
\sum_{k=1}^{n} a_{k}^{2} \sum_{k=1}^{n} b_{k}^{2} \geq\left(\sum_{k=1}^{n} a_{k} b_{k}\right)^{2},
$$

where the equality holds if and only if the $a_{i}$ 's and the $b_{i}$ 's are proportional. The expression

$$
\sum_{k=1}^{n} a_{k}^{2} \sum_{k=1}^{n} b_{k}^{2}-\left(\sum_{k=1}^{n} a_{k} b_{k}\right)^{2}
$$

is a quadratic function in the $a_{i}$ 's and $b_{i}$ 's. For it to have only nonnegative values, it should be a sum of squares. And this is true by the Lagrange identity

$$
\sum_{k=1}^{n} a_{k}^{2} \sum_{k=1}^{n} b_{k}^{2}-\left(\sum_{k=1}^{n} a_{k} b_{k}\right)^{2}=\sum_{i<k}\left(a_{i} b_{k}-a_{k} b_{i}\right)^{2} .
$$

Sadly, this proof works only in the finite-dimensional case, while the CauchySchwarz inequality is true in far more generality, such as for square integrable functions. Its correct framework is that of a real or complex vector space, which could be finite or infinite dimensional, endowed with an inner product $\langle\cdot, \cdot\rangle$.

By definition, an inner product is subject to the following conditions: (i) $\langle x, x\rangle \geq 0$, with equality if and only if $x=0$,

(ii) $\langle x, y\rangle=\overline{\langle y, x\rangle}$, for any vectors $x, y$ (here the bar stands for complex conjugation if the vector space is complex),

(iii) $\left\langle\lambda_{1} x_{1}+\lambda_{2} x_{2}, y\right\rangle=\lambda_{1}\left\langle x_{1}, y\right\rangle+\lambda_{2}\left\langle x_{2}, y\right\rangle$, for any vectors $x_{1}, x_{2}, y$ and scalars $\lambda_{1}$ and $\lambda_{2}$.

The quantity $\|x\|=\sqrt{\langle x, x\rangle}$ is called the norm of $x$. Examples of inner product spaces are $\mathbb{R}^{n}$ with the usual dot product, $\mathbb{C}^{n}$ with the inner product

$$
\left\langle\left(z_{1}, z_{2}, \ldots, z_{n}\right),\left(w_{1}, w_{2}, \ldots, w_{n}\right)\right\rangle=z_{1} \overline{w_{1}}+z_{2} \overline{w_{2}}+\cdots+z_{n} \overline{w_{n}},
$$

but also the space of square integrable functions on an interval $[a, b]$ with the inner product

$$
\langle f, g\rangle=\int_{a}^{b} f(t) \overline{g(t)} d t .
$$

The Cauchy-Schwarz inequality. Let $x, y$ be two vectors. Then

$$
\|x\| \cdot\|y\| \geq|\langle x, y\rangle|,
$$

with equality if and only if the vectors $x$ and $y$ are parallel and point in the same direction.

Proof. We have

$$
0 \leq\langle\|y\| x-\|x\| y,\|y\| x-\|x\| y\rangle=2\|x\|^{2}\|y\|^{2}-\|x\|\|y\|(\langle x, y\rangle+\langle y, x\rangle),
$$

hence $2\|x\| \cdot\|y\| \geq(\langle x, y\rangle+\langle y, x\rangle)$. Yet another trick: rotate $y$ by $\langle x, y\rangle /|\langle x, y\rangle|$. The left-hand side does not change, but because of property (ii) the right-hand side becomes $\frac{1}{\langle\langle x, y\rangle|}(\langle x, y\rangle \overline{\langle x, y\rangle}+\overline{\langle x, y\rangle}\langle x, y\rangle)$, which is the same as $2|\langle x, y\rangle|$. It follows that

$$
\|x\| \cdot\|y\| \geq|\langle x, y\rangle|,
$$

which is the Cauchy-Schwarz inequality in its full generality. In our sequence of deductions, the only inequality that showed up holds with equality precisely when the vectors are parallel and point in the same direction.

As an example, if $f$ and $g$ are two complex-valued continuous functions on the interval $[a, b]$, or more generally two square integrable functions, then

$$
\int_{a}^{b}|f(t)|^{2} d t \int_{a}^{b}|g(t)|^{2} d t \geq\left|\int_{a}^{b} f(t) \overline{g(t)} d t\right|^{2} .
$$

Let us turn to more elementary problems. Example. Find the maximum of the function $f(x, y, z)=5 x-6 y+7 z$ on the ellipsoid $2 x^{2}+3 y^{2}+4 z^{2}=1$

Solution. For a point $(x, y, z)$ on the ellipsoid,

$$
\begin{aligned}
(f(x, y, z))^{2} &=(5 x-6 y+7 z)^{2}=\left(\frac{5}{\sqrt{2}} \cdot \sqrt{2} x-\frac{6}{\sqrt{3}} \cdot \sqrt{3} y+\frac{7}{2} \cdot 2 z\right)^{2} \\
& \leq\left(\left(\frac{5}{\sqrt{2}}\right)^{2}+\left(-\frac{6}{\sqrt{3}}\right)^{2}+\left(\frac{7}{2}\right)^{2}\right)\left((\sqrt{2} x)^{2}+(\sqrt{3} y)^{2}+(2 z)^{2}\right) \\
&=\frac{147}{4}\left(2 x^{2}+3 y^{2}+4 z^{2}\right)=\frac{147}{4} .
\end{aligned}
$$

Hence the maximum of $f$ is $\sqrt{147} / 2$, reached at the point $(x, y, z)$ on the ellipsoid for which $x, z>0, y<0$, and $x: y: z=\frac{5}{\sqrt{2}}:-\frac{6}{\sqrt{3}}: \frac{7}{2}$.

The next problem was on the short list of the 1993 International Mathematical Olympiad, being proposed by the second author of the book.

Example. Prove that

$$
\frac{a}{b+2 c+3 d}+\frac{b}{c+2 d+3 a}+\frac{c}{b+2 a+3 b}+\frac{d}{a+2 b+3 c} \geq \frac{2}{3},
$$

for all $a, b, c, d>0$.

Solution. Denote by $E$ the expression on the left. Then

$$
\begin{aligned}
4(a b+a c+a d+b c+b d+c d) E \\
=&(a(b+2 c+3 d)+b(c+2 d+3 a)+c(d+2 a+3 b)+d(a+2 b+3 c)) \\
& \times\left(\frac{a}{b+2 c+3 d}+\frac{b}{c+2 d+3 a}+\frac{c}{b+2 a+3 b}+\frac{d}{a+2 b+3 c}\right) \\
\geq &(a+b+c+d)^{2},
\end{aligned}
$$

where the last inequality is a well-disguised Cauchy-Schwarz. Finally,

$$
3(a+b+c+d)^{2} \geq 8(a b+a c+a d+b c+b d+c d),
$$

because it reduces to

$$
(a-b)^{2}+(a-c)^{2}+(a-d)^{2}+(b-c)^{2}+(b-d)^{2}+(c-d)^{2} \geq 0 .
$$

Combining these two and cancelling the factor $a b+a c+a d+b c+b d+c d$, we obtain the inequality from the statement. And now a list of problems, all of which are to be solved using the Cauchy-Schwarz inequality.

103. If $a, b, c$ are positive numbers, prove that

$$
9 a^{2} b^{2} c^{2} \leq\left(a^{2} b+b^{2} c+c^{2} a\right)\left(a b^{2}+b c^{2}+c a^{2}\right) .
$$

104. If $a_{1}+a_{2}+\cdots+a_{n}=n$ prove that $a_{1}^{4}+a_{2}^{4}+\cdots+a_{n}^{4} \geq n$.

105. Let $a_{1}, a_{2}, \ldots, a_{n}$ be distinct real numbers. Find the maximum of

$$
a_{1} a_{\sigma(a)}+a_{2} a_{\sigma(2)}+\cdots+a_{n} a_{\sigma(n)}
$$

over all permutations of the set $\{1,2, \ldots, n\}$.

106. Let $f_{1}, f_{2}, \ldots, f_{n}$ be positive real numbers. Prove that for any real numbers $x_{1}, x_{2}, \ldots, x_{n}$, the quantity

$$
f_{1} x_{1}^{2}+f_{2} x_{2}^{2}+\cdots+f_{n} x_{n}^{2}-\frac{\left(f_{1} x_{1}+f_{2} x_{2}+\cdots+f_{n} x_{n}\right)^{2}}{f_{1}+f_{2}+\cdots+f_{n}}
$$

is nonnegative.

107. Find all positive integers $n, k_{1}, \ldots, k_{n}$ such that $k_{1}+\cdots+k_{n}=5 n-4$ and

$$
\frac{1}{k_{1}}+\cdots+\frac{1}{k_{n}}=1 .
$$

108. Prove that the finite sequence $a_{0}, a_{1}, \ldots, a_{n}$ of positive real numbers is a geometric progression if and only if

$$
\left(a_{0} a_{1}+a_{1} a_{2}+\cdots+a_{n-1} a_{n}\right)^{2}=\left(a_{0}^{2}+a_{1}^{2}+\cdots+a_{n-1}^{2}\right)\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right) .
$$

109. Let $P(x)$ be a polynomial with positive real coefficients. Prove that

$$
\sqrt{P(a) P(b)} \geq P(\sqrt{a b}),
$$

for all positive real numbers $a$ and $b$.

110. Consider the real numbers $x_{0}>x_{1}>x_{2}>\cdots>x_{n}$. Prove that

$$
x_{0}+\frac{1}{x_{0}-x_{1}}+\frac{1}{x_{1}-x_{2}}+\cdots+\frac{1}{x_{n-1}-x_{n}} \geq x_{n}+2 n \text {. }
$$

When does equality hold? 

111. Prove that

$$
\frac{\sin ^{3} a}{\sin b}+\frac{\cos ^{3} a}{\cos b} \geq \sec (a-b),
$$

for all $a, b \in\left(0, \frac{\pi}{2}\right)$.

112. Prove that

$$
\frac{1}{a+b}+\frac{1}{b+c}+\frac{1}{c+a}+\frac{1}{2 \sqrt[3]{a b c}} \geq \frac{(a+b+c+\sqrt[3]{a b c})^{2}}{(a+b)(b+c)(c+a)},
$$

for all $a, b, c>0$.

\subsubsection{The Triangle Inequality}

In its most general form, the triangle inequality states that in a metric space $X$ the distance function $\delta$ satisfies

$$
\delta(x, y) \leq \delta(x, z)+\delta(z, y), \quad \text { for any } x, y, z \in X .
$$

An equivalent form is

$$
|\delta(x, y)-\delta(y, z)| \leq \delta(x, z) .
$$

Here are some familiar examples of distance functions: the distance between two real or complex numbers as the absolute value of their difference, the distance between two vectors in $n$-dimensional Euclidean space as the length of their difference $\|v-w\|$, the distance between two matrices as the norm of their difference, the distance between two continuous functions on the same interval as the supremum of the absolute value of their difference. In all these cases the triangle inequality holds.

Let us see how the triangle inequality can be used to solve a problem from T.B. Soulami's book Les olympiades de mathématiques: Réflexes et stratégies (Ellipses, 1999)

Example. For positive numbers $a, b, c$ prove the inequality

$$
\sqrt{a^{2}-a b+b^{2}}+\sqrt{b^{2}-b c+c^{2}} \geq \sqrt{a^{2}+a c+c^{2}} .
$$

Solution. The inequality suggests the following geometric construction. With the same origin $O$, draw segments $O A, O B$, and $O C$ of lengths $a, b$, respectively, $c$, such that $O B$ makes $60^{\circ}$ angles with $O A$ and $O C$ (see Figure 12).

The law of cosines in the triangles $O A B, O B C$, and $O A C$ gives $A B^{2}=a^{2}-a b+b^{2}$, $B C^{2}=b^{2}-b c+c^{2}$, and $A C^{2}=a^{2}+a c+c^{2}$. Plugging these formulas into the triangle inequality $A B+B C \geq A C$ produces the inequality from the statement. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-051.jpg?height=359&width=657&top_left_y=254&top_left_x=539)

Figure 12

Example. Let $P(x)$ be a polynomial whose coefficients lie in the interval [1,2], and let $Q(x)$ and $R(x)$ be two nonconstant polynomials such that $P(x)=Q(x) R(x)$, with $Q(x)$ having the dominant coefficient equal to 1 . Prove that $|Q(3)|>1$.

Solution. Let $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$. We claim that the zeros of $P(x)$ lie in the union of the half-plane $\operatorname{Re} z \leq 0$ and the disk $|z|<2$.

Indeed, suppose that $P(x)$ has a zero $z$ such that $\operatorname{Re} z>0$ and $|z| \geq 2$. From $P(z)=0$, we deduce that $a_{n} z^{n}+a_{n-1} z^{n-1}=-a_{n-2} z^{n-2}-a_{n-3} z^{n-3}-\cdots-a_{0}$. Dividing through by $z^{n}$, which is not equal to 0 , we obtain

$$
a_{n}+\frac{a_{n-1}}{z}=-\frac{a_{n-2}}{z^{2}}-\frac{a_{n-3}}{z^{3}}-\cdots-\frac{a_{0}}{z^{n}} .
$$

Note that $\operatorname{Re} z>0$ implies that $\operatorname{Re} \frac{1}{z}>0$. Hence

$$
\begin{aligned}
1 & \leq a_{n} \leq \operatorname{Re}\left(a_{n}+\frac{a_{n-1}}{z}\right)=\operatorname{Re}\left(-\frac{a_{n-2}}{z^{2}}-\frac{a_{n-3}}{z^{3}}-\cdots-\frac{a_{0}}{z^{n}}\right) \\
& \leq\left|-\frac{a_{n-2}}{z^{2}}-\frac{a_{n-3}}{z^{3}}-\cdots-\frac{a_{0}}{z^{n}}\right| \leq \frac{a_{n-2}}{|z|^{2}}+\frac{a_{n-3}}{|z|^{3}}+\cdots+\frac{a_{0}}{|z|^{n}},
\end{aligned}
$$

where for the last inequality we used the triangle inequality. Because the $a_{i}$ 's are in the interval [1,2], this is strictly less than

$$
2|z|^{-2}\left(1+|z|^{-1}+|z|^{-2}+\cdots\right)=\frac{2|z|^{-2}}{1-|z|^{-1}} .
$$

The last quantity must therefore be greater than 1. But this cannot happen if $|z| \geq 2$, because the inequality reduces to $\left(\frac{2}{|z|}-1\right)\left(\frac{1}{|z|}+1\right)>0$, impossible. This proves the claim.

Returning to the problem, $Q(x)=\left(x-z_{1}\right)\left(x-z_{2}\right) \cdots\left(x-z_{k}\right)$, where $z_{1}, z_{2}, \ldots, z_{k}$ are some of the zeros of $P(x)$. Then

$$
|Q(3)|=\left|3-z_{1}\right| \cdot\left|3-z_{2}\right| \cdots\left|3-z_{k}\right| .
$$

If $\operatorname{Re} z_{i} \leq 0$, then $\left|3-z_{i}\right| \geq 3$. On the other hand, if $\left|z_{i}\right|<2$, then by the triangle inequality $\left|3-z_{i}\right| \geq 3-\left|z_{i}\right|>1$. Hence $|Q(3)|$ is a product of terms greater than 1 , and the conclusion follows.

More applications follow.

113. Let $a, b, c$ be the side lengths of a triangle with the property that for any positive integer $n$, the numbers $a^{n}, b^{n}, c^{n}$ can also be the side lengths of a triangle. Prove that the triangle is necessarily isosceles.

114. Given the vectors $\vec{a}, \vec{b}, \vec{c}$ in the plane, show that

$$
\|\vec{a}\|+\|\vec{b}\|+\|\vec{c}\|+\|\vec{a}+\vec{b}+\vec{c}\| \geq\|\vec{a}+\vec{b}\|+\|\vec{a}+\vec{c}\|+\|\vec{b}+\vec{c}\| .
$$

115. Let $P(z)$ be a polynomial with real coefficients whose roots can be covered by a disk of radius $R$. Prove that for any real number $k$, the roots of the polynomial $n P(z)-k P^{\prime}(z)$ can be covered by a disk of radius $R+|k|$, where $n$ is the degree of $P(z)$, and $P^{\prime}(z)$ is the derivative.

116. Prove that the positive real numbers $a, b, c$ are the side lengths of a triangle if and only if

$$
a^{2}+b^{2}+c^{2}<2 \sqrt{a^{2} b^{2}+b^{2} c^{2}+c^{2} a^{2}} .
$$

117. Let $A B C D$ be a convex cyclic quadrilateral. Prove that

$$
|A B-C D|+|A D-B C| \geq 2|A C-B D| .
$$

118. Let $V_{1}, V_{2}, \ldots, V_{m}$ and $W_{1}, W_{2}, \ldots, W_{m}$ be isometries of $\mathbb{R}^{n}(m, n$ positive integers). Assume that for all $x$ with $\|x\| \leq 1,\left\|V_{i} x-W_{i} x\right\| \leq 1, i=1,2, \ldots, m$. Prove that

$$
\left\|\left(\prod_{i=1}^{m} V_{i}\right) x-\left(\prod_{i=1}^{m} W_{i}\right) x\right\| \leq m,
$$

for all $x$ with $\|x\| \leq 1$.

119. Given an equilateral triangle $A B C$ and a point $P$ that does not lie on the circumcircle of $A B C$, show that one can construct a triangle with sides the segments $P A, P B$, and $P C$. If $P$ lies on the circumcircle, show that one of these segments is equal to the sum of the other two.

120. Let $M$ be a point in the plane of the triangle $A B C$ whose centroid is $G$. Prove that

$$
M A^{3} \cdot B C+M B^{3} \cdot A C+M C^{3} \cdot A B \geq 3 M G \cdot A B \cdot B C \cdot C A .
$$



\subsubsection{The Arithmetic Mean-Geometric Mean Inequality}

Jensen's inequality, which will be discussed in the section about convex functions, states that if $f$ is a real-valued concave function, then

$$
f\left(\lambda_{1} x_{1}+\lambda_{2} x_{2}+\cdots+\lambda_{n} x_{n}\right) \geq \lambda_{1} f\left(x_{1}\right)+\lambda_{2} f\left(x_{2}\right)+\cdots+\lambda_{n} f\left(x_{n}\right),
$$

for any $x_{1}, x_{2}, \ldots, x_{n}$ in the domain of $f$ and for any positive weights $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ with $\lambda_{1}+\lambda_{2}+\cdots+\lambda_{n}=1$. Moreover, if the function is nowhere linear (that is, if it is strictly concave) and the numbers $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ are nonzero, then equality holds if and only if $x_{1}=x_{2}=\cdots=x_{n}$.

Applying this to the concave function $f(x)=\ln x$, the positive numbers $x_{1}, x_{2}, \ldots$, $x_{n}$, and the weights $\lambda_{1}=\lambda_{2}=\cdots=\lambda_{n}=\frac{1}{n}$, we obtain

$$
\ln \frac{x_{1}+x_{2}+\cdots+x_{n}}{n} \geq \frac{\ln x_{1}+\ln x_{2}+\cdots+\ln x_{n}}{n} .
$$

Exponentiation yields the following inequality.

The arithmetic mean-geometric mean inequality. Let $x_{1}, x_{2}, \ldots, x_{n}$ be nonnegative real numbers. Then

$$
\frac{x_{1}+x_{2}+\cdots+x_{n}}{n} \geq \sqrt[n]{x_{1} x_{2} \cdots x_{n}},
$$

with equality if and only if all numbers are equal.

We will call this inequality AM-GM for short. We give it an alternative proof using derivatives, a proof by induction on $n$. For $n=2$ the inequality is equivalent to the obvious $\left(\sqrt{a_{1}}-\sqrt{a_{2}}\right)^{2} \geq 0$. Next, assume that the inequality holds for any $n-1$ positive numbers, meaning that

$$
\frac{x_{1}+x_{2}+\cdots+x_{n-1}}{n-1} \geq \sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}},
$$

with equality only when $x_{1}=x_{2}=\cdots=x_{n-1}$. To show that the same is true for $n$ numbers, consider the function $f:(0, \infty) \rightarrow \mathbb{R}$,

$$
f(x)=\frac{x_{1}+x_{2}+\cdots+x_{n-1}+x}{n}-\sqrt[n]{x_{1} x_{2} \cdots x_{n-1} x} .
$$

To find the minimum of this function we need the critical points. The derivative of $f$ is

$$
f^{\prime}(x)=\frac{1}{n}-\frac{\sqrt[n]{x_{1} x_{2} \cdots x_{n-1}}}{n} x^{\frac{1}{n}-1}=\frac{x^{\frac{1}{n}-1}}{n}\left(x^{1-\frac{1}{n}}-\sqrt[n]{x_{1} x_{2} \cdots x_{n-1}}\right) .
$$

Setting this equal to zero, we find the unique critical point $x=\sqrt[n-1]{x_{1} x_{2} \cdots x_{n}}$, since in this case $x^{1-\frac{1}{n}}=\sqrt[n]{x_{1} x_{2} \cdots x_{n-1}}$. Moreover, the function $x^{1-\frac{1}{n}}$ is increasing on $(0, \infty)$; hence $f^{\prime}(x)<0$ for $x<\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}$, and $f^{\prime}(x)>0$ for $x>\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}$. We find that $f$ has a global minimum at $x=\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}$, where it takes the value

$$
\begin{aligned}
f\left(\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}\right)=& \frac{x_{1}+x_{2}+\cdots+x_{n-1}+\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}}{n} \\
&-\sqrt[n]{x_{1} x_{2} \cdots x_{n-1}} \cdot \sqrt[n(n-1)]{x_{1} x_{2} \cdots x_{n-1}} \\
=& \frac{x_{1}+x_{2}+\cdots+x_{n-1}+\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}-\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}}{n} . \\
=& \frac{x_{1}+x_{2}+\cdots+x_{n-1}-(n-1) \sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}}{n} .
\end{aligned}
$$

By the induction hypothesis, this minimum is nonnegative, and is equal to 0 if and only if $x_{1}=x_{2}=\cdots=x_{n-1}$. We conclude that $f\left(x_{n}\right) \geq 0$ with equality if and only if $x_{1}=x_{2}=\cdots=x_{n-1}$ and $x_{n}=\sqrt[n-1]{x_{1} x_{2} \cdots x_{n-1}}=x_{1}$. This completes the induction.

We apply the AM-GM inequality to solve two problems composed by the second author of the book.

Example. Find the global minimum of the function $f: \mathbb{R}^{2} \rightarrow \mathbb{R}$,

$$
f(x, y)=3^{x+y}\left(3^{x-1}+3^{y-1}-1\right) .
$$

Solution. The expression

$$
3 f(x, y)+1=3^{2 x+y}+3^{x+2 y}+1-3 \cdot 3^{x+y}
$$

is of the form $a^{3}+b^{3}+c^{3}-3 a b c$, where $a=\sqrt[3]{3^{2 x+y}}, b=\sqrt[3]{3^{x+2 y}}$, and $c=1$, all of which are positive. By the AM-GM inequality, this expression is nonnegative. It is equal to zero only when $a=b=c$, that is, when $2 x+y=x+2 y=0$. We conclude that the minimum of $f$ is $f(0,0)=-\frac{1}{3}$.

Example. Let $a, b, c, d$ be positive real numbers with $a b c d=1$. Prove that

$$
\frac{a}{b+c+d+1}+\frac{b}{c+d+a+1}+\frac{c}{d+a+b+1}+\frac{d}{a+b+c+1} \geq 1 .
$$

Solution. A first idea is to homogenize this inequality, and for that we replace the 1 in each denominator by $\sqrt[4]{a b c d}$, transforming the inequality into

$$
\begin{aligned}
\frac{a}{b+c+d+\sqrt[4]{a b c d}}+\frac{b}{c+d+a+\sqrt[4]{a b c d}} &+\frac{c}{d+a+b+\sqrt[4]{a b c d}} \\
&+\frac{d}{a+b+c+\sqrt[4]{a b c d}} \geq 1 .
\end{aligned}
$$

Then we apply the AM-GM inequality to the last term in each denominator to obtain the stronger inequality

$$
\frac{4 a}{a+5(b+c+d)}+\frac{4 b}{b+5(c+d+a)}+\frac{4 c}{c+5(d+a+b)}+\frac{4 d}{d+5(a+b+c)} \geq 1,
$$

which we proceed to prove.

In order to simplify computations, it is better to denote the four denominators by $16 x, 16 y, 16 z, 16 w$, respectively. Then $a+b+c+d=x+y+z+w$, and so $4 a+16 x=4 b+16 y=4 c+16 z=4 d+16 w=5(x+y+z+2)$. The inequality becomes

$$
\begin{aligned}
\frac{-11 x+5(y+z+w)}{16 x}+\frac{-11 y+5(z+w+x)}{16 y} &+\frac{-11 z+5(w+x+y)}{16 z} \\
&+\frac{-11 w+5(x+y+z)}{16 w} \geq 1,
\end{aligned}
$$

or

$$
-4 \cdot 11+5\left(\frac{y}{x}+\frac{z}{x}+\frac{w}{x}+\frac{z}{y}+\frac{w}{y}+\frac{x}{y}+\frac{w}{z}+\frac{x}{z}+\frac{y}{z}+\frac{x}{w}+\frac{y}{w}+\frac{z}{w}\right) \geq 16 \text {. }
$$

And this follows by applying the AM-GM inequality to the twelve summands in the parentheses.

Try your hand at the following problems.

121. Show that all real roots of the polynomial $P(x)=x^{5}-10 x+35$ are negative.

122. Prove that for any positive integer $n$,

$$
n^{n}-1 \geq n^{\frac{n+1}{2}}(n-1) .
$$

123. Let $a_{1}, a_{2}, \ldots, a_{n}$ and $b_{1}, b_{2}, \ldots, b_{n}$ be nonnegative numbers. Show that

$$
\left(a_{1} a_{2} \cdots a_{n}\right)^{1 / n}+\left(b_{1} b_{2} \cdots b_{n}\right)^{1 / n} \leq\left(\left(a_{1}+b_{1}\right)\left(a_{2}+b_{2}\right) \cdots\left(a_{n}+b_{n}\right)\right)^{1 / n} .
$$

124. Let $a, b, c$ be the side lengths of a triangle with semiperimeter 1 . Prove that

$$
1<a b+b c+c a-a b c \leq \frac{28}{27} .
$$

125. Which number is larger,

$$
\prod_{n=1}^{25}\left(1-\frac{n}{365}\right) \text { or } \frac{1}{2} ?
$$

126. On a sphere of radius 1 are given four points $A, B, C, D$ such that

$$
A B \cdot A C \cdot A D \cdot B C \cdot B D \cdot C D=\frac{2^{9}}{3^{3}} .
$$

Prove that the tetrahedron $A B C D$ is regular.

127. Prove that

$$
\frac{y^{2}-x^{2}}{2 x^{2}+1}+\frac{z^{2}-y^{2}}{2 y^{2}+1}+\frac{x^{2}-z^{2}}{2 z^{2}+1} \geq 0,
$$

for all real numbers $x, y, z$.

128. Let $a_{1}, a_{2}, \ldots, a_{n}$ be positive real numbers such that $a_{1}+a_{2}+\cdots+a_{n}<1$. Prove that

$$
\frac{a_{1} a_{2} \cdots a_{n}\left(1-\left(a_{1}+a_{2}+\cdots+a_{n}\right)\right)}{\left(a_{1}+a_{2}+\cdots+a_{n}\right)\left(1-a_{1}\right)\left(1-a_{2}\right) \cdots\left(1-a_{n}\right)} \leq \frac{1}{n^{n+1}} .
$$

129. Consider the positive real numbers $x_{1}, x_{2}, \ldots, x_{n}$ with $x_{1} x_{2} \cdots x_{n}=1$. Prove that

$$
\frac{1}{n-1+x_{1}}+\frac{1}{n-1+x_{2}}+\cdots+\frac{1}{n-1+x_{n}} \leq 1 .
$$

\subsubsection{Sturm's Principle}

In this section we present a method for proving inequalities that has the flavor of real analysis. It is based on a principle attributed to R. Sturm, phrased as follows.

Sturm's principle. Given a function $f$ defined on a set $M$ and a point $x_{0} \in M$, if

(i) $f$ has a maximum (minimum) on $M$, and

(ii) if no other point $x$ in $M$ is a maximum (minimum) of $f$, then $x_{0}$ is the maximum (minimum) of $f$.

But how to decide whether the function $f$ has a maximum or a minimum? Two results from real analysis come in handy.

Theorem. A continuous function on a compact set always attains its extrema.

Theorem. A closed and bounded subset of $\mathbb{R}^{n}$ is compact.

Let us see how Sturm's principle can be applied to a problem from the first Balkan Mathematical Olympiad in 1984. Example. Let $\alpha_{1}, \alpha_{2}, \ldots, \alpha_{n}$ be positive real numbers, $n \geq 2$, such that $\alpha_{1}+\alpha_{2}+\cdots+$ $\alpha_{n}=1$. Prove that

$$
\frac{\alpha_{1}}{1+\alpha_{2}+\cdots+\alpha_{n}}+\frac{\alpha_{2}}{1+\alpha_{1}+\cdots+\alpha_{n}}+\cdots+\frac{\alpha_{n}}{1+\alpha_{1}+\cdots+\alpha_{n-1}} \geq \frac{n}{2 n-1} .
$$

Solution. Rewrite the inequality as

$$
\frac{\alpha_{1}}{2-\alpha_{1}}+\frac{\alpha_{2}}{2-\alpha_{2}}+\cdots+\frac{\alpha_{n}}{2-\alpha_{n}} \geq \frac{n}{2 n-1},
$$

and then define the function

$$
f\left(\alpha_{1}, \alpha_{2}, \ldots, \alpha_{n}\right)=\frac{\alpha_{1}}{2-\alpha_{1}}+\frac{\alpha_{2}}{2-\alpha_{2}}+\cdots+\frac{\alpha_{n}}{2-\alpha_{n}} .
$$

As said in the statement, this function is defined on the subset of $\mathbb{R}^{n}$ consisting of points whose coordinates are positive and add up to 1 . We would like to show that on this set $f$ is greater than or equal to $\frac{n}{2 n-1}$.

Does $f$ have a minimum? The domain of $f$ is bounded but is not closed, being the interior of a tetrahedron. We can enlarge it, though, by adding the boundary, to the set

$$
M=\left\{\left(\alpha_{1}, \alpha_{2}, \ldots, \alpha_{n}\right) \mid \alpha_{1}+\alpha_{2}+\cdots+\alpha_{n}=1, \alpha_{i} \geq 0, i=1,2, \ldots, n\right\} .
$$

We now know that $f$ has a minimum on $M$.

A look at the original inequality suggests that the minimum is attained when all the $\alpha_{i}$ 's are equal. So let us choose a point $\left(\alpha_{1}, \alpha_{2}, \ldots, \alpha_{n}\right)$ for which $\alpha_{i} \neq \alpha_{j}$ for some indices $i, j$. Assume that $\alpha_{i}<\alpha_{j}$ and let us see what happens if we substitute $\alpha_{i}+x$ for $\alpha_{i}$ and $\alpha_{j}-x$ for $\alpha_{j}$, with $0<x<\alpha_{j}-\alpha_{i}$. In the defining expression of $f$, only the $i$ th and $j$ th terms change. Moreover,

$$
\begin{aligned}
\frac{\alpha_{i}}{2-\alpha_{i}} &+\frac{\alpha_{j}}{2-\alpha_{j}}-\frac{\alpha_{i}+x}{2-\alpha_{i}-x}-\frac{\alpha_{j}-x}{2-\alpha_{j}+x} \\
=& \frac{2 x\left(\alpha_{j}-\alpha_{i}-x\right)\left(4-\alpha_{i}-\alpha_{j}\right)}{\left(2-\alpha_{i}\right)\left(2-\alpha_{j}\right)\left(2-\alpha_{i}-x\right)\left(2-\alpha_{j}-x\right)}>0,
\end{aligned}
$$

so on moving the numbers closer, the value of $f$ decreases. It follows that the point that we picked was not a minimum. Hence the only possible minimum is $\left(\frac{1}{n}, \frac{1}{n}, \ldots, \frac{1}{n}\right)$, in which case the value of $f$ is $\frac{n}{2 n-1}$. This proves the inequality.

However, in most situations, as is the case with this problem, we can bypass the use of real analysis and argue as follows. If the $a_{i}$ 's were not all equal, then one of them must be less than $\frac{1}{n}$ and one of them must be greater. Take these two numbers and move them closer until one of them reaches $\frac{1}{n}$. Then stop and choose another pair. Continue the algorithm until all numbers become $\frac{1}{n}$. At this very moment, the value of the expression is $\frac{1}{n}\left(2-\frac{1}{n}\right)^{-1} \cdot n=\frac{n}{2 n-1}$. Since during the process the value of the expression kept decreasing, initially it must have been greater than or equal to $\frac{n}{2 n-1}$. This proves the inequality.

Let us summarize the last idea. We want to maximize (or minimize) an $n$-variable function, and we have a candidate for the extremum. If we can move the variables one by one toward the maximum without decreasing (respectively, increasing) the value of the function, than the candidate is indeed the desired extremum. You can find more applications of Sturm's principle below.

130. Let $a, b, c$ be nonnegative real numbers such that $a+b+c=1$. Prove that

$$
4(a b+b c+a c)-9 a b c \leq 1 .
$$

131. Let $x_{1}, x_{2}, \ldots, x_{n}, n \geq 2$, be positive numbers such that $x_{1}+x_{2}+\cdots+x_{n}=1$. Prove that

$$
\left(1+\frac{1}{x_{1}}\right)\left(1+\frac{1}{x_{2}}\right) \cdots\left(1+\frac{1}{x_{n}}\right) \geq(n+1)^{n} .
$$

132. Prove that a necessary and sufficient condition that a triangle inscribed in an ellipse have maximum area is that its centroid coincide with the center of the ellipse.

133. Let $a, b, c>0, a+b+c=1$. Prove that

$$
0 \leq a b+b c+a c-2 a b c \leq \frac{7}{27} .
$$

134. Let $x_{1}, x_{2}, \ldots, x_{n}$ be $n$ real numbers such that $0<x_{j} \leq \frac{1}{2}$, for $1 \leq j \leq n$. Prove the inequality

$$
\frac{\prod_{j=1}^{n} x_{j}}{\left(\sum_{j=1}^{n} x_{j}\right)^{n}} \leq \frac{\prod_{j=1}^{n}\left(1-x_{j}\right)}{\left(\sum_{j=1}^{n}\left(1-x_{j}\right)\right)^{n}} .
$$

135. Let $a, b, c$, and $d$ be nonnegative numbers such that $a \leq 1, a+b \leq 5, a+b+c \leq 14$, $a+b+c+d \leq 30$. Prove that

$$
\sqrt{a}+\sqrt{b}+\sqrt{c}+\sqrt{d} \leq 10 .
$$

136. What is the maximal value of the expression $\sum_{i<j} x_{i} x_{j}$ if $x_{1}, x_{2}, \ldots, x_{n}$ are nonnegative integers whose sum is equal to $m$ ?

137. Given the $n \times n$ array $\left(a_{i j}\right)_{i j}$ with $a_{i j}=i+j-1$, what is the smallest product of $n$ elements of the array provided that no two lie on the same row or column?

138. Given a positive integer $n$, find the minimum value of

$$
\frac{x_{1}^{3}+x_{2}^{3}+\cdots+x_{n}^{3}}{x_{1}+x_{2}+\cdots+x_{n}}
$$

subject to the condition that $x_{1}, x_{2}, \ldots, x_{n}$ be distinct positive integers. 

\subsubsection{Other Inequalities}

We conclude with a section for the inequalities aficionado. Behind each problem hides a famous inequality.

139. If $x$ and $y$ are positive real numbers, show that $x^{y}+y^{x}>1$.

140. Prove that for all $a, b, c \geq 0$,

$$
\left(a^{5}-a^{2}+3\right)\left(b^{5}-b^{2}+3\right)\left(c^{5}-c^{2}+3\right) \geq(a+b+c)^{3} .
$$

141. Assume that all the zeros of the polynomial $P(x)=x^{n}+a_{1} x^{n-1}+\cdots+a_{n}$ are real and positive. Show that if there exist $1 \leq m<p \leq n$ such that $a_{m}=(-1)^{m}\left(\begin{array}{l}n \\ m\end{array}\right)$ and $a_{p}=(-1)^{p}\left(\begin{array}{l}n \\ p\end{array}\right)$, then $P(x)=(x-1)^{n}$.

142. Let $n>2$ be an integer, and let $x_{1}, x_{2}, \ldots, x_{n}$ be positive numbers with the sum equal to 1 . Prove that

$$
\prod_{i=1}^{n}\left(1+\frac{1}{x_{i}}\right) \geq \prod_{i=1}^{n}\left(\frac{n-x_{i}}{1-x_{i}}\right) .
$$

143. Let $a_{1}, a_{2}, \ldots, a_{n}, b_{1}, b_{2}, \ldots, b_{n}$ be real numbers such that

$$
\begin{gathered}
\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}-1\right)\left(b_{1}^{2}+b_{2}^{2}+\cdots+b_{n}^{2}-1\right) \\
>\left(a_{1} b_{1}+a_{2} b_{2}+\cdots+a_{n} b_{n}-1\right)^{2} .
\end{gathered}
$$

Prove that $a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}>1$ and $b_{1}^{2}+b_{2}^{2}+\cdots+b_{n}^{2}>1$.

144. Let $a, b, c, d$ be positive numbers such that $a b c=1$. Prove that

$$
\frac{1}{a^{3}(b+c)}+\frac{1}{b^{3}(c+a)}+\frac{1}{c^{3}(a+b)} \geq \frac{3}{2} .
$$

\subsection{Polynomials}

\subsubsection{A Warmup}

A polynomial is a sum of the form

$$
P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0},
$$

where $x$ is the variable, and $a_{n}, a_{n-1}, \ldots, a_{0}$ are constant coefficients. If $a_{n} \neq 0$, the number $n$ is called the degree, denoted by $\operatorname{deg}(P(x))$. If $a_{n}=1$, the polynomial is called monic. The sets, which, in fact, are rings, of polynomials with integer, rational, real, or complex coefficients are denoted, respectively, by $\mathbb{Z}[x], \mathbb{Q}[x], \mathbb{R}[x]$, and $\mathbb{C}[x]$. A number $r$ such that $P(r)=0$ is called a zero of $P(x)$, or a root of the equation $P(x)=0$. By the Gauss-d'Alembert theorem, also called the fundamental theorem of algebra, every nonconstant polynomial with complex coefficients has at least one complex zero. Consequently, the number of zeros of a polynomial equals the degree, multiplicities counted. For a number $\alpha, P(\alpha)=a_{n} \alpha^{n}+a_{n-1} \alpha^{n-1}+\cdots+a_{0}$ is called the value of the polynomial at $\alpha$.

We begin the section on polynomials with an old problem from the 1943 competition of the Mathematics Gazette, Bucharest, proposed by Gh. Buicliu.

Example. Verify the equality

$$
\sqrt[3]{20+14 \sqrt{2}}+\sqrt[3]{20-14 \sqrt{2}}=4 .
$$

Solution. Apparently, this problem has nothing to do with polynomials. But let us denote the complicated irrational expression by $x$ and analyze its properties. Because of the cube roots, it becomes natural to raise $x$ to the third power:

$$
\begin{aligned}
x^{3}=& 20+14 \sqrt{2}+20-14 \sqrt{2} \\
&+3 \sqrt[3]{(20+14 \sqrt{2})(20-14 \sqrt{2})}(\sqrt[3]{20+14 \sqrt{2}}+\sqrt[3]{20-14 \sqrt{2}}) \\
=& 40+3 x \sqrt[3]{400-392}=40+6 x .
\end{aligned}
$$

And now we see that $x$ satisfies the polynomial equation

$$
x^{3}-6 x-40=0 \text {. }
$$

We have already been told that 4 is a root of this equation. The other two roots are complex, and hence $x$ can only equal 4 , the desired answer.

Of course, one can also recognize the quantities under the cube roots to be the cubes of $2+\sqrt{2}$ and $2-\sqrt{2}$, but that is just a lucky strike.

145. Given the polynomial $P(x, y, z)$ prove that the polynomial

$$
\begin{aligned}
Q(x, y, z)=& P(x, y, z)+P(y, z, x)+P(z, x, y) \\
&-P(x, z, y)-P(y, x, z)-P(z, y, x)
\end{aligned}
$$

is divisible by $(x-y)(y-z)(z-x)$.

146. Find all polynomials satisfying the functional equation

$$
(x+1) P(x)=(x-10) P(x+1) \text {. }
$$

147. Let $P(x)$ be a polynomial of odd degree with real coefficients. Show that the equation $P(P(x))=0$ has at least as many real roots as the equation $P(x)=0$, counted without multiplicities.

148. Determine all polynomials $P(x)$ with real coefficients for which there exists a positive integer $n$ such that for all $x$,

$$
P\left(x+\frac{1}{n}\right)+P\left(x-\frac{1}{n}\right)=2 P(x) .
$$

149. Find a polynomial with integer coefficients that has the zero $\sqrt{2}+\sqrt[3]{3}$.

150. Let $P(x)=x^{4}+a x^{3}+b x^{2}+c x+d$ and $Q(x)=x^{2}+p x+q$ be two polynomials with real coefficients. Suppose that there exists an interval $(r, s)$ of length greater than 2 such that both $P(x)$ and $Q(x)$ are negative for $x \in(r, s)$ and both are positive for $x<r$ or $x>s$. Show that there is a real number $x_{0}$ such that $P\left(x_{0}\right)<Q\left(x_{0}\right)$.

151. Let $P(x)$ be a polynomial of degree $n$. Knowing that

$$
P(k)=\frac{k}{k+1}, \quad k=0,1, \ldots, n,
$$

find $P(m)$ for $m>n$.

152. Consider the polynomials with complex coefficients

$$
P(x)=x^{n}+a_{1} x^{n-1}+\cdots+a_{n}
$$

with zeros $x_{1}, x_{2}, \ldots, x_{n}$ and

$$
Q(x)=x^{n}+b_{1} x^{n-1}+\cdots+b_{n}
$$

with zeros $x_{1}^{2}, x_{2}^{2}, \ldots, x_{n}^{2}$. Prove that if $a_{1}+a_{3}+a_{5}+\cdots$ and $a_{2}+a_{4}+a_{6}+\cdots$ are both real numbers, then so is $b_{1}+b_{2}+\cdots+b_{n}$.

153. Let $P(x)$ be a polynomial with complex coefficients. Prove that $P(x)$ is an even function if and only if there exists a polynomial $Q(x)$ with complex coefficients satisfying

$$
P(x)=Q(x) Q(-x) .
$$

\subsubsection{Viète's Relations}

From the Gauss-d'Alembert fundamental theorem of algebra it follows that a polynomial

$$
P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}
$$

can be factored over the complex numbers as

$$
P(x)=a_{n}\left(x-x_{1}\right)\left(x-x_{2}\right) \cdots\left(x-x_{n}\right) .
$$

Equating the coefficients of $x$ in the two expressions, we obtain

$$
\begin{aligned}
x_{1}+x_{2}+\cdots+x_{n} &=-\frac{a_{n-1}}{a_{n}}, \\
x_{1} x_{2}+x_{1} x_{3}+\cdots+x_{n-1} x_{n} &=\frac{a_{n-2}}{a_{n}}, \\
& \cdots \\
x_{1} x_{2} \cdots x_{n} &=(-1)^{n} \frac{a_{0}}{a_{n}} .
\end{aligned}
$$

These relations carry the name of the French mathematician F. Viète. They combine two ways of looking at a polynomial: as a sum of monomials and as a product of linear factors. As a first application of these relations, we have selected a problem from a 1957 Chinese mathematical competition.

Example. If $x+y+z=0$, prove that

$$
\frac{x^{2}+y^{2}+z^{2}}{2} \cdot \frac{x^{5}+y^{5}+z^{5}}{5}=\frac{x^{7}+y^{7}+z^{7}}{7} .
$$

Solution. Consider the polynomial $P(X)=X^{3}+p X+q$, whose zeros are $x, y, z$. Then

$$
x^{2}+y^{2}+z^{2}=(x+y+z)^{2}-2(x y+x z+y z)=-2 p .
$$

Adding the relations $x^{3}=-p x-q, y^{3}=-p y-q$, and $z^{3}=-p z-q$, which hold because $x, y, z$ are zeros of $P(X)$, we obtain

$$
x^{3}+y^{3}+z^{3}=-3 q .
$$

Similarly,

$$
x^{4}+y^{4}+z^{4}=-p\left(x^{2}+y^{2}+z^{2}\right)-q(x+y+z)=2 p^{2},
$$

and therefore

$$
\begin{aligned}
&x^{5}+y^{5}+z^{5}=-p\left(x^{3}+y^{3}+z^{3}\right)-q\left(x^{2}+y^{2}+z^{2}\right)=5 p q, \\
&x^{7}+y^{7}+z^{7}=-p\left(x^{5}+y^{5}+z^{5}\right)-q\left(x^{4}+y^{4}+z^{4}\right)=-5 p^{2} q-2 p^{2} q=-7 p^{2} q .
\end{aligned}
$$

The relation from the statement reduces to the obvious

$$
\frac{-2 p}{2} \cdot \frac{5 p q}{5}=\frac{-7 p^{2} q}{7} .
$$

Next, a problem from the short list of the 2005 Ibero-American Mathematical Olympiad.

Example. Find the largest real number $k$ with the property that for all fourth-degree polynomials $P(x)=x^{4}+a x^{3}+b x^{2}+c x+d$ whose zeros are all real and positive, one has

$$
(b-a-c)^{2} \geq k d,
$$

and determine when equality holds.

Solution. Let $r_{1}, r_{2}, r_{3}, r_{4}$ be the zeros of $P(x)$. Viète's relations read

$$
\begin{aligned}
a &=-\left(r_{1}+r_{2}+r_{3}+r_{4}\right), \\
b &=r_{1} r_{2}+r_{1} r_{3}+r_{1} r_{4}+r_{2} r_{3}+r_{2} r_{4}+r_{3} r_{4}, \\
c &=-\left(r_{1} r_{2} r_{3}+r_{1} r_{2} r_{4}+r_{1} r_{3} r_{4}+r_{2} r_{3} r_{4}\right), \\
d &=r_{1} r_{2} r_{3} r_{4} .
\end{aligned}
$$

From here we obtain

$$
\begin{aligned}
b-a-c=&\left(r_{1} r_{2}+r_{1} r_{3}+r_{1} r_{4}+r_{2} r_{3}+r_{2} r_{4}+r_{3} r_{4}\right)+\left(r_{1}+r_{2}+r_{3}+r_{4}\right) \\
&+\left(r_{1} r_{2} r_{3}+r_{1} r_{2} r_{4}+r_{1} r_{3} r_{4}+r_{2} r_{3} r_{4}\right) .
\end{aligned}
$$

By the AM-GM inequality this is greater than or equal to

$$
14 \sqrt[14]{\left(r_{1} r_{2} r_{3} r_{4}\right)^{7}}=14 \sqrt{d} .
$$

Since equality can hold in the AM-GM inequality, we conclude that $k=196$ is the answer to the problem. Moreover, equality holds exactly when $r_{1}=r_{2}=r_{3}=r_{4}=1$, that is, when $P(x)=x^{4}-4 x^{3}+6 x^{2}-4 x+1$.

And now a challenging problem from A. Krechmar's Problem Book in Algebra (Mir Publishers, 1974).

Example. Prove that

$$
\sqrt[3]{\cos \frac{2 \pi}{7}}+\sqrt[3]{\cos \frac{4 \pi}{7}}+\sqrt[3]{\cos \frac{8 \pi}{7}}=\sqrt[3]{\frac{1}{2}(5-3 \sqrt[3]{7})} .
$$

Solution. We would like to find a polynomials whose zeros are the three terms on the left. Let us simplify the problem and forget the cube roots for a moment. In this case we have to find a polynomial whose zeros are $\cos \frac{2 \pi}{7}, \cos \frac{4 \pi}{7}, \cos \frac{8 \pi}{7}$. The seventh roots of unity come in handy. Except for $x=1$, which we ignore, these are also roots of the equation $x^{6}+x^{5}+x^{4}+x^{3}+x^{2}+x+1=0$, and are $\cos \frac{2 k \pi}{7}+i \sin \frac{2 k \pi}{7}, k=1,2, \ldots, 6$. We see that the numbers $2 \cos \frac{2 \pi}{7}, 2 \cos \frac{4 \pi}{7}$, and $2 \cos \frac{8 \pi}{7}$ are of the form $x+\frac{1}{x}$, with $x$ one of these roots.

If we define $y=x+\frac{1}{x}$, then $x^{2}+\frac{1}{x^{2}}=y^{2}-2$ and $x^{3}+\frac{1}{x^{3}}=y^{3}-3 y$. Dividing the equation $x^{6}+x^{5}+x^{4}+x^{3}+x^{2}+x+1=0$ through by $x^{3^{3}}$ and substituting $y$ in it, we obtain the cubic equation

$$
y^{3}+y^{2}-2 y-1=0 .
$$

The numbers $2 \cos \frac{2 \pi}{7}, 2 \cos \frac{4 \pi}{7}$, and $2 \cos \frac{8 \pi}{7}$ are the three roots of this equation. The simpler task is fulfilled.

But the problem asks us to find the sum of the cube roots of these numbers. Looking at symmetric polynomials, we have

$$
X^{3}+Y^{3}+Z^{3}-3 X Y Z=(X+Y+Z)^{3}-3(X+Y+Z)(X Y+Y Z+Z X)
$$

and

$$
\begin{aligned}
X^{3} Y^{3}+Y^{3} Z^{3}+Z^{3} X^{3}-3(X Y Z)^{2}=&(X Y+Y Z+X Z)^{3} \\
&-3 X Y Z(X+Y+Z)(X Y+Y Z+Z X) .
\end{aligned}
$$

Because $X^{3}, Y^{3}, Z^{3}$ are the roots of the equation $y^{3}+y^{2}-2 y-1=0$, by Viète's relations, $X^{3} Y^{3} Z^{3}=1$, so $X Y Z=\sqrt[3]{1}=1$, and also $X^{3}+Y^{3}+Z^{3}=-1$ and $X^{3} Y^{3}+X^{3} Z^{3}+Y^{3} Z^{3}=-2$. In the above two equalities we now know the left-hand sides. The equalities become a system of two equations in the unknowns $u=X+Y+Z$ and $v=X Y+Y Z+Z X$, namely

$$
\begin{aligned}
&u^{3}-3 u v=-4, \\
&v^{3}-3 u v=-5 .
\end{aligned}
$$

Writing the two equations as $u^{3}=3 u v-4$ and $v^{3}=3 u v-5$ and multiplying them, we obtain $(u v)^{3}=9(u v)^{2}-27 u v+20$. With the substitution $m=u v$ this becomes $m^{3}-3 m^{3}+27 m-20=0$, or $(m-3)^{3}+7=0$. This equation has the unique solution $m=3-\sqrt[3]{7}$. Hence $u=\sqrt[3]{3 m-4}=\sqrt[3]{5-3 \sqrt[3]{7}}$. We conclude that

$$
\sqrt[3]{\cos \frac{2 \pi}{7}}+\sqrt[3]{\cos \frac{4 \pi}{7}}+\sqrt[3]{\cos \frac{8 \pi}{7}}=X+Y+Z=\frac{1}{\sqrt[3]{2}} u=\sqrt[3]{\frac{1}{2}(5-3 \sqrt[3]{7})},
$$

as desired.

All problems below can be solved using Viète's relations.

154. Find the zeros of the polynomial

$$
P(x)=x^{4}-6 x^{3}+18 x^{2}-30 x+25
$$

knowing that the sum of two of them is 4 . 


155. Let $a, b, c$ be real numbers. Show that $a \geq 0, b \geq 0$, and $c \geq 0$ if and only if $a+b+c \geq 0, a b+b c+c a \geq 0$, and $a b c \geq 0$.

156. Solve the system

$$
\begin{array}{r}
x+y+z=1, \\
x y z=1,
\end{array}
$$

knowing that $x, y, z$ are complex numbers of absolute value equal to 1 .

157. Find all real numbers $r$ for which there is at least one triple $(x, y, z)$ of nonzero real numbers such that

$$
x^{2} y+y^{2} z+z^{2} x=x y^{2}+y z^{2}+z x^{2}=r x y z .
$$

158. For five integers $a, b, c, d, e$ we know that the sums $a+b+c+d+e$ and $a^{2}+$ $b^{2}+c^{2}+d^{2}+e^{2}$ are divisible by an odd number $n$. Prove that the expression $a^{5}+b^{5}+c^{5}+d^{5}+e^{5}-5 a b c d e$ is also divisible by $n$.

159. Find all polynomials whose coefficients are equal either to 1 or $-1$ and whose zeros are all real.

160. Let $P(z)=a z^{4}+b z^{3}+c z^{2}+d z+e=a\left(z-r_{1}\right)\left(z-r_{2}\right)\left(z-r_{3}\right)\left(z-r_{4}\right)$, where $a, b, c, d, e$ are integers, $a \neq 0$. Show that if $r_{1}+r_{2}$ is a rational number, and if $r_{1}+r_{2} \neq r_{3}+r_{4}$, then $r_{1} r_{2}$ is a rational number.

161. The zeros of the polynomial $P(x)=x^{3}-10 x+11$ are $u$, $v$, and $w$. Determine the value of $\arctan u+\arctan v+\arctan w$.

162. Prove that for every positive integer $n$,

$$
\tan \frac{\pi}{2 n+1} \tan \frac{2 \pi}{2 n+1} \cdots \tan \frac{n \pi}{2 n+1}=\sqrt{2 n+1} .
$$

163. Let $P(x)=x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$ be a polynomial of degree $n \geq 3$. Knowing that $a_{n-1}=-\left(\begin{array}{c}n \\ 1\end{array}\right), a_{n-2}=\left(\begin{array}{l}n \\ 2\end{array}\right)$, and that all roots are real, find the remaining coefficients.

164. Determine the maximum value of $\lambda$ such that whenever $P(x)=x^{3}+a x^{2}+b x+c$ is a cubic polynomial with all zeros real and nonnegative, then

$$
P(x) \geq \lambda(x-a)^{3}
$$

for all $x \geq 0$. Find the equality condition.

165. Prove that there are unique positive integers $a, n$ such that

$$
a^{n+1}-(a+1)^{n}=2001 .
$$



\subsubsection{The Derivative of a Polynomial}

This section adds some elements of real analysis. We remind the reader that the derivative of a polynomial

$$
P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}
$$

is the polynomial

$$
P^{\prime}(x)=n a_{n} x^{n-1}+(n-1) a_{n-1} x^{n-2}+\cdots+a_{1} .
$$

If $x_{1}, x_{2}, \ldots, x_{n}$ are the zeros of $P(x)$, then by the product rule,

$$
\frac{P^{\prime}(x)}{P(x)}=\frac{1}{x-x_{1}}+\frac{1}{x-x_{2}}+\cdots+\frac{1}{x-x_{n}} .
$$

If a zero of $P(x)$ has multiplicity greater than 1 , then it is also a zero of $P^{\prime}(x)$, and the converse is also true. By Rolle's theorem, if all zeros of $P(x)$ are real, then so are those of $P^{\prime}(x)$. Let us discuss in detail two problems, the second of which is authored by R. Gologan.

Example. Find all polynomials $P(x)$ with the property that $P(x)$ is a multiple of $P^{\prime \prime}(x)$.

Solution. Let $P(x)=Q(x) P^{\prime \prime}(x)$, with $Q(x)$ a polynomial that is necessarily quadratic. Since the multiplicity of a zero of $P(x)$ is strictly greater than the multiplicity of the same zero in $P^{\prime \prime}(x)$, it follows that $P(x)$ has at most two distinct zeros, and these must be zeros of $Q(x)$. So let $P(x)=\alpha(x-a)^{k}(x-b)^{n-k}$.

If $a \neq b$, then $a$ and $b$ are both zeros of $Q(x)$, so $P^{\prime \prime}(x)=n(n-1) \alpha(x-a)^{k-1}(x-$ $b)^{n-k-1}$ and $Q(x)=\frac{1}{n(n-1)}(x-a)(x-b)$. But this cannot happen unless $k-1=$ $n-k-1=0$, for if a number is a zero of both $P(x)$ and $P^{\prime \prime}(x)$, then the difference between the multiplicities of this zero in the two polynomials is 2.

If $a=b$, then $P(x)=\alpha(x-a)^{n}, n \geq 2$, is a multiple of $P^{\prime \prime}(x)$. The answer to the problem consists of all quadratic polynomials and all polynomials of the form $P(x)=\alpha(x-a)^{n}, n \geq 2$.

Example. Let $P(x) \in \mathbb{Z}[x]$ be a polynomial with $n$ distinct integer zeros. Prove that the polynomial $(P(x))^{2}+1$ has a factor of degree at least $2\left\lfloor\frac{n+1}{2}\right\rfloor$ that is irreducible over $\mathbb{Z}[x]$.

Solution. The statement apparently offers no clue about derivatives. The standard approach is to assume that

$$
(P(x))^{2}+1=P_{1}(x) P_{2}(x) \cdots P_{k}(x)
$$

is a decomposition into factors that are irreducible over $\mathbb{Z}[x]$. Letting $x_{1}, x_{2}, \ldots, x_{n}$ be the integer zeros of $P(x)$, we find that 

$$
P_{1}\left(x_{j}\right) P_{2}\left(x_{j}\right) \cdots P_{k}\left(x_{j}\right)=1, \quad \text { for } j=1,2, \ldots, n .
$$

Hence $P_{i}\left(x_{j}\right)=\pm 1$, which then implies $\frac{1}{P_{i}\left(x_{j}\right)}=P_{i}\left(x_{j}\right), i=1,2, \ldots, k, j=$ $1,2, \ldots, n$

Now let us see how derivatives come into play. The key observation is that the zeros $x_{j}$ of $(P(x))^{2}$ appear with multiplicity greater than 1 , and so they are zeros of the derivative. Differentiating with the product rule, we obtain

$$
\sum_{i=1}^{k} P_{1}\left(x_{j}\right) \cdots P_{i}^{\prime}\left(x_{j}\right) \cdots P_{k}\left(x_{j}\right)=0, \quad \text { for } j=1,2, \ldots, n .
$$

This sum can be simplified by taking into account that $P_{1}\left(x_{j}\right) P_{2}\left(x_{j}\right) \cdots P_{k}\left(x_{j}\right)=1$ and $\frac{1}{P_{i}\left(x_{j}\right)}=P_{i}\left(x_{j}\right)$ as

$$
\sum_{i=1}^{k} P_{i}^{\prime}\left(x_{j}\right) P_{i}\left(x_{j}\right)=0, \quad \text { for } j=1,2, \ldots, n \text {. }
$$

It follows that $x_{j}$ is a zero of the polynomial

$$
\sum_{i=1}^{k} 2 P_{i}^{\prime}(x) P_{i}(x)=\left(\sum_{i=1}^{k} P_{i}^{2}(x)\right)^{\prime} .
$$

Let us remember that $P_{i}\left(x_{j}\right)=\pm 1$, which then implies $\sum_{i=1}^{k} P_{i}^{2}\left(x_{j}\right)-n=0$ for $j=1,2, \ldots, n$. The numbers $x_{j}, j=1,2, \ldots, n$, are zeros of both $\sum_{i=1}^{k} P_{i}^{2}(x)-n$ and its derivative, so they are zeros of order at least 2 of this polynomial. Therefore,

$$
\sum_{i=1}^{k} P_{i}^{2}(x)=\left(x-x_{1}\right)^{2}\left(x-x_{2}\right)^{2} \cdots\left(x-x_{n}\right)^{2} Q(x)+n,
$$

for some polynomial $Q(x)$ with integer coefficients. We deduce that there exists an index $i_{0}$ such that the degree of $P_{i_{0}}(x)$ is greater than or equal to $n$. For $n$ even, $n=2\left\lfloor\frac{n+1}{2}\right\rfloor$, and we are done. For $n$ odd, since $(P(x))^{2}+1$ does not have real zeros, neither does $P_{i_{0}}(x)$, so this polynomial has even degree. Thus the degree of $P_{i_{0}}(x)$ is at least $n+1=2\left\lfloor\frac{n+1}{2}\right\rfloor$. This completes the solution.

166. Find all polynomials $P(x)$ with integer coefficients satisfying $P\left(P^{\prime}(x)\right)=$ $P^{\prime}(P(x))$ for all $x \in \mathbb{R}$.

167. Determine all polynomials $P(x)$ with real coefficients satisfying $(P(x))^{n}=P\left(x^{n}\right)$ for all $x \in \mathbb{R}$, where $n>1$ is a fixed integer. 

168. Let $P(z)$ and $Q(z)$ be polynomials with complex coefficients of degree greater than or equal to 1 with the property that $P(z)=0$ if and only if $Q(z)=0$ and $P(z)=1$ if and only if $Q(z)=1$. Prove that the polynomials are equal.

169. Let $P(x)$ be a polynomial with all roots real and distinct and such that none of its zeros is equal to 0 . Prove that the polynomial $x^{2} P^{\prime \prime}(x)+3 x P^{\prime}(x)+P(x)$ also has all roots real and distinct.

170. Let $P_{n}(x)=\left(x^{n}-1\right)\left(x^{n-1}-1\right) \cdots(x-1), n \geq 1$. Prove that for $n \geq 2, P_{n}^{\prime}(x)$ is divisible by $P_{\lfloor n / 2\rfloor}(x)$ in the ring of polynomials with integer coefficients.

171. The zeros of the $n$ th-degree polynomial $P(x)$ are all real and distinct. Prove that the zeros of the polynomial $G(x)=n P(x) P^{\prime \prime}(x)-(n-1)\left(P^{\prime}(x)\right)^{2}$ are all complex.

172. Let $P(x)$ be a polynomial of degree $n>3$ whose zeros $x_{1}<x_{2}<x_{3}<\cdots<$ $x_{n-1}<x_{n}$ are real. Prove that

$$
P^{\prime}\left(\frac{x_{1}+x_{2}}{2}\right) \cdot P^{\prime}\left(\frac{x_{n-1}+x_{n}}{2}\right) \neq 0 .
$$

\subsubsection{The Location of the Zeros of a Polynomial}

Since not all polynomial equations can be solved by radicals, methods of approximation are necessary. Results that allow you to localize the roots in certain regions of the real axis or complex plane are therefore useful.

The qualitative study of the position of the zeros of a polynomial has far-reaching applications. For example, the solutions of a homogeneous ordinary linear differential equation with constant coefficients are stable (under errors of measuring the coefficients) if and only if the roots of the characteristic equation lie in the open left half-plane (i.e., have negative real part). Stability is, in fact, an essential question in control theory, where one is usually interested in whether the zeros of a particular polynomial lie in the open left half-plane (Hurwitz stability) or in the open unit disk (Schur stability). Here is a famous result.

Lucas' theorem. The zeros of the derivative $P^{\prime}(z)$ of a polynomial $P(z)$ lie in the convex hull of the zeros of $P(z)$.

Proof. Because any convex domain can be obtained as the intersection of half-planes, it suffices to show that if the zeros of $P(z)$ lie in an open half-plane, then the zeros of $P^{\prime}(z)$ lie in that half-plane as well. Moreover, by rotating and translating the variable $z$ we can further reduce the problem to the case in which the zeros of $P(z)$ lie in the upper half-plane $\operatorname{Im} z>0$. Here $\operatorname{Im} z$ denotes the imaginary part.

So let $z_{1}, z_{2}, \ldots, z_{n}$ be the (not necessarily distinct) zeros of $P(z)$, which by hypothesis have positive imaginary part. If $\operatorname{Im} w \leq 0$, then $\operatorname{Im} \frac{1}{w-z_{k}}>0$, for $k=1, \ldots, n$, and therefore 

$$
\operatorname{Im} \frac{P^{\prime}(w)}{P(w)}=\sum_{k=1}^{n} \operatorname{Im} \frac{1}{w-z_{k}}>0 .
$$

This shows that $w$ is not a zero of $P^{\prime}(z)$ and so all zeros of $P^{\prime}(z)$ lie in the upper half-plane. The theorem is proved.

173. Let $a_{1}, a_{2}, \ldots, a_{n}$ be positive real numbers. Prove that the polynomial $P(x)=$ $x^{n}-a_{1} x^{n-1}-a_{2} x^{n-2}-\cdots-a_{n}$ has a unique positive zero.

174. Prove that the zeros of the polynomial

$$
P(z)=z^{7}+7 z^{4}+4 z+1
$$

lie inside the disk of radius 2 centered at the origin.

175. For $a \neq 0$ a real number and $n>2$ an integer, prove that every nonreal root $z$ of the polynomial equation $x^{n}+a x+1=0$ satisfies the inequality $|z| \geq \sqrt[n]{\frac{1}{n-1}}$.

176. Let $a \in \mathbb{C}$ and $n \geq 2$. Prove that the polynomial equation $a x^{n}+x+1=0$ has a root of absolute value less than or equal to 2 .

177. Let $P(z)$ be a polynomial of degree $n$, all of whose zeros have absolute value 1 in the complex plane. Set $g(z)=\frac{P(z)}{z^{n / 2}}$. Show that all roots of the equation $g^{\prime}(z)=0$ have absolute value 1.

178. The polynomial $x^{4}-2 x^{2}+a x+b$ has four distinct real zeros. Show that the absolute value of each zero is smaller than $\sqrt{3}$.

179. Let $P_{n}(z), n \geq 1$, be a sequence of monic $k$ th-degree polynomials whose coefficients converge to the coefficients of a monic $k$ th-degree polynomial $P(z)$. Prove that for any $\epsilon>0$ there is $n_{0}$ such that if $n \geq n_{0}$ then $\left|z_{i}(n)-z_{i}\right|<\epsilon, i=1,2, \ldots, k$, where $z_{i}(n)$ are the zeros of $P_{n}(z)$ and $z_{i}$ are the zeros of $P(z)$, taken in the appropriate order.

180. Let $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$ be a polynomial with complex coefficients, with $a_{0} \neq 0$, and with the property that there exists an $m$ such that

$$
\left|\frac{a_{m}}{a_{0}}\right| \geq\left(\begin{array}{c}
n \\
m
\end{array}\right) .
$$

Prove that $P(x)$ has a zero of absolute value less than 1 .

181. For a polynomial $P(x)=\left(x-x_{1}\right)\left(x-x_{2}\right) \cdots\left(x-x_{n}\right)$, with distinct real zeros $x_{1}<x_{2}<\cdots<x_{n}$, we set $\delta(P(x))=\min _{i}\left(x_{i+1}-x_{i}\right)$. Prove that for any real number $k$,

$$
\delta\left(P^{\prime}(x)-k P(x)\right)>\delta(P(x)),
$$

where $P^{\prime}(x)$ is the derivative of $P(x)$. In particular, $\delta\left(P^{\prime}(x)\right)>\delta(P(x))$. 

\subsubsection{Irreducible Polynomials}

A polynomial is irreducible if it cannot be written as a product of two polynomials in a nontrivial manner. The question of irreducibility depends on the ring of coefficients. When the coefficients are complex numbers, only linear polynomials are irreducible. For real numbers some quadratic polynomials are irreducible as well. Both these cases are rather dull. The interesting situations occur when the coefficients are rational or integer, in which case there is an interplay between polynomials and arithmetic. The cases of rational and integer coefficients are more or less equivalent, with minor differences such as the fact that $2 x+2$ is irreducible over $\mathbb{Q}[x]$ but reducible over $\mathbb{Z}[x]$. For matters of elegance we focus on polynomials with integer coefficients. We will assume implicitly from now on that for any polynomial with integer coefficients, the greatest common divisor of its coefficients is 1 .

Definition. A polynomial $P(x) \in \mathbb{Z}[x]$ is called irreducible over $\mathbb{Z}[x]$ if there do not exist polynomials $Q(x), R(x) \in \mathbb{Z}[x]$ different from $\pm 1$ such that $P(x)=Q(x) R(x)$. Otherwise, $P(x)$ is called reducible.

We commence with an easy problem.

Example. Let $P(x)$ be an $n$ th-degree polynomial with integer coefficients with the property that $|P(x)|$ is a prime number for $2 n+1$ distinct integer values of the variable $x$. Prove that $P(x)$ is irreducible over $\mathbb{Z}[x]$.

Solution. Assume the contrary and let $P(x)=Q(x) R(x)$ with $Q(x), R(x) \in \mathbb{Z}[x]$, $Q(x), R(x) \neq \pm 1$. Let $k=\operatorname{deg}(Q(x))$. Then $Q(x)=1$ at most $k$ times and $Q(x)=$ $-1$ at most $n-k$ times. Also, $R(x)=1$ at most $n-k$ times and $R(x)=-1$ at most $k$ times. Consequently, the product $|Q(x) R(x)|$ is composite except for at most $k+(n-k)+(n-k)+k=2 n$ values of $x$. This contradicts the hypothesis. Hence $P(x)$ is irreducible.

The bound is sharp. For example, $P(x)=(x+1)(x+5)$ has $|P(-2)|=|P(-4)|=$ $3, P(0)=5$, and $|P(-6)|=7$.

Probably the most beautiful criterion of irreducibility of polynomials is that discovered independently by F.G.M. Eisenstein in 1850 and T. Schönemann in 1846. We present it below.

Theorem. Given a polynomial $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$ with integer coefficients, suppose that there exists a prime number $p$ such that $a_{n}$ is not divisible by $p$, $a_{k}$ is divisible by $p$ for $k=0,1, \ldots, n-1$, and $a_{0}$ is not divisible by $p^{2}$. Then $P(x)$ is irreducible over $\mathbb{Z}[x]$. Proof. We argue by contradiction. Suppose that $P(x)=Q(x) R(x)$, with $Q(x)$ and $R(x)$ not identically equal to $\pm 1$. Let

$$
\begin{aligned}
&Q(x)=b_{k} x^{k}+b_{k-1} x_{k-1}+\cdots+b_{0}, \\
&R(x)=c_{n-k} x^{n-k}+c_{n-k-1} x^{n-k-1}+\cdots+c_{0} .
\end{aligned}
$$

Let us look closely at the equalities

$$
\sum_{j=0}^{i} b_{j} c_{i-j}=a_{i}, \quad i=0,1, \ldots, n,
$$

obtained by identifying the coefficients. From the first of them, $b_{0} c_{0}=a_{0}$, and because $a_{0}$ is divisible by $p$ but not by $p^{2}$ it follows that exactly one of $b_{0}$ and $c_{0}$ is divisible by $p$. Assume that $b_{0}$ is divisible by $p$ and take the next equality $b_{0} c_{1}+b_{1} c_{0}=a_{1}$. The right-hand side is divisible by $p$, and the first term on the left is also divisible by $p$. Hence $b_{1} c_{0}$ is divisible by $p$, and since $c_{0}$ is not, $b_{1}$ must be divisible by $p$.

This reasoning can be repeated to prove that all the $b_{i}$ 's are divisible by $p$. It is important that both $Q(x)$ and $R(x)$ have degrees greater than or equal to 1 , for the fact that $b_{k}$ is divisible by $p$ follows from

$$
b_{k} c_{0}+b_{k-1} c_{1}+\cdots=a_{k},
$$

where $a_{k}$ is divisible by $p$ for $k<n$. The contradiction arises in the equality $a_{n}=b_{k} c_{n-k}$, since the right-hand side is divisible by $p$, while the left-hand side is not. This proves the theorem.

The first three problems listed below use this result, while the others apply similar ideas.

182. Prove that the polynomial

$$
P(x)=x^{101}+101 x^{100}+102
$$

is irreducible over $\mathbb{Z}[x]$.

183. Prove that for every prime number $p$, the polynomial

$$
P(x)=x^{p-1}+x^{p-2}+\cdots+x+1
$$

is irreducible over $\mathbb{Z}[x]$.

184. Prove that for every positive integer $n$, the polynomial $P(x)=x^{2^{n}}+1$ is irreducible over $\mathbb{Z}[x]$ 

185. Prove that for any distinct integers $a_{1}, a_{2}, \ldots, a_{n}$ the polynomial

$$
P(x)=\left(x-a_{1}\right)\left(x-a_{2}\right) \cdots\left(x-a_{n}\right)-1
$$

cannot be written as a product of two nonconstant polynomials with integer coefficients.

186. Prove that for any distinct integers $a_{1}, a_{2}, \ldots, a_{n}$ the polynomial

$$
P(x)=\left(x-a_{1}\right)^{2}\left(x-a_{2}\right)^{2} \cdots\left(x-a_{n}\right)^{2}+1
$$

cannot be written as a product of two nonconstant polynomials with integer coefficients.

187. Associate to a prime the polynomial whose coefficients are the decimal digits of the prime (for example, for the prime 7043 the polynomial is $P(z)=7 x^{3}+4 x+3$ ). Prove that this polynomial is always irreducible over $\mathbb{Z}[x]$.

188. Let $p$ be a prime number of the form $4 k+3, k$ an integer. Prove that for any positive integer $n$, the polynomial $\left(x^{2}+1\right)^{n}+p$ is irreducible in the ring $\mathbb{Z}[x]$.

189. Let $p$ be a prime number. Prove that the polynomial

$$
P(x)=x^{p-1}+2 x^{p-2}+3 x^{p-3}+\cdots+(p-1) x+p
$$

is irreducible in $\mathbb{Z}[x]$.

190. Let $P(x)$ be a monic polynomial in $\mathbb{Z}[x]$, irreducible over this ring, and such that $|P(0)|$ is not the square of an integer. Prove that the polynomial $Q(x)$ defined by $Q(x)=P\left(x^{2}\right)$ is also irreducible over $\mathbb{Z}[x]$.

\subsubsection{Chebyshev Polynomials}

The $n$th Chebyshev polynomial $T_{n}(x)$ expresses $\cos n \theta$ as a polynomial in $\cos \theta$. This means that $T_{n}(x)=\cos (n \arccos x)$, for $n \geq 0$. These polynomials satisfy the recurrence

$$
T_{0}(x)=1, \quad T_{1}(x)=x, \quad T_{n+1}(x)=2 x T_{n}(x)-T_{n-1}(x), \quad \text { for } n \geq 1 .
$$

For example, $T_{2}(x)=2 x^{2}-1, T_{3}(x)=4 x^{3}-3 x, T_{4}(x)=8 x^{4}-8 x^{2}+1$.

One usually calls these the Chebyshev polynomials of the first kind, to distinguish them from the Chebyshev polynomials of the second kind $U_{n}(x)$ defined by $U_{0}(x)=1$, $U_{1}(x)=2 x, U_{n+1}(x)=2 x U_{n}(x)-U_{n-1}(x)$, for $n \geq 1$ (same recurrence relation but different initial condition). Alternatively, $U_{n}(x)$ can be defined by the equality $U_{n}(\cos \theta)=\frac{\sin (n+1) \theta}{\sin \theta}$. Chebyshev's theorem. For fixed $n \geq 1$, the polynomial $2^{-n+1} T_{n}(x)$ is the unique monic nth-degree polynomial satisfying

$$
\max _{-1 \leq x \leq 1}\left|2^{-n+1} T(x)\right| \leq \max _{-1 \leq x \leq 1}|P(x)|,
$$

for any other monic nth-degree polynomial $P(x)$.

One says that among all monic $n$ th-degree polynomials, $2^{-n+1} T_{n}(x)$ has the smallest variation away from zero on $[-1,1]$. This variation is $\frac{1}{2^{n-1}}$. Let us see how Chebyshev's theorem applies to a problem from Challenging Mathematical Problems with Elementary Solutions by A.M. Yaglom and I.M. Yaglom.

Example. Let $A_{1}, A_{2}, \ldots, A_{n}$ be points in the plane. Prove that on any segment of length $l$ there is a point $M$ such that

$$
M A_{1} \cdot M A_{2} \cdots M A_{n} \geq 2\left(\frac{l}{4}\right)^{n} .
$$

Solution. Rescaling, we can assume that $l=2$. Associate complex coordinates to points in such a way that the segment coincides with the interval $[-1,1]$. Then

$$
M A_{1} \cdot M A_{2} \cdots M A_{n}=\left|z-z_{1}\right| \cdot\left|z-z_{2}\right| \cdots\left|z-z_{n}\right|=|P(z)|,
$$

where $P(z)$ is a monic polynomial with complex coefficients, and $z \in[-1,1]$. Write $P(z)=R(z)+i Q(z)$, where $R(z)$ is the real part and $Q(z)$ is the imaginary part of the polynomial. Since $z$ is real, we have $|P(z)| \geq|R(z)|$. The polynomial $R(z)$ is monic, so on the interval $[-1,1]$ it varies away from zero at least as much as the Chebyshev polynomial. Thus we can find $z$ in this interval such that $|R(z)| \geq \frac{1}{2^{n-1}}$. This implies $|P(z)| \geq 2 \cdot \frac{1}{2^{n}}$, and rescaling back we deduce the existence in the general case of a point $M$ satisfying the inequality from the statement.

Stepping aside from the classical picture, let us also consider the families of polynomials $\mathcal{T}_{n}(x)$ and $\mathcal{U}_{n}(x)$ defined by $\mathcal{T}_{0}(x)=2, \mathcal{T}_{1}(x)=x, \mathcal{T}_{n+1}(x)=x \mathcal{T}_{n}(x)-\mathcal{T}_{n-1}(x)$, and $\mathcal{U}_{0}(x)=1, \mathcal{U}_{1}(x)=x, \mathcal{U}_{n+1}(x)=x \mathcal{U}_{n}(x)-\mathcal{U}_{n-1}(x)$. These polynomials are determined by the equalities

$$
\mathcal{T}_{n}\left(z+\frac{1}{z}\right)=z^{n}+\frac{1}{z^{n}} \quad \text { and } \quad \mathcal{U}_{n}\left(z+\frac{1}{z}\right)=\left(z^{n+1}-\frac{1}{z^{n+1}}\right) /\left(z-\frac{1}{z}\right) .
$$

Also, $T_{n}(x)=\frac{1}{2} \mathcal{T}_{n}(2 x)$ and $U_{n}(x)=\mathcal{U}_{n}(2 x)$. Here is a quickie that uses $\mathcal{T}_{n}(x)$.

Example. Let $a$ be a real number such that $a+a^{-1}$ is an integer. Prove that for any $n \geq 1$, the number $a^{n}+a^{-n}$ is an integer. Solution. An inductive argument based on the recurrence relation shows that $\mathcal{T}_{n}(x)$ is a polynomial with integer coefficients. And since $a^{n}+a^{-n}=\mathcal{T}_{n}\left(a+a^{-1}\right)$, it follows that this number is an integer.

191. Prove that for $n \geq 1$,

$$
\begin{aligned}
T_{n+1}(x) &=x T_{n}(x)-\left(1-x^{2}\right) U_{n-1}(x), \\
U_{n}(x) &=x U_{n-1}(x)+T_{n}(x),
\end{aligned}
$$

192. Compute the $n \times n$ determinants

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-074.jpg?height=324&width=791&top_left_y=683&top_left_x=517)

193. Prove Chebyshev's theorem for $n=4$ : namely, show that for any monic fourthdegree polynomial $P(x)$,

$$
\max _{-1 \leq x \leq 1}|P(x)| \geq \max _{-1 \leq x \leq 1}\left|2^{-3} T_{4}(x)\right|,
$$

with equality if and only if $P(x)=2^{-3} T_{4}(x)$.

194. Let $r$ be a positive real number such that $\sqrt[6]{r}+\frac{1}{\sqrt[6]{r}}=6$. Find the maximum value of $\sqrt[4]{r}-\frac{1}{\sqrt[4]{r}}$

195. Let $\alpha=\frac{2 \pi}{n}$. Prove that the matrix

$$
\left(\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
\cos \alpha & \cos 2 \alpha & \cdots & \cos n \alpha \\
\cos 2 \alpha & \cos 4 \alpha & \cdots & \cos 2 n \alpha \\
\vdots & \vdots & \ddots & \vdots \\
\cos (n-1) \alpha \cos 2(n-1) \alpha & \cdots & \cos (n-1) n \alpha
\end{array}\right)
$$

is invertible.

196. Find all quintuples $(x, y, z, v, w)$ with $x, y, z, v, w \in[-2,2]$ satisfying the system of equations

$$
\begin{aligned}
x+y+z+v+w &=0, \\
x^{3}+y^{3}+z^{3}+v^{3}+w^{3} &=0, \\
x^{5}+y^{5}+z^{5}+v^{5}+w^{5} &=-10 .
\end{aligned}
$$

197. Let $x_{1}, x_{2}, \ldots, x_{n}, n \geq 2$, be distinct real numbers in the interval $[-1,1]$. Prove that

$$
\frac{1}{t_{1}}+\frac{1}{t_{2}}+\cdots+\frac{1}{t_{n}} \geq 2^{n-2},
$$

where $t_{k}=\prod_{j \neq k}\left|x_{j}-x_{k}\right|, k=1,2, \ldots, n$.

198. For $n \geq 1$, prove the following identities:

$$
\begin{aligned}
\frac{T_{n}(x)}{\sqrt{1-x^{2}}} &=\frac{(-1)^{n}}{1 \cdot 3 \cdot 5 \cdots(2 n-1)} \frac{d^{n}}{d x^{n}}\left(1-x^{2}\right)^{n-\frac{1}{2}}, \\
U_{n}(x) \sqrt{1-x^{2}} &=\frac{(-1)^{n}(n+1)}{1 \cdot 3 \cdot 5 \cdots(2 n+1)} \frac{d^{n}}{d x^{n}}\left(1-x^{2}\right)^{n+\frac{1}{2}} .
\end{aligned}
$$

\subsection{Linear Algebra}

\subsubsection{Operations with Matrices}

An $m \times n$ matrix is an array with $m$ rows and $n$ columns. The standard notation is $A=\left(a_{i j}\right)_{i, j}$, where $a_{i j}$ is the entry (element) in the $i$ th row and $j$ th column. We denote by $\mathcal{I}_{n}$ the $n \times n$ identity matrix (for which $a_{i j}=1$ if $i=j$, and 0 otherwise) and by $\mathcal{O}_{n}$ the $n \times n$ zero matrix (for which $a_{i j}=0$ for all $i, j$ ).

Given the matrix $A=\left(a_{i j}\right)_{i, j}, A^{t}$ denotes the transpose of $A$, in which the $i, j$ entry is $a_{j i}$, and $\bar{A}$ denotes the complex conjugate, whose entries are the complex conjugates of the entries of $A$. Also, $\operatorname{tr} A$ is the trace of $A$, namely the sum of the elements on the main diagonal: $a_{11}+a_{22}+\cdots+a_{n n}$.

We illustrate how matrix multiplication can be used to prove an identity satisfied by the Fibonacci sequence $\left(F_{0}=0, F_{1}=1, F_{n+1}=F_{n}+F_{n-1}, n \geq 1\right)$. The identity we have in mind has already been discussed in the introductory chapter in the solution to problem 24; we put it here in a new perspective.

Example. Prove that

$$
F_{m+n+1}=F_{m+1} F_{n+1}+F_{m} F_{n}, \quad \text { for } m, n \geq 0 .
$$

Solution. Consider the matrix

$$
M=\left(\begin{array}{ll}
1 & 1 \\
1 & 0
\end{array}\right) .
$$

An easy induction shows that for $n \geq 1$,

$$
M^{n}=\left(\begin{array}{ll}
F_{n+1} & F_{n} \\
F_{n} & F_{n-1}
\end{array}\right) .
$$

The equality $M^{m+n}=M^{m} M^{n}$ written in explicit form is

$$
\left(\begin{array}{ll}
F_{m+n+1} & F_{m+n} \\
F_{m+n} & F_{m+n-1}
\end{array}\right)=\left(\begin{array}{ll}
F_{m+1} & F_{m} \\
F_{m} & F_{m-1}
\end{array}\right)\left(\begin{array}{ll}
F_{n+1} & F_{n} \\
F_{n} & F_{n-1}
\end{array}\right) .
$$

We obtain the identity by setting the upper left corners of both sides equal.

Here are some problems for the reader.

199. Let $M$ be an $n \times n$ complex matrix. Prove that there exist Hermitian matrices $A$ and $B$ such that $M=A+i B$. (A matrix $X$ is called Hermitian if $\overline{X^{t}}=X$ ).

200. Do there exist $n \times n$ matrices $A$ and $B$ such that $A B-B A=\mathcal{I}_{n}$ ?

201. Let $A$ and $B$ be $2 \times 2$ matrices with real entries satisfying $(A B-B A)^{n}=\mathcal{I}_{2}$ for some positive integer $n$. Prove that $n$ is even and $(A B-B A)^{4}=\mathcal{I}_{2}$.

202. Let $A$ and $B$ be two $n \times n$ matrices that do not commute and for which there exist nonzero real numbers $p, q, r$ such that $p A B+q B A=\mathcal{I}_{n}$ and $A^{2}=r B^{2}$. Prove that $p=q$.

203. Let $a, b, c, d$ be real numbers such that $c \neq 0$ and $a d-b c=1$. Prove that there exist $u$ and $v$ such that

$$
\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)=\left(\begin{array}{rr}
1 & -u \\
0 & 1
\end{array}\right)\left(\begin{array}{ll}
1 & 0 \\
c & 1
\end{array}\right)\left(\begin{array}{rr}
1 & -v \\
0 & 1
\end{array}\right) .
$$

204. Compute the $n$th power of the $m \times m$ matrix

$$
J_{m}(\lambda)=\left(\begin{array}{ccccc}
\lambda & 1 & 0 & \cdots & 0 \\
0 & \lambda & 1 & \cdots & 0 \\
0 & 0 & \lambda & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
0 & 0 & 0 & \cdots & \lambda
\end{array}\right), \quad \lambda \in \mathbb{C} .
$$

205. Let $A$ and $B$ be $n \times n$ matrices with real entries satisfying

$$
\operatorname{tr}\left(A A^{t}+B B^{t}\right)=\operatorname{tr}\left(A B+A^{t} B^{t}\right) .
$$

Prove that $A=B^{t}$. 

\subsubsection{Determinants}

The determinant of an $n \times n$ matrix $A=\left(a_{i j}\right)_{i, j}$, denoted by $\operatorname{det} A$ or $\left|a_{i j}\right|$, is the volume taken with sign of the $n$-dimensional parallelepiped determined by the row (or column) vectors of $A$. Formally, the determinant can be introduced as follows. Let $e_{1}=(1,0, \ldots, 0), e_{2}=(0,1, \ldots, 0), \ldots, e_{n}=(0,0, \ldots, 1)$ be the canonical basis of $\mathbb{R}^{n}$. The exterior algebra of $\mathbb{R}^{n}$ is the vector space spanned by products of the form $e_{i_{1}} \wedge e_{i_{2}} \wedge \cdots \wedge e_{i_{k}}$, where the multiplication $\wedge$ is distributive with respect to sums and is subject to the noncommutativity rule $e_{i} \wedge e_{j}=-e_{j} \wedge e_{i}$ for all $i, j$ (which then implies $e_{i} \wedge e_{i}=0$, for all $i$ ). If the row vectors of the matrix $A$ are $r_{1}, r_{2}, \ldots, r_{n}$, then the determinant is defined by the equality

$$
r_{1} \wedge r_{2} \wedge \cdots \wedge r_{n}=(\operatorname{det} A) e_{1} \wedge e_{2} \wedge \cdots \wedge e_{n} .
$$

The explicit formula is

$$
\operatorname{det} A=\sum_{\sigma} \operatorname{sign}(\sigma) a_{1 \sigma(1)} a_{2 \sigma(2)} \cdots a_{n \sigma(n)},
$$

with the sum taken over all permutations $\sigma$ of $\{1,2, \ldots, n\}$.

To compute the determinant of a matrix, one applies repeatedly the row operation that adds to one row a multiple of another until the matrix either becomes diagonal or has a row of zeros. In the first case this transforms the parallelepiped determined by the row vectors into a right parallelepiped in standard position without changing its volume, as suggested in Figure 13.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-077.jpg?height=310&width=1196&top_left_y=1361&top_left_x=267)

Figure 13

But it is not our purpose to teach the basics. We insist only on nonstandard tricks and methods. A famous example is the computation of the Vandermonde determinant.

Example. Let $x_{1}, x_{2}, \ldots, x_{n}$ be arbitrary numbers $(n \geq 1)$. Compute the determinant

$$
\left|\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
x_{1} & x_{2} & \cdots & x_{n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-1} & x_{2}^{n-1} & \cdots & x_{n}^{n-1}
\end{array}\right| .
$$

Solution. The key idea is to view $x_{n}$ as a variable and think of the determinant as an $(n-1)$ st-degree polynomial in $x_{n}$. The leading coefficient is itself a Vandermonde determinant of order $n-1$, while the $n-1$ roots are obviously $x_{2}, x_{3}, \ldots, x_{n-1}$. The determinant is therefore equal to

$$
\left|\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
x_{1} & x_{2} & \cdots & x_{n-1} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-2} & x_{2}^{n-2} & \cdots & x_{n-1}^{n-2}
\end{array}\right|\left(x_{n}-x_{1}\right)\left(x_{n}-x_{2}\right) \cdots\left(x_{n}-x_{n-1}\right) \text {. }
$$

Now we can induct on $n$ to prove that the Vandermonde determinant is equal to $\prod_{i>j}\left(x_{i}-x_{j}\right)$. This determinant is equal to zero if and only if two of the $x_{i}$ 's are equal.

We continue with a problem of D. Andrica.

Example. (a) Consider the real numbers $a_{i j}, i=1,2, \ldots, n-2, j=1,2, \ldots, n, n \geq 3$, and the determinants

$$
A_{k}=\left|\begin{array}{cccccc}
1 & \cdots & 1 & 1 & \cdots & 1 \\
a_{11} & \cdots & a_{1, k-1} & a_{1, k+1} & \cdots & a_{1 n} \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
a_{n-2,1} & \cdots & a_{n-2, k-1} & a_{n-2, k+1} & \cdots & a_{n-2, n}
\end{array}\right| .
$$

Prove that

$$
A_{1}+A_{3}+A_{5}+\cdots=A_{2}+A_{4}+A_{6}+\cdots .
$$

(b) Define

$$
p_{k}=\prod_{i=0}^{n-(k+1)}\left(x_{n-i}-x_{k}\right), \quad q_{k}=\prod_{i=1}^{k-1}\left(x_{k}-x_{i}\right),
$$

where $x_{i}, i=1,2, \ldots, n$, are some distinct real numbers. Prove that

$$
\sum_{k=1}^{n} \frac{(-1)^{k}}{p_{k} q_{k}}=0 .
$$

(c) Prove that for any positive integer $n \geq 3$ the following identity holds:

$$
\sum_{k=1}^{n} \frac{(-1)^{k} k^{2}}{(n-k) !(n+k) !}=0 .
$$

Solution. We have

$$
\left|\begin{array}{ccccc}
1 & 1 & \cdots & 1 & 1 \\
1 & 1 & \cdots & 1 & 1 \\
a_{11} & a_{12} & \cdots & a_{1, n-1} & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2, n-1} & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
a_{n-2,1} & a_{n-2,2} & \cdots & a_{n-2, n-1} & a_{n-2, n}
\end{array}\right|=0 .
$$

Expanding by the first row, we obtain

$$
A_{1}-A_{2}+A_{3}-A_{4}+\cdots=0 .
$$

This implies

$$
A_{1}+A_{3}+A_{5}+\cdots=A_{2}+A_{4}+A_{6}+\cdots,
$$

and (a) is proved.

For (b), we substitute $a_{i j}=x_{i}^{j}, i=1,2, \ldots, n-2, j=1,2, \ldots, n$. Then

$$
A_{k}=\left|\begin{array}{cccccc}
1 & \cdots & 1 & 1 & \ldots & 1 \\
x_{1} & \cdots & x_{k-1} & x_{k+1} & \ldots & x_{n} \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-2} & \cdots & x_{k-1}^{n-2} & x_{k+1}^{n-2} & \cdots & x_{n}^{n-2}
\end{array}\right|,
$$

which is a Vandermonde determinant. Its value is equal to

$$
\prod_{\substack{i>j \\ i, j \neq k}}\left(x_{i}-x_{j}\right)=\frac{1}{p_{k} q_{k}} .
$$

The equality proved in (a) becomes, in this particular case,

$$
\sum_{k=1}^{n} \frac{(-1)^{k}}{p_{k} q_{k}}=0,
$$

as desired.

Finally, if in this we let $x_{k}=k^{2}$, then we obtain the identity from part (c), and the problem is solved.

And here comes a set of problems for the reader. 

206. Prove that

$$
\left|\begin{array}{c}
\left(x^{2}+1\right)^{2}(x y+1)^{2}(x z+1)^{2} \\
(x y+1)^{2}\left(y^{2}+1\right)^{2}(y z+1)^{2} \\
(x z+1)^{2}(y z+1)^{2}\left(z^{2}+1\right)^{2}
\end{array}\right|=2(y-z)^{2}(z-x)^{2}(x-y)^{2} .
$$

207. Let $\left(F_{n}\right)_{n}$ be the Fibonacci sequence. Using determinants, prove the identity

$$
F_{n+1} F_{n-1}-F_{n}^{2}=(-1)^{n}, \quad \text { for all } n \geq 1 \text {. }
$$

208. Let $p<m$ be two positive integers. Prove that

$$
\left|\begin{array}{cccc}
\left(\begin{array}{c}
m \\
0
\end{array}\right) & \left(\begin{array}{c}
m \\
1
\end{array}\right) & \cdots & \left(\begin{array}{c}
m \\
p
\end{array}\right) \\
\left(\begin{array}{c}
m+1 \\
0
\end{array}\right) & \left(\begin{array}{c}
m+1 \\
1
\end{array}\right) & \cdots & \left(\begin{array}{c}
m+1 \\
p
\end{array}\right) \\
\vdots & \vdots & \ddots & \vdots \\
\left(\begin{array}{c}
m+p \\
0
\end{array}\right) & \left(\begin{array}{c}
m+p \\
1
\end{array}\right) & \cdots & \left(\begin{array}{c}
m+p \\
p
\end{array}\right)
\end{array}\right|=1 .
$$

209. Given distinct integers $x_{1}, x_{2}, \ldots, x_{n}$, prove that $\prod_{i>j}\left(x_{i}-x_{j}\right)$ is divisible by $1 ! 2 ! \cdots(n-1) !$

210. Prove the formula for the determinant of a circulant matrix

$$
\left|\begin{array}{lllll}
x_{1} & x_{2} & x_{3} & \cdots & x_{n} \\
x_{n} & x_{1} & x_{2} & \cdots & x_{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
x_{3} & x_{4} & x_{5} & \cdots & x_{2} \\
x_{2} & x_{3} & x_{4} & \cdots & x_{1}
\end{array}\right|=(-1)^{n-1} \prod_{j=0}^{n-1}\left(\sum_{k=1}^{n} \zeta^{j k} x_{k}\right) \text {, }
$$

where $\zeta=e^{2 \pi i / n}$

211. Compute the determinant of the $n \times n$ matrix $A=\left(a_{i j}\right)_{i j}$, where

$$
a_{i j}= \begin{cases}(-1)^{|i-j|} & \text { if } i \neq j, \\ 2 & \text { if } i=j .\end{cases}
$$

212. Prove that for any integers $x_{1}, x_{2}, \ldots, x_{n}$ and positive integers $k_{1}, k_{2}, \ldots, k_{n}$, the determinant

$$
\left|\begin{array}{cccc}
x_{1}^{k_{1}} & x_{2}^{k_{1}} & \cdots & x_{n}^{k_{1}} \\
x_{1}^{k_{2}} & x_{2}^{k_{2}} & \cdots & x_{n}^{k_{2}} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{k_{n}} & x_{2}^{k_{n}} & \cdots & x_{n}^{k_{n}}
\end{array}\right|
$$

is divisible by $n !$ ! 

213. Let $A$ and $B$ be $3 \times 3$ matrices with real elements such that $\operatorname{det} A=\operatorname{det} B=$ $\operatorname{det}(A+B)=\operatorname{det}(A-B)=0$. Prove that $\operatorname{det}(x A+y B)=0$ for any real numbers $x$ and $y$.

Sometimes it is more convenient to work with blocks instead of entries. For that we recall the rule of Laplace, which is the direct generalization of the row or column expansion. The determinant is computed by expanding over all $k \times k$ minors of some $k$ rows or columns. Explicitly, given $A=\left(a_{i j}\right)_{i, j=1}^{n}$, when expanding by the rows $i_{1}, i_{2}, \ldots, i_{k}$, the determinant is given by

$$
\operatorname{det} A=\sum_{j_{1}<j_{2}<\cdots<j_{k}}(-1)^{i_{1}+\cdots+i_{k}+j_{1}+\cdots+j_{k}} M_{k} N_{k},
$$

where $M_{k}$ is the determinant of the $k \times k$ matrix whose entries are $a_{i j}$, with $i \in$ $\left\{i_{1}, i_{2}, \ldots, i_{k}\right\}$ and $j \in\left\{j_{1}, j_{2}, \ldots, j_{k}\right\}$, while $N_{k}$ is the determinant of the $(n-k) \times(n-k)$ matrix whose entries are $a_{i j}$ with $i \notin\left\{i_{1}, i_{2}, \ldots, i_{k}\right\}$ and $j \notin\left\{j_{1}, j_{2}, \ldots, j_{k}\right\}$. We exemplify this rule with a problem from the 4th International Competition in Mathematics for University Students (1997).

Example. Let $M$ be an invertible $2 n \times 2 n$ matrix, represented in block form as

$$
M=\left(\begin{array}{ll}
A & B \\
C & D
\end{array}\right) \quad \text { and } \quad M^{-1}=\left(\begin{array}{cc}
E & F \\
G & H
\end{array}\right) .
$$

Show that $\operatorname{det} M \cdot \operatorname{det} H=\operatorname{det} A$.

Solution. The idea of the solution is that the relation between determinants should come from a relation between matrices. To this end, we would like to find three matrices $X, Y, Z$ such that $X Y=Z$, while $\operatorname{det} X=\operatorname{det} M$, $\operatorname{det} Y=\operatorname{det} H$, and $\operatorname{det} Z=\operatorname{det} A$. Since among $M, H$, and $A$, the matrix $M$ has the largest dimension, we might try to set $X=M$ and find $2 n \times 2 n$ matrices $Y$ and $Z$. The equality $M \cdot M^{-1}=\mathcal{I}_{2 n}$ yields two relations involving $H$, namely $A F+B H=0$ and $C F+D H=\mathcal{I}_{n}$. This suggests that we should use both $F$ and $H$ in the definition of $Y$. So we need an equality of the form

$$
\left(\begin{array}{ll}
A & B \\
C & D
\end{array}\right)\left(\begin{array}{cc}
* & F \\
* & H
\end{array}\right)=\left(\begin{array}{cc}
* & 0 \\
* & \mathcal{I}_{n}
\end{array}\right) .
$$

We can try

$$
Y=\left(\begin{array}{rr}
\mathcal{I}_{n} & F \\
0 & H
\end{array}\right) .
$$

The latter has determinant equal to det $H$, as desired. Also, 

$$
Z=\left(\begin{array}{cc}
A & 0 \\
C & \mathcal{I}_{n}
\end{array}\right) .
$$

According to the rule of Laplace, the determinant of $Z$ can be computed by expanding along the $n \times n$ minors from the top $n$ rows, and all of them are zero except for the first. Hence $\operatorname{det} Z=\operatorname{det} A \cdot \operatorname{det} \mathcal{I}_{n}=\operatorname{det} A$, and so the matrices $X, Y, Z$ solve the problem.

214. Show that if

$$
x=\left|\begin{array}{ll}
a & b \\
c & d
\end{array}\right| \quad \text { and } \quad x^{\prime}=\left|\begin{array}{ll}
a^{\prime} & b^{\prime} \\
c^{\prime} & d^{\prime}
\end{array}\right|,
$$

then

$$
\left(x x^{\prime}\right)^{2}=\left|\begin{array}{llll}
a b^{\prime} & c b^{\prime} & b a^{\prime} & d a^{\prime} \\
a d^{\prime} & c d^{\prime} & b c^{\prime} & d c^{\prime} \\
b b^{\prime} & d b^{\prime} & a a^{\prime} & c a^{\prime} \\
b d^{\prime} & d d^{\prime} & a c^{\prime} & c c^{\prime}
\end{array}\right| .
$$

215. Let $A, B, C, D$ be $n \times n$ matrices such that $A C=C A$. Prove that

$$
\operatorname{det}\left(\begin{array}{ll}
A & B \\
C & D
\end{array}\right)=\operatorname{det}(A D-C B) .
$$

216. Let $X$ and $Y$ be $n \times n$ matrices. Prove that

$$
\operatorname{det}\left(\mathcal{I}_{n}-X Y\right)=\operatorname{det}\left(\mathcal{I}_{n}-Y X\right) .
$$

A property exploited often in Romanian mathematics competitions states that for any $n \times n$ matrix $A$ with real entries,

$$
\operatorname{det}\left(\mathcal{I}_{n}+A^{2}\right) \geq 0 .
$$

The proof is straightforward:

$$
\begin{aligned}
\operatorname{det}\left(\mathcal{I}_{n}+A^{2}\right) &=\operatorname{det}\left(\left(\mathcal{I}_{n}+i A\right)\left(\mathcal{I}_{n}-i A\right)\right)=\operatorname{det}\left(\mathcal{I}_{n}+i A\right) \operatorname{det}\left(\mathcal{I}_{n}-i A\right) \\
&=\operatorname{det}\left(\mathcal{I}_{n}+i A\right) \operatorname{det}\left(\overline{\mathcal{I}_{n}+i A}\right)=\operatorname{det}\left(\mathcal{I}_{n}+i A\right) \overline{\operatorname{det}\left(\mathcal{I}_{n}+i A\right)} .
\end{aligned}
$$

In this computation the bar denotes the complex conjugate, and the last equality follows from the fact that the determinant is a polynomial in the entries. The final expression is positive, being equal to $\left|\operatorname{det}\left(\mathcal{I}_{n}+i A\right)\right|^{2}$.

Use this property to solve the following problems, while assuming that all matrices have real entries.

217. Let $A$ and $B$ be $n \times n$ matrices that commute. Prove that if $\operatorname{det}(A+B) \geq 0$, then $\operatorname{det}\left(A^{k}+B^{k}\right) \geq 0$ for all $k \geq 1$. 

218. Let $A$ be an $n \times n$ matrix such that $A+A^{t}=\mathcal{O}_{n}$. Prove that

$$
\operatorname{det}\left(\mathcal{I}_{n}+\lambda A^{2}\right) \geq 0,
$$

for all $\lambda \in \mathbb{R}$.

219. Let $P(t)$ be a polynomial of even degree with real coefficients. Prove that the function $f(X)=P(X)$ defined on the set of $n \times n$ matrices is not onto.

220. Let $n$ be an odd positive integer and $A$ an $n \times n$ matrix with the property that $A^{2}=\mathcal{O}_{n}$ or $A^{2}=\mathcal{I}_{n}$. Prove that $\operatorname{det}\left(A+\mathcal{I}_{n}\right) \geq \operatorname{det}\left(A-\mathcal{I}_{n}\right)$.

\subsubsection{The Inverse of a Matrix}

An $n \times n$ matrix $A$ is called invertible if there exists an $n \times n$ matrix $A^{-1}$ such that $A A^{-1}=A^{-1} A=\mathcal{I}_{n}$. The inverse of a matrix can be found either by using the adjoint matrix, which amounts to computing several determinants, or by performing row and column operations. We illustrate how the latter method can be applied to a problem from the first International Competition in Mathematics for University Students (1994).

\section{Example.}

(a) Let $A$ be an $n \times n$ symmetric invertible matrix with positive real entries, $n \geq 2$. Show that $A^{-1}$ has at most $n^{2}-2 n$ entries equal to zero.

(b) How many entries are equal to zero in the inverse of the $n \times n$ matrix

$$
A=\left(\begin{array}{cccccc}
1 & 1 & 1 & 1 & \cdots & 1 \\
1 & 2 & 2 & 2 & \cdots & 2 \\
1 & 2 & 1 & 1 & \cdots & 1 \\
1 & 2 & 1 & 2 & \cdots & 2 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 2 & 1 & 2 & \cdots & \cdots
\end{array}\right) ?
$$

Solution. Denote by $a_{i j}$ and $b_{i j}$ the entries of $A$, respectively, $A^{-1}$. Then we have $\sum_{i=0}^{n} a_{m i} b_{i m}=1$, so for fixed $m$ not all the $b_{i m}$ 's are equal to zero. For $k \neq m$ we have $\sum_{i=0}^{n} a_{k i} b_{i m}=0$, and from the positivity of the $a_{k i}$ 's we conclude that at least one $b_{i m}$ is negative, and at least one is positive. Hence every column of $A^{-1}$ contains at least two nonzero elements. This proves part (a).

To compute the inverse of the matrix in part (b), we consider the extended matrix $\left(A \mathcal{I}_{n}\right)$, and using row operations we transform it into the matrix $\left(\mathcal{I}_{n} A^{-1}\right)$. We start with 

$$
\left(\begin{array}{cccccccccccc}
1 & 1 & 1 & 1 & \cdots & 1 & 1 & 0 & 0 & 0 & \cdots & 0 \\
1 & 2 & 2 & 2 & \cdots & 2 & 0 & 1 & 0 & 0 & \cdots & 0 \\
1 & 2 & 1 & 1 & \cdots & 1 & 0 & 0 & 1 & 0 & \cdots & 0 \\
1 & 2 & 1 & 2 & \cdots & 2 & 0 & 0 & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 2 & 1 & 2 & \cdots & \cdots & 0 & 0 & 0 & 0 & \cdots & 1
\end{array}\right) .
$$

Subtracting the first row from each of the others, then the second row from the first, we obtain

$$
\left(\begin{array}{cccccccccccc}
1 & 0 & 0 & 0 & \cdots & 0 & 2 & -1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 1 & 1 & \cdots & 1 & -1 & 1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & 0 & \cdots & 0 & -1 & 0 & 1 & 0 & \cdots & 0 \\
0 & 1 & 0 & 1 & \cdots & 1 & -1 & 0 & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 1 & 0 & 1 & \cdots & \cdots & -1 & 0 & 0 & 0 & \cdots & 1
\end{array}\right) .
$$

We continue as follows. First, we subtract the second row from the third, fourth, and so on. Then we add the third row to the second. Finally, we multiply all rows, beginning with the third, by $-1$. This way we obtain

$$
\left(\begin{array}{cccccccccccc}
1 & 0 & 0 & 0 & \cdots & 0 & 2 & -1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & 0 & \cdots & 0 & -1 & 0 & 1 & 0 & \cdots & 0 \\
0 & 0 & 1 & 1 & \cdots & 1 & 0 & 1 & -1 & 0 & \cdots & 0 \\
0 & 0 & 1 & 0 & \cdots & 0 & 0 & 1 & 0 & -1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 1 & 0 & \cdots & \cdots & 1 & 0 & 0 & 0 & \cdots & -1
\end{array}\right) .
$$

Now the inductive pattern is clear. At each step we subtract the $k$ th row from the rows below, then subtract the $(k+1)$ st from the $k$ th, and finally multiply all rows starting with the $(k+1)$ st by $-1$. In the end we find that the entries of $A^{-1}$ are $b_{1,1}=2, b_{n, n}=(-1)^{n}$, $b_{i, i+1}=b_{i+1, i}=(-1)^{i}$, and $b_{i j}=0$, for $|i-j| \geq 2$. This example shows that equality can hold in part (a).

221. For distinct numbers $x_{1}, x_{2}, \ldots, x_{n}$, consider the matrix

$$
A=\left(\begin{array}{llll}
1 & 1 & \cdots & 1 \\
x_{1} & x_{2} & \cdots & x_{n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-1} & x_{2}^{n-1} & \cdots & x_{n}^{n-1}
\end{array}\right) .
$$

It is known that $\operatorname{det} A$ is the Vandermonde determinant $\Delta\left(x_{1}, x_{2}, \ldots, x_{n}\right)=$ $\prod_{i>j}\left(x_{i}-x_{j}\right)$. Prove that the inverse of $A$ is $B=\left(b_{k m}\right)_{1 \leq k, m \leq n}$, where 

$$
\begin{aligned}
b_{k m}=&(-1)^{k+m} \Delta\left(x_{1}, x_{2}, \ldots, x_{n}\right)^{-1} \Delta\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) \\
& \times S_{n-1}\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) .
\end{aligned}
$$

Here $S_{n-1}$ denotes the $(n-1)$ st symmetric polynomial in $n-1$ variables.

222. Let $A$ and $B$ be $2 \times 2$ matrices with integer entries such that $A, A+B, A+2 B$, $A+3 B$, and $A+4 B$ are all invertible matrices whose inverses have integer entries. Prove that $A+5 B$ is invertible and that its inverse has integer entries.

223. Determine the matrix $A$ knowing that its adjoint matrix (the one used in the computation of the inverse) is

$$
A^{*}=\left(\begin{array}{ccc}
m^{2}-1 & 1-m & 1-m \\
1-m & m^{2}-1 & 1-m \\
1-m & 1-m & m^{2}-1
\end{array}\right), \quad m \neq 1,-2
$$

224. Let $A=\left(a_{i j}\right)_{i j}$ be an $n \times n$ matrix such that $\sum_{j=1}^{n}\left|a_{i j}\right|<1$ for each $i$. Prove that $\mathcal{I}_{n}-A$ is invertible.

225. Let $\alpha=\frac{\pi}{n+1}, n>2$. Prove that the $n \times n$ matrix

$$
\left(\begin{array}{cccc}
\sin \alpha & \sin 2 \alpha & \cdots & \sin n \alpha \\
\sin 2 \alpha & \sin 4 \alpha & \cdots & \sin 2 n \alpha \\
\vdots & \vdots & \ddots & \vdots \\
\sin n \alpha & \sin 2 n \alpha & \cdots & \sin n^{2} \alpha
\end{array}\right)
$$

is invertible.

226. Assume that $A$ and $B$ are invertible complex $n \times n$ matrices such that $i\left(A^{\dagger} B-B^{\dagger} A\right)$ is positive semidefinite, where $X^{\dagger}=\bar{X}^{t}$, the transpose conjugate of $X$. Prove that $A+i B$ is invertible. (A matrix $T$ is positive semidefinite if $\langle T v, v\rangle \geq 0$ for all vectors $v$, where $\langle v, w\rangle=v^{t} \bar{w}$ is the complex inner product.)

We continue with problems that exploit the ring structure of the set of $n \times n$ matrices. There are some special properties that matrices satisfy that do not hold in arbitrary rings. For example, an $n \times n$ matrix $A$ is either a zero divisor (there exist nonzero matrices $B$ and $C$ such that $A B=C A=\mathcal{O}_{n}$ ), or it is invertible. Also, if a matrix has a left (or right) inverse, then the matrix is invertible, which means that if $A B=I_{n}$ then also $B A=I_{n}$.

A good example is a problem of I.V. Maftei that appeared in the 1982 Romanian Mathematical Olympiad.

Example. Let $A, B, C$ be $n \times n$ matrices, $n \geq 1$, satisfying

$$
A B C+A B+B C+A C+A+B+C=\mathcal{O}_{n} .
$$

Prove that $A$ and $B+C$ commute if and only if $A$ and $B C$ commute. Solution. If we add $\mathcal{I}_{n}$ to the left-hand side of the identity from the statement, we recognize this expression to be the polynomial $P(X)=(X+A)(X+B)(X+C)$ evaluated at the identity matrix. This means that

$$
\left(\mathcal{I}_{n}+A\right)\left(\mathcal{I}_{n}+B\right)\left(\mathcal{I}_{n}+C\right)=\mathcal{I}_{n} .
$$

This shows that $\mathcal{I}_{n}+A$ is invertible, and its inverse is $\left(\mathcal{I}_{n}+B\right)\left(\mathcal{I}_{n}+C\right)$. It follows that

$$
\left(\mathcal{I}_{n}+B\right)\left(\mathcal{I}_{n}+C\right)\left(\mathcal{I}_{n}+A\right)=\mathcal{I}_{n},
$$

or

$$
B C A+B C+B A+C A+A+B+C=\mathcal{O}_{n} .
$$

Subtracting this relation from the one in the statement and grouping the terms appropriately, we obtain

$$
A B C-B C A=(B+C) A-A(B+C) .
$$

The conclusion follows.

Here are other examples.

227. Let $A$ be an $n \times n$ matrix such that there exists a positive integer $k$ for which

$$
k A^{k+1}=(k+1) A^{k} .
$$

Prove that the matrix $A-\mathcal{I}_{n}$ is invertible and find its inverse.

228. Let $A$ be an invertible $n \times n$ matrix, and let $B=X Y$, where $X$ and $Y$ are $1 \times n$, respectively, $n \times 1$ matrices. Prove that the matrix $A+B$ is invertible if and only if $\alpha=Y A^{-1} X \neq-1$, and in this case its inverse is given by

$$
(A+B)^{-1}=A^{-1}-\frac{1}{\alpha+1} A^{-1} B A^{-1} .
$$

229. Given two $n \times n$ matrices $A$ and $B$ for which there exist nonzero real numbers $a$ and $b$ such that $A B=a A+b B$, prove that $A$ and $B$ commute.

230. Let $A$ and $B$ be $n \times n$ matrices, $n \geq 1$, satisfying $A B-B^{2} A^{2}=\mathcal{I}_{n}$ and $A^{3}+B^{3}=$ $\mathcal{O}_{n}$. Prove that $B A-A^{2} B^{2}=\mathcal{I}_{n}$. 

\subsubsection{Systems of Linear Equations}

A system of $m$ linear equations with $n$ unknowns can be written as

$$
A x=b,
$$

where $A$ is an $m \times n$ matrix called the coefficient matrix, and $b$ is an $m$-dimensional vector. If $m=n$, the system has a unique solution if and only if the coefficient matrix $A$ is invertible. If $A$ is not invertible, the system can have either infinitely many solutions or none at all. If additionally $b=0$, then the system does have infinitely many solutions and the codimension of the space of solutions is equal to the rank of $A$.

We illustrate this section with two problems that apparently have nothing to do with the topic. The first was published in Mathematics Gazette, Bucharest, by L. Pîrşan.

Example. Consider the matrices

$$
A=\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right), \quad B=\left(\begin{array}{cc}
\alpha & \beta \\
\gamma & \delta
\end{array}\right), \quad C=\left(\begin{array}{llll}
a \alpha & b \beta & a \gamma & b \gamma \\
a \beta & b \beta & a \delta & b \delta \\
c \alpha & d \alpha & c \gamma & d \gamma \\
c \beta & d \beta & c \delta & d \delta
\end{array}\right),
$$

where $a, b, c, d, \alpha, \beta, \gamma, \delta$ are real numbers. Prove that if $A$ and $B$ are invertible, then $C$ is invertible as well.

Solution. Let us consider the matrix equation $A X B=D$, where

$$
X=\left(\begin{array}{ll}
x & z \\
y & t
\end{array}\right) \quad \text { and } \quad D=\left(\begin{array}{cc}
m & n \\
p & q
\end{array}\right) \text {. }
$$

Solving it for $X$ gives $X=A^{-1} D B^{-1}$, and so $X$ is uniquely determined by $A, B$, and D. Multiplying out the matrices in this equation,

$$
\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)\left(\begin{array}{ll}
x & z \\
y & t
\end{array}\right)\left(\begin{array}{ll}
\alpha & \beta \\
\gamma & \delta
\end{array}\right)=\left(\begin{array}{ll}
m & n \\
p & q
\end{array}\right),
$$

we obtain

$$
\left(\begin{array}{l}
a \alpha x+b \alpha y+a \gamma z+b \gamma t a \beta x+b \beta y+a \delta z+b \delta t \\
c \alpha x+d \alpha y+c \gamma z+d \gamma t c \beta x+d \beta y+c \delta z+d \delta t
\end{array}\right)=\left(\begin{array}{cc}
m & n \\
p & q
\end{array}\right) .
$$

This is a system in the unknowns $x, y, z, t$ :

$$
\begin{aligned}
a \alpha x+b \alpha y+a \gamma z+b \gamma t &=m, \\
a \beta x+b \beta y+a \delta z+b \delta t &=n,
\end{aligned}
$$



$$
\begin{aligned}
c \alpha x+d \alpha y+c \gamma z+d \gamma t &=p, \\
c \beta x+d \beta y+c \delta z+d \delta t &=q .
\end{aligned}
$$

We saw above that this system has a unique solution, which implies that its coefficient matrix is invertible. This coefficient matrix is $C$.

The second problem we found in an old textbook on differential and integral calculus.

Example. Given the distinct real numbers $a_{1}, a_{2}, a_{3}$, let $x_{1}, x_{2}, x_{3}$ be the three roots of the equation

$$
\frac{u_{1}}{a_{1}+t}+\frac{u_{2}}{a_{2}+t}+\frac{u_{3}}{a_{3}+t}=1,
$$

where $u_{1}, u_{2}, u_{3}$ are real parameters. Prove that $u_{1}, u_{2}, u_{3}$ are smooth functions of $x_{1}, x_{2}, x_{3}$ and that

$$
\operatorname{det}\left(\frac{\partial u_{i}}{\partial x_{j}}\right)=-\frac{\left(x_{1}-x_{2}\right)\left(x_{2}-x_{3}\right)\left(x_{3}-x_{1}\right)}{\left(a_{1}-a_{2}\right)\left(a_{2}-a_{3}\right)\left(a_{3}-a_{1}\right)} .
$$

Solution. After eliminating the denominators, the equation from the statement becomes a cubic equation in $t$, so $x_{1}, x_{2}, x_{3}$ are well defined. The parameters $u_{1}, u_{2}, u_{3}$ satisfy the system of equations

$$
\begin{aligned}
&\frac{1}{a_{1}+x_{1}} u_{1}+\frac{1}{a_{2}+x_{1}} u_{2}+\frac{1}{a_{3}+x_{1}} u_{3}=1, \\
&\frac{1}{a_{1}+x_{2}} u_{1}+\frac{1}{a_{2}+x_{2}} u_{2}+\frac{1}{a_{3}+x_{2}} u_{3}=1, \\
&\frac{1}{a_{1}+x_{3}} u_{1}+\frac{1}{a_{2}+x_{3}} u_{2}+\frac{1}{a_{3}+x_{3}} u_{3}=1 .
\end{aligned}
$$

When solving this system, we might end up entangled in algebraic computations. Thus it is better instead to take a look at the two-variable situation. Solving the system

$$
\begin{aligned}
&\frac{1}{a_{1}+x_{1}} u_{1}+\frac{1}{a_{2}+x_{1}} u_{2}=1, \\
&\frac{1}{a_{1}+x_{2}} u_{1}+\frac{1}{a_{2}+x_{2}} u_{2}=1,
\end{aligned}
$$

with Cramer's rule we obtain

$$
u_{1}=\frac{\left(a_{1}+x_{1}\right)\left(a_{1}+x_{2}\right)}{\left(a_{1}-a_{2}\right)} \quad \text { and } \quad u_{2}=\frac{\left(a_{2}+x_{1}\right)\left(a_{2}+x_{2}\right)}{\left(a_{2}-a_{1}\right)} .
$$

Now we can extrapolate to the three-dimensional situation and guess that 

$$
u_{i}=\frac{\prod_{k=1}^{3}\left(a_{i}+x_{k}\right)}{\prod_{k \neq i}\left(a_{i}-a_{k}\right)}, \quad i=1,2,3 .
$$

It is not hard to check that these satisfy the system of equations. Observe that

$$
\frac{\partial u_{i}}{\partial x_{j}}=\frac{\prod_{k \neq j}\left(a_{i}+x_{k}\right)}{\prod_{j \neq i}\left(a_{i}-a_{j}\right)}, \quad \text { and so } \quad \frac{\partial u_{i}}{\partial x_{j}}=\frac{1}{a_{i}+x_{j}} u_{i}, \quad i, j=1,2,3 .
$$

The determinant in question looks again difficult to compute. Some tricks simplify the task. An observation is that the sum of the columns is 1 . Indeed, these sums are

$$
\frac{\partial u_{1}}{\partial x_{i}}+\frac{\partial u_{2}}{\partial x_{i}}+\frac{\partial u_{3}}{\partial x_{i}}, \quad i=1,2,3,
$$

which we should recognize as the left-hand sides of the linear system. So the determinant becomes much simpler if we add the first and second rows to the last. Another observation is that the determinant is a 3-variable polynomial in $x_{1}, x_{2}, x_{3}$. Its total degree is 3 , and it becomes zero if $x_{i}=x_{j}$ for some $i \neq j$. Consequently, the determinant is a number not depending on $x_{1}, x_{2}, x_{3}$ times $\left(x_{1}-x_{2}\right)\left(x_{2}-x_{3}\right)\left(x_{3}-x_{1}\right)$. This number can be determined by looking just at the coefficient of $x_{2}^{2} x_{3}$. And an easy computation shows that this is equal to $\frac{1}{\left(a_{1}-a_{2}\right)\left(a_{2}-a_{3}\right)\left(a_{3}-a_{1}\right)}$.

From the very many practical applications of the theory of systems of linear equations, let us mention the Global Positioning System (GPS). The principle behind the GPS is the measurement of the distances between the receiver and 24 satellites (in practice some of these satellites might have to be ignored in order to avoid errors due to atmospheric phenomena). This yields 24 quadratic equations $d\left(P, S_{i}\right)^{2}=r_{i}^{2}, i=1,2, \ldots, 24$, in the three spatial coordinates of the receiver. Subtracting the first of the equations from the others cancels the quadratic terms and gives rise to an overdetermined system of 23 linear equations in three unknowns. Determining the location of the receiver is therefore a linear algebra problem.

231. Solve the system of linear equations

$$
\begin{aligned}
x_{1}+x_{2}+x_{3} &=0, \\
x_{2}+x_{3}+x_{4} &=0, \\
& \cdots \\
x_{99}+x_{100}+x_{1} &=0, \\
x_{100}+x_{1}+x_{2} &=0 .
\end{aligned}
$$

232. Find the solutions $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$ to the system of equations

$$
x_{5}+x_{2}=y x_{1}, \quad x_{1}+x_{3}=y x_{2}, \quad x_{2}+x_{4}=y x_{3},
$$



$$
x_{3}+x_{5}=y x_{1}, \quad x_{4}+x_{1}=y x_{5},
$$

where $y$ is a parameter.

233. Let $a, b, c, d$ be positive numbers different from 1 , and $x, y, z, t$ real numbers satisfying $a^{x}=b c d, b^{y}=c d a, c^{z}=d a b, d^{t}=a b c$. Prove that

$$
\left|\begin{array}{cccc}
-x & 1 & 1 & 1 \\
1 & -y & 1 & 1 \\
1 & 1 & -z & 1 \\
1 & 1 & 1 & -t
\end{array}\right|=0
$$

234. Given the system of linear equations

$$
\begin{aligned}
&a_{11} x_{1}+a_{12} x_{2}+a_{13} x_{3}=0, \\
&a_{21} x_{1}+a_{22} x_{2}+a_{23} x_{3}=0, \\
&a_{31} x_{1}+a_{32} x_{2}+a_{33} x_{3}=0,
\end{aligned}
$$

whose coefficients satisfy the conditions

(a) $a_{11}, a_{22}, a_{33}$ are positive,

(b) all other coefficients are negative,

(c) in each equation, the sum of the coefficients is positive,

prove that the system has the unique solution $x_{1}=x_{2}=x_{3}=0$.

235. Let $P(x)=x^{n}+x^{n-1}+\cdots+x+1$. Find the remainder obtained when $P\left(x^{n+1}\right)$ is divided by $P(x)$.

236. Find all functions $f: \mathbb{R} \backslash\{-1,1\} \rightarrow \mathbb{R}$ satisfying

$$
f\left(\frac{x-3}{x+1}\right)+f\left(\frac{3+x}{1-x}\right)=x
$$

for all $x \neq \pm 1$.

237. Find all positive integer solutions $(x, y, z, t)$ to the Diophantine equation

$$
(x+y)(y+z)(z+x)=t x y z
$$

such that $\operatorname{gcd}(x, y)=\operatorname{gcd}(y, z)=\operatorname{gcd}(z, x)=1$.

238. We have $n$ coins of unknown masses and a balance. We are allowed to place some of the coins on one side of the balance and an equal number of coins on the other side. After thus distributing the coins, the balance gives a comparison of the total mass of each side, either by indicating that the two masses are equal or by indicating that a particular side is the more massive of the two. Show that at least $n-1$ such comparisons are required to determine whether all of the coins are of equal mass. 

239. Let $a_{0}=0, a_{1}, \ldots, a_{n}, a_{n+1}=0$ be a sequence of real numbers that satisfy $\mid a_{k-1}-$ $2 a_{k}+a_{k+1} \mid \leq 1$ for $k=1,2, \ldots, n-1$. Prove that $\left|a_{k}\right| \leq \frac{k(n-k+1)}{2}$ for $k=$ $1,2, \ldots, n-1$.

240. Prove that the Hilbert matrix

$$
\left(\begin{array}{ccccc}
1 & \frac{1}{2} & \frac{1}{3} & \cdots & \frac{1}{n} \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \cdots & \frac{1}{n+1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{1}{n} & \frac{1}{n+1} & \frac{1}{n+2} & \cdots & \frac{1}{2 n-1}
\end{array}\right)
$$

is invertible. Prove also that the sum of the entries of the inverse matrix is $n^{2}$.

\subsubsection{Vector Spaces, Linear Combinations of Vectors, Bases}

In general, a vector space $V$ over a field of scalars (which in our book will be only $\mathbb{C}, \mathbb{R}$, or $\mathbb{Q}$ ) is a set endowed with a commutative addition and a scalar multiplication that have the same properties as those for vectors in Euclidean space.

A linear combination of the vectors $v_{1}, v_{2}, \ldots, v_{m}$ is a sum $c_{1} v_{1}+c_{2} v_{2}+\cdots+c_{m} v_{m}$ with scalar coefficients. The vectors are called linearly independent if a combination of these vectors is equal to zero only when all coefficients are zero. Otherwise, the vectors are called linearly dependent. If $v_{1}, v_{2}, \ldots, v_{n}$ are linearly independent and if every vector in $V$ is a linear combination of these vectors, then $v_{1}, v_{2}, \ldots, v_{n}$ is called a basis of $V$. The number of elements of a basis of a vector space depends only on the vector space, and is called the dimension of the vector space. We will be concerned only with finite-dimensional vector spaces. We also point out that if in a vector space there are given more vectors than the dimension, then these vectors must be linearly dependent.

The rank of a matrix is the dimension of its row vectors, which is the same as the dimension of the column vectors. A square matrix is invertible if and only if its rank equals its size.

Let us see some examples. The first appeared in the Soviet University Student Mathematical Competition in 1977.

Example. Let $X$ and $B_{0}$ be $n \times n$ matrices, $n \geq 1$. Define $B_{i}=B_{i-1} X-X B_{i-1}$, for $i \geq 1$. Prove that if $X=B_{n^{2}}$, then $X=\mathcal{O}_{n}$.

Solution. Because the space of $n \times n$ matrices is $n^{2}$-dimensional, $B_{0}, B_{1}, \ldots, B_{n^{2}}$ must be linearly dependent, so there exist scalars $c_{0}, c_{1}, \ldots, c_{n^{2}}$ such that

$$
c_{0} B_{0}+c_{1} B_{1}+\cdots+c_{n^{2}} B_{n^{2}}=\mathcal{O}_{n} .
$$

Let $k$ be the smallest index for which $c_{k} \neq 0$. Then 

$$
B_{k}=a_{1} B_{k+1}+a_{2} B_{k+2}+\cdots+a_{n^{2}-k} B_{n^{2}},
$$

where $a_{j}=-\frac{c_{k+j}}{c_{k}}$. Computing $B_{k+1}=B_{k} X-X B_{k}$, we obtain

$$
B_{k+1}=a_{1} B_{k+2}+a_{2} B_{k+3}+\cdots+a_{n^{2}-k} B_{n^{2}+1},
$$

and inductively

$$
B_{k+j}=a_{1} B_{k+j+1}+a_{2} B_{k+j+2}+\cdots+a_{n^{2}-k} B_{n^{2}+j}, \quad \text { for } j \geq 1 .
$$

In particular,

$$
B_{n^{2}}=a_{1} B_{n^{2}+1}+a_{2} B_{n^{2}+2}+\cdots+a_{n^{2}-k} B_{n^{2}+k} .
$$

But $B_{n^{2}+1}=B_{n^{2}} X-X B_{n^{2}}=X^{2}-X^{2}=\mathcal{O}_{n}$, and hence $B_{n^{2}+j}=\mathcal{O}_{n}$, for $j \geq 1$. It follows that $X$, which is a linear combination of $B_{n^{2}+1}, B_{n^{2}+2}, \ldots, B_{n^{2}+k}$, is the zero matrix. And we are done.

The second example was given at the 67th W.L. Putnam Mathematical Competition in 2006, and the solution that we present was posted by C. Zara on the Internet.

Example. Let $Z$ denote the set of points in $\mathbb{R}^{n}$ whose coordinates are 0 or 1 . (Thus $Z$ has $2^{n}$ elements, which are the vertices of a unit hypercube in $\mathbb{R}^{n}$.) Let $k$ be given, $0 \leq k \leq n$. Find the maximum, over all vector subspaces $V \subseteq \mathbb{R}^{n}$ of dimension $k$, of the number of points in $Z \cap V$.

Solution. Let us consider the matrix whose rows are the elements of $V \cap Z$. By construction it has row rank at most $k$. It thus also has column rank at most $k$; in particular, there are $k$ columns such that any other column is a linear combination of these $k$. It means that the coordinates of each point of $V \cap Z$ are determined by the $k$ coordinates that lie in these $k$ columns. Since each such coordinate can have only two values, $V \cap Z$ can have at most $2^{k}$ elements.

This upper bound is reached for the vectors that have all possible choices of 0 and 1 for the first $k$ entries, and 0 for the remaining entries.

241. Prove that every odd polynomial function of degree equal to $2 m-1$ can be written as

$$
P(x)=c_{1}\left(\begin{array}{c}
x \\
1
\end{array}\right)+c_{2}\left(\begin{array}{c}
x+1 \\
3
\end{array}\right)+c_{3}\left(\begin{array}{c}
x+2 \\
5
\end{array}\right)+\cdots+c_{m}\left(\begin{array}{c}
x+m-1 \\
2 m-1
\end{array}\right),
$$

where $\left(\begin{array}{l}x \\ m\end{array}\right)=x(x-1) \cdots \frac{x-m+1}{n !}$.

242. Let $n$ be a positive integer and $P(x)$ an $n$ th-degree polynomial with complex coefficients such that $P(0), P(1), \ldots, P(n)$ are all integers. Prove that the polynomial $n ! P(x)$ has integer coefficients. 

243. Let $A$ be the $n \times n$ matrix whose $i, j$ entry is $i+j$ for all $i, j=1,2, \ldots, n$. What is the rank of $A$ ?

244. For integers $n \geq 2$ and $0 \leq k \leq n-2$, compute the determinant

$$
\left|\begin{array}{ccccc}
1^{k} & 2^{k} & 3^{k} & \cdots & n^{k} \\
2^{k} & 3^{k} & 4^{k} & \cdots & (n+1)^{k} \\
3^{k} & 4^{k} & 5^{k} & \cdots & (n+2)^{k} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
n^{k} & (n+1)^{k} & (n+2)^{k} & \cdots & (2 n-1)^{k}
\end{array}\right| .
$$

245. Let $V$ be a vector space and let $f, f_{1}, f_{2}, \ldots, f_{n}$ be linear maps from $V$ to $\mathbb{R}$. Suppose that $f(x)=0$ whenever $f_{1}(x)=f_{2}(x)=\cdots=f_{n}(x)=0$. Prove that $f$ is a linear combination of $f_{1}, f_{2}, \ldots, f_{n}$.

246. Given a set $S$ of $2 n-1$ different irrational numbers, $n \geq 1$, prove that there exist $n$ distinct elements $x_{1}, x_{2}, \ldots, x_{n} \in S$ such that for all nonnegative rational numbers $a_{1}, a_{2}, \ldots, a_{n}$ with $a_{1}+a_{2}+\cdots+a_{n}>0$, the number $a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n}$ is irrational.

247. There are given $2 n+1$ real numbers, $n \geq 1$, with the property that whenever one of them is removed, the remaining $2 n$ can be split into two sets of $n$ elements that have the same sum of elements. Prove that all the numbers are equal.

\subsubsection{Linear Transformations, Eigenvalues, Eigenvectors}

A linear transformation between vector spaces is a map $T: V \rightarrow W$ that satisfies $T\left(\alpha_{1} v_{1}+\alpha_{2} v_{2}\right)=\alpha_{1} T\left(v_{1}\right)+\alpha_{2} T\left(v_{2}\right)$ for any scalars $\alpha_{1}, \alpha_{2}$ and vectors $v_{1}, v_{2}$. A matrix $A$ defines a linear transformation by $v \rightarrow A v$, and any linear transformation between finite-dimensional vector spaces with specified bases is of this form. An eigenvalue of a matrix $A$ is a zero of the characteristic polynomial $P_{A}(\lambda)=\operatorname{det}\left(\lambda \mathcal{I}_{n}-A\right)$. Alternatively, it is a scalar $\lambda$ for which the equation $A v=\lambda v$ has a nontrivial solution $v$. In this case $v$ is called an eigenvector of the eigenvalue $\lambda$. If $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{m}$ are distinct eigenvalues and $v_{1}, v_{2}, \ldots, v_{m}$ are corresponding eigenvectors, then $v_{1}, v_{2}, \ldots, v_{m}$ are linearly independent. Moreover, if the matrix $A$ is Hermitian, meaning that $A$ is equal to its transpose conjugate, then $v_{1}, v_{2}, \ldots, v_{m}$ may be chosen to be pairwise orthogonal.

The set of eigenvalues of a matrix is called its spectrum. The reason for this name is that in quantum mechanics, observable quantities are modelled by matrices. Physical spectra, such as the emission spectrum of the hydrogen atom, become spectra of matrices. Among all results in spectral theory we stopped at the spectral mapping theorem, mainly because we want to bring to your attention the method used in the proof. The spectral mapping theorem. Let $A$ be an $n \times n$ matrix with not necessarily distinct eigenvalues $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$, and let $P(x)$ be a polynomial. Then the eigenvalues of the matrix $P(A)$ are $P\left(\lambda_{1}\right), P\left(\lambda_{2}\right), \ldots, P\left(\lambda_{n}\right)$.

Proof. To prove this result we will apply a widely used idea (see for example the splitting principle in algebraic topology). We will first assume that the eigenvalues of $A$ are all distinct. Then $A$ can be diagonalized by eigenvectors as

$$
\left(\begin{array}{cccc}
\lambda_{1} & 0 & \cdots & 0 \\
0 & \lambda_{2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \lambda_{n}
\end{array}\right),
$$

and in the basis formed by the eigenvectors of $A$, the matrix $P(A)$ assumes the form

$$
\left(\begin{array}{cccc}
P\left(\lambda_{1}\right) & 0 & \cdots & 0 \\
0 & P\left(\lambda_{2}\right) & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & P\left(\lambda_{n}\right)
\end{array}\right) .
$$

The conclusion is now straightforward. In general, the characteristic polynomial of a matrix depends continuously on the entries. Problem 172 in Section 2.2.4 proved that the roots of a polynomial depend continuously on the coefficients. Hence the eigenvalues of a matrix depend continuously on the entries.

The set of matrices with distinct eigenvalues is dense in the set of all matrices. To prove this claim we need the notion of the discriminant of a polynomial. By definition, if the zeros of a polynomial are $x_{1}, x_{2}, \ldots, x_{n}$, the discriminant is $\prod_{i<j}\left(x_{i}-x_{j}\right)^{2}$. It is equal to zero if and only if the polynomial has multiple zeros. Being a symmetric polynomial in the $x_{i}$ 's, the discriminant is a polynomial in the coefficients. Therefore, the condition that the eigenvalues of a matrix be not all distinct can be expressed as a polynomial equation in the entries. By slightly varying the entries, we can violate this condition. Therefore, arbitrarily close to any matrix there are matrices with distinct eigenvalues.

The conclusion of the spectral mapping theorem for an arbitrary matrix now follows by a limiting argument.

We continue with two more elementary problems.

Example. Let $A: V \rightarrow W$ and $B: W \rightarrow V$ be linear maps between finite-dimensional vector spaces. Prove that the linear maps $A B$ and $B A$ have the same set of nonzero eigenvalues, counted with multiplicities. Solution. Choose a basis that identifies $V$ with $\mathbb{R}^{m}$ and $W$ with $\mathbb{R}^{n}$. Associate to $A$ and $B$ their matrices, denoted by the same letters. The problem is solved if we prove the equality

$$
\operatorname{det}\left(\lambda \mathcal{I}_{n}-A B\right)=\lambda^{k} \operatorname{det}\left(\lambda I_{m}-B A\right),
$$

where $k$ is of course $n-m$. The relation being symmetric, we may assume that $n \geq m$. In this case, complete the two matrices with zeros to obtain two $n \times n$ matrices $A^{\prime}$ and $B^{\prime}$. Because $\operatorname{det}\left(\lambda \mathcal{I}_{n}-A^{\prime} B^{\prime}\right)=\operatorname{det}(\lambda I-A B)$ and $\operatorname{det}\left(\lambda \mathcal{I}_{n}-B^{\prime} A^{\prime}\right)=\lambda^{n-m} \operatorname{det}\left(\lambda \mathcal{I}_{n}-B A\right)$, the problem reduces to proving that $\operatorname{det}\left(\lambda \mathcal{I}_{n}-A^{\prime} B^{\prime}\right)=\operatorname{det}\left(\lambda \mathcal{I}_{n}-B^{\prime} A^{\prime}\right)$. And this is true for arbitrary $n \times n$ matrices $A^{\prime}$ and $B^{\prime}$. For a proof of this fact we refer the reader to problem 209 in Section 2.3.2.

If $B=A^{\dagger}$, the transpose conjugate of $A$, then this example shows that $A A^{\dagger}$ and $A^{\dagger} A$ have the same nonzero eigenvalues. The square roots of these eigenvalues are called the singular values of $A$. The second example comes from the first International Mathematics Competition, 1994.

Example. Let $\alpha$ be a nonzero real number and $n$ a positive integer. Suppose that $F$ and $G$ are linear maps from $\mathbb{R}^{n}$ into $\mathbb{R}^{n}$ satisfying $F \circ G-G \circ F=\alpha F$.

(a) Show that for all $k \geq 1$ one has $F^{k} \circ G-G \circ F^{k}=\alpha k F^{k}$.

(b) Show that there exists $k \geq 1$ such that $F^{k}=\mathcal{O}_{n}$.

Here $F \circ G$ denotes $F$ composed with $G$.

Solution. Expand $F^{k} \circ G-G \circ F^{k}$ using a telescopic sum as follows:

$$
\begin{aligned}
F^{k} \circ G-G \circ F^{k} &=\sum_{i=1}^{k}\left(F^{k-i+1} \circ G \circ F^{i-1}-F^{k-i} \circ G \circ F^{i}\right) \\
&=\sum_{i=1}^{k} F^{k-i} \circ(F \circ G-G \circ F) \circ F^{i-1} \\
&=\sum_{i=1}^{k} F^{k-i} \circ \alpha F \circ F^{i-1}=\alpha k F^{k} .
\end{aligned}
$$

This proves (a). For (b), consider the linear map $L(F)=F \circ G-G \circ F$ acting on all $n \times n$ matrices $F$. Assuming $F^{k} \neq \mathcal{O}_{n}$ for all $k$, we deduce from (a) that $\alpha k$ is an eigenvalue of $L$ for all $k$. This is impossible since the linear map $L$ acts on an $n^{2}$-dimensional space, so it can have at most $n^{2}$ eigenvalues. This contradiction proves (b).

248. Let $A$ be a $2 \times 2$ matrix with complex entries and let $C(A)$ denote the set of $2 \times 2$ matrices that commute with $A$. Prove that $|\operatorname{det}(A+B)| \geq|\operatorname{det} B|$ for all $B \in C(A)$ if and only if $A^{2}=\mathcal{O}_{2}$. 

249. Let $A, B$ be $2 \times 2$ matrices with integer entries, such that $A B=B A$ and det $B=1$. Prove that if $\operatorname{det}\left(A^{3}+B^{3}\right)=1$, then $A^{2}=\mathcal{O}_{2}$.

250. Consider the $n \times n$ matrix $A=\left(a_{i j}\right)$ with $a_{i j}=1$ if $j-i \equiv 1(\bmod n)$ and $a_{i j}=0$ otherwise. For real numbers $a$ and $b$ find the eigenvalues of $a A+b A^{t}$.

251. Let $A$ be an $n \times n$ matrix. Prove that there exists an $n \times n$ matrix $B$ such that $A B A=A$.

252. Consider the angle formed by two half-lines in three-dimensional space. Prove that the average of the measure of the projection of the angle onto all possible planes in the space is equal to the angle.

253. A linear map $A$ on the $n$-dimensional vector space $V$ is called an involution if $A^{2}=\mathcal{I}$

(a) Prove that for every involution $A$ on $V$ there exists a basis of $V$ consisting of eigenvectors of $A$.

(b) Find the maximal number of distinct pairwise commuting involutions.

254. Let $A$ be a $3 \times 3$ real matrix such that the vectors $A u$ and $u$ are orthogonal for each column vector $u \in \mathbb{R}^{3}$. Prove that

(a) $A^{t}=-A$, where $A^{t}$ denotes the transpose of the matrix $A$;

(b) there exists a vector $v \in \mathbb{R}^{3}$ such that $A u=v \times u$ for every $u \in \mathbb{R}^{3}$.

255. Denote by $M_{n}(\mathbb{R})$ the set of $n \times n$ matrices with real entries and let $f: M_{n}(\mathbb{R}) \rightarrow \mathbb{R}$ be a linear function. Prove that there exists a unique matrix $C \in M_{n}(\mathbb{R})$ such that $f(A)=\operatorname{tr}(A C)$ for all $A \in M_{n}(\mathbb{R})$. In addition, if $f(A B)=f(B A)$ for all matrices $A$ and $B$, prove that there exists $\lambda \in \mathbb{R}$ such that $f(A)=\lambda \operatorname{tr} A$ for any matrix $A$.

256. Let $U$ and $V$ be isometric linear transformations of $\mathbb{R}^{n}, n \geq 1$, with the property that $\|U x-x\| \leq \frac{1}{2}$ and $\|V x-x\| \leq \frac{1}{2}$ for all $x \in \mathbb{R}^{n}$ with $\|x\|=1$. Prove that

$$
\left\|U V U^{-1} V^{-1} x-x\right\| \leq \frac{1}{2},
$$

for all $x \in \mathbb{R}^{n}$ with $\|x\|=1$.

257. For an $n \times n$ matrix $A$ denote by $\phi_{k}(A)$ the symmetric polynomial in the eigenvalues $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ of $A$,

$$
\phi_{k}(A)=\sum_{i_{1} i_{2} \cdots i_{k}} \lambda_{i_{1}} \lambda_{i_{2}} \cdots \lambda_{i_{k}}, \quad k=1,2, \ldots, n .
$$

For example, $\phi_{1}(A)$ is the trace and $\phi_{n}(A)$ is the determinant. Prove that for two $n \times n$ matrices $A$ and $B, \phi_{k}(A B)=\phi_{k}(B A)$ for all $k=1,2, \ldots, n$. 

\subsubsection{The Cayley-Hamilton and Perron-Frobenius Theorems}

We devote this section to two more advanced results, which seem to be relevant to mathematics competitions. All matrices below are assumed to have complex entries.

The Cayley-Hamilton Theorem. Any $n \times n$ matrix A satisfies its characteristic equation, which means that if $P_{A}(\lambda)=\operatorname{det}\left(\lambda \mathcal{I}_{n}-A\right)$, then $P_{A}(A)=\mathcal{O}_{n}$.

Proof. Let $P_{A}(\lambda)=\lambda^{n}+a_{n-1} \lambda^{n-1}+\cdots+a_{0}$. Denote by $\left(\lambda \mathcal{I}_{n}-A\right)$ the adjoint of $\left(\lambda \mathcal{I}_{n}-A\right)$ (the one used in the computation of the inverse). Then

$$
\left(\lambda \mathcal{I}_{n}-A\right)\left(\lambda \mathcal{I}_{n}-A\right)^{*}=\operatorname{det}\left(\lambda \mathcal{I}_{n}-A\right) \mathcal{I}_{n} .
$$

The entries of the adjoint matrix $\left(\lambda \mathcal{I}_{n}-A\right)^{*}$ are polynomials in $\lambda$ of degree at most $n-1$. Splitting the matrix by the powers of $\lambda$, we can write

$$
\left(\lambda \mathcal{I}_{n}-A\right)^{*}=B_{n-1} \lambda^{n-1}+B_{n-2} \lambda^{n-2}+\cdots+B_{0} .
$$

Equating the coefficients of $\lambda$ on both sides of

$$
\left(\lambda \mathcal{I}_{n}-A\right)\left(B_{n-1} \lambda^{n-1}+B_{n-2} \lambda^{n-2}+\cdots+B_{0}\right)=\operatorname{det}\left(\lambda \mathcal{I}_{n}-A\right) \mathcal{I}_{n},
$$

we obtain the equations

$$
\begin{gathered}
B_{n-1}=\mathcal{I}_{n}, \\
-A B_{n-1}+B_{n-2}=a_{n-1} \mathcal{I}_{n}, \\
-A B_{n-2}+B_{n-3}=a_{n-2} \mathcal{I}_{n}, \\
\cdots \\
-A B_{0}=a_{0} \mathcal{I}_{n} .
\end{gathered}
$$

Multiply the first equation by $A^{n}$, the second by $A^{n-1}$, the third by $A^{n-2}$, and so on, then add the $n+1$ equations to obtain

$$
\mathcal{O}_{n}=A^{n}+a_{n-1} A^{n-1}+a_{n-2} A^{n-2}+\cdots+a_{0} \mathcal{I}_{n} .
$$

This equality is just the desired $P_{A}(A)=\mathcal{O}_{n}$.

As a corollary we prove the trace identity for $\operatorname{SL}(2, \mathbb{C})$ matrices. This identity is important in the study of characters of group representations.

Example. Let $A$ and $B$ be $2 \times 2$ matrices with determinant equal to 1 . Prove that

$$
\operatorname{tr}(A B)-(\operatorname{tr} A)(\operatorname{tr} B)+\operatorname{tr}\left(A B^{-1}\right)=0 .
$$

Solution. By the Cayley-Hamilton Theorem,

$$
B^{2}-(\operatorname{tr} B) B+\mathcal{I}_{2}=\mathcal{O}_{2} .
$$

Multiply on the left by $A B^{-1}$ to obtain

$$
A B-(\operatorname{tr} B) A+A B^{-1}=\mathcal{O}_{2},
$$

and then take the trace to obtain the identity from the statement.

Five more examples are left to the reader.

258. Let $A$ be a $2 \times 2$ matrix. Show that if for some complex numbers $u$ and $v$ the matrix $u \mathcal{I}_{2}+v A$ is invertible, then its inverse is of the form $u^{\prime} \mathcal{I}_{2}+v^{\prime} A$ for some complex numbers $u^{\prime}$ and $v^{\prime}$.

259. Find the $2 \times 2$ matrices with real entries that satisfy the equation

$$
X^{3}-3 X^{2}=\left(\begin{array}{ll}
-2 & -2 \\
-2 & -2
\end{array}\right) \text {. }
$$

260. Let $A, B, C, D$ be $2 \times 2$ matrices. Prove that the matrix $[A, B] \cdot[C, D]+[C, D]$. $[A, B]$ is a multiple of the identity matrix (here $[A, B]=A B-B A$, the commutator of $A$ and $B)$.

261. Let $A$ and $B$ be $3 \times 3$ matrices. Prove that

$$
\operatorname{det}(A B-B A)=\frac{\operatorname{tr}\left((A B-B A)^{3}\right)}{3} .
$$

262. Show that there do not exist real $2 \times 2$ matrices $A$ and $B$ such that their commutator is nonzero and commutes with both $A$ and $B$.

Here is the simplest version of the other result that we had in mind.

The Perron-Frobenius Theorem. Any square matrix with positive entries has a unique eigenvector with positive entries (up to a multiplication by a positive scalar), and the corresponding eigenvalue has multiplicity one and is strictly greater than the absolute value of any other eigenvalue.

Proof. The proof uses real analysis. Let $A=\left(a_{i j}\right)_{i, j=1}^{n}, n \geq 1$. We want to show that there is a unique $v \in[0, \infty)^{n}, v \neq 0$, such that $A v=\lambda v$ for some $\lambda$. Of course, since $A$ has positive entries and $v$ has positive coordinates, $\lambda$ has to be a positive number. Denote by $K$ the intersection of $[0, \infty)^{n}$ with the $n$-dimensional unit sphere. Reformulating the problem, we want to show that the function $f: K \rightarrow K, f(v)=\frac{A v}{\|A v\|}$ has a fixed point. Now, there is a rather general result that states that a contractive function on a complete metric space has a unique fixed point, which we will prove in Section 3.1.3. Recall that a metric space is a set $X$ endowed with a function $\delta: X \times X \rightarrow[0, \infty)$ satisfying (i) $\delta(x, y)=0$ if and only if $x=y$, (ii) $\delta(x, y)=\delta(y, x)$ for all $x, y \in X$, (iii) $\delta(x, y)+$ $\delta(y, z) \geq \delta(x, z)$ for all $x, y, z \in X$. A metric space is complete if every Cauchy sequence converges to a limit in $X$. A function $f: X \rightarrow X$ is contractive if for any $x \neq y$,

$$
\delta(f(x), f(y)) \leq c \delta(x, y)
$$

for some fixed constant $c, 0<c<1$.

With this in mind, we want to find a distance on the set $K$ that makes the function $f$ defined above contractive. This is the Hilbert metric defined by the formula

$$
\delta(v, w)=\ln \left(\max _{i}\left\{\frac{v_{i}}{w_{i}}\right\} / \min _{i}\left\{\frac{v_{i}}{w_{i}}\right\}\right),
$$

for $v=\left(v_{1}, v_{2}, \ldots, v_{n}\right)$ and $w=\left(w_{1}, w_{2}, \ldots, w_{n}\right) \in K$. That this satisfies the triangle inequality $\delta(v, w)+\delta(w, u) \geq \delta(v, w)$ is a consequence of the inequalities

$$
\begin{gathered}
\max _{i}\left\{\frac{v_{i}}{w_{i}}\right\} \cdot \max _{i}\left\{\frac{w_{i}}{u_{i}}\right\} \geq \max _{i}\left\{\frac{v_{i}}{w_{i}}\right\}, \\
\min _{i}\left\{\frac{v_{i}}{w_{i}}\right\} \cdot \min _{i}\left\{\frac{w_{i}}{u_{i}}\right\} \leq \min _{i}\left\{\frac{v_{i}}{w_{i}}\right\} .
\end{gathered}
$$

Let us show that $f$ is contractive. If $v=\left(v_{1}, v_{2}, \ldots, v_{n}\right)$ and $w=\left(w_{1}, w_{2}, \ldots, w_{n}\right)$ are in $K, v \neq w$, and if $\alpha_{i}>0, i=1,2, \ldots, n$, then

$$
\min _{i}\left\{\frac{v_{i}}{w_{i}}\right\}<\frac{\alpha_{1} v_{1}+\alpha_{2} v_{2}+\cdots+\alpha_{n} v_{n}}{\alpha_{1} w_{1}+\alpha_{2} w_{2}+\cdots+\alpha_{n} w_{n}}<\max _{i}\left\{\frac{v_{i}}{w_{i}}\right\} \text {. }
$$

Indeed, to prove the first inequality, add the obvious inequalities $w_{j} \min _{i}\left\{\frac{v_{i}}{w_{i}}\right\} \leq v_{j}, j=$ $1,2, \ldots, n$. Because $v \neq w$ and both vectors are on the unit sphere, at least one inequality is strict. The second inequality follows from $w_{j} \max _{i}\left\{\frac{v_{i}}{w_{i}}\right\} \geq v_{j}, j=1,2, \ldots, n$, where again at least one inequality is strict.

Using this fact, we obtain for all $j, 1 \leq j \leq n$,

$$
\frac{\frac{a_{j 1} v_{1}+\cdots+a_{j n} v_{n}}{a_{j 1} w_{1}+\cdots+a_{j n} w_{n}}}{\max _{i}\left\{\frac{v_{i}}{w_{i}}\right\}}<1<\frac{\frac{a_{j 1} v_{1}+\cdots+a_{j n} v_{n}}{a_{j 1} w_{1}+\cdots+a_{j n} w_{n}}}{\min _{i}\left\{\frac{v_{i}}{w_{i}}\right\}} .
$$

Therefore,

$$
\frac{\max _{j}\left\{\frac{a_{j 1} v_{1}+\cdots+a_{j n} v_{n}}{a_{j 1} w_{1}+\cdots+a_{j n} w_{n}}\right\}}{\max _{i}\left\{\frac{v_{i}}{w_{i}}\right\}}<\frac{\min _{i}\left\{\frac{a_{j 1} v_{1}+\cdots+a_{j n} v_{n}}{a_{j 1} w_{1}+\cdots+a_{j n} w_{n}}\right\}}{\min _{i}\left\{\frac{v_{i}}{w_{i}}\right\}} .
$$

It follows that for $v, w \in K, v \neq w, \delta(f(v), f(w))<\delta(v, w)$.

Now, $K$ is closed and but is not bounded in the Hilbert norm; some points are infinitely far apart. But even if $K$ is not bounded in the Hilbert metric, $f(K)$ is (prove it!). If we denote by $K_{0}$ the closure of $f(K)$ in the Hilbert norm, then this space is closed and bounded.

The function $\phi: K_{0} \times K_{0} \rightarrow[0, \infty), \phi(v, w)=\frac{\delta(f(v), f(w))}{\delta(v, w)}$ attains its maximum $c$. Since $\phi$ is strictly less than $1, c<1$. This proves that $f$ is contractive on $K_{0}$; its fixed point is the unique eigenvector of $A$ with positive coordinates.

We are done with the first half of the proof. Now let us show that the eigenvalue of this positive vector is larger than the absolute value of any other eigenvalue. Let $r(A)$ be the largest of the absolute values of the eigenvalues of $A$ and let $\lambda$ be an eigenvalue with $|\lambda|=r(A)$. In general, for a vector $v$ we denote by $|v|$ the vector whose coordinates are the absolute values of the coordinates of $v$. Also, for two vectors $v, w$ we write $v \geq w$ if each coordinate of $v$ is greater than the corresponding coordinate of $w$. If $v$ is an eigenvector of $A$ corresponding to the eigenvalue $\lambda$, then $|A v|=|\lambda| \cdot|v|$. The triangle inequality implies $A|v| \geq|A v|=r(A)|v|$. It follows that the set

$$
K_{1}=\{v \mid\|v\|=1, v \geq 0, A v \geq r(A) v\},
$$

is nonempty. Because $A$ has positive entries, $A(A v-r(A) v) \geq 0$ for $v \in K_{0}$. So $A(A v) \geq r(A)(A v)$, for $v \in K_{1}$, proving that $f\left(K_{1}\right) \in K$. Again $K_{1}$ is closed and $f\left(K_{1}\right)$ is bounded, so we can reason as above to prove that $f$ restricted to $K_{1}$ has a fixed point, and because $K_{1} \subset K$, this is the fixed point that we detected before. Thus $r(A)$ is the unique positive eigenvalue.

There cannot exist another eigenvalue $\lambda$ with $|\lambda|=r(A)$, for otherwise, for a small $\epsilon>0$ the matrix $A-\epsilon \mathcal{I}_{n}$ would still have positive entries, but its positive eigenvalue $r(A)-\epsilon$ would be smaller than the absolute value of the eigenvalue $\lambda-\epsilon$, contradicting what we just proved. This concludes the proof of the theorem.

Nowhere in the book are more appropriate the words of Sir Arthur Eddington: "Proof is an idol before which the mathematician tortures himself.",

The conclusion of the theorem still holds in the more general setting of irreducible matrices with nonnegative entries (irreducible means that there is no reordering of the rows and columns that makes it block upper triangular). This more general form of the Perron-Frobenius Theorem is currently used by the Internet browser Google to sort the entries of a search. The idea is the following: Write the adjacency matrix of the Internet with a link highlighted if it is related to the subject. Then multiply each nonzero entry by a larger or smaller number that takes into account how important the subject is in that page. The Perron-Frobenius vector of this new matrix assigns a positive weight to each site on the Internet. The Internet browser then lists the sites in decreasing order of their weights.

We now challenge you with some problems. 

263. Let $A$ be a square matrix whose off-diagonal entries are positive. Prove that the rightmost eigenvalue of $A$ in the complex plane is real and all other eigenvalues are strictly to its left in the complex plane.

264. Let $a_{i j}, i, j=1,2,3$, be real numbers such that $a_{i j}$ is positive for $i=j$ and negative for $i \neq j$. Prove that there exist positive real numbers $c_{1}, c_{2}, c_{3}$ such that the numbers

$$
a_{11} c_{1}+a_{12} c_{2}+a_{13} c_{3}, \quad a_{21} c_{1}+a_{22} c_{2}+a_{23} c_{3}, \quad a_{31} c_{1}+a_{32} c_{2}+a_{33} c_{3}
$$

are all negative, all positive, or all zero.

265. Let $x_{1}, x_{2}, \ldots, x_{n}$ be differentiable (real-valued) functions of a single variable $t$ that satisfy

$$
\begin{aligned}
\frac{d x_{1}}{d t} &=a_{11} x_{1}+a_{12} x_{2}+\cdots+a_{1 n} x_{n}, \\
\frac{d x_{2}}{d t} &=a_{21} x_{1}+a_{22} x_{2}+\cdots+a_{2 n} x_{n}, \\
& \cdots \\
\frac{d x_{n}}{d t} &=a_{n 1} x_{1}+a_{n 2} x_{2}+\cdots+a_{n n} x_{n},
\end{aligned}
$$

for some constants $a_{i j}>0$. Suppose that for all $i, x_{i}(t) \rightarrow 0$ as $t \rightarrow \infty$. Are the functions $x_{1}, x_{2}, \ldots, x_{n}$ necessarily linearly independent?

266. For a positive integer $n$ and any real number $c$, define $\left(x_{k}\right)_{k \geq 0}$ recursively by $x_{0}=0$, $x_{1}=1$, and for $k \geq 0$,

$$
x_{k+2}=\frac{c x_{k+1}-(n-k) x_{k}}{k+1} .
$$

Fix $n$ and then take $c$ to be the largest value for which $x_{n+1}=0$. Find $x_{k}$ in terms of $n$ and $k, 1 \leq k \leq n$.

\subsection{Abstract Algebra}

\subsubsection{Binary Operations}

A binary operation $*$ on a set $S$ associates to each pair $(a, b) \in S \times S$ an element $a * b \in S$. The operation is called associative if $a *(b * c)=(a * b) * c$ for all $a, b, c \in S$, and commutative if $a * b=b * a$ for all $a, b \in S$. If there exists an element $e$ such that $a * e=e * a=a$ for all $a \in S$, then $e$ is called an identity element. If an identity exists, it is unique. In this case, if for an element $a \in S$ there exists $b \in S$ such that $a * b=b * a=e$, then $b$ is called the inverse of $a$ and is denoted by $a^{-1}$. If an element has an inverse, the inverse is unique.

Just as a warmup, we present a problem from the 62nd W.L. Putnam Competition, 2001.

Example. Consider a set $S$ and a binary operation $*$ on $S$. Assume that $(a * b) * a=b$ for all $a, b \in S$. Prove that $a *(b * a)=b$ for all $a, b \in S$.

Solution. Substituting $b * a$ for $a$, we obtain

$$
((b * a) * b) *(b * a)=b .
$$

The expression in the first set of parentheses is $a$. Therefore,

$$
a *(b * a)=b,
$$

as desired.

Often, problems about binary operations look like innocent puzzles, yet they can have profound implications. This is the case with the following example.

Example. For three-dimensional vectors $X=(p, q, t)$ and $Y=\left(p^{\prime}, q^{\prime}, t^{\prime}\right)$ define the operations $(p, q, t) *\left(p^{\prime}, q^{\prime}, t^{\prime}\right)=\left(0,0, p q^{\prime}-q p^{\prime}\right)$, and $X \circ Y=X+Y+\frac{1}{2} X * Y$, where $+$ denotes the addition in $\mathbb{R}^{3}$.

(a) Prove that $\left(\mathbb{R}^{3}, \circ\right)$ is a group.

(b) Let $\alpha:\left(\mathbb{R}^{3}, \circ\right) \rightarrow\left(\mathbb{R}^{3}\right.$, o) be a continuous map satisfying $\alpha(X \circ Y)=\alpha(X) \circ \alpha(Y)$ for all $X, Y$ (which means that $\alpha$ is a homomorphism). Prove that

$$
\alpha(X+Y)=\alpha(X)+\alpha(Y) \quad \text { and } \quad \alpha(X * Y)=\alpha(X) * \alpha(Y) .
$$

Solution. (a) Associativity can be verified easily, the identity element is $(0,0,0)$, and the inverse of $(p, q, t)$ is $(-p,-q,-t)$.

(b) First, note that $X * Y=-Y * X$. Therefore, if $X$ is a scalar multiple of $Y$, then $X * Y=Y * X=0$. In general, if $X * Y=0$, then $X \circ Y=X+Y=Y \circ X$. Hence in this case,

$$
\alpha(X+Y)=\alpha(X \circ Y)=\alpha(X) \circ \alpha(Y)=\alpha(X)+\alpha(Y)+\frac{1}{2} \alpha(X) * \alpha(Y)
$$

on the one hand, and

$$
\alpha(X+Y)=\alpha(Y \circ X)=\alpha(Y) \circ \alpha(X)=\alpha(Y)+\alpha(X)+\frac{1}{2} \alpha(Y) * \alpha(X) .
$$

Because $\alpha(X) * \alpha(Y)=-\alpha(Y) * \alpha(X)$, this implies that $\alpha(X) * \alpha(Y)=0$, and consequently $\alpha(X+Y)=\alpha(X)+\alpha(Y)$. In particular, $\alpha$ is additive on every one-dimensional space, whence $\alpha(r X)=r \alpha(X)$, for every rational number $r$. But $\alpha$ is continuous, so $\alpha(s X)=s \alpha(X)$ for every real number $s$. Applying this property we find that for any $X, Y \in \mathbb{R}^{3}$ and $s \in \mathbb{R}$,

$$
\begin{aligned}
s \alpha\left(X+Y+\frac{1}{2} s X * Y\right) &\left.=\alpha\left(s X+s Y+\frac{1}{2} s^{2} X * Y\right)=\alpha(s X) \circ(s Y)\right) \\
&=\alpha(s X) \circ \alpha(s Y)=(s \alpha(X)) \circ(s \alpha(Y)) \\
&=s \alpha(X)+s \alpha(Y)+\frac{1}{2} s^{2} \alpha(X) * \alpha(Y) .
\end{aligned}
$$

Dividing both sides by $s$, we obtain

$$
\alpha\left(X+Y+\frac{1}{2} s X * Y\right)=\alpha(X)+\alpha(Y)+\frac{1}{2} s X * Y .
$$

In this equality if we let $s \rightarrow 0$, we obtain $\alpha(X+Y)=\alpha(X)+\alpha(Y)$. Also, if we let $s=1$ and use the additivity we just proved, we obtain $\alpha(X * Y)=\alpha(X) * \alpha(Y)$. The problem is solved.

Traditionally, $X * Y$ is denoted by $[X, Y]$ and $\mathbb{R}^{3}$ endowed with this operation is called the Heisenberg Lie algebra. Also, $\mathbb{R}^{3}$ endowed with $\circ$ is called the Heisenberg group. And we just proved a famous theorem showing that a continuous automorphism of the Heisenberg group is also an automorphism of the Heisenberg Lie algebra. The Heisenberg group and algebra are fundamental concepts of quantum mechanics.

267. With the aid of a calculator that can add, subtract, and determine the inverse of a nonzero number, find the product of two nonzero numbers using at most 20 operations.

268. Invent a binary operation from which $+,-, \times$, and / can be derived.

269. A finite set $S$ is endowed with an associative binary operation $*$ that satisfies ( $a *$ $a) * b=b *(a * a)=b$ for all $a, b \in S$. Prove that the set of all elements of the form $a *(b * c)$ with $a, b, c$ distinct elements of $S$ coincides with $S$.

270. Let $S$ be the smallest set of rational functions containing $f(x, y)=x$ and $g(x, y)=$ $y$ and closed under subtraction and taking reciprocals. Show that $S$ does not contain the nonzero constant functions.

271. Let $*$ and $\circ$ be two binary operations on the set $M$, with identity elements $e$, respectively, $e^{\prime}$, and with the property that for every $x, y, u, v \in M$,

$$
(x * y) \circ(u * v)=(x \circ u) *(y \circ v) .
$$

Prove that 
(a) $e=e^{\prime}$
(b) $x * y=x \circ y$, for every $x, y \in M$;
(c) $x * y=y * x$, for every $x, y \in M$.

272. Consider a set $S$ and a binary operation $*$ on $S$ such that $x *(y * x)=y$ for all $x, y$ in $S$. Prove that each of the equations $a * x=b$ and $x * a=b$ has a unique solution in $S$.

273. On a set $M$ an operation $*$ is given satisfying the properties

(i) there exists an element $e \in M$ such that $x * e=x$ for all $x \in M$;

(ii) $(x * y) * z=(z * x) * y$ for all $x, y, z \in M$.

Prove that the operation $*$ is both associative and commutative.

274. Prove or disprove the following statement: If $F$ is a finite set with two or more elements, then there exists a binary operation $*$ on $F$ such that for all $x, y, z$ in $F$, (i) $x * z=y * z$ implies $x=y$ (right cancellation holds), and

(ii) $x *(y * z) \neq(x * y) * z$ (no case of associativity holds).

275. Let $*$ be an associative binary operation on a set $S$ satisfying $a * b=b * a$ only if $a=b$. Prove that $a *(b * c)=a * c$ for all $a, b, c \in S$. Give an example of such an operation.

276. Let $S$ be a set and $*$ a binary operation on $S$ satisfying the laws

(i) $x *(x * y)=y$ for all $x, y \in S$,

(ii) $(y * x) * x=y$ for all $x, y$ in $S$.

Show that $*$ is commutative but not necessarily associative.

277. Let $*$ be a binary operation on the set $\mathbb{Q}$ of rational numbers that is associative and commutative and satisfies $0 * 0=0$ and $(a+c) *(b+c)=a * b+c$ for all $a, b, c \in \mathbb{Q}$. Prove that either $a * b=\max (a, b)$ for all $a, b \in \mathbb{Q}$, or $a * b=\min (a, b)$ for all $a, b \in \mathbb{Q}$.

\subsubsection{Groups}

Definition. A group is a set of transformations (of some space) that contains the identity transformation and is closed under composition and under the operation of taking the inverse.

The isometries of the plane, the permutations of a set, the continuous bijections on a closed bounded interval all form groups.

There is a more abstract, and apparently more general definition, which calls a group a set $G$ endowed with a binary operation · that satisfies

(i) (associativity) $x(y z)=(x y) z$ for all $x, y, z \in S$; (ii) (identity element) there is $e \in G$ such that for any $x \in G, e x=x e=x$;

(iii) (existence of the inverse) for every $x \in G$ there is $x^{-1} \in G$ such that $x x^{-1}=$ $x^{-1} x=e$.

But Cayley observed the following fact.

Theorem. Any group is a group of transformations.

Proof. Indeed, any group $G$ acts on itself on the left. Specifically, $x \in G$ acts as a transformation of $G$ by $y \rightarrow x y, y \in G$.

A group $G$ is called Abelian (after N. Abel) if the operation is commutative, that is, if $x y=y x$ for all $x, y \in G$. An example of an Abelian group is the Klein four-group, introduced abstractly as $K=\left\{a, b, c, e \mid a^{2}=b^{2}=c^{2}=e, a b=c, a c=b, b c=a\right\}$, or concretely as the group of the symmetries of a rectangle (depicted in Figure 14).

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-105.jpg?height=320&width=477&top_left_y=940&top_left_x=629)

Figure 14

A group is called cyclic if it is generated by a single element, that is, if it consists of the identity element and the powers of some element.

Let us turn to problems and start with one published by L. Daia in the Mathematics Gazette, Bucharest.

Example. A certain multiplicative operation on a nonempty set $G$ is associative and allows cancellations on the left, and there exists $a \in G$ such that $x^{3}=a x a$ for all $x \in G$. Prove that $G$ endowed with this operation is an Abelian group.

Solution. Replacing $x$ by $a x$ in the given relation, we obtain axaxax $=a^{2} x a$. Cancelling $a$ on the left, we obtain $x(a x a) x=a x a$. Because axa $=x^{3}$, it follows that $x^{5}=x^{3}$, and cancelling an $x^{2}$, we obtain

$$
x^{3}=x \quad \text { for all } x \in G .
$$

In particular, $a^{3}=a$, and hence $a^{3} x=a x$ for all $x \in G$. Cancel $a$ on the left to find that

$$
a^{2} x=x \quad \text { for all } x \in G .
$$

Substituting $x$ by $x a$, we obtain $a^{2} x a=x a$, or $a x^{3}=x a$, and since $x^{3}=x$, it follows that $a$ commutes with all elements in $G$. We can therefore write

$$
a^{2} x=a(a x)=a(x a)=(x a) a=x a^{2},
$$

whence $x a^{2}=a^{2} x=x$. This shows that $a^{2}$ is the identity element of the multiplicative operation; we denote it by $e$. The relation from the statement implies $x^{3}=a x a=x a^{2}=$ $x e$; cancelling $x$, we obtain $x^{2}=e$; hence for all $x \in G, x^{-1}=x$. It follows that $G$ is a group. It is Abelian by the well-known computation

$$
x y=(x y)^{-1}=y^{-1} x^{-1}=y x .
$$

Here are more examples of the kind.

278. Prove that in order for a set $G$ endowed with an associative operation to be a group, it suffices for it to have a left identity, and for each element to have a left inverse. This means that there should exist $e \in G$ such that $e x=x$ for all $x \in G$, and for each $x \in G$, there should exist $x^{\prime} \in G$ such that $x^{\prime} x=e$. The same conclusion holds if "left" is replaced by "right."

279. Let $(G, \perp)$ and $(G, *)$ be two group structures defined on the same set $G$. Assume that the two groups have the same identity element and that their binary operations satisfy

$$
a * b=(a \perp a) \perp(a \perp b),
$$

for all $a, b \in G$. Prove that the binary operations coincide and the group they define is Abelian.

280. Let $r, s, t$ be positive integers that are pairwise relatively prime. If the elements $a$ and $b$ of an Abelian group with identity element $e$ satisfy $a^{r}=b^{s}=(a b)^{t}=e$, prove that $a=b=e$. Does the same conclusion hold if $a$ and $b$ are elements of an arbitrary nonAbelian group?

281. Assume that $a$ and $b$ are elements of a group with identity element $e$ satisfying $\left(a b a^{-1}\right)^{n}=e$ for some positive integer $n$. Prove that $b^{n}=e$.

282. Let $G$ be a group with the following properties:

(i) $G$ has no element of order 2 ,

(ii) $(x y)^{2}=(y x)^{2}$, for all $x, y \in G$.

Prove that $G$ is Abelian.

283. A multiplicative operation on a set $M$ satisfies (i) $a^{2}=b^{2}$, (ii) $a b^{2}=a$, (iii) $a^{2}(b c)=c b$, (iv) $(a c)(b c)=a b$, for all $a, b, c \in M$. Define on $M$ the operation 

$$
a * b=a\left(b^{2} b\right)
$$

Prove that $(M, *)$ is a group.

284. Given $\Gamma$ a finite multiplicative group of matrices with complex entries, denote by $M$ the sum of the matrices in $\Gamma$. Prove that $\operatorname{det} M$ is an integer.

We would like to point out the following property of the set of real numbers.

Theorem. A nontrivial subgroup of the additive group of real numbers is either cyclic or it is dense in the set of real numbers.

Proof. Denote the group by $G$. It is either discrete, or it has an accumulation point on the real axis. If it is discrete, let $a$ be its smallest positive element. Then any other element is of the form $b=k a+\alpha$ with $0 \leq \alpha<a$. But $b$ and $k a$ are both in $G$; hence $\alpha$ is in $G$ as well. By the minimality of $a, \alpha$ can only be equal to 0 , and hence the group is cyclic.

If there is a sequence $\left(x_{n}\right)_{n}$ in $G$ converging to some real number, then $\pm\left(x_{n}-x_{m}\right)$ approaches zero as $n, m \rightarrow \infty$. Choosing the indices $m$ and $n$ appropriately, we can find a sequence of positive elements in $G$ that converges to 0 . Thus for any $\epsilon>0$ there is an element $c \in G$ with $0<c<\epsilon$. For some integer $k$, the distance between $k c$ and $(k+1) c$ is less than $\epsilon$; hence any interval of length $\epsilon$ contains some multiple of $c$. Varying $\epsilon$, we conclude that $G$ is dense in the real axis.

Try to use this result to solve the following problems.

285. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function satisfying $f(x)=f(x+\sqrt{2})=$ $f(x+\sqrt{3})$ for all $x$. Prove that $f$ is constant.

286. Prove that the sequence $(\sin n)_{n}$ is dense in the interval $[-1,1]$.

287. Show that infinitely many powers of 2 start with the digit 7 .

288. Given a rectangle, we are allowed to fold it in two or in three, parallel to one side or the other, in order to form a smaller rectangle. Prove that for any $\epsilon>0$ there are finitely many such operations that produce a rectangle with the ratio of the sides lying in the interval $(1-\epsilon, 1+\epsilon$ ) (which means that we can get arbitrarily close to a square).

289. A set of points in the plane is invariant under the reflections across the sides of some given regular pentagon. Prove that the set is dense in the plane.

"There is no certainty in sciences where one of the mathematical sciences cannot be applied, or which are not in relation with this mathematics." This thought of Leonardo da Vinci motivated us to include an example of how groups show up in natural sciences.

The groups of symmetries of three-dimensional space play an important role in chemistry and crystallography. In chemistry, the symmetries of molecules give rise to physical properties such as optical activity. The point groups of symmetries of molecules were classified by A. Schönflies as follows:

- $C_{s}$ : a reflection with respect to a plane, isomorphic to $\mathbb{Z}_{2}$,

- $C_{i}:$ a reflection with respect to a point, isomorphic to $\mathbb{Z}_{2}$,

- $C_{n}$ : the rotations by multiples of $\frac{2 \pi}{n}$ about an axis, isomorphic to $\mathbb{Z}_{n}$,

- $C_{n v}$ : generated by a $C_{n}$ and a $C_{s}$ with the reflection plane containing the axis of rotation; in mathematics this is called the dihedral group,

- $C_{n h}$ : generated by a $C_{n}$ and a $C_{s}$ with the reflection plane perpendicular to the axis of rotation, isomorphic to $C_{n} \times C_{2}$,

- $D_{n}$ : generated by a $C_{n}$ and a $C_{2}$, with the rotation axes perpendicular to each other, isomorphic to the dihedral group,

- $D_{n d}$ : generated by a $C_{n}$ and a $C_{2}$, together with a reflection across a plane that divides the angle between the two rotation axes,

- $D_{n h}$ : generated by a $C_{n}$ and a $C_{2}$ with perpendicular rotation axes, together with a reflection with respect to a plane perpendicular to the first rotation axis,

- $S_{n}$ : improper rotations by multiples of $\frac{2 \pi}{\eta}$, i.e., the group generated by the element that is the composition of the rotation by $\frac{2 \pi}{n}$ and the reflection with respect to a plane perpendicular to the rotation axis,

- Special point groups: $C_{\infty v}$ 's and $D_{\infty h}$ 's (same as $C_{n v}$ and $D_{n h}$ but with all rotations about the axis allowed), together with the symmetry groups of the five Platonic solids.

When drawing a molecule, we use the convention that all segments represent bonds in the plane of the paper, all bold arrows represent bonds with the tip of the arrow below the tail of the arrow. The molecules from Figure 15 have respective symmetry point groups the octahedral group and $C_{3 h}$.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-108.jpg?height=234&width=746&top_left_y=1738&top_left_x=500)

Figure 15

290. Find the symmetry groups of the molecules depicted in Figure 16. 
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-109.jpg?height=198&width=1128&top_left_y=250&top_left_x=304)

Figure 16

\subsubsection{Rings}

Rings mimic in the abstract setting the properties of the sets of integers, polynomials, or matrices.

Definition. A ring is a set $R$ endowed with two operations $+$ and - (addition and multiplication) such that $(R,+)$ is an Abelian group with identity element 0 and the multiplication satisfies

(i) (associativity) $x(y z)=(x y) z$ for all $x, y, z \in R$, and

(ii) (distributivity) $x(y+z)=x y+x z$ and $(x+y) z=x z+y z$ for all $x, y, z \in R$.

A ring is called commutative if the multiplication is commutative. It is said to have identity if there exists $1 \in R$ such that $1 \cdot x=x \cdot 1=x$ for all $x \in R$. An element $x \in R$ is called invertible if there exists $x^{-1} \in R$ such that $x x^{-1}=x^{-1} x=1$.

We consider two examples, the second of which appeared many years ago in the Balkan Mathematics Competition for university students.

Example. Let $x$ and $y$ be elements in a ring with identity. Prove that if $1-x y$ is invertible, then so is $1-y x$.

Solution. Let $v$ be the inverse of $1-x y$. Then $v(1-x y)=(1-x y) v=1$; hence $v x y=x y v=v-1$. We compute

$$
(1+y v x)(1-y x)=1-y x+y v x-y v x y x=1-y x+y v x-y(v-1) x=1 .
$$

A similar verification shows that $(1-y x)(1+y v x)=1$. It follows that $1-y x$ is invertible and its inverse is $1+y v x$.

Example. Prove that if in a ring $R$ (not necessarily with identity element) $x^{3}=x$ for all $x \in R$, then the ring is commutative.

Solution. For $x, y \in R$, we have

$$
\begin{aligned}
x y^{2}-y^{2} x y^{2}=&\left(x y^{2}-y^{2} x y^{2}\right)^{3}=x y^{2} x y^{2} x y^{2}-x y^{2} x y^{2} y^{2} x y^{2}-x y^{2} y^{2} x y^{2} x y^{2} \\
&-y^{2} x y^{2} x y^{2} x y^{2}+y^{2} x y^{2} x y^{2} y^{2} x y^{2}+y^{2} x y^{2} y^{2} x y^{2} x y^{2} \\
&-y^{2} x y^{2} y^{2} x y^{2} y^{2} x y^{2}+x y^{2} y^{2} x y^{2} y^{2} x y^{2} .
\end{aligned}
$$

Using the fact that $y^{4}=y^{2}$, we see that this is equal to zero, and hence $x y^{2}-y^{2} x y^{2}=0$, that is, $x y^{2}=y^{2} x y^{2}$. A similar argument shows that $y^{2} x=y^{2} x y^{2}$, and so $x y^{2}=y^{2} x$ for all $x, y \in R$.

Using this we obtain

$$
x y=x y x y x y=x y(x y)^{2}=x(x y)^{2} y=x^{2} y x y^{2}=y^{3} x^{3}=y x .
$$

This proves that the ring is commutative, as desired.

We remark that both this and the second problem below are particular cases of a general theorem of Jacobson, which states that if a ring (with or without identity) has the property that for every element $x$ there exists an integer $n(x)>1$ such that $x^{n(x)}=x$, then the ring is commutative.

291. Let $R$ be a nontrivial ring with identity, and $M=\left\{x \in R \mid x=x^{2}\right\}$ the set of its idempotents. Prove that if $M$ is finite, then it has an even number of elements.

292. Let $R$ be a ring with identity such that $x^{6}=x$ for all $x \in R$. Prove that $x^{2}=x$ for all $x \in R$. Prove that any such ring is commutative.

293. Let $R$ be a ring with identity with the property that $(x y)^{2}=x^{2} y^{2}$ for all $x, y \in R$. Show that $R$ is commutative.

294. Let $x$ and $y$ be elements in a ring with identity and $n$ a positive integer. Prove that if $1-(x y)^{n}$ is invertible, then so is $1-(y x)^{n}$.

295. Let $R$ be a ring with the property that if $x \in R$ and $x^{2}=0$, then $x=0$.

(a) Prove that if $x, z \in R$ and $z^{2}=z$, then $z x z-x z=0$.

(b) Prove that any idempotent of $R$ belongs to the center of $R$ (the center of a ring consists of those elements that commute with all elements of the ring).

296. Show that if a ring $R$ with identity has three elements $a, b, c$ such that

(i) $a b=b a, b c=c b$;

(ii) for any $x, y \in R, b x=b y$ implies $x=y$;

(iii) $c a=b$ but $a c \neq b$,

then the ring cannot be finite. 

\section{Real Analysis}

The chapter on real analysis groups material covering differential and integral calculus, ordinary differential equations, and also a rigorous introduction to real analysis with $\epsilon-\delta$ proofs.

We found it natural, and also friendly, to begin with sequences. As you will discover, the theory of linear recurrences parallels that of linear ordinary differential equations. The theory of limits is well expanded, covering for example Cauchy's criterion for convergence, the convergence of bounded monotone sequences, the Cesàro-Stolz theorem, and Cantor's nested intervals theorem. It is followed by some problems about series, with particular attention given to the telescopic method for computing sums and products.

A long discussion is devoted to one-variable functions. You might find the first three sections (on limits, continuity, and the intermediate value property) rather theoretical. Next, you will be required to apply derivatives and their properties to a wide range of examples. Then come integrals, with emphasis placed on computations and inequalities. One-variable real analysis ends with Taylor and Fourier series.

From multivariable differential and integral calculus we cover partial derivatives and their applications, computations of integrals, focusing on change of variables and on Fubini's theorem, all followed by a section of geometric flavor devoted to Green's theorem, Stokes' theorem, and the Gauss-Ostrogradski (divergence) theorem.

The chapter concludes with functional equations, among which will befound Cauchy's equation, and with ordinary differential and integral equations.

This is a long chapter, with many challenging problems. Now, as you start it, think of Edison's words: "Opportunity is missed by many people because it is dressed in overalls and looks like work." 

\subsection{Sequences and Series}

\subsubsection{Search for a Pattern}

In this section we train guessing. In each problem you should try particular cases until you guess either the general term of a sequence, a relation that the terms satisfy, or an appropriate construction. The idea to write such a section came to us when we saw the following Putnam problem.

Example. Consider the sequence $\left(u_{n}\right)_{n}$ defined by $u_{0}=u_{1}=u_{2}=1$, and

$$
\operatorname{det}\left(\begin{array}{cc}
u_{n+3} & u_{n+2} \\
u_{n+1} & u_{n}
\end{array}\right)=n !, \quad n \geq 0 .
$$

Prove that $u_{n}$ is an integer for all $n$.

Solution. The recurrence relation of the sequence is

$$
u_{n+3}=\frac{u_{n+2} u_{n+1}}{u_{n}}+\frac{n !}{u_{n}} .
$$

Examining some terms:

$$
\begin{aligned}
&u_{3}=\frac{1 \cdot 1}{1}+\frac{1}{1}=2 \\
&u_{4}=\frac{2 \cdot 1}{1}+\frac{1}{1}=3, \\
&u_{5}=\frac{3 \cdot 2}{1}+\frac{2}{1}=4 \cdot 2, \\
&u_{6}=\frac{4 \cdot 2 \cdot 3}{2}+\frac{3 \cdot 2}{2}=4 \cdot 3+1 \cdot 3=5 \cdot 3, \\
&u_{7}=\frac{5 \cdot 3 \cdot 4 \cdot 2}{3}+\frac{4 \cdot 3 \cdot 2}{3}=5 \cdot 4 \cdot 2+4 \cdot 2=6 \cdot 4 \cdot 2, \\
&u_{8}=\frac{6 \cdot 4 \cdot 2 \cdot 5 \cdot 3}{4 \cdot 2}+\frac{5 \cdot 4 \cdot 3 \cdot 2}{4 \cdot 2}=6 \cdot 5 \cdot 3+5 \cdot 3=7 \cdot 5 \cdot 3 .
\end{aligned}
$$

we conjecture that

$$
u_{n}=(n-1)(n-3)(n-5) \cdots .
$$

This formula can be proved by induction. Assuming the formula true for $u_{n}, u_{n+1}$, and $u_{n+2}$, we obtain

$$
u_{n+3}=\frac{u_{n+2} u_{n+1}+n !}{u_{n}}=\frac{(n+1)(n-1)(n-3) \cdots n(n-2)(n-4) \cdots+n !}{(n-1)(n-3)(n-5) \cdots}
$$



$$
\begin{aligned}
&=\frac{(n+1) \cdot n !+n !}{(n-1)(n-3)(n-5) \cdots}=\frac{(n+2) n !}{(n-1)(n-3)(n-5) \cdots} \\
&=(n+2) n(n-2)(n-4) \cdots
\end{aligned}
$$

This completes the induction, and the problem is solved.

297. Find a formula for the general term of the sequence

$$
1,2,2,3,3,3,4,4,4,4,5,5,5,5,5, \ldots
$$

298. Find a formula in compact form for the general term of the sequence defined recursively by $x_{1}=1, x_{n}=x_{n-1}+n$ if $n$ is odd, and $x_{n}=x_{n-1}+n-1$ if $n$ is even.

299. Define the sequence $\left(a_{n}\right)_{n \geq 0}$ by $a_{0}=0, a_{1}=1, a_{2}=2, a_{3}=6$, and

$$
a_{n+4}=2 a_{n+3}+a_{n+2}-2 a_{n+1}-a_{n}, \quad \text { for } n \geq 0 .
$$

Prove that $n$ divides $a_{n}$ for all $n \geq 1$.

300. The sequence $a_{0}, a_{1}, a_{2}, \ldots$ satisfies

$$
a_{m+n}+a_{m-n}=\frac{1}{2}\left(a_{2 m}+a_{2 n}\right),
$$

for all nonnegative integers $m$ and $n$ with $m \geq n$. If $a_{1}=1$, determine $a_{n}$.

301. Consider the sequences $\left(a_{n}\right)_{n},\left(b_{n}\right)_{n}$, defined by

$$
\begin{aligned}
& a_{0}=0, \quad a_{1}=2, \quad a_{n+1}=4 a_{n}+a_{n-1}, \quad n \geq 0, \\
& b_{0}=0, \quad b_{1}=1, \quad b_{n+1}=a_{n}-b_{n}+b_{n-1}, \quad n \geq 0 .
\end{aligned}
$$

Prove that $\left(a_{n}\right)^{3}=b_{3 n}$ for all $n$.

302. A sequence $u_{n}$ is defined by

$$
u_{0}=2, \quad u_{1}=\frac{5}{2}, \quad u_{n+1}=u_{n}\left(u_{n-1}^{2}-2\right)-u_{1}, \quad \text { for } n \geq 1 .
$$

Prove that for all positive integers $n$,

$$
\left\lfloor u_{n}\right\rfloor=2^{\left(2^{n}-(-1)^{n}\right) / 3},
$$

where $L \cdot\rfloor$ denotes the greatest integer function.

303. Consider the sequences $\left(a_{n}\right)_{n}$ and $\left(b_{n}\right)_{n}$ defined by $a_{1}=3, b_{1}=100, a_{n+1}=3^{a_{n}}$, $b_{n+1}=100^{b_{n}}$. Find the smallest number $m$ for which $b_{m}>a_{100}$. 

\subsubsection{Linear Recursive Sequences}

In this section we give an overview of the theory of linear recurrences with constant coefficients. You should notice the analogy with the theory of ordinary differential equations. This is not an accident, since linear recurrences are discrete approximations of differential equations.

A $k$ th-order linear recurrence with constant coefficients is a relation of the form

$$
x_{n}=a_{1} x_{n-1}+a_{2} x_{n-2}+\cdots+a_{k} x_{n-k}, \quad n \geq k,
$$

satisfied by a sequence $\left(x_{n}\right)_{n \geq 0}$.

The sequence $\left(x_{n}\right)_{n}$ is completely determined by $x_{0}, x_{1}, \ldots, x_{k-1}$ (the initial condition). To find the formula for the general term, we introduce the vector-valued first-order linear recursive sequence $\mathbf{v}_{n}=\left(v_{n}^{1}, v_{n}^{2}, \ldots, v_{n}^{k}\right)$ defined by $v_{n}^{1}=x_{n+k-1}, v_{n}^{2}=x_{n+k-2}$, $\ldots, v_{n}^{k}=x_{n}$. This new sequence satisfies the recurrence relation $\mathbf{v}_{n+1}=A \mathbf{v}_{n}, n \geq 0$, where

$$
A=\left(\begin{array}{cccccc}
a_{1} & a_{2} & a_{3} & \cdots & a_{k-1} & a_{k} \\
1 & 0 & 0 & \cdots & 0 & 0 \\
0 & 1 & 0 & \cdots & 0 & 0 \\
0 & 0 & 1 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & 1 & 0
\end{array}\right) .
$$

It follows that $\mathbf{v}_{n}=A^{n} \mathbf{v}_{0}$, and the problem reduces to the computation of the $n$th power of $A$. A standard method employs the Jordan canonical form.

First, we determine the eigenvalues of $A$. The characteristic polynomial is

$$
P_{A}(\lambda)=\left|\begin{array}{cccccc}
\lambda-a_{1} & -a_{2} & -a_{3} & \cdots & a_{k-1} & -a_{k} \\
-1 & \lambda & 0 & \cdots & 0 & 0 \\
0 & -1 & \lambda & \cdots & 0 & 0 \\
0 & 0 & -1 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & -1 & \lambda
\end{array}\right| .
$$

When expanding by the first row it is easy to remark that all minors are triangular, so the determinant is equal to $\lambda^{k}-a_{1} \lambda^{k-1}-a_{2} \lambda^{k-2}-\cdots-a_{k}$. The equation

$$
P_{A}(\lambda)=\lambda^{k}-a_{1} \lambda^{k-1}-a_{2} \lambda^{k-2}-\cdots-a_{k}=0
$$

is called the characteristic equation of the recursive sequence.

Let $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{k}$ be the roots of the characteristic equation, which are, in fact, the eigenvalues of $A$. If these roots are all distinct, the situation encountered most often, then A is diagonalizable. There exists an invertible matrix $S$ such that $A=S D S^{-1}$, where $D$ is diagonal with diagonal entries equal to the eigenvalues of $A$. From the equality

$$
\mathbf{v}_{n}=S D^{n} S^{-1} \mathbf{v}_{0},
$$

we conclude that the entries of $\mathbf{v}_{n}$ are linear combinations of $\lambda_{1}^{n}, \lambda_{2}^{n}, \ldots, \lambda_{k}^{n}$. In particular, for $x_{n}$, which is the first coordinate of $\mathbf{v}_{n}$, there exist constants $\alpha_{1}, \alpha_{2}, \ldots, \alpha_{k}$ such that

$$
x_{n}=\alpha_{1} \lambda_{1}^{n}+\alpha_{2} \lambda_{2}^{n}+\cdots+\alpha_{k} \lambda_{k}^{n}, \quad \text { for } n \geq 0 \text {. }
$$

The numbers $\alpha_{1}, \alpha_{2}, \ldots, \alpha_{k}$ are found from the initial condition, by solving the linear system

$$
\begin{aligned}
\alpha_{1}+\alpha_{2}+\cdots \alpha_{k} &=x_{0}, \\
\lambda_{1} \alpha_{1}+\lambda_{2} \alpha_{2}+\cdots \lambda_{k} \alpha_{k} &=x_{1}, \\
\lambda_{1}^{2} \alpha_{1}+\lambda_{2}^{2} \alpha_{2}+\cdots \lambda_{k}^{2} \alpha_{k} &=x_{2}, \\
& \cdots \\
\lambda_{1}^{k-1} \alpha_{1}+\lambda_{2}^{k-1} \alpha_{2}+\cdots \lambda_{k}^{k-1} \alpha_{k} &=x_{k-1} .
\end{aligned}
$$

Note that the determinant of the coefficient matrix is Vandermonde, so the system has a unique solution!

If the roots of the characteristic equation have multiplicities greater than 1 , it might happen that $A$ is not diagonalizable. The Jordan canonical form of $A$ has blocks of the form

$$
J_{m}\left(\lambda_{i}\right)=\left(\begin{array}{ccccc}
\lambda_{i} & 1 & 0 & \cdots & 0 \\
0 & \lambda_{i} & 1 & \cdots & 0 \\
0 & 0 & \lambda_{i} & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & \lambda_{i}
\end{array}\right) .
$$

An exercise in Section 2.3.1 shows that for $j \geq i$, the $i j$ entry of $J_{m}\left(\lambda_{i}\right)^{n}$ is $\left(\begin{array}{c}n \\ j-i\end{array}\right) \lambda_{i}^{n+i-j}$. We conclude that if the roots of the characteristic equations are $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{t}$ and $m_{1}, m_{2}, \ldots, m_{t}$ their respective multiplicities, then there exist constants $\alpha_{i j}, i=$ $1,2, \ldots, t, j=0,1, \ldots, m_{i}-1$, such that

$$
x_{n}=\sum_{i=1}^{t} \sum_{j=0}^{m_{i}-1} \alpha_{i j}\left(\begin{array}{l}
n \\
j
\end{array}\right) \lambda_{i}^{n-j}, \quad \text { for } n \geq 0 .
$$

It might be more useful to write this as 

$$
x_{n}=\sum_{i=1}^{t} \sum_{j=0}^{m_{i}} \beta_{i j} n^{j} \lambda_{i}^{n-j}, \quad \text { for } n \geq 0 .
$$

As is the case with differential equations, to find the general term of an inhomogeneous linear recurrence

$$
x_{n}=a_{1} x_{n-1}+a_{2} x_{n-2}+\cdots+a_{k} x_{n-k}+f(n), \quad n \geq 1,
$$

one has to find a particular solution to the recurrence, then add to it the general term of the associated homogeneous recurrence relation.

Putting these ideas together, let us compute the general-term formula of the Fibonacci sequence. The recurrence relation $F_{n+1}=F_{n}+F_{n-1}$ has characteristic equation $\lambda^{2}-$ $\lambda-1=0$, with roots $\lambda_{1,2}=\frac{1 \pm \sqrt{5}}{2}$. Writing $F_{n}=\alpha_{1} \lambda_{1}^{n}+\alpha_{2} \lambda_{2}^{n}$ and solving the system

$$
\begin{aligned}
\alpha_{1}+\alpha_{2} &=F_{0}=0, \\
\alpha_{1} \lambda_{1}+\alpha_{2} \lambda_{2} &=F_{1}=1,
\end{aligned}
$$

we obtain $\alpha_{1}=-\alpha_{2}=-\frac{1}{\sqrt{5}}$. We rediscover the well-known Binet formula

$$
F_{n}=\frac{1}{\sqrt{5}}\left(\left(\frac{1+\sqrt{5}}{2}\right)^{n}-\left(\frac{1-\sqrt{5}}{2}\right)^{n}\right) .
$$

In the same vein, let us solve a problem published in the American Mathematical Monthly by I. Tomescu.

Example. In how many ways can one tile a $2 n \times 3$ rectangle with $2 \times 1$ tiles?

Solution. Denote by $u_{n}$ the number of such tilings. Start tiling the rectangle from the short side of length 3 , as shown in Figure 17.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-116.jpg?height=192&width=1270&top_left_y=1555&top_left_x=232)

Figure 17

In the last two cases from the figure, an uncovered $1 \times 1$ square can be covered in a single way: by the shaded rectangle. We thus obtain

$$
u_{n+1}=3 u_{n}+2 v_{n},
$$

where $v_{n}$ is the number of tilings of a $(2 n-1) \times 3$ rectangle with a $1 \times 1$ square missing in one corner, like the one in Figure 18. That figure shows how to continue tiling this kind of rectangle, giving rise to the recurrence 

$$
v_{n+1}=u_{n}+v_{n} .
$$

Combining the two, we obtain the (vector-valued) recurrence relation

$$
\left(\begin{array}{l}
u_{n+1} \\
v_{n+1}
\end{array}\right)=\left(\begin{array}{ll}
3 & 2 \\
1 & 1
\end{array}\right)\left(\begin{array}{l}
u_{n} \\
v_{n}
\end{array}\right) .
$$

The characteristic equation, of the coefficient matrix but also of the sequences $u_{n}$ and $v_{n}$, is

$$
\left|\begin{array}{cc}
\lambda-3 & -2 \\
-1 & \lambda-1
\end{array}\right|=\lambda^{2}-4 \lambda+1=0
$$

Its roots are $\lambda_{1,2}=2 \pm \sqrt{3}$. We compute easily $u_{1}=3$ and $v_{1}=1$, so $u_{2}=3 \cdot 3+2 \cdot 1=11$. The desired general-term formula is then

$$
u_{n}=\frac{1}{2 \sqrt{3}}\left((\sqrt{3}+1)(2+\sqrt{3})^{m}+(\sqrt{3}-1)(2-\sqrt{3})^{m}\right)
$$
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-117.jpg?height=210&width=996&top_left_y=1101&top_left_x=374)

Figure 18

Below are listed more problems of this kind.

304. Let $p(x)=x^{2}-3 x+2$. Show that for any positive integer $n$ there exist unique numbers $a_{n}$ and $b_{n}$ such that the polynomial $q_{n}(x)=x^{n}-a_{n} x-b_{n}$ is divisible by $p(x)$

305. Find the general term of the sequence given by $x_{0}=3, x_{1}=4$, and

$$
(n+1)(n+2) x_{n}=4(n+1)(n+3) x_{n-1}-4(n+2)(n+3) x_{n-2}, \quad n \geq 2 .
$$

306. Let $\left(x_{n}\right)_{n \geq 0}$ be defined by the recurrence relation $x_{n+1}=a x_{n}+b x_{n-1}$, with $x_{0}=0$. Show that the expression $x_{n}^{2}-x_{n-1} x_{n+1}$ depends only on $b$ and $x_{1}$, but not on $a$.

307. Define the sequence $\left(a_{n}\right)_{n}$ recursively by $a_{1}=1$ and

$$
a_{n+1}=\frac{1+4 a_{n}+\sqrt{1+24 a_{n}}}{16}, \quad \text { for } n \geq 1
$$

Find an explicit formula for $a_{n}$ in terms of $n$. 

308. Let $a=4 k-1$, where $k$ is an integer. Prove that for any positive integer $n$ the number

$$
1-\left(\begin{array}{l}
n \\
2
\end{array}\right) a+\left(\begin{array}{l}
n \\
4
\end{array}\right) a^{2}-\left(\begin{array}{l}
n \\
6
\end{array}\right) a^{3}+\cdots
$$

is divisible by $2^{n-1}$.

309. Let $A$ and $E$ be opposite vertices of a regular octagon. A frog starts jumping at vertex $A$. From any vertex of the octagon except $E$, it may jump to either of the two adjacent vertices. When it reaches vertex $E$, the frog stops and stays there. Let $a_{n}$ be the number of distinct paths of exactly $n$ jumps ending at $E$. Prove that $a_{2 n-1}=0$ and

$$
a_{2 n}=\frac{1}{\sqrt{2}}\left(x^{n-1}-y^{n-1}\right), \quad n=1,2,3, \ldots,
$$

where $x=2+\sqrt{2}$ and $y=2-\sqrt{2}$.

310. Find all functions $f: \mathbb{N} \rightarrow \mathbb{N}$ satisfying

$$
f(f(f(n)))+6 f(n)=3 f(f(n))+4 n+2001, \quad \text { for all } n \in \mathbb{N} .
$$

311. The sequence $\left(x_{n}\right)_{n}$ is defined by $x_{1}=4, x_{2}=19$, and for $n \geq 2, x_{n+1}=\left\lceil\frac{x_{n}^{2}}{x_{n-1}}\right\rceil$, the smallest integer greater than or equal to $\frac{x_{n}^{2}}{x_{n-1}}$. Prove that $x_{n}-1$ is always a multiple of 3.

312. Consider the sequences given by

$$
\begin{array}{lll}
a_{0}=1, & a_{n+1}=\frac{3 a_{n}+\sqrt{5 a_{n}^{2}-4}}{2}, & n \geq 1, \\
b_{0}=0, & b_{n+1}=a_{n}-b_{n}, & n \geq 1 .
\end{array}
$$

Prove that $\left(a_{n}\right)^{2}=b_{2 n+1}$ for all $n$.

\subsubsection{Limits of Sequences}

There are three methods for determining the limit of a sequence. The first of them is based on the following definition.

\section{Cauchy's definition.}

(a) A sequence $\left(x_{n}\right)_{n}$ converges to a finite limit $L$ if and only if for every $\epsilon>0$ there exists $n(\epsilon)$ such that for every $n>n(\epsilon),\left|x_{n}-L\right|<\epsilon$. (b) A sequence $\left(x_{n}\right)_{n}$ tends to infinity iffor every $\epsilon>0$ there exists $n(\epsilon)$ such that for $n>n(\epsilon), x_{n}>\epsilon$.

The definition of convergence is extended to $\mathbb{R}^{n}$, and in general to any metric space, by replacing the absolute value with the distance. The second method for finding the limit is called the squeezing principle.

\section{The squeezing principle.}

(a) If $a_{n} \leq b_{n} \leq c_{n}$ for all $n$, and if $\left(a_{n}\right)_{n}$ and $\left(c_{n}\right)_{n}$ converge to the finite limit $L$, then $\left(b_{n}\right)_{n}$ also converges to $L$.

(b) If $a_{n} \leq b_{n}$ for all $n$ and if $\left(a_{n}\right)_{n}$ tends to infinity, then $\left(b_{n}\right)_{n}$ also tends to infinity.

Finally, the third method reduces the problem via algebraic operations to sequences whose limits are known. We illustrate each method with an example. The first is from P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics (Springer, 2004).

Example. Let $\left(x_{n}\right)_{n}$ be a sequence of real numbers such that

$$
\lim _{n \rightarrow \infty}\left(2 x_{n+1}-x_{n}\right)=L .
$$

Prove that the sequence $\left(x_{n}\right)_{n}$ converges and its limit is $L$.

Solution. By hypothesis, for every $\epsilon$ there is $n(\epsilon)$ such that if $n \geq n(\epsilon)$, then

$$
L-\epsilon<2 x_{n+1}-x_{n}<L+\epsilon .
$$

For such $n$ and some $k>0$ let us add the inequalities

$$
\begin{aligned}
L-\epsilon &<2 x_{n+1}-x_{n}<L+\epsilon \\
2(L-\epsilon) &<4 x_{n+2}-2 x_{n+1}<2(L+\epsilon), \\
& \cdots \\
2^{k-1}(L-\epsilon) &<2^{k} x_{n+k}-2^{k-1} x_{n+k-1}<2^{k-1}(L+\epsilon) .
\end{aligned}
$$

We obtain

$$
\left(1+2+\cdots+2^{k-1}\right)(L-\epsilon)<2^{k} x_{n+k}-x_{n}<\left(1+2+\cdots+2^{k-1}\right)(L+\epsilon),
$$

which after division by $2^{k}$ becomes

$$
\left(1-\frac{1}{2^{k}}\right)(L-\epsilon)<x_{n+k}-\frac{1}{2^{k}} x_{n}<\left(1-\frac{1}{2^{k}}\right)(L+\epsilon) .
$$

Now choose $k$ such that $\left|\frac{1}{2^{k}} x_{n}\right|<\epsilon$ and $\left|\frac{1}{2^{k}}(L \pm \epsilon)\right|<\epsilon$. Then for $m \geq n+k$,

$$
L-3 \epsilon<x_{m}<L+3 \epsilon,
$$

and since $\epsilon$ was arbitrary, this implies that $\left(x_{n}\right)_{n}$ converges to $L$. Example. Prove that $\lim _{n \rightarrow \infty} \sqrt[n]{n}=1$.

Solution. The sequence $x_{n}=\sqrt[n]{n}-1$ is clearly positive, so we only need to bound it from above by a sequence converging to 0 . For that we employ the binomial expansion

$$
n=\left(1+x_{n}\right)^{n}=1+\left(\begin{array}{c}
n \\
1
\end{array}\right) x_{n}+\left(\begin{array}{c}
n \\
2
\end{array}\right) x_{n}^{2}+\cdots+\left(\begin{array}{c}
n \\
n-1
\end{array}\right) x_{n}^{n-1}+x_{n}^{n} .
$$

Forgetting all terms but one, we can write

$$
n>\left(\begin{array}{l}
n \\
2
\end{array}\right) x_{n}^{2},
$$

which translates to $x_{n}<\sqrt{\frac{2}{n-1}}$, for $n \geq 2$. The sequence $\sqrt{\frac{2}{n-1}}, n \geq 2$, converges to 0 , and hence by the squeezing principle, $\left(x_{n}\right)_{n}$ itself converges to 0 , as desired.

The third example was published by the Romanian mathematician T. Lalescu in 1901 in the Mathematics Gazette, Bucharest.

Example. Prove that the sequence $a_{n}=\sqrt[n+1]{(n+1) !}-\sqrt[n]{n !}, n \geq 1$, is convergent and find its limit.

Solution. The solution we present belongs to M. Tुena. It uses Stirling's formula

$$
n !=\sqrt{2 \pi n}\left(\frac{n}{e}\right)^{n} \cdot e^{\frac{\theta_{n}}{12 n}}, \quad \text { with } 0<\theta_{n}<1,
$$

which will be proved in Section 3.2.11. Taking the $n$th root and passing to the limit, we obtain

$$
\lim _{n \rightarrow \infty} \frac{n}{\sqrt[n]{n !}}=e
$$

We also deduce that

$$
\lim _{n \rightarrow \infty} \frac{n+1}{\sqrt[n]{n !}}=\lim _{n \rightarrow \infty} \frac{n+1}{n} \cdot \frac{n}{\sqrt[n]{n !}}=e .
$$

Therefore,

$$
\begin{aligned}
& \lim _{n \rightarrow \infty}\left(\frac{\sqrt[n+1]{(n+1) !}}{\sqrt[n]{n !}}\right)^{n}=\lim _{n \rightarrow \infty}\left(\sqrt[n(n+1)]{\frac{((n+1) !)^{n}}{(n !)^{n+1}}}\right)^{n}=\lim _{n \rightarrow \infty}\left(\sqrt[n(n+1)]{\frac{(n+1)^{n}}{n !}}\right)^{n} \\
& =\lim _{n \rightarrow \infty}\left(\sqrt[n+1]{\frac{n+1}{\sqrt[n]{n !}}}\right)^{n}=\lim _{n \rightarrow \infty}\left(\frac{n+1}{\sqrt[n]{n !}}\right)^{\frac{n}{n+1}} 
\end{aligned}
$$



$$
=\left(\lim _{n \rightarrow \infty} \frac{n+1}{\sqrt[n]{n !}}\right)^{\lim _{n \rightarrow \infty} \frac{n}{n+1}}=e
$$

Taking the $n$th root and passing to the limit, we obtain

$$
\lim _{n \rightarrow \infty} \frac{\sqrt[n+1]{(n+1) !}}{\sqrt[n]{n !}}=1
$$

and hence

$$
\lim _{n \rightarrow \infty} \frac{a_{n}}{\sqrt[n]{n !}}=\lim _{n \rightarrow \infty} \frac{\sqrt[n+1]{(n+1) !}}{\sqrt[n]{n !}}-1=0
$$

Thus, if we set

$$
b_{n}=\left(1+\frac{a_{n}}{\sqrt[n]{n !}}\right)^{\frac{\sqrt[n]{n !}}{a_{n}}}
$$

then $\lim _{n \rightarrow \infty} b_{n}=e$. From the equality

$$
\left(\frac{\sqrt[n+1]{(n+1) !}}{\sqrt[n]{n !}}\right)^{n}=b_{n}^{a_{n} \frac{n}{\sqrt[n]{n !}}}
$$

we obtain

$$
a_{n}=\ln \left(\frac{\sqrt[n+1]{(n+1) !}}{\sqrt[n]{n !}}\right)^{n}\left(\ln b_{n}\right)^{-1}\left(\frac{n}{\sqrt[n]{n !}}\right)^{-1}
$$

The right-hand side is a product of three sequences that converge, respectively, to $1=\ln e$, $1=\ln e$, and $\frac{1}{e}$. Therefore, the sequence $\left(a_{n}\right)_{n}$ converges to the limit $\frac{1}{e}$.

Apply these methods to the problems below.

313. Compute

$$
\lim _{n \rightarrow \infty}\left|\sin \left(\pi \sqrt{n^{2}+n+1}\right)\right| .
$$

314. Let $k$ be a positive integer and $\mu$ a positive real number. Prove that

$$
\lim _{n \rightarrow \infty}\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(\frac{\mu}{n}\right)^{k}\left(1-\frac{\mu}{n}\right)^{n-k}=\frac{\mu^{k}}{e^{\mu} \cdot k !}
$$

315. Let $\left(x_{n}\right)_{n}$ be a sequence of positive integers such that $x_{x_{n}}=n^{4}$ for all $n \geq 1$. Is it true that $\lim _{n \rightarrow \infty} x_{n}=\infty$ ? 

316. Let $\left(a_{n}\right)_{n}$ be a sequence of real numbers with the property that for any $n \geq 2$ there exists an integer $k, \frac{n}{2} \leq k<n$, such that $a_{n}=\frac{a_{k}}{2}$. Prove that $\lim _{n \rightarrow \infty} a_{n}=0$.

317. Given two natural numbers $k$ and $m$ let $a_{1}, a_{2}, \ldots, a_{k}, b_{1}, b_{2}, \ldots, b_{m}$ be positive numbers such that

$$
\sqrt[n]{a_{1}}+\sqrt[n]{a_{2}}+\cdots+\sqrt[n]{a_{k}}=\sqrt[n]{b_{1}}+\sqrt[n]{b_{2}}+\cdots+\sqrt[n]{b_{m}},
$$

for all positive integers $n$. Prove that $k=m$ and $a_{1} a_{2} \cdots a_{k}=b_{1} b_{2} \cdots b_{m}$.

318. Prove that

$$
\lim _{n \rightarrow \infty} n^{2} \int_{0}^{\frac{1}{n}} x^{x+1} d x=\frac{1}{2} .
$$

319. Let $a$ be a positive real number and $\left(x_{n}\right)_{n \geq 1}$ a sequence of real numbers such that $x_{1}=a$ and

$$
x_{n+1} \geq(n+2) x_{n}-\sum_{k=1}^{n-1} k x_{k}, \quad \text { for all } n \geq 1 .
$$

Find the limit of the sequence.

320. Let $\left(x_{n}\right)_{n \geq 1}$ be a sequence of real numbers satisfying

$$
x_{n+m} \leq x_{n}+x_{m}, \quad n, m \geq 1 .
$$

Show that $\lim _{n \rightarrow \infty} \frac{x_{n}}{n}$ exists and is equal to $\inf _{n \geq 1} \frac{x_{n}}{n}$.

321. Compute

$$
\lim _{n \rightarrow \infty} \sum_{k=1}^{n}\left(\frac{k}{n^{2}}\right)^{\frac{k}{n^{2}}+1} .
$$

322. Let $b$ be an integer greater than 5 . For each positive integer $n$, consider the number

$$
x_{n}=\underbrace{11 \ldots 1}_{n-1} \underbrace{22 \ldots 2}_{n} 5,
$$

written in base $b$. Prove that the following condition holds if and only if $b=10$ :

There exists a positive integer $M$ such that for any integer $n$ greater than $M$, the number $x_{n}$ is a perfect square.

We exhibit two criteria for proving that a sequence is convergent without actually computing the limit. The first is due to Karl Weierstrass. 

\section{Weierstrass' theorem. A monotonic bounded sequence of real numbers is convergent.}

Below are some instances in which this theorem is used.

323. Prove that the sequence $\left(a_{n}\right)_{n \geq 1}$ defined by

$$
a_{n}=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln (n+1), \quad n \geq 1,
$$

is convergent.

324. Prove that the sequence

$$
a_{n}=\sqrt{1+\sqrt{2+\sqrt{3+\cdots+\sqrt{n}}}}, \quad n \geq 1,
$$

is convergent.

325. Let $\left(a_{n}\right)_{n}$ be a sequence of real numbers that satisfies the recurrence relation $a_{n+1}=$ $\sqrt{a_{n}^{2}+a_{n}-1}$, for $n \geq 1$. Prove that $a_{1} \notin(-2,1)$.

326. Using the Weierstrass theorem, prove that any bounded sequence of real numbers has a convergent subsequence.

Widely used in higher mathematics is the following convergence test.

Cauchy's criterion for convergence. A sequence $\left(x_{n}\right)_{n}$ of points in $\mathbb{R}^{n}$ (or, in general, in a complete metric space) is convergent if and only iffor any $\epsilon>0$ there is a positive integer $n_{\epsilon}$ such that whenever $n, m \geq n_{\epsilon},\left\|x_{n}-x_{m}\right\|<\epsilon$.

A sequence satisfying this property is called Cauchy, and it is the completeness of the space (the fact that it has no gaps) that forces a Cauchy sequence to be convergent. This property is what essentially distinguishes the set of real numbers from the rationals. In fact, the set of real numbers can be defined as the set of Cauchy sequences of rational numbers, with two such sequences identified if the sequence formed from alternating numbers of the two sequences is also Cauchy.

327. Let $\left(a_{n}\right)_{n \geq 1}$ be a decreasing sequence of positive numbers converging to 0 . Prove that the series $S=a_{1}-a_{2}+a_{3}-a_{4}+\cdots$ is convergent.

328. Let $a_{0}, b_{0}, c_{0}$ be real numbers. Define the sequences $\left(a_{n}\right)_{n},\left(b_{n}\right)_{n},\left(c_{n}\right)_{n}$ recursively by

$$
a_{n+1}=\frac{a_{n}+b_{n}}{2}, b_{n+1}=\frac{b_{n}+c_{n}}{2}, c_{n+1}=\frac{c_{n}+a_{n}}{2}, \quad n \geq 0 .
$$

Prove that the sequences are convergent and find their limits. 

329. Show that if the series $\sum a_{n}$ converges, where $\left(a_{n}\right)_{n}$ is a decreasing sequence, then $\lim _{n \rightarrow \infty} n a_{n}=0$.

The following fixed point theorem is a direct application of Cauchy's criterion for convergence.

Theorem. Let $X$ be a closed subset of $\mathbb{R}^{n}$ (or in general of a complete metric space) and $f: X \rightarrow X$ a function with the property that $\|f(x)-f(y)\| \leq c\|x-y\|$ for any $x, y \in X$, where $0<c<1$ is a constant. Then $f$ has a unique fixed point in $X$.

Such a function is called contractive. Recall that a set is closed if it contains all its limit points.

Proof. Let $x_{0} \in X$. Recursively define the sequence $x_{n}=f\left(x_{n-1}\right), n \geq 1$. Then

$$
\left\|x_{n+1}-x_{n}\right\| \leq c\left\|x_{n}-x_{n-1}\right\| \leq \cdots \leq c^{n}\left\|x_{1}-x_{0}\right\| .
$$

Applying the triangle inequality, we obtain

$$
\begin{aligned}
\left\|x_{n+p}-x_{n}\right\| & \leq\left\|x_{n+p}-x_{n+p-1}\right\|+\left\|x_{n+p-1}-x_{n+p-2}\right\|+\cdots+\left\|x_{n+1}-x_{n}\right\| \\
& \leq\left(c^{n+p-1}+c^{n+p-2}+\cdots+c^{n}\right)\left\|x_{1}-x_{0}\right\| \\
&=c^{n}\left(1+c+\cdots+c^{p-1}\right)\left\|x_{1}-x_{0}\right\| \leq \frac{c^{n}}{1-c}\left\|x_{1}-x_{0}\right\| .
\end{aligned}
$$

This shows that the sequence $\left(x_{n}\right)_{n}$ is Cauchy. Its limit $x^{*}$ satisfies $f\left(x^{*}\right)=\lim _{n \rightarrow \infty} f\left(x_{n}\right)$ $=\lim _{n \rightarrow \infty} x_{n}=x^{*}$; it is a fixed point of $f$. A second fixed point $y^{*}$ would give rise to the contradiction $\left\|x^{*}-y^{*}\right\|=\left\|f\left(x^{*}\right)-f\left(y^{*}\right)\right\| \leq c\left\|x^{*}-y^{*}\right\|$. Therefore, the fixed point is unique.

Use this theorem to solve the next three problems.

330. Two maps of the same region drawn to different scales are superimposed so that the smaller map lies entirely inside the larger. Prove that there is precisely one point on the small map that lies directly over a point on the large map that represents the same place of the region.

331. Let $t$ and $\epsilon$ be real numbers with $|\epsilon|<1$. Prove that the equation $x-\epsilon \sin x=t$ has a unique real solution.

332. Let $c$ and $x_{0}$ be fixed positive numbers. Define the sequence

$$
x_{n}=\frac{1}{2}\left(x_{n-1}+\frac{c}{x_{n-1}}\right), \quad \text { for } n \geq 1 .
$$

Prove that the sequence converges and that its limit is $\sqrt{c}$. 

\subsubsection{More About Limits of Sequences}

We continue our discussion about limits of sequences with three more topics: the method of passing to the limit in a recurrence relation, the Cesàro-Stolz theorem, and Cantor's nested intervals theorem. We illustrate the first with the continued fraction expansion of the golden ratio.

Example. Prove that

$$
\frac{1+\sqrt{5}}{2}=1+\frac{1}{1+\frac{1}{1+\frac{1}{1+\frac{1}{1+\cdots}}}} .
$$

Solution. A close look at the right-hand side shows that it is the limit of a sequence $\left(x_{n}\right)_{n}$ subject to the recurrence relation $x_{1}=1, x_{n+1}=1+\frac{1}{x_{n}}$. If this sequence has a finite limit $L$, then passing to the limit on both sides of the recurrence relation yields $L=1+\frac{1}{L}$. Because $L$ can only be positive, it must be equal to the golden ratio.

But does the limit exist? Investigating the first terms of the sequence we see that

$$
x_{1}<x_{3}<\frac{1+\sqrt{5}}{2}<x_{4}<x_{2},
$$

and we expect the general situation to be

$$
x_{1}<x_{3}<\cdots<x_{2 n+1}<\cdots<\frac{1+\sqrt{5}}{2}<\cdots<x_{2 n}<x_{2 n-2}<\cdots<x_{2} .
$$

This can be proved by induction. Firstly, if $x_{2 n+1}<\frac{1+\sqrt{5}}{2}$, then

$$
x_{2 n+2}=1+\frac{1}{x_{2 n+1}}>1+\frac{2}{1+\sqrt{5}}=1+\frac{\sqrt{5}-1}{2}=\frac{1+\sqrt{5}}{2},
$$

and by a similar computation, if $x_{2 n+2}>\frac{1+\sqrt{5}}{2}$, then $x_{2 n+3}<\frac{1+\sqrt{5}}{2}$. Secondly,

$$
x_{n+2}=2-\frac{1}{x_{n}+1} \text {, }
$$

and the inequality $x_{n+2}>x_{n}$ is equivalent to $x_{n}^{2}-x_{n}-1<0$, which holds if and only if $x_{n}<\frac{1+\sqrt{5}}{2}$. Now an inductive argument shows that $\left(x_{2 n+1}\right)_{n}$ is increasing and $\left(x_{2 n+2}\right)_{n}$ is decreasing. Being bounded, both sequences are convergent. Their limits are positive, and both should satisfy the equation $L=2-\frac{1}{L+1}$. The unique positive solution to this equation is the golden ratio, which is therefore the limit of both sequences, and consequently the limit of the sequence $\left(x_{n}\right)_{n}$. Next, we present a famous identity of S.A. Ramanujan.

Example. Prove that

$$
\sqrt{1+2 \sqrt{1+3 \sqrt{1+4 \sqrt{1+\cdots}}}}=3 .
$$

Solution. We approach the problem in more generality by introducing the function $f$ : $[1, \infty) \rightarrow \mathbb{R}$

$$
f(x)=\sqrt{1+x \sqrt{1+(x+1) \sqrt{1+(x+2) \sqrt{1+\cdots}}}}
$$

Is this function well defined? Truncating to $n$ square roots, we obtain an increasing sequence. All we need to show is that this sequence is bounded from above. And it is, because

$$
\begin{aligned}
& f(x) \leq \sqrt{(x+1) \sqrt{(x+2) \sqrt{(x+3) \cdots}}} \\
& \leq \sqrt{2 x \sqrt{3 x \sqrt{4 x \cdots}}} \leq \sqrt{2 x \sqrt{4 x \sqrt{8 x \cdots}}} \\
& =2^{\sum \frac{k}{2^{k}}} x^{\sum \frac{1}{2^{k}}} \leq 2^{\frac{1}{2}+\frac{1}{2}+\frac{1}{4}+\frac{1}{4}+\frac{1}{8}+\frac{1}{8}+\cdots} x=2 x \text {. }
\end{aligned}
$$

This shows, moreover, that $f(x) \leq 2 x$, for $x \geq 1$. Note also that

$$
f(x) \geq \sqrt{x \sqrt{x \sqrt{x \cdots}}}=x .
$$

For reasons that will become apparent, we weaken this inequality to $f(x) \geq \frac{1}{2}(x+1)$. We then square the defining relation and obtain the functional equation

$$
(f(x))^{2}=x f(x+1)+1 .
$$

Combining this with

$$
\frac{1}{2}(x+1) \leq f(x+1) \leq 2(x+1),
$$

we obtain

$$
x \cdot \frac{x+1}{2}+1 \leq(f(x))^{2} \leq 2 x(x+1)+1,
$$

which yields the sharper double inequality 

$$
\frac{1}{\sqrt{2}}(x+1) \leq f(x) \leq \sqrt{2}(x+1) .
$$

Repeating successively the argument, we find that

$$
2^{-\frac{1}{2^{n}}}(x+1) \leq f(x) \leq 2^{\frac{1}{2^{n}}}(x+1), \quad \text { for } n \geq 1 .
$$

If in this double inequality we let $n \rightarrow \infty$, we obtain $x+1 \leq f(x) \leq x+1$, and hence $f(x)=x+1$. The particular case $x=2$ yields Ramanujan's formula

$$
\sqrt{1+2 \sqrt{1+3 \sqrt{1+4 \sqrt{1+\cdots}}}}=3 .
$$

Here are some problems of this kind.

333. Compute

$$
\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\cdots}}}}
$$

334. Let $a$ and $b$ be real numbers. Prove that the recurrence sequence $\left(x_{n}\right)_{n}$ defined by $x_{1}>0$ and $x_{n+1}=\sqrt{a+b x_{n}}, n \geq 1$, is convergent, and find its limit.

335. Let $0<a<b$ be two real numbers. Define the sequences $\left(a_{n}\right)_{n}$ and $\left(b_{n}\right)_{n}$ by $a_{0}=a, b_{0}=b$, and

$$
a_{n+1}=\sqrt{a_{n} b_{n}}, \quad b_{n+1}=\frac{a_{n}+b_{n}}{2}, \quad n \geq 0 .
$$

Prove that the two sequences are convergent and have the same limit.

336. Prove that for $n \geq 2$, the equation $x^{n}+x-1=0$ has a unique root in the interval $[0,1]$. If $x_{n}$ denotes this root, prove that the sequence $\left(x_{n}\right)_{n}$ is convergent and find its limit.

337. Compute up to two decimal places the number

$$
\sqrt{1+2 \sqrt{1+2 \sqrt{1+\cdots+2 \sqrt{1+2 \sqrt{1969}}}}}
$$

where the expression contains 1969 square roots.

338. Find the positive real solutions to the equation

$$
\sqrt{x+2 \sqrt{x+\cdots+2 \sqrt{x+2 \sqrt{3 x}}}}=x .
$$

339. Show that the sequence

$$
\sqrt{7}, \sqrt{7-\sqrt{7}}, \sqrt{7-\sqrt{7+\sqrt{7}}}, \sqrt{7-\sqrt{7+\sqrt{7-\sqrt{7}}}}, \ldots
$$

converges, and evaluate its limit.

There is a vocabulary for translating the language of derivatives to the discrete framework of sequences. The first derivative of a sequence $\left(x_{n}\right)_{n}$, usually called the first difference, is the sequence $\left(\Delta x_{n}\right)_{n}$ defined by $\Delta x_{n}=x_{n+1}-x_{n}$. The second derivative, or second difference, is $\Delta^{2} x_{n}=\Delta\left(\Delta x_{n}\right)=x_{n+2}-2 x_{n+1}+x_{n}$. A sequence is increasing if the first derivative is positive; it is convex if the second derivative is positive. The Cesàro-Stolz theorem, which we discuss below, is the discrete version of L'Hôpital's theorem.

The Cesàro-Stolz Theorem. Let $\left(x_{n}\right)_{n}$ and $\left(y_{n}\right)_{n}$ be two sequences of real numbers with $\left(y_{n}\right)_{n}$ strictly positive, increasing, and unbounded. If

$$
\lim _{n \rightarrow \infty} \frac{x_{n+1}-x_{n}}{y_{n+1}-y_{n}}=L,
$$

then the limit

$$
\lim _{n \rightarrow \infty} \frac{x_{n}}{y_{n}}
$$

exists and is equal to $L$.

Proof. We apply the same $\epsilon-\delta$ argument as for L'Hôpital's theorem. We do the proof only for $L$ finite, the cases $L=\pm \infty$ being left to the reader.

Fix $\epsilon>0$. There exists $n_{0}$ such that for $n \geq n_{0}$,

$$
L-\frac{\epsilon}{2}<\frac{x_{n+1}-x_{n}}{y_{n+1}-y_{n}}<L+\frac{\epsilon}{2} .
$$

Because $y_{n+1}-y_{n} \geq 0$, this is equivalent to

$$
\left(L-\frac{\epsilon}{2}\right)\left(y_{n+1}-y_{n}\right)<x_{n+1}-x_{n}<\left(L+\frac{\epsilon}{2}\right)\left(y_{n+1}-y_{n}\right) .
$$

We sum all these inequalities for $n$ ranging between $n_{0}$ and $m-1$, for some $m$. After cancelling terms in the telescopic sums that arise, we obtain

$$
\left(L-\frac{\epsilon}{2}\right)\left(y_{m}-y_{n_{0}}\right)<x_{m}-x_{n_{0}}<\left(L+\frac{\epsilon}{2}\right)\left(y_{m}-y_{n_{0}}\right) .
$$

We divide by $y_{m}$ and write the answer as 

$$
L-\frac{\epsilon}{2}+\left(-L \frac{y_{n_{0}}}{y_{m}}+\frac{\epsilon}{2} \cdot \frac{y_{n_{0}}}{y_{m}}+\frac{x_{n_{0}}}{y_{m}}\right)<\frac{x_{m}}{y_{m}}<L+\frac{\epsilon}{2}+\left(-L \frac{y_{n_{0}}}{y_{m}}-\frac{\epsilon}{2} \cdot \frac{y_{n_{0}}}{y_{m}}+\frac{x_{n_{0}}}{y_{m}}\right) .
$$

Because $y_{n} \rightarrow \infty$, there exists $n_{1}>n_{0}$ such that for $m \geq n_{1}$, the absolute values of the terms in the parentheses are less than $\frac{\epsilon}{2}$. Hence for $m \geq n_{1}$,

$$
L-\epsilon<\frac{x_{m}}{y_{m}}<L+\epsilon \text {. }
$$

Since $\epsilon$ was arbitrary, this proves that the sequence $\left(\frac{x_{n}}{y_{n}}\right)_{n}$ converges to $L$.

We continue this discussion with an application to Cesàro means. By definition, the Cesàro means of a sequence $\left(a_{n}\right)_{n \geq 1}$ are

$$
s_{n}=\frac{a_{1}+a_{2}+\cdots+a_{n}}{n}, \quad n \geq 1 .
$$

Theorem. If $\left(a_{n}\right)_{n \geq 1}$ converges to $L$, then $\left(s_{n}\right)_{n \geq 1}$ also converges to $L$.

Proof. Apply the Cesàro-Stolz theorem to the sequences $x_{n}=a_{1}+a_{2}+\cdots+a_{n}$ and $y_{n}=n, n \geq 1$

The Cesàro-Stolz theorem can be used to solve the following problems.

340. If $\left(u_{n}\right)_{n}$ is a sequence of positive real numbers and if $\lim _{n \rightarrow \infty} \frac{u_{n+1}}{u_{n}}=u>0$, then $\lim _{n \rightarrow \infty} \sqrt[n]{u_{n}}=u$

341. Let $p$ be a real number, $p \neq 1$. Compute

$$
\lim _{n \rightarrow \infty} \frac{1^{p}+2^{p}+\cdots+n^{p}}{n^{p+1}}
$$

342. Let $0<x_{0}<1$ and $x_{n+1}=x_{n}-x_{n}^{2}$ for $n \geq 0$. Compute $\lim _{n \rightarrow \infty} n x_{n}$.

343. Let $x_{0} \in[-1,1]$ and $x_{n+1}=x_{n}-\arcsin \left(\sin ^{2} x_{n}\right)$ for $n \geq 0$. Compute $\lim _{n \rightarrow \infty} \sqrt{n} x_{n}$

344. For an arbitrary number $x_{0} \in(0, \pi)$ define recursively the sequence $\left(x_{n}\right)_{n}$ by $x_{n+1}=\sin x_{n}, n \geq 0$. Compute $\lim _{n \rightarrow \infty} \sqrt{n} x_{n}$.

345. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that the sequence $\left(a_{n}\right)_{n \geq 0}$ defined by $a_{n}=\int_{0}^{1} f(n+x) d x$ is convergent. Prove that the sequence $\left(b_{n}\right)_{n \geq 0}$, with $b_{n}=\int_{0}^{1} f(n x) d x$ is also convergent.

346. Consider the polynomial $P(x)=a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{0}, a_{i}>0, i=$ $0,1, \ldots, m$. Denote by $A_{n}$ and $G_{n}$ the arithmetic and, respectively, geometric means of the numbers $P(1), P(2), \ldots, P(n)$. Prove that

$$
\lim _{n \rightarrow \infty} \frac{A_{n}}{G_{n}}=\frac{e^{m}}{m+1}
$$

347. Let $k$ be an integer greater than 1 . Suppose $a_{0}>0$, and define

$$
a_{n+1}=a_{n}+\frac{1}{\sqrt[k]{a_{n}}}
$$

for $n>0$. Evaluate

$$
\lim _{n \rightarrow \infty} \frac{a_{n}^{k+1}}{n^{k}} .
$$

We conclude the discussion about limits of sequences with the theorem of Georg Cantor.

Cantor's nested intervals theorem. Given a decreasing sequence of closed intervals $I_{1} \supset I_{2} \supset \cdots \supset I_{n} \supset \cdots$ with lengths converging to zero, the intersection $\cap_{n=1}^{\infty} I_{n}$ consists of exactly one point.

This theorem is true in general if the intervals are replaced by closed and bounded subsets of $\mathbb{R}^{n}$ with diameters converging to zero. As an application of this theorem we prove the compactness of a closed bounded interval. A set of real numbers is called compact if from every family of open intervals that cover the set one can choose finitely many that still cover it.

The Heine-Borel Theorem. A closed and bounded interval of real numbers is compact.

Proof. Let the interval be $[a, b]$ and assume that for some family of open intervals $\left(I_{\alpha}\right)_{\alpha}$ that covers $[a, b]$ one cannot choose finitely many that still cover it. We apply the dichotomic (division into two parts) method. Cut the interval $[a, b]$ in half. One of the two intervals thus obtained cannot be covered by finitely many $I_{\alpha}$ 's. Call this interval $J_{1}$. Cut $J_{1}$ in half. One of the newly obtained intervals will again not be covered by finitely many $I_{\alpha}$ 's. Call it $J_{2}$. Repeat the construction to obtain a decreasing sequence of intervals $J_{1} \supset J_{2} \supset J_{3} \supset \cdots$, with the length of $J_{k}$ equal to $\frac{b-a}{2^{k}}$ and such that none of these intervals can be covered by finitely many $I_{\alpha}$ 's. By Cantor's nested intervals theorem, the intersection of the intervals $J_{k}, k \geq 1$, is some point $x$. This point belongs to an open interval $I_{\alpha_{0}}$, and so an entire $\epsilon$-neighborhood of $x$ is in $I_{\alpha_{0}}$. But then $J_{k} \subset I_{\alpha_{0}}$ for $k$ large enough, a contradiction. Hence our assumption was false, and a finite subcover always exists.

Recall that the same dichotomic method can be applied to show that any sequence in a closed and bounded interval (and more generally in a compact metric space) has a converent subsequence. And if you find the following problems demanding, remember Charlie Chaplin's words: "Failure is unimportant. It takes courage to make a fool of yourself." 

348. Let $f:[a, b] \rightarrow[a, b]$ be an increasing function. Show that there exists $\xi \in[a, b]$ such that $f(\xi)=\xi$.

349. For every real number $x_{1}$ construct the sequence $x_{1}, x_{2}, x_{3}, \ldots$ by setting $x_{n+1}=$ $x_{n}\left(x_{n}+\frac{1}{n}\right)$ for each $n \geq 1$. Prove that there exists exactly one value of $x_{1}$ for which $0<x_{n}<x_{n+1}<1$ for every $n$.

350. Given a sequence $\left(a_{n}\right)_{n}$ such that for any $\gamma>1$ the subsequence $a_{\left\lfloor\gamma^{n}\right\rfloor}$ converges to zero, does it follow that the sequence $\left(a_{n}\right)_{n}$ itself converges to zero?

351. Let $f:(0, \infty) \rightarrow \mathbb{R}$ be a continuous function with the property that for any $x>0$, $\lim _{n \rightarrow \infty} f(n x)=0$. Prove that $\lim _{x \rightarrow \infty} f(x)=0$.

\subsubsection{Series}

A series is a sum

$$
\sum_{n=1}^{\infty} a_{n}=a_{1}+a_{2}+\cdots+a_{n}+\cdots .
$$

The first question asked about a series is whether it converges. Convergence can be decided using Cauchy's $\epsilon-\delta$ criterion, or by comparing it with another series. For comparison, two families of series are most useful:

(i) geometric series

$$
1+x+x^{2}+\cdots+x^{n}+\cdots,
$$

which converge if $|x|<1$ and diverge otherwise, and

(ii) $p$-series

$$
1+\frac{1}{2^{p}}+\frac{1}{3^{p}}+\cdots+\frac{1}{n^{p}}+\cdots,
$$

which converge if $p>1$ and diverge otherwise.

The $p$-series corresponding to $p=1$ is the harmonic series. Its truncation to the $n$th term approximates $\ln n$. Let us use the harmonic series to answer the following question.

Example. Does the series $\sum_{n=1}^{\infty} \frac{|\sin n|}{n}$ converge?

Solution. The inequality $|\sin x|>\frac{\sqrt{2-\sqrt{2}}}{2}$ holds if and only if $\frac{1}{8}<\left\{\frac{x}{\pi}\right\}<\frac{7}{8}$, where $\{x\}$ denotes the fractional part of $x(x-\lfloor x\rfloor)$. Because $\frac{1}{4}<\frac{1}{\pi}$, it follows that for any $n$, either $|\sin n|$ or $|\sin (n+1)|$ is greater than $\frac{\sqrt{2-\sqrt{2}}}{2}$. Therefore, 

$$
\frac{|\sin n|}{n}+\frac{|\sin (n+1)|}{n+1} \geq \frac{\sqrt{2-\sqrt{2}}}{2} \cdot \frac{1}{n+1} .
$$

Adding up these inequalities for all odd numbers $n$, we obtain

$$
\sum_{n=1}^{\infty} \frac{|\sin n|}{n} \geq \frac{\sqrt{2-\sqrt{2}}}{2} \sum_{n=1}^{\infty} \frac{1}{2 n}=\frac{\sqrt{2-\sqrt{2}}}{4} \sum_{n=1}^{\infty} \frac{1}{n}=\infty .
$$

Hence the series diverges.

In fact, the so-called equidistribution criterion implies that if $f: \mathbb{R} \rightarrow \mathbb{R}$ is a continuous periodic function with irrational period and if $\sum_{n} \frac{|f(n)|}{n}<\infty$, then $f$ is identically zero.

The comparison with a geometric series gives rise to d'Alembert's ratio test: $\sum_{n=0}^{\infty} a_{n}$ converges if $\lim \sup _{n}\left|\frac{a_{n+1}}{a_{n}}\right|<1$ and diverges if $\lim \inf _{n}\left|\frac{a_{n+1}}{a_{n}}\right|>1$. Here is a problem of P. Erdós from the American Mathematical Monthly that applies this test among other things.

Example. Let $\left(n_{k}\right)_{k \geq 1}$ be a strictly increasing sequence of positive integers with the property that

$$
\lim _{k \rightarrow \infty} \frac{n_{k}}{n_{1} n_{2} \cdots n_{k-1}}=\infty .
$$

Prove that the series $\sum_{k \geq 1} \frac{1}{n_{k}}$ is convergent and that its sum is an irrational number.

Solution. The relation from the statement implies in particular that $n_{k+1} \geq 3 n_{k}$ for $k \geq 3$. By the ratio test the series $\sum_{k} \frac{1}{n_{k}}$ is convergent, since the ratio of two consecutive terms is less than or equal to $\frac{1}{3}$.

By way of contradiction, suppose that the sum of the series is a rational number $\frac{p}{q}$. Using the hypothesis we can find $k \geq 3$ such that

$$
\frac{n_{j+1}}{n_{1} n_{2} \cdots n_{j}} \geq 3 q, \quad \text { if } j \geq k .
$$

Let us start with the obvious equality

$$
p\left(n_{1} n_{2} \cdots n_{k}\right)=q\left(n_{1} n_{2} \cdots n_{k}\right) \sum_{j=1}^{\infty} \frac{1}{n_{j}} .
$$

From it we derive

$$
p\left(n_{1} n_{2} \cdots n_{k}\right)-\sum_{j=1}^{k} \frac{q n_{1} n_{2} \cdots n_{k}}{n_{j}}=\sum_{j>k} \frac{q n_{1} n_{2} \cdots n_{k}}{n_{j}} .
$$

Clearly, the left-hand side of this equality is an integer. For the right-hand side, we have $0<\sum_{j>k} \frac{q n_{1} n_{2} \cdots n_{k}}{n_{j}} \leq \frac{q n_{1} n_{2} \cdots n_{k}}{n_{k+1}}+\frac{q n_{1} n_{2} \cdots n_{k}}{3 n_{k+1}}+\cdots \leq \frac{1}{3}+\frac{1}{9}+\frac{1}{27}+\cdots=\frac{1}{2}$.

Here we used the fact that $n_{1} n_{2} \cdots \frac{n_{k}}{n_{k+1}} \leq \frac{1}{3 q}$ and that $n_{j+1} \geq 3 n_{j}$, for $j \geq k$ and $k$ sufficiently large. This shows that the right-hand side cannot be an integer, a contradiction. It follows that the sum of the series is irrational.

352. Show that the series

$$
\frac{1}{1+x}+\frac{2}{1+x^{2}}+\frac{4}{1+x^{4}}+\cdots+\frac{2^{n}}{1+x^{2^{n}}}+\cdots
$$

converges when $|x|>1$, and in this case find its sum.

353. For what positive $x$ does the series

$$
(x-1)+(\sqrt{x}-1)+(\sqrt[3]{x}-1)+\cdots+(\sqrt[n]{x}-1)+\cdots
$$

converge?

354. Let $a_{1}, a_{2}, \ldots, a_{n}, \ldots$ be nonnegative numbers. Prove that $\sum_{n=1}^{\infty} a_{n}<\infty$ implies $\sum_{n=1}^{\infty} \sqrt{a_{n+1} a_{n}}<\infty$

355. Let $S=\left\{x_{1}, x_{2}, \ldots, x_{n}, \ldots\right\}$ be the set of all positive integers that do not contain the digit 9 in their decimal representation. Prove that

$$
\sum_{n=1}^{\infty} \frac{1}{x_{n}}<80 .
$$

356. Suppose that $\left(x_{n}\right)_{n}$ is a sequence of real numbers satisfying

$$
x_{n+1} \leq x_{n}+\frac{1}{n^{2}}, \quad \text { for all } n \geq 1 .
$$

Prove that $\lim _{n \rightarrow \infty} x_{n}$ exists.

357. Does the series $\sum_{n=1}^{\infty} \sin \pi \sqrt{n^{2}+1}$ converge?

358. (a) Does there exist a pair of divergent series $\sum_{n=1}^{\infty} a_{n}, \sum_{n=1}^{\infty} b_{n}$, with $a_{1} \geq a_{2} \geq$ $a_{3} \geq \cdots \geq 0$ and $b_{1} \geq b_{2} \geq b_{3} \geq \cdots \geq 0$, such that the series $\sum_{n} \min \left(a_{n}, b_{n}\right)$ is convergent?

(b) Does the answer to this question change if we assume additionally that $b_{n}=\frac{1}{n}$, $n=1,2, \ldots ?$ 

359. Given a sequence $\left(x_{n}\right)_{n}$ with $x_{1} \in(0,1)$ and $x_{n+1}=x_{n}-n x_{n}^{2}$ for $n \geq 1$, prove that the series $\sum_{n=1}^{\infty} x_{n}$ is convergent.

360. Is the number

$$
\sum_{n=1}^{\infty} \frac{1}{2^{n^{2}}}
$$

rational?

361. Let $\left(a_{n}\right)_{n \geq 0}$ be a strictly decreasing sequence of positive numbers, and let $z$ be a complex number of absolute value less than 1 . Prove that the sum

$$
a_{0}+a_{1} z+a_{2} z^{2}+\cdots+a_{n} z^{n}+\cdots
$$

is not equal to zero.

362. Let $w$ be an irrational number with $0<w<1$. Prove that $w$ has a unique convergent expansion of the form

$$
w=\frac{1}{p_{0}}-\frac{1}{p_{0} p_{1}}+\frac{1}{p_{0} p_{1} p_{2}}-\frac{1}{p_{0} p_{1} p_{2} p_{3}}+\cdots,
$$

where $p_{0}, p_{1}, p_{2}, \ldots$ are integers $1 \leq p_{0}<p_{1}<p_{2}<\cdots$.

363. The number $q$ ranges over all possible powers with both the base and the exponent positive integers greater than 1 , assuming each such value only once. Prove that

$$
\sum_{q} \frac{1}{q-1}=1 .
$$

364. Prove that for any $n \geq 2$,

$$
\sum_{p \leq n, p \text { prime }} \frac{1}{p}>\ln \ln n-1 .
$$

Conclude that the sum of the reciprocals of all prime numbers is infinite.

\subsubsection{Telescopic Series and Products}

We mentioned earlier the idea of translating notions from differential and integral calculus to sequences. For example, the derivative of $\left(x_{n}\right)_{n}$ is the sequence whose terms are $x_{n+1}-x_{n}, n \geq 1$, while the definite integral is the sum $x_{1}+x_{2}+x_{3}+\cdots$. The Leibniz-Newton theorem 

$$
\int_{a}^{b} f(t) d t=F(b)-F(a), \quad \text { where } F^{\prime}(t)=f(t)
$$

becomes the telescopic method for summing a series

$$
\sum_{1}^{n} a_{k}=b_{n+1}-b_{1}, \quad \text { where } a_{k}=b_{k+1}-b_{k}, k \geq 1
$$

As in the case of integrals, when applying the telescopic method to a series, the struggle is to find the "antiderivative" of the general term. But compared to the case of integrals, here we lack an algorithmic way. This is what makes such problems attractive for mathematics competitions. A simple example that comes to mind is the following.

Example. Find the sum

$$
\frac{1}{\sqrt{1}+\sqrt{2}}+\frac{1}{\sqrt{2}+\sqrt{3}}+\cdots+\frac{1}{\sqrt{n}+\sqrt{n+1}}
$$

Solution. The "antiderivative" of the general term of the sum is found by rationalizing the denominator:

$$
\frac{1}{\sqrt{k}+\sqrt{k+1}}=\frac{\sqrt{k+1}-\sqrt{k}}{k+1-k}=\sqrt{k+1}-\sqrt{k}
$$

The sum is therefore equal to

$$
(\sqrt{2}-\sqrt{1})+(\sqrt{3}-\sqrt{2})+\cdots+(\sqrt{n+1}-\sqrt{n})=\sqrt{n+1}-1 .
$$

Not all problems are so simple, as the next two examples show.

Example. Let $a_{0}=1, a_{1}=3, a_{n+1}=\frac{a_{n}^{2}+1}{2}, n \geq 1$. Prove that

$$
\frac{1}{a_{0}+1}+\frac{1}{a_{1}+1}+\cdots+\frac{1}{a_{n}+1}+\frac{1}{a_{n+1}-1}=1, \quad \text { for all } n \geq 1
$$

Solution. We have

$$
a_{k+1}-1=\frac{a_{k}^{2}-1}{2}
$$

so

$$
\frac{1}{a_{k+1}-1}=\frac{1}{a_{k}-1}-\frac{1}{a_{k}+1}, \quad \text { for } k \geq 1 \text {. }
$$

This allows us to express the terms of the sum from the statement as "derivatives": 

$$
\frac{1}{a_{k}+1}=\frac{1}{a_{k}-1}-\frac{1}{a_{k+1}-1}, \quad \text { for } k \geq 1 .
$$

Summing up these equalities for $k=1,2, \ldots, n$ yields

$$
\begin{aligned}
\frac{1}{a_{1}+1}+\cdots+\frac{1}{a_{n}+1}=& \frac{1}{a_{1}-1}-\frac{1}{a_{2}-1}+\frac{1}{a_{2}-1}-\frac{1}{a_{3}-1}+\cdots \\
&+\frac{1}{a_{n}-1}-\frac{1}{a_{n+1}-1}=\frac{1}{2}-\frac{1}{a_{n+1}-1} .
\end{aligned}
$$

Finally, add $\frac{1}{a_{0}+1}+\frac{1}{a_{n+1}-1}$ to both sides to obtain the identity from the statement.

Example. Express

$$
\sum_{n=1}^{49} \frac{1}{\sqrt{n+\sqrt{n^{2}-1}}}
$$

as $a+b \sqrt{2}$ for some integers $a$ and $b$.

Solution. We have

$$
\begin{aligned}
\frac{1}{\sqrt{n+\sqrt{n^{2}-1}}} &=\frac{1}{\sqrt{\left(\sqrt{\frac{n+1}{2}}+\sqrt{\frac{n-1}{2}}\right)^{2}}}=\frac{1}{\sqrt{\frac{n+1}{2}}+\sqrt{\frac{n-1}{2}}} \\
&=\frac{\sqrt{\frac{n+1}{2}}-\sqrt{\frac{n-1}{2}}}{\frac{n+1}{2}-\frac{n-1}{2}}=\sqrt{\frac{n+1}{2}}-\sqrt{\frac{n-1}{2}} .
\end{aligned}
$$

Hence the sum from the statement telescopes to

$$
\sqrt{\frac{49+1}{2}}+\sqrt{\frac{48+1}{2}}-\sqrt{\frac{1}{2}}-0=5+\frac{7}{\sqrt{2}}-\frac{1}{\sqrt{2}}=5+3 \sqrt{2} .
$$

Apply the telescopic method to the following problems.

365. Prove the identity

$$
\sum_{k=1}^{n}\left(k^{2}+1\right) k !=n(n+1) ! .
$$

366. Let $\zeta$ be a root of unity. Prove that

$$
\zeta^{-1}=\sum_{n=0}^{\infty} \zeta^{n}(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right),
$$

with the convention that the 0th term of the series is 1 . 

367. For a nonnegative integer $k$, define $S_{k}(n)=1^{k}+2^{k}+\cdots+n^{k}$. Prove that

$$
1+\sum_{k=0}^{r-1}\left(\begin{array}{l}
r \\
k
\end{array}\right) S_{k}(n)=(n+1)^{r} .
$$

368. Let

$$
a_{n}=\frac{4 n+\sqrt{4 n^{2}-1}}{\sqrt{2 n+1}+\sqrt{2 n-1}}, \quad \text { for } n \geq 1 .
$$

Prove that $a_{1}+a_{2}+\cdots+a_{40}$ is a positive integer.

369. Prove that

$$
\sum_{k=1}^{n} \frac{(-1)^{k+1}}{1^{2}-2^{2}+3^{2}-\cdots+(-1)^{k+1} k^{2}}=\frac{2 n}{n+1} .
$$

370. Prove that

$$
\sum_{n=1}^{9999} \frac{1}{(\sqrt{n}+\sqrt{n+1})(\sqrt[4]{n}+\sqrt[4]{n+1})}=9
$$

371. Let $a_{n}=\sqrt{1+\left(1+\frac{1}{n}\right)^{2}}+\sqrt{1+\left(1-\frac{1}{n}\right)^{2}}, n \geq 1$. Prove that

$$
\frac{1}{a_{1}}+\frac{1}{a_{2}}+\cdots+\frac{1}{a_{20}}
$$

is a positive integer.

372. Evaluate in closed form

$$
\sum_{m=0}^{\infty} \sum_{n=0}^{\infty} \frac{m ! n !}{(m+n+2) !} .
$$

373. Let $a_{n}=3 n+\sqrt{n^{2}-1}$ and $b_{n}=2\left(\sqrt{n^{2}-n}+\sqrt{n^{2}+n}\right), n \geq 1$. Show that

$$
\sqrt{a_{1}-b_{1}}+\sqrt{a_{2}-b_{2}}+\cdots+\sqrt{a_{49}-b_{49}}=A+B \sqrt{2},
$$

for some integers $A$ and $B$.

374. Evaluate in closed form

$$
\sum_{k=0}^{n}(-1)^{k}(n-k) !(n+k) !
$$

375. Let $a_{0}=1994$ and $a_{n+1}=\frac{a_{n}^{2}}{a_{n}+1}$ for each nonnegative integer $n$. Prove that for $0 \leq n \leq 998$, the number $1994-n$ is the greatest integer less than or equal to $a_{n}$.

376. Fix $k$ a positive integer and define the sequence

$$
a_{n}=\left\lfloor\left(k+\sqrt{k^{2}+1}\right)^{n}+\left(\frac{1}{2}\right)^{n}\right\rfloor, \quad n \geq 0 .
$$

Prove that

$$
\sum_{n=1}^{\infty} \frac{1}{a_{n-1} a_{n+1}}=\frac{1}{8 k^{2}} .
$$

The telescopic method can be applied to products as well. Within the first, relatively easy, problem, the reader will recognize in disguise the Fermat numbers $2^{2^{n}}+1, n \geq 1$.

Example. Define the sequence $\left(a_{n}\right)_{n}$ by $a_{0}=3$, and $a_{n+1}=a_{0} a_{1} \cdots a_{n}+2, n \geq 0$. Prove that

$$
a_{n+1}=2\left(a_{0}-1\right)\left(a_{1}-1\right) \cdots\left(a_{n}-1\right)+1, \quad \text { for all } n \geq 0 .
$$

Solution. The recurrence relation gives $a_{0} a_{1} \cdots a_{k-1}=a_{k}-2, k \geq 1$. Substitute this in the formula for $a_{k+1}$ to obtain $a_{k+1}=\left(a_{k}-2\right) a_{k}+2$, which can be written as $a_{k+1}-1=\left(a_{k}-1\right)^{2}$. And so

$$
\frac{a_{k+1}-1}{a_{k}-1}=a_{k}-1 .
$$

Multiplying these relations for $k=0,1, \ldots, n$, we obtain

$$
\frac{a_{n+1}-1}{a_{n}-1} \cdot \frac{a_{n}-1}{a_{n-1}-1} \cdots \frac{a_{1}-1}{a_{0}-1}=\left(a_{n}-1\right)\left(a_{n-1}-1\right) \cdots\left(a_{0}-1\right) .
$$

Since the left-hand side telescopes, we obtain

$$
\frac{a_{n+1}-1}{a_{0}-1}=\left(a_{0}-1\right)\left(a_{1}-1\right) \cdots\left(a_{n}-1\right),
$$

and the identity follows.

A more difficult problem is the following.

Example. Compute the product

$$
\prod_{n=1}^{\infty}\left(1+\frac{(-1)^{n}}{F_{n}^{2}}\right),
$$

where $F_{n}$ is the $n$th Fibonacci number. Solution. Recall that the Fibonacci numbers satisfy the Cassini identity

$$
F_{n+1} F_{n-1}-F_{n}^{2}=(-1)^{n} .
$$

Hence

$$
\begin{aligned}
\prod_{n=1}^{\infty}\left(1+\frac{(-1)^{n}}{F_{n}^{2}}\right) &=\lim _{N \rightarrow \infty} \prod_{n=1}^{N} \frac{F_{n}^{2}+(-1)^{n}}{F_{n}^{2}}=\lim _{N \rightarrow \infty} \prod_{n=1}^{N} \frac{F_{n-1}}{F_{n}} \cdot \frac{F_{n+1}}{F_{n}} \\
&=\lim _{N \rightarrow \infty} \frac{F_{0} F_{N+1}}{F_{1} F_{N}}=\lim _{N \rightarrow \infty} \frac{F_{N+1}}{F_{N}} .
\end{aligned}
$$

Because of the Binet formula

$$
F_{n}=\frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}\right)^{n+1}-\left(\frac{1-\sqrt{5}}{2}\right)^{n+1}\right], \quad \text { for } n \geq 0
$$

the above limit is equal to $\frac{1+\sqrt{5}}{2}$.

377. Compute the product

$$
\left(1-\frac{4}{1}\right)\left(1-\frac{4}{9}\right)\left(1-\frac{4}{25}\right) \cdots
$$

378. Let $x$ be a positive number less than 1 . Compute the product

$$
\prod_{n=0}^{\infty}\left(1+x^{2^{n}}\right) .
$$

379. Let $x$ be a real number. Define the sequence $\left(x_{n}\right)_{n \geq 1}$ recursively by $x_{1}=1$ and $x_{n+1}=x^{n}+n x_{n}$ for $n \geq 1$. Prove that

$$
\prod_{n=1}^{\infty}\left(1-\frac{x^{n}}{x_{n+1}}\right)=e^{-x} .
$$

\subsection{Continuity, Derivatives, and Integrals}

\subsubsection{Limits of Functions}

Among the various ways to find the limit of a function, the most basic is the definition itself. Definition. For $x_{0}$ an accumulation point of the domain of a function $f$, we say that $\lim _{x \rightarrow x_{0}} f(x)=L$ if for every neighborhood $V$ of $L$, there is a neighborhood $U$ of $x_{0}$ such that $f(U) \subset V$.

This definition is, however, seldom used in applications. Instead, it is more customary to use operations with limits, the squeezing principle (if $f(x) \leq g(x) \leq h(x)$ for all $x$ and $\lim _{x \rightarrow x_{0}} f(x)=\lim _{x \rightarrow x_{0}} h(x)=L$, then $\left.\lim _{x \rightarrow x_{0}} g(x)=L\right)$, continuity, or L'Hôpital's theorem, to be discussed later.

Example. Compute

$$
\lim _{x \rightarrow \infty}(\sqrt{x+\sqrt{x+\sqrt{x}}}-\sqrt{x}) .
$$

Solution. The usual algorithm is to multiply and divide by the conjugate to obtain

$$
\begin{aligned}
& \lim _{x \rightarrow \infty}(\sqrt{x+\sqrt{x+\sqrt{x}}}-\sqrt{x})=\lim _{x \rightarrow \infty} \frac{x+\sqrt{x+\sqrt{x}}-x}{\sqrt{x+\sqrt{x+\sqrt{x}}}+\sqrt{x}} \\
& =\lim _{x \rightarrow \infty} \frac{\sqrt{x+\sqrt{x}}}{\sqrt{x+\sqrt{x+\sqrt{x}}}+\sqrt{x}}=\lim _{x \rightarrow \infty} \frac{\sqrt{1+\sqrt{\frac{1}{x}}}}{\sqrt{1+\sqrt{\frac{1}{x}+\sqrt{\frac{1}{x^{3}}}}}+1}=\frac{1}{2} .
\end{aligned}
$$

And now an example of type $1^{\infty}$.

Example. Let $a_{1}, a_{2}, \ldots, a_{n}$ be positive real numbers. Prove that

$$
\lim _{x \rightarrow 0}\left(\frac{a_{1}^{x}+a_{2}^{x}+\cdots+a_{n}^{x}}{n}\right)^{\frac{1}{x}}=\sqrt[n]{a_{1} a_{2} \cdots a_{n}} .
$$

Solution. First, note that

$$
\lim _{x \rightarrow 0} \frac{a^{x}-1}{x}=\ln a .
$$

Indeed, the left-hand side can be recognized as the derivative of the exponential at 0 . Or to avoid a logical vicious circle, we can argue as follows: let $a^{x}=1+t$, with $t \rightarrow 0$. Then $x=\frac{\ln (1+t)}{\ln a}$, and the limit becomes

$$
\lim _{t \rightarrow 0} \frac{t \ln a}{\ln (1+t)}=\lim _{t \rightarrow 0} \frac{\ln a}{\ln (1+t)^{t}}=\frac{\ln a}{\ln e}=\ln a .
$$

Let us return to the problem. Because the limit is of the form $1^{\infty}$, it is standard to write it as

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-141.jpg?height=145&width=950&top_left_y=359&top_left_x=390)

Using the fact that $\lim _{t \rightarrow 0}(1+t)^{1 / t}=e$, we find this to be equal to

$$
\begin{aligned}
\exp \left[\lim _{x \rightarrow 0}\left(\frac{a_{1}^{x}+a_{2}^{x}+\cdots+a_{n}^{x}-n}{n x}\right)\right] \\
&=\exp \left[\frac{1}{n} \lim _{x \rightarrow 0}\left(\frac{a_{1}^{x}-1}{x}+\frac{a_{2}^{x}-1}{x}+\cdots+\frac{a_{n}^{x}-1}{x}\right)\right] \\
&=\exp \left[\frac{1}{n}\left(\ln a_{1}+\ln a_{2}+\cdots+\ln a_{n}\right)\right]=\sqrt[n]{a_{1} a_{2} \cdots a_{n}},
\end{aligned}
$$

the desired answer.

We continue with a problem of theoretical flavor that requires an $\epsilon-\delta$ argument. Written by M. Becheanu it was given at a Romanian competition in 2004.

Example. Let $a \in(0,1)$ be a real number and $f: \mathbb{R} \rightarrow \mathbb{R}$ a function that satisfies the following conditions:

(i) $\lim _{x \rightarrow \infty} f(x)=0$;

(ii) $\lim _{x \rightarrow \infty} \frac{f(x)-f(a x)}{x}=0$.

Show that $\lim _{x \rightarrow \infty} \frac{f(x)}{x}=0$.

Solution. The second condition reads, for any $\epsilon>0$, there exists $\delta>0$ such that if $x \in(-\delta, \delta)$ then $|f(x)-f(a x)|<\epsilon|x|$. Applying the triangle inequality, we find that for all positive integers $n$ and all $x \in(-\delta, \delta)$,

$$
\begin{aligned}
\left|f(x)-f\left(a^{n} x\right)\right| & \leq|f(x)-f(a x)|+\left|f(a x)-f\left(a^{2} x\right)\right|+\cdots+\left|f\left(a^{n-1} x\right)-f\left(a^{n} x\right)\right| \\
&<\epsilon|x|\left(1+a+a^{2}+\cdots+a^{n-1}\right)=\epsilon \frac{1-a^{n}}{1-a}|x| \leq \frac{\epsilon}{1-a}|x| .
\end{aligned}
$$

Taking the limit as $n \rightarrow \infty$, we obtain

$$
|f(x)| \leq \frac{\epsilon}{1-a}|x| .
$$

Since $\epsilon>0$ was arbitrary, this proves that $\lim _{x \rightarrow \infty} \frac{f(x)}{x}=0$.

380. Find the real parameters $m$ and $n$ such that the graph of the function $f(x)=$ $\sqrt[3]{8 x^{3}+m x^{2}}-n x$ has the horizontal asymptote $y=1$. 

381. Does

$$
\lim _{x \rightarrow \pi / 2}(\sin x)^{\frac{1}{\cos x}}
$$

exist?

382. For two positive integers $m$ and $n$, compute

$$
\lim _{x \rightarrow 0} \frac{\sqrt[m]{\cos x}-\sqrt[n]{\cos x}}{x^{2}} .
$$

383. Does there exist a nonconstant function $f:(1, \infty) \rightarrow \mathbb{R}$ satisfying the relation $f(x)=f\left(\frac{x^{2}+1}{2}\right)$ for all $x>1$ and such that $\lim _{x \rightarrow \infty} f(x)$ exists?

384. Let $f:(0, \infty) \rightarrow(0, \infty)$ be an increasing function with $\lim _{t \rightarrow \infty} \frac{f(2 t)}{f(t)}=1$. Prove that $\lim _{t \rightarrow \infty} \frac{f(m t)}{f(t)}=1$ for any $m>0$.

385. Let $f(x)=\sum_{k=1}^{n} a_{k} \sin k x$, with $a_{1}, a_{2}, \ldots, a_{n} \in \mathbb{R}, n \geq 1$. Prove that if $f(x) \leq$ $|\sin x|$ for all $x \in \mathbb{R}$, then

$$
\left|\sum_{k=1}^{n} k a_{k}\right| \leq 1
$$

\subsubsection{Continuous Functions}

A function $f$ is continuous at $x_{0}$ if it has limit at $x_{0}$ and this limit is equal to $f\left(x_{0}\right)$. A function that is continuous at every point of its domain is simply called continuous.

Example. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying $f(0)=1$ and

$$
f(2 x)-f(x)=x, \quad \text { for all } x \in \mathbb{R} .
$$

Solution. Write the functional equation as

$$
f(x)-f\left(\frac{x}{2}\right)=\frac{x}{2} ;
$$

then iterate

$$
\begin{aligned}
& f\left(\frac{x}{2}\right)-f\left(\frac{x}{4}\right)=\frac{x}{4}, \\
& f\left(\frac{x}{4}\right)-f\left(\frac{x}{8}\right)=\frac{x}{8} \text {, } \\
& f\left(\frac{x}{2^{n-1}}\right)-f\left(\frac{x}{2^{n}}\right)=\frac{x}{2^{n}} . 
\end{aligned}
$$

Summing up, we obtain

$$
f(x)-f\left(\frac{x}{2^{n}}\right)=x\left(\frac{1}{2}+\frac{1}{4}+\cdots+\frac{1}{2^{n}}\right),
$$

which, when $n$ tends to infinity, becomes $f(x)-1=x$. Hence $f(x)=x+1$ is the (unique) solution.

We will now present the spectacular example of a continuous curve that covers a square completely. A planar curve $\phi(t)=(x(t), y(t))$ is called continuous if both coordinate functions $x(t)$ and $y(t)$ depend continuously on the parameter $t$.

Peano's theorem. There exists a continuous surjection $\phi:[0,1] \rightarrow[0,1] \times[0,1]$.

Proof. G. Peano found an example of such a function in the early twentieth century. The curve presented below was constructed later by $\mathrm{H}$. Lebesgue.

The construction of this "Peano curve"' uses the Cantor set. This is the set $C$ of all numbers in the interval $[0,1]$ that can be written in base 3 with only the digits 0 and 2. For example, $0.1$ is in $C$ because it can also be written as $0.0222 \ldots$, but $0.101$ is not. The Cantor set is obtained by removing from $[0,1]$ the interval $\left(\frac{1}{3}, \frac{2}{3}\right)$, then $\left(\frac{1}{9}, \frac{2}{9}\right)$ and $\left(\frac{7}{9}, \frac{8}{9}\right)$, then successively from each newly formed closed interval an open interval centered at its midpoint and $\frac{1}{3}$ of its size (Figure 19). The Cantor set is a fractal: each time we cut a piece of it and magnify it, the piece resembles the original set.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-143.jpg?height=50&width=1019&top_left_y=1337&top_left_x=358)

Figure 19

Next, we define a function $\phi: C \rightarrow[0,1] \times[0,1]$ in the following manner. For a number written in base 3 as $0 . a_{1} a_{2} \ldots a_{n} \ldots$ with only the digits 0 and 2 (hence in the Cantor set), divide the digits by 2 , then separate the ones in even positions from those in odd positions. Explicitly, if $b_{n}=\frac{a_{n}}{2}, n \geq 1$, construct the pair $\left(0 . b_{1} b_{3} b_{5} \ldots, 0 . b_{2} b_{4} b_{6} \ldots\right)$. This should be interpreted as a point in $[0,1] \times[0,1]$ with coordinates written in base 2. Then $\phi\left(0 . a_{1} a_{2} a_{3} a_{4} \ldots\right)=\left(0 . b_{1} b_{3} \ldots, 0 . b_{2} b_{4} \ldots\right)$. The function is clearly onto. Is it continuous?

First, what does continuity mean in this case? It means that whenever a sequence $\left(x_{n}\right)_{n}$ in $C$ converges to a point $x \in C$, the sequence $\left(\phi\left(x_{n}\right)\right)_{n}$ should converge to $\phi(x)$. Note that since the complement of $C$ is a union of open intervals, $C$ contains all its limit points. Moreover, the Cantor set has the very important property that a sequence $\left(x_{n}\right)_{n}$ of points in it converges to $x \in C$ if and only if the base-3 digits of $x_{n}$ successively become equal to the digits of $x$. It is essential that the base- 3 digits of a number in $C$ can equal only 0 or 2 , so that the ambiguity of the ternary expansion is eliminated. This fundamental property of the Cantor set guarantees the continuity of $\phi$. The function $\phi$ is extended linearly over each open interval that was removed in the process of constructing $C$, to obtain a continuous surjection $\phi:[0,1] \rightarrow[0,1] \times[0,1]$. This concludes the proof of the theorem.

To visualize this Peano curve, consider the "truncations" of the Cantor set

$$
\begin{aligned}
C_{1}=&\left\{0, \frac{1}{3}, \frac{2}{3}, 1\right\}, \quad C_{2}=\left\{0, \frac{1}{9}, \frac{2}{9}, \frac{1}{3}, \frac{2}{3}, \frac{7}{9}, \frac{8}{9}, 1\right\}, \\
C_{3}=&\left\{0, \frac{1}{27}, \frac{2}{27}, \frac{1}{9}, \frac{2}{9}, \frac{7}{27}, \frac{8}{27}, \frac{1}{3}, \frac{2}{3}, \frac{19}{27}, \frac{20}{27}, \frac{7}{9}, \frac{8}{9}, \frac{25}{27}, \frac{26}{27}, 1\right\}, \\
C_{4}=&\left\{0, \frac{1}{81}, \frac{2}{81}, \frac{1}{27}, \frac{2}{27}, \frac{7}{81}, \frac{8}{81}, \frac{1}{9}, \frac{2}{9}, \frac{19}{81}, \frac{20}{81}, \frac{7}{27}, \frac{8}{27}, \frac{25}{81}, \frac{26}{81}, \frac{1}{3}, \frac{2}{3},\right.\\
&\left.\frac{55}{81}, \frac{56}{81}, \frac{19}{27}, \frac{20}{27}, \frac{61}{81}, \frac{62}{81}, \frac{7}{9}, \frac{8}{9}, \frac{73}{81}, \frac{74}{81}, \frac{25}{27}, \frac{26}{27}, \frac{79}{81}, \frac{80}{81}, 1\right\}, \ldots,
\end{aligned}
$$

and define $\phi_{n}: C_{n} \rightarrow[0,1] \times[0,1], n \geq 1$, as above, and then extend linearly. This gives rise to the curves from Figure 20. The curve $\phi$ is their limit. It is a fractal: if we cut the unit square into four equal squares, the curve restricted to each of these squares resembles the original curve.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-144.jpg?height=226&width=226&top_left_y=1120&top_left_x=339)

$n=1$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-144.jpg?height=226&width=222&top_left_y=1120&top_left_x=614)

$n=2$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-144.jpg?height=226&width=235&top_left_y=1120&top_left_x=885)

$n=3$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-144.jpg?height=224&width=224&top_left_y=1121&top_left_x=1171)

$n=4$

Figure 20

386. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function satisfying $f(x)=f\left(x^{2}\right)$ for all $x \in \mathbb{R}$. Prove that $f$ is constant.

387. Does there exist a continuous function $f:[0,1] \rightarrow \mathbb{R}$ that assumes every element of its range an even (finite) number of times?

388. Let $f(x)$ be a continuous function defined on $[0,1]$ such that

(i) $f(0)=f(1)=0$;

(ii) $2 f(x)+f(y)=3 f\left(\frac{2 x+y}{3}\right)$ for all $x, y \in[0,1]$.

Prove that $f(x)=0$ for all $x \in[0,1]$.

389. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function with the property that

$$
\lim _{h \rightarrow 0^{+}} \frac{f(x+2 h)-f(x+h)}{h}=0, \quad \text { for all } x \in \mathbb{R} .
$$

Prove that $f$ is constant. 

390. Let $a$ and $b$ be real numbers in the interval $\left(0, \frac{1}{2}\right)$ and let $f$ be a continuous realvalued function such that

$$
f(f(x))=a f(x)+b x, \quad \text { for all } x \in \mathbb{R} .
$$

Prove that $f(0)=0$.

391. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function. Prove that the series $\sum_{n=1}^{\infty} \frac{f\left(x^{n}\right)}{2^{n}}$ is convergent for every $x \in[0,1]$. Find a function $f$ satisfying

$$
f(x)=\sum_{n=1}^{\infty} \frac{f\left(x^{n}\right)}{2^{n}}, \quad \text { for all } x \in[0,1] .
$$

392. Prove that there exists a continuous surjective function $\psi:[0,1] \rightarrow[0,1] \times[0,1]$ that takes each value infinitely many times.

393. Give an example of a continuous function on an interval that is nowhere differentiable.

\subsubsection{The Intermediate Value Property}

A real-valued function $f$ defined on an interval is said to have the intermediate value property (or the Darboux property) if for every $a<b$ in the interval and for every $\lambda$ between $f(a)$ and $f(b)$, there exists $c$ between $a$ and $b$ such that $f(c)=\lambda$. Equivalently, a real-valued function has the intermediate property if it maps intervals to intervals. The higher-dimensional analogue requires the function to map connected sets to connected sets. Continuous functions and derivatives of functions are known to have this property, although the class of functions with the intermediate value property is considerably larger.

Here is a problem from the 1982 Romanian Mathematical Olympiad, proposed by M. Chiriţă.

Example. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function with the property that $\int_{0}^{1} f(x) d x=\frac{\pi}{4}$. Prove that there exists $x_{0} \in(0,1)$ such that

$$
\frac{1}{1+x_{0}}<f\left(x_{0}\right)<\frac{1}{2 x_{0}} \text {. }
$$

Solution. Note that

$$
\int_{0}^{1} \frac{1}{1+x^{2}} d x=\frac{\pi}{4}
$$

Consequently, the integral of the function $g(x)=f(x)-\frac{1}{1+x^{2}}$ on the interval $[0,1]$ is equal to 0 . If $g(x)$ is identically 0 , choose $x_{0}$ to be any number between 0 and 1 . Otherwise, $g(x)$ assumes both positive and negative values on this interval. Being continuous, $g$ has the intermediate value property, so there is some $x_{0} \in(0,1)$ for which $g\left(x_{0}\right)=0$. We have thus found $x_{0} \in(0,1)$ such that $f\left(x_{0}\right)=\frac{1}{1+x_{0}^{2}}$. The double inequality from the statement follows from $2 x_{0}<1+x_{0}^{2}<1+x_{0}$, which clearly holds since on the one hand, $x_{0}^{2}-2 x_{0}+1=\left(x_{0}-1\right)^{2}>0$, and on the other, $x_{0}^{2}<x_{0}$.

Example. Prove that every continuous mapping of a circle into a line carries some pair of diametrically opposite points to the same point.

Solution. Yes, this problem uses the intermediate value property, or rather the more general property that the image through a continuous map of a connected set is connected. The circle is connected, so its image must be an interval. This follows from a more elementary argument, if we think of the circle as the gluing of two intervals along their endpoints. The image of each interval is another interval, and the two images overlap, determining an interval.

Identify the circle with the set $S^{1}=\{z \in \mathbb{C}|| z \mid=1\}$. If $f: S^{1} \rightarrow \mathbb{R}$ is the continuous mapping from the statement, then $\psi: S^{1} \rightarrow \mathbb{R}, \psi(z)=f(z)-f(-\bar{z})$ is also continuous (here the bar denotes the complex conjugate, and as such, $-\bar{z}$ is diametrically opposite to $z$ ).

Pick $z_{0} \in S^{1}$. If $\psi\left(z_{0}\right)=0$, then $z_{0}$ and $-\overline{z_{0}}$ map to the same point on the line. Otherwise,

$$
\psi\left(-\overline{z_{0}}\right)=f\left(-\overline{z_{0}}\right)-f(z)=-\psi\left(z_{0}\right)
$$

Hence $\psi$ takes a positive and a negative value, and by the intermediate value property it must have a zero. The property is proved.

A more difficult theorem of Borsuk and Ulam states that any continuous map of the sphere into the plane sends two antipodal points on the sphere to the same point in the plane. A nice interpretation of this fact is that at any time there are two antipodal points on earth with the same temperature and barometric pressure.

We conclude our list of examples with a surprising fact discovered by Lebesgue.

Theorem. There exists a function $f:[0,1] \rightarrow[0,1]$ that has the intermediate value property and is discontinuous at every point.

Proof. Lebesgue's function acts like an automaton. The value at a certain point is produced from information read from the digital expansion of the variable.

The automaton starts acting once it detects that all even-order digits have become 0. More precisely, if $x=0 . a_{0} a_{1} a_{2} \ldots$, the automaton starts acting once $a_{2 k}=0$ for all $k \geq n$. It then reads the odd-order digits and produces the value $f(x)=0 . a_{2 n+1} a_{2 n+3} a_{2 n+5} \ldots$. If the even-order digits do not eventually become zero, the automaton remains inactive, producing the value 0 . Because only the rightmost digits of the numbers count, for any value of $y$ and any interval $I \subset[0,1]$, one can find a number $x \in I$ such that $f(x)=y$. Hence the function $f$ maps any subinterval of $[0,1]$ onto $[0,1]$. It satisfies the intermediate value property trivially. And because any neighborhood of a point is mapped to the entire interval $[0,1]$, the function is discontinuous everywhere.

As the poet Paul Valéry said: "a dangerous state is to think that you understand." To make sure that you do understand the intermediate value property, solve the following problems.

394. Let $f:[a, b] \rightarrow[a, b]$ be a continuous function. Prove that $f$ has a fixed point.

395. One day, a Buddhist monk climbed from the valley to the temple up on the mountain. The next day, the monk came down, on the same trail and during the same time interval. Prove that there is a point on the trail that the monk reached at precisely the same moment of time on the two days.

396. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous decreasing function. Prove that the system

$$
\begin{aligned}
&x=f(y), \\
&y=f(z), \\
&z=f(x)
\end{aligned}
$$

has a unique solution.

397. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that $|f(x)-f(y)| \geq|x-y|$ for all $x, y \in \mathbb{R}$. Prove that the range of $f$ is all of $\mathbb{R}$.

398. A cross-country runner runs a six-mile course in 30 minutes. Prove that somewhere along the course the runner ran a mile in exactly 5 minutes.

399. Let $A$ and $B$ be two cities connected by two different roads. Suppose that two cars can travel from $A$ to $B$ on different roads keeping a distance that does not exceed one mile between them. Is it possible for the cars to travel the first one from $A$ to $B$ and the second one from $B$ to $A$ in such a way that the distance between them is always greater than one mile?

400. Let

$$
P(x)=\sum_{k=1}^{n} a_{k} x^{k} \quad \text { and } \quad Q(x)=\sum_{k=1}^{n} \frac{a_{k}}{2^{k}-1} x^{k},
$$

where $a_{1}, a_{2}, \ldots, a_{n}$ are real numbers, $n \geq 1$. Show that if 1 and $2^{n+1}$ are zeros of the polynomial $Q(x)$, then $P(x)$ has a positive zero less than $2^{n}$. 

401. Prove that any convex polygonal surface can be divided by two perpendicular lines into four regions of equal area.

402. Let $f: I \rightarrow \mathbb{R}$ be a function defined on an interval. Show that if $f$ has the intermediate value property and for any $y \in \mathbb{R}$ the set $f^{-1}(y)$ is closed, then $f$ is continuous.

403. Show that the function

$$
f_{a}(x)= \begin{cases}\cos \frac{1}{x} & \text { for } x \neq 0 \\ a & \text { for } x=0\end{cases}
$$

has the intermediate value property if $a \in[-1,1]$ but is the derivative of a function only if $a=0$.

\subsubsection{Derivatives and Their Applications}

A function $f$ defined in an open interval containing the point $x_{0}$ is called differentiable at $x_{0}$ if

$$
\lim _{h \rightarrow 0} \frac{f\left(x_{0}+h\right)-f\left(x_{0}\right)}{h}
$$

exists. In this case, the limit is called the derivative of $f$ at $x_{0}$ and is denoted by $f^{\prime}\left(x_{0}\right)$ or $\frac{d f}{d x}\left(x_{0}\right)$. If the derivative is defined at every point of the domain of $f$, then $f$ is simply called differentiable.

The derivative is the instantaneous rate of change. Geometrically, it is the slope of the tangent to the graph of the function. Because of this, where the derivative is positive the function is increasing, where the derivative is negative the function is decreasing, and on intervals where the derivative is zero the function is constant. Moreover, the maxima and minima of a differentiable function show up at points where the derivative is zero, the so-called critical points.

Let us present some applications of derivatives. We begin with an observation made by F. Pop during the grading of USA Mathematical Olympiad 1997 about a student's solution. The student reduced one of the problems to a certain inequality, and the question was whether this inequality is easy or difficult to prove. Here is the inequality and Pop's argument.

Example. Let $a, b, c$ be positive real numbers such that $a b c=1$. Prove that

$$
a^{2}+b^{2}+c^{2} \leq a^{3}+b^{3}+c^{3} .
$$

Solution. We prove that the function

$$
f(t)=a^{t}+b^{t}+c^{t}
$$

is increasing for $t \geq 0$. Its first derivative is

$$
f^{\prime}(t)=a^{t} \ln a+b^{t} \ln b+c^{t} \ln c,
$$

for which we can tell only that $f^{\prime}(0)=\ln a b c=\ln 1=0$. However, the second derivative is $f^{\prime \prime}(t)=a^{t} \ln ^{2} a+b^{t} \ln ^{2} b+c^{t} \ln ^{2} c$, which is clearly positive. We thus deduce that $f^{\prime}$ is increasing, and so $f^{\prime}(t) \geq f^{\prime}(0)=0$ for $t \geq 0$. Therefore, $f$ itself is increasing for $t \geq 0$, and the conclusion follows.

And now an exciting example found in D. Buşneag, I. Maftei, Themes for Mathematics Circles and Contests (Scrisul Românesc, Craiova).

Example. Prove that

$$
\left|\begin{array}{cccc}
1+a_{1} & 1 & \cdots & 1 \\
1 & 1+a_{2} & \cdots & 1 \\
\vdots & \vdots & \ddots & \vdots \\
1 & 1 & \cdots & 1+a_{n}
\end{array}\right|=a_{1} a_{2} \cdots a_{n}\left(1+\frac{1}{a_{1}}+\frac{1}{a_{2}}+\cdots+\frac{1}{a_{n}}\right) .
$$

Solution. In general, if the entries of a matrix depend in a differentiable manner on a parameter $x$,

$$
\left(\begin{array}{cccc}
a_{11}(x) & a_{12}(x) & \cdots & a_{1 n}(x) \\
a_{21}(x) & a_{22}(x) & \cdots & a_{2 n}(x) \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}(x) & a_{n 2}(x) & \cdots & a_{n n}(x)
\end{array}\right),
$$

then the determinant is a differentiable function of $x$, and its derivative is equal to

$$
\begin{aligned}
\left|\begin{array}{cccc}
a_{11}^{\prime}(x) & a_{12}^{\prime}(x) & \cdots & a_{1 n}^{\prime}(x) \\
a_{21}(x) & a_{22}(x) & \cdots & a_{2 n}(x) \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}(x) & a_{n 2}(x) & \cdots & a_{n n}(x)
\end{array}\right| &+\left|\begin{array}{cccc}
a_{11}(x) & a_{12}(x) & \cdots & a_{1 n}(x) \\
a_{21}^{\prime}(x) & a_{22}^{\prime}(x) & \cdots & a_{2 n}^{\prime}(x) \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}(x) & a_{n 2}(x) & \cdots & a_{n n}(x)
\end{array}\right|+\cdots \\
&+\left|\begin{array}{cccc}
a_{11}(x) & a_{12}(x) & \cdots & a_{1 n}(x) \\
a_{21}(x) & a_{22}(x) & \cdots & a_{2 n}(x) \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}^{\prime}(x) & a_{n 2}^{\prime}(x) & \vdots & a_{n n}^{\prime}(x)
\end{array}\right|
\end{aligned}
$$

This follows by applying the product rule to the formula of the determinant. For our problem, consider the function

$$
f(x)=\left|\begin{array}{cccc}
x+a_{1} & x & \cdots & x \\
x & x+a_{2} & \cdots & x \\
\vdots & \vdots & \ddots & \vdots \\
x & x & \cdots & x+a_{n}
\end{array}\right|
$$

Its first derivative is

$$
\begin{aligned}
& f^{\prime}(x)=\left|\begin{array}{cccc}1 & 1 & \cdots & 1 \\x & x+a_{2} & \cdots & x \\\vdots & \vdots & \ddots & \vdots \\x & x & \cdots & x+a_{n}\end{array}\right|+\left|\begin{array}{cccc}x+a_{1} & x & \cdots & x \\1 & 1 & \cdots & 1 \\\vdots & \vdots & \ddots & \vdots \\x & x & \cdots & x+a_{n}\end{array}\right|+\cdots \\
& +\left|\begin{array}{cccc}x+a_{1} & x & \cdots & x \\x & x+a_{2} & \cdots & x \\\vdots & \vdots & \ddots & \vdots \\1 & 1 & \cdots & 1\end{array}\right| .
\end{aligned}
$$

Proceeding one step further, we see that the second derivative of $f$ consists of two types of determinants: some that have a row of 0 's, and others that have two rows of 1 's. In both cases the determinants are equal to zero, showing that $f^{\prime \prime}(x)=0$. It follows that $f$ itself must be a linear function,

$$
f(x)=f(0)+f^{\prime}(0) x .
$$

One finds immediately that $f(0)=a_{1} a_{2} \cdots a_{n}$. To compute

$$
f^{\prime}(0)=\left|\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
0 & a_{2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & a_{n}
\end{array}\right|+\left|\begin{array}{cccc}
a_{1} & 0 & \cdots & 0 \\
1 & 1 & \cdots & 1 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & a_{n}
\end{array}\right|+\cdots+\left|\begin{array}{cccc}
a_{1} & 0 & \cdots & 0 \\
0 & a_{2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
1 & 1 & \cdots & 1
\end{array}\right|
$$

expand each determinant along the row of 1's. The answer is

$$
f^{\prime}(0)=a_{2} a_{3} \cdots a_{n}+a_{1} a_{3} \cdots a_{n}+\cdots+a_{1} a_{2} \cdots a_{n-1},
$$

whence

$$
f(x)=a_{1} a_{2} \cdots a_{n}\left[1+\left(\frac{1}{a_{1}}+\frac{1}{a_{2}}+\cdots+\frac{1}{a_{n}}\right) x\right] .
$$

Substituting $x=1$, we obtain the formula from the statement. 

404. For a nonzero real number $x$ prove that $e^{x}>x+1$.

405. Find all positive real solutions to the equation $2^{x}=x^{2}$.

406. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be given by $f(x)=\left(x-a_{1}\right)\left(x-a_{2}\right)+\left(x-a_{2}\right)\left(x-a_{3}\right)+(x-$ $\left.a_{3}\right)\left(x-a_{1}\right)$ with $a_{1}, a_{2}, a_{3}$ real numbers. Prove that $f(x) \geq 0$ for all real numbers $x$ if and only if $a_{1}=a_{2}=a_{3}$.

407. Determine

$$
\max _{z \in \mathbb{C},|z|=1}\left|z^{3}-z+2\right| .
$$

408. Find the minimum of the function $f: \mathbb{R} \rightarrow \mathbb{R}$,

$$
f(x)=\frac{\left(x^{2}-x+1\right)^{3}}{x^{6}-x^{3}+1} .
$$

409. How many real solutions does the equation

$$
\sin (\sin (\sin (\sin (\sin x))))=\frac{x}{3}
$$

have?

410. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function. For $x \in \mathbb{R}$ we define

$$
g(x)=f(x) \int_{0}^{x} f(t) d t .
$$

Show that if $g$ is a nonincreasing function, then $f$ is identically equal to zero.

411. Let $f$ be a function having a continuous derivative on $[0,1]$ and with the property that $0<f^{\prime}(x) \leq 1$. Also, suppose that $f(0)=0$. Prove that

$$
\left[\int_{0}^{1} f(x) d x\right]^{2} \geq \int_{0}^{1}[f(x)]^{3} d x .
$$

Give an example in which equality occurs.

412. Let $x, y, z$ be nonnegative real numbers. Prove that

(a) $(x+y+z)^{x+y+z} x^{x} y^{y} z^{z} \leq(x+y)^{x+y}(y+z)^{y+z}(z+x)^{z+x}$.

(b) $(x+y+z)^{(x+y+z)^{2}} x^{x^{2}} y^{y^{2}} z^{z^{2}} \geq(x+y)^{(x+y)^{2}}(y+z)^{(y+z)^{2}}(z+x)^{(z+x)^{2}}$.

Derivatives have an important application to the computation of limits.

L'Hôpital's rule. For an open interval I, if the functions $f$ and $g$ are differentiable on $I \backslash\left\{x_{0}\right\}, g^{\prime}(x) \neq 0$ for $x \in I, x \neq x_{0}$, and either $\lim _{x \rightarrow x_{0}} f(x)=\lim _{x \rightarrow x_{0}} g(x)=0$ or $\lim _{x \rightarrow x_{0}}|f(x)|=\lim _{x \rightarrow x_{0}}|g(x)|=\infty$, and if additionally $\lim _{x \rightarrow x_{0}} \frac{f^{\prime}(x)}{g^{\prime}(x)}$ exists, then $\lim _{x \rightarrow x_{0}} \frac{f(x)}{g(x)}$ exists and

$$
\lim _{x \rightarrow x_{0}} \frac{f(x)}{g(x)}=\lim _{x \rightarrow x_{0}} \frac{f^{\prime}(x)}{g^{\prime}(x)} .
$$

Let us see how L'Hôpital's rule is applied.

Example. Prove that if $f: \mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function with the property that $\lim _{x \rightarrow \infty} f(x)$ exists and is finite, and if $\lim _{x \rightarrow \infty} x f^{\prime}(x)$ exists, then this limit is equal to zero.

Solution. If the limit $\lim _{x \rightarrow \infty} x f^{\prime}(x)$ exists, then so does $\lim _{x \rightarrow \infty}(x f(x))^{\prime}$, and the latter is equal to $\lim _{x \rightarrow \infty} f(x)+\lim _{x \rightarrow \infty} x f^{\prime}(x)$. Applying L'Hôpital's rule yields

$$
\lim _{x \rightarrow \infty}(x f(x))^{\prime}=\lim _{x \rightarrow \infty} \frac{(x f(x))^{\prime}}{x^{\prime}}=\lim _{x \rightarrow \infty} \frac{x f(x)}{x}=\lim _{x \rightarrow \infty} f(x) .
$$

Therefore,

$$
\lim _{x \rightarrow \infty} f(x)=\lim _{x \rightarrow \infty} f(x)+\lim _{x \rightarrow \infty} x f^{\prime}(x),
$$

and it follows that $\lim _{x \rightarrow \infty} x f^{\prime}(x)=0$, as desired.

More problems follow.

413. Let $f$ and $g$ be $n$-times continuously differentiable functions in a neighborhood of a point $a$, such that $f(a)=g(a)=\alpha, f^{\prime}(a)=g^{\prime}(a), \ldots, f^{(n-1)}(a)=g^{(n-1)}(a)$, and $f^{(n)}(a) \neq g^{(n)}(a)$. Find, in terms of $\alpha$,

$$
\lim _{x \rightarrow a} \frac{e^{f(x)}-e^{g(x)}}{f(x)-g(x)} .
$$

414. For any real number $\lambda \geq 1$, denote by $f(\lambda)$ the real solution to the equation $x(1+\ln x)=\lambda$. Prove that

$$
\lim _{\lambda \rightarrow \infty} \frac{f(\lambda)}{\frac{\lambda}{\ln \lambda}}=1 .
$$

\subsubsection{The Mean Value Theorem}

In the old days, when mathematicians were searching for methods to solve polynomial equations, an essential tool was Rolle's theorem. Rolle's theorem. If $f:[a, b] \rightarrow \mathbb{R}$ is continuous on $[a, b]$, differentiable on $(a, b)$, and satisfies $f(a)=f(b)$, then there exists $c \in(a, b)$ such that $f^{\prime}(c)=0$.

Its standard use was on problems like the following.

Example. Prove that the Legendre polynomial

$$
P_{n}(x)=\frac{d^{n}}{d x^{n}}\left(x^{2}-1\right)^{n}
$$

has $n$ distinct zeros in the interval $(-1,1)$.

Solution. Consider the polynomial function $Q_{n}(x)=\left(x^{2}-1\right)^{n}$. Its zeros $x=1$ and $x=-1$ have multiplicity $n$. Therefore, for every $k<n$, the $k$ th derivative $Q_{n}^{(k)}(x)$ has 1 and $-1$ as zeros. We prove by induction on $k$ that for $1<k \leq n, Q_{n}^{(k)}(x)$ has $k$ distinct zeros in $(-1,1)$.

By Rolle's theorem this is true for $k=1$. Assume that the property is true for $k<n$, and let us prove it for $k+1$. The polynomial $Q_{n}^{(k)}(x)$ has $k+2$ zeros $x_{0}=-1<$ $x_{1}<\cdots x_{k}<x_{k+1}=1$. By Rolle's theorem, between any two consecutive zeros of the function there is a zero of the derivative $Q_{n}^{(k+1)}(x)$. Hence $Q_{n}^{(k+1)}(x)$ has $k+1$ distinct zeros between $-1$ and 1 . This completes the induction.

In particular, $Q_{n}^{(n)}(x)=P_{n}(x)$ has $n$ distinct zeros between $-1$ and 1 , as desired.

Rolle's theorem applied to the function $\phi:[a, b] \rightarrow \mathbb{R}$,

$$
\phi(x)=\left|\begin{array}{lll}
f(x) & g(x) & 1 \\
f(a) & g(a) & 1 \\
f(b) & g(b) & 1
\end{array}\right|,
$$

yields the following theorem.

Cauchy's theorem. If $f, g:[a, b] \rightarrow \mathbb{R}$ are two functions, continuous on $[a, b]$ and differentiable on $(a, b)$, then there exists a point $c \in(a, b)$ such that

$$
(f(b)-f(a)) g^{\prime}(c)=(g(b)-g(a)) f^{\prime}(c) .
$$

In the particular case $g(x)=x$, we have the following.

The mean value theorem (Lagrange). If $f:[a, b] \rightarrow \mathbb{R}$ is a function that is continuous on $[a, b]$ and differentiable on $(a, b)$, then there exists $c \in(a, b)$ such that

$$
f^{\prime}(c)=\frac{f(b)-f(a)}{b-a} .
$$

We use the mean value theorem to solve a problem of $\mathrm{D}$. Andrica. Example. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a twice-differentiable function, with positive second derivative. Prove that

$$
f\left(x+f^{\prime}(x)\right) \geq f(x),
$$

for any real number $x$.

Solution. If $x$ is such that $f^{\prime}(x)=0$, then the relation holds with equality. If for a certain $x, f^{\prime}(x)<0$, then the mean value theorem applied on the interval $\left[x+f^{\prime}(x), x\right]$ yields

$$
f(x)-f\left(x+f^{\prime}(x)\right)=f^{\prime}(c)\left(-f^{\prime}(x)\right),
$$

for some $c$ with $x+f^{\prime}(x)<c<x$. Because the second derivative is positive, $f^{\prime}$ is increasing; hence $f^{\prime}(c)<f^{\prime}(x)<0$. Therefore, $f(x)-f\left(x+f^{\prime}(x)\right)<0$, which yields the required inequality.

In the case $f^{\prime}(x)>0$, by the same argument $f\left(x+f^{\prime}(x)\right)-f(x)=f^{\prime}(x) f^{\prime}(c)$ for $c$ between $x$ and $x+f^{\prime}(x)$, and $f^{\prime}(c)>f^{\prime}(x)>0$. We obtain again $f(x)-f\left(x+f^{\prime}(x)\right)<$ 0 , as desired.

Example. Find all real solutions to the equation

$$
4^{x}+6^{x^{2}}=5^{x}+5^{x^{2}} .
$$

Solution. This problem was given at the 1984 Romanian Mathematical Olympiad, being proposed by M. Chiriţă. The solution runs as follows.

Note that $x=0$ and $x=1$ satisfy the equation from the statement. Are there other solutions? The answer is no, but to prove it we use the amazing idea of treating the numbers $4,5,6$ as variables and the presumably new solution $x$ as a constant.

Thus let us consider the function $f(t)=t^{x^{2}}+(10-t)^{x}$. The fact that $x$ satisfies the equation from the statement translates to $f(5)=f(6)$. By Rolle's theorem there exists $c \in(5,6)$, such that $f^{\prime}(c)=0$. This means that $x^{2} c^{x^{2}-1}-x(10-c)^{x-1}=0$, or

$$
x c^{x^{2}-1}=(10-c)^{x-1} .
$$

Because exponentials are positive, this implies that $x$ is positive.

If $x>1$, then $x c^{x^{2}-1}>c^{x^{2}-1}>c^{x-1}>(10-c)^{x-1}$, which is impossible since the first and the last terms in this chain of inequalities are equal. Here we used the fact that $c>5$.

If $0<x<1$, then $x c^{x^{2}-1}<x c^{x-1}$. Let us prove that $x c^{x-1}<(10-c)^{x-1}$. With the substitution $y=x-1, y \in(-1,0)$, the inequality can be rewritten as $y+1<\left(\frac{10-c}{c}\right)^{y}$. The exponential has base less than 1 , so it is decreasing, while the linear function on the left is increasing. The two meet at $y=0$. The inequality follows. Using it we conclude again that $x c^{x^{2}-1}$ cannot be equal to $(10-c)^{x-1}$. This shows that a third solution to the equation from the statement does not exist. So the only solutions to the given equation are $x=0$ and $x=1$. Below you will find a variety of problems based on the above-mentioned theorems (Rolle, Lagrange, Cauchy). Try to solve them, remembering that "good judgment comes from experience, and experience comes from bad judgment"' (Barry LePatner).

415. Prove that not all zeros of the polynomial $P(x)=x^{4}-\sqrt{7} x^{3}+4 x^{2}-\sqrt{22} x+15$ are real.

416. Let $f:[a, b] \rightarrow \mathbb{R}$ be a function, continuous on $[a, b]$ and differentiable on $(a, b)$. Prove that if there exists $c \in(a, b)$ such that

$$
\frac{f(b)-f(c)}{f(c)-f(a)}<0,
$$

then there exists $\xi \in(a, b)$ such that $f^{\prime}(\xi)=0$.

417. For $x \geq 2$ prove the inequality

$$
(x+1) \cos \frac{\pi}{x+1}-x \cos \frac{\pi}{x}>1 .
$$

418. Let $n>1$ be an integer, and let $f:[a, b] \rightarrow \mathbb{R}$ be a continuous function, $n$-times differentiable on $(a, b)$, with the property that the graph of $f$ has $n+1$ collinear points. Prove that there exists a point $c \in(a, b)$ with the property that $f^{(n)}(c)=0$.

419. Let $f:[a, b] \rightarrow \mathbb{R}$ be a function, continuous on $[a, b]$ and differentiable on $(a, b)$. Let $M(\alpha, \beta)$ be a point on the line passing through the points $(a, f(a))$ and $(b, f(b))$ with $\alpha \notin[a, b]$. Prove that there exists a line passing through $M$ that is tangent to the graph of $f$.

420. Let $f:[a, b] \rightarrow \mathbb{R}$ be a function, continuous on $[a, b]$ and twice differentiable on $(a, b)$. If $f(a)=f(b)$ and $f^{\prime}(a)=f^{\prime}(b)$, prove that for every real number $\lambda$ the equation

$$
f^{\prime \prime}(x)-\lambda\left(f^{\prime}(x)\right)^{2}=0
$$

has at least one solution in the interval $(a, b)$.

421. Prove that there are no positive numbers $x$ and $y$ such that

$$
x 2^{y}+y 2^{-x}=x+y .
$$

422. Let $\alpha$ be a real number such that $n^{\alpha}$ is an integer for every positive integer $n$. Prove that $\alpha$ is a nonnegative integer.

423. Find all real solutions to the equation

$$
6^{x}+1=8^{x}-27^{x-1} .
$$

424. Let $P(x)$ be a polynomial with real coefficients such that for every positive integer $n$, the equation $P(x)=n$ has at least one rational root. Prove that $P(x)=a x+b$ with $a$ and $b$ rational numbers. 

\subsubsection{Convex Functions}

A function is called convex if any segment with endpoints on its graph lies above the graph itself. The picture you should have in mind is Figure 21. Formally, if $D$ is an interval of the real axis, or more generally a convex subset of a vector space, then a function $f: D \rightarrow \mathbb{R}$ is called convex if

$$
f(\lambda x+(1-\lambda) y) \leq \lambda f(x)+(1-\lambda) f(y), \quad \text { for all } x, y \in D, \lambda \in(0,1) .
$$

Here we should remember that a set $D$ is called convex if for any $x, y \in D$ and $\lambda \in(0,1)$ the point $\lambda x+(1-\lambda) y$ is also in $D$, which geometrically means that $D$ is an intersection of half-spaces.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-156.jpg?height=529&width=818&top_left_y=815&top_left_x=463)

Figure 21

A function $f$ is called concave if $-f$ is convex. If $f$ is both convex and concave, then $f$ is linear, i.e., $f(x)=a x+b$ for some constants $a$ and $b$.

Proposition. A twice-differentiable function on an interval is convex if and only if its second derivative is nonnegative.

In general, a twice-differentiable function defined on a convex domain in $\mathbb{R}^{n}$ is convex if at any point its Hessian matrix is semipositive definite. This is a way of saying that modulo a local change of coordinates, around each point the function $f$ is of the form

$$
f\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\phi\left(x_{1}, x_{2}, \ldots, x_{n}\right)+x_{1}^{2}+x_{2}^{2}+\cdots+x_{k}^{2},
$$

where $k \leq n$ and $\phi\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ is linear.

As an application, we use convexity to prove Hölder's inequality.

Hölder's inequality. If $x_{1}, x_{2}, \ldots, x_{n}, y_{1}, y_{2}, \ldots, y_{n}, p$, and $q$ are positive numbers with $\frac{1}{p}+\frac{1}{q}=1$, then 

$$
\sum_{i=1}^{n} x_{i} y_{i} \leq\left(\sum_{i=1}^{n} x_{i}^{p}\right)^{1 / p}\left(\sum_{i=1}^{n} y_{i}^{q}\right)^{1 / q}
$$

with equality if and only if the two vectors $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ and $\left(y_{1}, y_{2}, \ldots, y_{n}\right)$ are parallel.

Proof. The second derivative of $f:(0, \infty) \rightarrow \mathbb{R}, f(x)=\ln x$, is $f^{\prime \prime}(x)=-\frac{1}{x^{2}}$, which is negative. So this function is concave. Setting $\lambda=\frac{1}{p}$, we obtain

$$
\ln X^{1 / p} Y^{1 / q}=\frac{1}{p} \ln X+\frac{1}{q} \ln Y \leq \ln \left(\frac{1}{p} X+\frac{1}{q} Y\right), \quad \text { for all } X, Y>0
$$

hence

$$
X^{1 / p} Y^{1 / q} \leq \frac{1}{p} X+\frac{1}{q} Y .
$$

Using this fact, if we let $X=\sum_{i} x_{i}^{p}$ and $Y=\sum_{i} y_{i}^{q}$, then

$$
\begin{aligned}
\frac{1}{X^{1 / p} Y^{1 / q}} \sum_{i=1}^{n} x_{i} y_{i} &=\sum_{i=1}^{n}\left(\frac{x_{i}^{p}}{X}\right)^{1 / p}\left(\frac{y_{i}^{q}}{Y}\right)^{1 / q} \leq \sum_{i=1}^{n}\left(\frac{1}{p} \cdot \frac{x_{i}^{p}}{X}+\frac{1}{q} \cdot \frac{y_{i}^{q}}{Y}\right) \\
&=\left(\frac{1}{p}+\frac{1}{q}\right)=1 .
\end{aligned}
$$

Hence

$$
\sum_{i=1}^{n} x_{i} y_{i} \leq X^{1 / p} Y^{1 / q}=\left(\sum_{i=1}^{n} x_{i}^{p}\right)^{1 / p}\left(\sum_{i=1}^{n} y_{i}^{q}\right)^{1 / q}
$$

and the inequality is proved.

By analogy, a sequence $\left(a_{n}\right)_{n \geq 0}$ is called convex if

$$
a_{n} \leq \frac{a_{n+1}+a_{n-1}}{2}, \quad \text { for all } n \geq 1,
$$

and concave if $\left(-a_{n}\right)_{n}$ is convex. Equivalently, a sequence is convex if its second difference (derivative) is nonnegative, and concave if its second difference is nonpositive. The following example motivates why convex sequences and functions should be studied together.

Example. Let $\left(a_{n}\right)_{n}$ be a bounded convex sequence. Prove that

$$
\lim _{n \rightarrow \infty}\left(a_{n+1}-a_{n}\right)=0
$$

Solution. A bounded convex function on $(0, \infty)$ has a horizontal asymptote, so its derivative tends to zero at infinity. Our problem is the discrete version of this result. The first derivative of the sequence is $b_{n}=a_{n+1}-a_{n}, n \geq 1$. The convexity condition can be written as $a_{n+1}-a_{n} \geq a_{n}-a_{n-1}$, which shows that $\left(b_{n}\right)_{n}$ is increasing. Since $\left(a_{n}\right)_{n}$ is bounded, $\left(b_{n}\right)_{n}$ is bounded too, and being monotonic, by the Weierstrass theorem it converges at a finite limit $L$. If $L>0$, then $b_{n}$ eventually becomes positive, so $a_{n}$ becomes increasing because it has a positive derivative. Again by the Weierstrass theorem, $a_{n}$ converges to some limit $l$, and then $L=l-l=0$, a contradiction. A similar argument rules out the case $L<0$. We are left with the only possibility $L=0$.

And now some problems.

425. Let $x_{1}, x_{2}, \ldots, x_{n}$ be real numbers. Find the real numbers $a$ that minimize the expression

$$
\left|a-x_{1}\right|+\left|a-x_{2}\right|+\cdots+\left|a-x_{n}\right| .
$$

426. Let $a, b>0$ and $x, c>1$. Prove that

$$
x^{a^{c}}+x^{b^{c}} \geq 2 x^{(a b)^{c / 2}} \text {. }
$$

427. A triangle has side lengths $a \geq b \geq c$ and vertices of measures $A, B$, and $C$, respectively. Prove that

$$
A b+B c+C a \geq A c+B a+C b .
$$

428. Show that if a function $f:[a, b] \rightarrow \mathbb{R}$ is convex, then it is continuous on $(a, b)$.

429. Prove that a continuous function defined on a convex domain (for example, on an interval of the real axis) is convex if and only if

$$
f\left(\frac{x+y}{2}\right) \leq \frac{f(x)+f(y)}{2}, \quad \text { for all } x, y \in D .
$$

430. Call a real-valued function very convex if

$$
\frac{f(x)+f(y)}{2} \geq f\left(\frac{x+y}{2}\right)+|x-y|
$$

holds for all real numbers $x$ and $y$. Prove that no very convex function exists.

431. Let $f:[a, b] \rightarrow \mathbb{R}$ be a convex function. Prove that

$$
\begin{aligned}
f(x) &+f(y)+f(z)+3 f\left(\frac{x+y+z}{3}\right) \\
& \geq 2\left[f\left(\frac{x+y}{2}\right)+f\left(\frac{y+z}{2}\right)+f\left(\frac{z+x}{2}\right)\right],
\end{aligned}
$$

for all $x, y, z \in[a, b]$. 

432. Prove that if a sequence of positive real numbers $\left(b_{n}\right)_{n}$ has the property that $\left(a^{n} b_{n}\right)_{n}$ is a convex sequence for all real numbers $a$, then the sequence $\left(\ln b_{n}\right)_{n}$ is also convex.

433. Find the largest constant $C$ such that for every $n \geq 3$ and every positive concave sequence $\left(a_{k}\right)_{k=1}^{n}$,

$$
\left(\sum_{k=1}^{n} a_{k}\right)^{2} \geq C(n-1) \sum_{k=1}^{n} a_{k}^{2} .
$$

A convex function on a closed interval attains its maximum at an endpoint of the interval. We illustrate how this fact can be useful with a problem from Timişoara Mathematics Gazette, proposed by V. Cârtoaje and M. Lascu.

Example. Let $a, b, c, d \in[1,3]$. Prove that

$$
(a+b+c+d)^{2} \geq 3\left(a^{2}+b^{2}+c^{2}+d^{2}\right) .
$$

Solution. Divide by 2 and move everything to one side to obtain the equivalent inequality

$$
a^{2}+b^{2}+c^{2}+d^{2}-2 a b-2 a c-2 a d-2 b c-2 b d-2 c d \leq 0 .
$$

Now we recognize the expression on the left to be a convex function in each variable. So the maximum is attained for some choice of $a, b, c, d=1$ or 3 . If $k$ of these numbers are equal to 3 , and $4-k$ are equal to 1 , where $k$ could be $1,2,3$, or 4 , then the original inequality becomes

$$
(3 k+4-k)^{2}=3(9 k+4-k) .
$$

Dividing by 3 , we obtain $k^{2}+4 k+4 \geq 6 k+3$, or $(k-1)^{2} \geq 0$, which is clearly true. The inequality is proved. Equality occurs when one of the numbers $a, b, c, d$ is equal to 3 and the other three are equal to 1 .

Here are additional problems of this kind.

434. Let $\alpha, \beta$, and $\gamma$ be three fixed positive numbers and $[a, b]$ a given interval. Find $x, y, z$ in $[a, b]$ for which the expression

$$
E(x, y, z)=\alpha(x-y)^{2}+\beta(y-z)^{2}+\gamma(z-x)^{2}
$$

has maximal value.

435. Let $0<a<b$ and $t_{i} \geq 0, i=1,2, \ldots, n$. Prove that for any $x_{1}, x_{2}, \ldots, x_{n} \in$ $[a, b]$

$$
\left(\sum_{i=1}^{n} t_{i} x_{i}\right)\left(\sum_{i=1}^{n} \frac{t_{i}}{x_{i}}\right) \leq \frac{(a+b)^{2}}{4 a b}\left(\sum_{i=1}^{n} t_{i}\right)^{2} .
$$

436. Prove that for any natural number $n \geq 2$ and any $|x| \leq 1$,

$$
(1+x)^{n}+(1-x)^{n} \leq 2^{n} .
$$

437. Prove that for any positive real numbers $a, b, c$ the following inequality holds

$$
\frac{a+b+c}{3}-\sqrt[3]{a b c} \leq \max \left\{(\sqrt{a}-\sqrt{b})^{2},(\sqrt{b}-\sqrt{c})^{2},(\sqrt{c}-\sqrt{a})^{2}\right\} .
$$

438. Let $f$ be a real-valued continuous function on $\mathbb{R}$ satisfying

$$
f(x) \leq \frac{1}{2 h} \int_{x-h}^{x+h} f(y) d y, \quad \text { for all } x \in \mathbb{R} \text { and } h>0 .
$$

Prove that (a) the maximum of $f$ on any closed interval is assumed at one of the endpoints, and (b) the function $f$ is convex.

An important property of convex (respectively, concave) functions is known as Jensen's inequality.

Jensen's inequality. For a convex function $f$ let $x_{1}, x_{2}, \ldots, x_{n}$ be points in its domain and let $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ be positive numbers with $\lambda_{1}+\lambda_{2}+\cdots+\lambda_{n}=1$. Then

$$
f\left(\lambda_{1} x_{1}+\lambda_{2} x_{2}+\cdots+\lambda_{n} x_{n}\right) \leq \lambda_{1} f\left(x_{1}\right)+\lambda_{2} f\left(x_{2}\right)+\cdots+\lambda_{n} f\left(x_{n}\right) .
$$

If $f$ is nowhere linear and the $x_{i}$ 's are not all equal, then the inequality is strict. The inequality is reversed for a concave function.

Proof. The proof is by induction on $n$. The base case is the definition of convexity. Let us assume that the inequality is true for any $n-1$ points $x_{i}$ and any $n-1$ weights $\lambda_{i}$. Consider $n$ points and weights, and let $\lambda=\lambda_{1}+\cdots+\lambda_{n-1}$. Note that $\lambda+\lambda_{n}=1$ and $\frac{\lambda_{1}}{\lambda}+\frac{\lambda_{2}}{\lambda}+\cdots+\frac{\lambda_{n-1}}{\lambda}=1$. Using the base case and the inductive hypothesis we can write

$$
\begin{aligned}
f\left(\lambda_{1} x_{1}+\cdots+\lambda_{n-1} x_{n-1}+\lambda_{n} x_{n}\right) &=f\left(\lambda\left(\frac{\lambda_{1}}{\lambda} x_{1}+\cdots+\frac{\lambda_{n-1}}{\lambda} x_{n-1}\right)+\lambda_{n} x_{n}\right) \\
& \leq \lambda f\left(\frac{\lambda_{1}}{\lambda} x_{1}+\cdots+\frac{\lambda_{n-1}}{\lambda} x_{n-1}\right)+\lambda_{n} f\left(x_{n}\right) \\
& \leq \lambda\left(\frac{\lambda_{1}}{\lambda} f\left(x_{1}\right)+\cdots+\frac{\lambda_{n-1}}{\lambda} f\left(x_{n-1}\right)\right)+\lambda_{n} f\left(x_{n}\right) \\
&=\lambda_{1} f\left(x_{1}\right)+\cdots+\lambda_{n-1} f\left(x_{n-1}\right)+\lambda_{n} f\left(x_{n}\right),
\end{aligned}
$$

as desired. For the case of concave functions, reverse the inequalities.

As an application, we prove the following. The generalized mean inequality. Given the positive numbers $x_{1}, x_{2}, \ldots, x_{n}$ and the positive weights $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ with $\lambda_{1}+\lambda_{2}+\cdots+\lambda_{n}=1$, the following inequality holds:

$$
\lambda_{1} x_{1}+\lambda_{2} x_{2}+\cdots+\lambda_{n} x_{n} \geq x_{1}^{\lambda_{1}} x_{2}^{\lambda_{2}} \cdots x_{n}^{\lambda_{n}} .
$$

Solution. Simply write Jensen's inequality for the concave function $f(x)=\ln x$, then exponentiate.

For $\lambda_{1}=\lambda_{2}=\cdots=\lambda_{n}=\frac{1}{n}$ one obtains the AM-GM inequality.

439. Show that if $A, B, C$ are the angles of a triangle, then

$$
\sin A+\sin B+\sin C \geq \frac{3 \sqrt{3}}{2} .
$$

440. Let $a_{i}, i=1,2, \ldots, n$, be nonnegative numbers with $\sum_{i=1}^{n} a_{i}=1$, and let $0<x_{i} \leq 1, i=1,2, \ldots, n$. Prove that

$$
\sum_{i=1}^{n} \frac{a_{i}}{1+x_{i}} \leq \frac{1}{1+x_{1}^{a_{1}} x_{2}^{a_{2}} \cdots x_{n}^{a_{n}}} .
$$

441. Prove that for any three positive real numbers $a_{1}, a_{2}, a_{3}$,

$$
\frac{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}{a_{1}^{3}+a_{2}^{3}+a_{3}^{3}} \geq \frac{a_{1}^{3}+a_{2}^{3}+a_{3}^{3}}{a_{1}^{4}+a_{2}^{4}+a_{3}^{4}} .
$$

442. Let $0<x_{i}<\pi, i=1,2, \ldots, n$, and set $x=\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}$. Prove that

$$
\prod_{i=1}^{n}\left(\frac{\sin x_{i}}{x_{i}}\right) \leq\left(\frac{\sin x}{x}\right)^{n} .
$$

443. Let $n>1$ and $x_{1}, x_{2}, \ldots, x_{n}>0$ be such that $x_{1}+x_{2}+\cdots+x_{n}=1$. Prove that

$$
\frac{x_{1}}{\sqrt{1-x_{1}}}+\frac{x_{2}}{\sqrt{1-x_{2}}}+\cdots+\frac{x_{n}}{\sqrt{1-x_{n}}} \geq \frac{\sqrt{x_{1}}+\sqrt{x_{2}}+\cdots+\sqrt{x_{n}}}{\sqrt{n-1}} .
$$

\subsubsection{Indefinite Integrals}

"Anyone who stops learning is old, whether at twenty or eighty. Anyone who keeps learning stays young. The greatest thing in life is to keep your mind young." Following this advice of Henry Ford, let us teach you some clever tricks for computing indefinite integrals. We begin by recalling the basic facts about indefinite integrals. Integration is the inverse operation to differentiation. The fundamental methods for computing integrals are the backward application of the chain rule, which takes the form

$$
\int f(u(x)) u^{\prime}(x) d x=\int f(u) d u
$$

and shows up in the guise of the first and second substitutions, and integration by parts

$$
\int u d v=u v-\int v d u,
$$

which comes from the product rule for derivatives. Otherwise, there is Jacobi's partial fraction decomposition method for computing integrals of rational functions, as well as standard substitutions such as the trigonometric and Euler's substitutions.

Now let us turn to our nonstandard examples.

Example. Compute

$$
I_{1}=\int \frac{\sin x}{\sin x+\cos x} d x \quad \text { and } \quad I_{2}=\int \frac{\cos x}{\sin x+\cos x} d x .
$$

Solution. The well-known approach is to use the substitution $\tan \frac{x}{2}=t$. But it is much simpler to write the system

$$
\begin{aligned}
I_{1}+I_{2} &=\int \frac{\sin x+\cos x}{\sin x+\cos x} d x=\int 1 d x=x+C_{1}, \\
-I_{1}+I_{2} &=\int \frac{\cos x-\sin x}{\sin x+\cos x} d x=\ln (\sin x+\cos x)+C_{2},
\end{aligned}
$$

and then solve to obtain

$$
I_{1}=\frac{1}{2} x-\frac{1}{2} \ln (\sin x+\cos x)+C_{1}^{\prime} \quad \text { and } \quad I_{2}=\frac{1}{2} x+\frac{1}{2} \ln (\sin x+\cos x)+C_{2}^{\prime} .
$$

We continue with a more difficult computation based on a substitution.

Example. For $a>0$ compute the integral

$$
\int \frac{1}{x \sqrt{x^{2 a}+x^{a}+1}} d x, \quad x>0 .
$$

Solution. Factor an $x^{2 a}$ under the square root to transform the integral into

$$
\int \frac{1}{x^{a+1} \sqrt{1+\frac{1}{x^{a}}+\frac{1}{x^{2 a}}}} d x=\int \frac{1}{\sqrt{\left(\frac{1}{x^{a}}+\frac{1}{2}\right)^{2}+\frac{3}{4}}} \cdot \frac{1}{x^{a+1}} d x .
$$

With the substitution $u=\frac{1}{x^{a}}+\frac{1}{2}$ the integral becomes

$$
\begin{aligned}
-\frac{1}{a} \int \frac{1}{\sqrt{u^{2}+\frac{3}{4}}} d u &=-\frac{1}{a} \ln \left(u+\sqrt{u^{2}+\frac{3}{4}}\right)+C \\
&=-\frac{1}{a} \ln \left(\frac{1}{x^{a}}+\frac{1}{2}+\sqrt{\frac{1}{x^{2 a}}+\frac{1}{x^{a}}+1}\right)+C .
\end{aligned}
$$

444. Compute the integral

$$
\int\left(1+2 x^{2}\right) e^{x^{2}} d x
$$

445. Compute

446. Find

$$
\int \frac{x+\sin x-\cos x-1}{x+e^{x}+\sin x} d x .
$$

$$
\int\left(x^{6}+x^{3}\right) \sqrt[3]{x^{3}+2} d x
$$

447. Compute the integral

$$
\int \frac{x^{2}+1}{x^{4}-x^{2}+1} d x
$$

448. Compute

$$
\int \sqrt{\frac{e^{x}-1}{e^{x}+1}} d x, \quad x>0 .
$$

449. Find the antiderivatives of the function $f:[0,2] \rightarrow \mathbb{R}$,

$$
f(x)=\sqrt{x^{3}+2-2 \sqrt{x^{3}+1}}+\sqrt{x^{3}+10-6 \sqrt{x^{3}+1}} .
$$

450. For a positive integer $n$, compute the integral

$$
\int \frac{x^{n}}{1+x+\frac{x^{2}}{2 !}+\cdots+\frac{x^{n}}{n !}} d x
$$

451. Compute the integral

$$
\int \frac{d x}{\left(1-x^{2}\right) \sqrt[4]{2 x^{2}-1}}
$$

452. Compute

$$
\int \frac{x^{4}+1}{x^{6}+1} d x .
$$

Give the answer in the form $\alpha \arctan \frac{P(x)}{Q(x)}+C, \alpha \in \mathbb{Q}$, and $P(x), Q(x) \in \mathbb{Z}[x]$. 

\subsubsection{Definite Integrals}

Next, definite integrals. Here the limits of integration also play a role.

Example. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function. Prove that

$$
\int_{0}^{\pi} x f(\sin x) d x=\pi \int_{0}^{\frac{\pi}{2}} f(\sin x) d x .
$$

Solution. We have

$$
\int_{0}^{\pi} x f(\sin x) d x=\int_{0}^{\frac{\pi}{2}} x f(\sin x) d x+\int_{\frac{\pi}{2}}^{\pi} x f(\sin x) d x .
$$

We would like to transform both integrals on the right into the same integral, and for that we need a substitution in the second integral that changes the limits of integration. This substitution should leave $f(\sin x)$ invariant, so it is natural to try $t=\pi-x$. The integral becomes

$$
\int_{0}^{\frac{\pi}{2}}(\pi-t) f(\sin t) d t .
$$

Adding the two, we obtain $\pi \int_{0}^{\frac{\pi}{2}} f(\sin x) d x$, as desired.

453. Compute the integral

$$
\int_{-1}^{1} \frac{\sqrt[3]{x}}{\sqrt[3]{1-x}+\sqrt[3]{1+x}} d x
$$

454. Compute

$$
\int_{0}^{\pi} \frac{x \sin x}{1+\sin ^{2} x} d x .
$$

455. Let $a$ and $b$ be positive real numbers. Compute

$$
\int_{a}^{b} \frac{e^{\frac{x}{a}}-e^{\frac{b}{x}}}{x} d x .
$$

456. Compute the integral

$$
I=\int_{0}^{1} \sqrt[3]{2 x^{3}-3 x^{2}-x+1} d x
$$

457. Compute the integral

$$
\int_{0}^{a} \frac{d x}{x+\sqrt{a^{2}-x^{2}}} \quad(a>0) .
$$

458. Compute the integral

$$
\int_{0}^{\frac{\pi}{4}} \ln (1+\tan x) d x
$$

459. Find

$$
\int_{0}^{1} \frac{\ln (1+x)}{1+x^{2}} d x
$$

460. Compute

$$
\int_{0}^{\infty} \frac{\ln x}{x^{2}+a^{2}} d x,
$$

where $a$ is a positive constant.

461. Compute the integral

$$
\int_{0}^{\frac{\pi}{2}} \frac{x \cos x-\sin x}{x^{2}+\sin ^{2} x} d x
$$

462. Let $\alpha$ be a real number. Compute the integral

$$
I(\alpha)=\int_{-1}^{1} \frac{\sin \alpha d x}{1-2 x \cos \alpha+x^{2}} .
$$

463. Give an example of a function $f:(2, \infty) \rightarrow(0, \infty)$ with the property that

$$
\int_{2}^{\infty} f^{p}(x) d x
$$

is finite if and only if $p \in[2, \infty)$.

There are special types of integrals that are computed recursively. We illustrate this with a proof of the Leibniz formula.

\section{The Leibniz formula.}

$$
\frac{\pi}{4}=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots .
$$

Proof. To prove the formula we start by computing recursively the integral

$$
I_{n}=\int_{0}^{\frac{\pi}{4}} \tan ^{2 n} x d x, \quad n \geq 1 .
$$

We have

$$
\begin{aligned}
I_{n} &=\int_{0}^{\frac{\pi}{4}} \tan ^{2 n} x d x=\int_{0}^{\frac{\pi}{4}} \tan ^{2 n-2} x \tan ^{2} x d x \\
&=\int_{0}^{\frac{\pi}{4}} \tan ^{2 n-2} x\left(1+\tan ^{2} x\right) d x-\int_{0}^{\frac{\pi}{4}} \tan ^{2 n-2} x d x \\
&=\int_{0}^{\frac{\pi}{4}} \tan ^{2 n-2} x \sec ^{2} x d x+I_{n-1} .
\end{aligned}
$$

The remaining integral can be computed using the substitution $\tan x=t$. In the end, we obtain the recurrence

$$
I_{n}=\frac{1}{2 n-1}-I_{n-1}, \quad n \geq 1 .
$$

So for $n \geq 1$,

$$
I_{n}=\frac{1}{2 n-1}-\frac{1}{2 n-3}+\cdots+\frac{(-1)^{n-2}}{3}+(-1)^{n-1} I_{1},
$$

with

$$
I_{1}=\int_{0}^{\frac{\pi}{4}} \tan ^{2} x d x=\int_{0}^{\frac{\pi}{4}} \sec ^{2} x d x-\int_{0}^{\frac{\pi}{4}} 1 d x=\left.\tan x\right|_{0} ^{\frac{\pi}{4}}-\frac{\pi}{4}=1-\frac{\pi}{4} .
$$

We find that

$$
I_{n}=\frac{1}{2 n-1}-\frac{1}{2 n-3}+\cdots+\frac{(-1)^{n-2}}{3}+(-1)^{n-1}+(-1)^{n} \frac{\pi}{4} .
$$

Because $\tan ^{2 n} x \rightarrow 0$ as $n \rightarrow \infty$ uniformly on any interval of the form [0,a), $a<\frac{\pi}{4}$, it follows that $\lim _{n \rightarrow \infty} I_{n}=0$. The Leibniz formula follows.

Below are more examples of this kind.

464. Let $P(x)$ be a polynomial with real coefficients. Prove that

$$
\int_{0}^{\infty} e^{-x} P(x) d x=P(0)+P^{\prime}(0)+P^{\prime \prime}(0)+\cdots .
$$

465. Let $n \geq 0$ be an integer. Compute the integral

$$
\int_{0}^{\pi} \frac{1-\cos n x}{1-\cos x} d x .
$$

466. Compute the integral

$$
I_{n}=\int_{0}^{\frac{\pi}{2}} \sin ^{n} x d x .
$$

Use the answer to prove the Wallis formula

$$
\lim _{n \rightarrow \infty}\left[\frac{2 \cdot 4 \cdot 6 \cdots 2 n}{1 \cdot 3 \cdot 5 \cdots(2 n-1)}\right]^{2} \cdot \frac{1}{n}=\pi
$$

467. Compute

$$
\int_{-\pi}^{\pi} \frac{\sin n x}{\left(1+2^{x}\right) \sin x} d x, \quad n \geq 0 .
$$

\subsubsection{Riemann Sums}

The definite integral of a function is the area under the graph of the function. In approximating the area under the graph by a family of rectangles, the sum of the areas of the rectangles, called a Riemann sum, approximates the integral. When these rectangles have equal width, the approximation of the integral by Riemann sums reads

$$
\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{i=1}^{n} f\left(\xi_{i}\right)=\int_{a}^{b} f(x) d x
$$

where each $\xi_{i}$ is a number in the interval $\left[a+\frac{i-1}{n}(b-a), a+\frac{i}{n}(b-a)\right]$.

Since the Riemann sum depends on the positive integer $n$, it can be thought of as the term of a sequence. Sometimes the terms of a sequence can be recognized as the Riemann sums of a function, and this can prove helpful for finding the limit of the sequence. Let us show how this works, following Hilbert's advice: "always start with an easy example."

Example. Compute the limit

$$
\lim _{n \rightarrow \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2 n}\right) .
$$

Solution. If we rewrite

$$
\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2 n}
$$

as

$$
\frac{1}{n}\left[\frac{1}{1+\frac{1}{n}}+\frac{1}{1+\frac{2}{n}}+\cdots+\frac{1}{1+\frac{n}{n}}\right]
$$

we recognize the Riemann sum of the function $f:[0,1] \rightarrow \mathbb{R}, f(x)=\frac{1}{1+x}$ associated to the subdivision $x_{0}=0<x_{1}=\frac{1}{n}<x_{2}=\frac{2}{n}<\cdots<x_{n}=\frac{n}{n}=1$, with the intermediate points $\xi_{i}=\frac{i}{n} \in\left[x_{i}, x_{i+1}\right]$. It follows that

$$
\lim _{n \rightarrow \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2 n}\right)=\int_{0}^{1} \frac{1}{1+x}=\left.\ln (1+x)\right|_{0} ^{1}=\ln 2
$$

and the problem is solved.

We continue with a beautiful example from the book of G. Pólya, G. Szegő, Aufgaben und Lehrsätze aus der Analysis (Springer-Verlag, 1964).

Example. Denote by $G_{n}$ the geometric mean of the binomial coefficients

$$
\left(\begin{array}{l}
n \\
0
\end{array}\right),\left(\begin{array}{l}
n \\
1
\end{array}\right), \ldots,\left(\begin{array}{l}
n \\
n
\end{array}\right)
$$

Prove that

$$
\lim _{n \rightarrow \infty} \sqrt[n]{G_{n}}=\sqrt{e}
$$

Solution. We have

$$
\begin{aligned}
\left(\begin{array}{l}
n \\
0
\end{array}\right)\left(\begin{array}{l}
n \\
1
\end{array}\right) \cdots\left(\begin{array}{l}
n \\
n
\end{array}\right) &=\prod_{k=0}^{n} \frac{n !}{k !(n-k) !}=\frac{(n !)^{n+1}}{(1 ! 2 ! \cdots n !)^{2}} \\
&=\prod_{k=1}^{n}(n+1-k)^{n+1-2 k}=\prod_{k=1}^{n}\left(\frac{n+1-k}{n+1}\right)^{n+1-2 k}
\end{aligned} .
$$

The last equality is explained by $\sum_{k=1}^{n}(n+1-2 k)=0$, which shows that the denominator is just $(n+1)^{0}=1$. Therefore,

$$
G_{n}=\sqrt[n+1]{\left(\begin{array}{l}
n \\
0
\end{array}\right)\left(\begin{array}{l}
n \\
1
\end{array}\right) \cdots\left(\begin{array}{l}
n \\
n
\end{array}\right)}=\prod_{k=1}^{n}\left(1-\frac{k}{n+1}\right)^{1-\frac{2 k}{n+1}}
$$

Taking the natural logarithm, we obtain

$$
\frac{1}{n} \ln G_{n}=\frac{1}{n} \sum_{k=1}^{n}\left(1-\frac{2 k}{n+1}\right) \ln \left(1-\frac{k}{n+1}\right) \text {. }
$$

This is just a Riemann sum of the function $(1-2 x) \ln (1-x)$ over the interval $[0,1]$. Passing to the limit, we obtain

$$
\lim _{n \rightarrow \infty} \frac{1}{n} \ln G_{n}=\int_{0}^{1}(1-2 x) \ln (1-x) d x .
$$

The integral is computed by parts as follows:

$$
\begin{aligned}
&\int_{0}^{1}(1-2 x) \ln (1-x) d x \\
&\quad=2 \int_{0}^{1}(1-x) \ln (1-x) d x-\int_{0}^{1} \ln (1-x) d x \\
&\quad=-\left.(1-x)^{2} \ln (1-x)\right|_{0} ^{1}-2 \int_{0}^{1} \frac{(1-x)^{2}}{2} \cdot \frac{1}{1-x} d x+\left.(1-x) \ln (1-x)\right|_{0} ^{1}+\left.x\right|_{0} ^{1} \\
&\quad=-\int_{0}^{1}(1-x) d x+1=\frac{1}{2} .
\end{aligned}
$$

Exponentiating back, we obtain $\lim _{n \rightarrow \infty} \sqrt[n]{G_{n}}=\sqrt{e}$.

468. Compute

$$
\lim _{n \rightarrow \infty}\left[\frac{1}{\sqrt{4 n^{2}-1^{2}}}+\frac{1}{\sqrt{4 n^{2}-2^{2}}}+\cdots+\frac{1}{\sqrt{4 n^{2}-n^{2}}}\right] .
$$

469. Prove that for $n \geq 1$,

$$
\frac{1}{\sqrt{2+5 n}}+\frac{1}{\sqrt{4+5 n}}+\frac{1}{\sqrt{6+5 n}}+\cdots+\frac{1}{\sqrt{2 n+5 n}}<\sqrt{7 n}-\sqrt{5 n}
$$

470. Compute

$$
\lim _{n \rightarrow \infty}\left(\frac{2^{1 / n}}{n+1}+\frac{2^{2 / n}}{n+\frac{1}{2}}+\cdots+\frac{2^{n / n}}{n+\frac{1}{n}}\right) .
$$

471. Compute the integral

$$
\int_{0}^{\pi} \ln \left(1-2 a \cos x+a^{2}\right) d x .
$$

472. Find all continuous functions $f: \mathbb{R} \rightarrow[1, \infty)$ for which there exist $a \in \mathbb{R}$ and $k$ a positive integer such that

$$
f(x) f(2 x) \cdots f(n x) \leq a n^{k},
$$

for every real number $x$ and positive integer $n$. 

\subsubsection{Inequalities for Integrals}

A very simple inequality states that if $f:[a, b] \rightarrow \mathbb{R}$ is a nonnegative continuous function, then

$$
\int_{a}^{b} f(x) d x \geq 0,
$$

with equality if and only if $f$ is identically equal to zero. Easy as this inequality looks, its applications are often tricky. This is the case with a problem from the 1982 Romanian Mathematical Olympiad, proposed by the second author of the book.

Example. Find all continuous functions $f:[0,1] \rightarrow \mathbb{R}$ satisfying

$$
\int_{0}^{1} f(x) d x=\frac{1}{3}+\int_{0}^{1} f^{2}\left(x^{2}\right) d x .
$$

Solution. First, we would like the functions in both integrals to have the same variable. A substitution in the first integral changes it to $\int_{0}^{1} f\left(x^{2}\right) 2 x d x$. Next, we would like to express the number $\frac{1}{3}$ as an integral, and it is natural to choose $\int_{0}^{1} x^{2} d x$. The condition from the statement becomes

$$
\int_{0}^{1} 2 x f\left(x^{2}\right) d x=\int_{0}^{1} x^{2}+\int_{0}^{1} f^{2}\left(x^{2}\right) d x .
$$

This is the same as

$$
\int_{0}^{1}\left[f^{2}\left(x^{2}\right)-2 x f\left(x^{2}\right)+x^{2}\right] d x=0 .
$$

Note that the function under the integral, $f^{2}\left(x^{2}\right)-2 x f\left(x^{2}\right)+x^{2}=\left(f\left(x^{2}\right)-x\right)^{2}$, is a perfect square, so it is nonnegative. Therefore, its integral on $[0,1]$ is nonnegative, and it can equal zero only if the function itself is identically zero. We find that $f\left(x^{2}\right)=x$. So $f(x)=\sqrt{x}$ is the unique function satisfying the condition from the statement.

473. Determine the continuous functions $f:[0,1] \rightarrow \mathbb{R}$ that satisfy

$$
\int_{0}^{1} f(x)(x-f(x)) d x=\frac{1}{12} \text {. }
$$

474. Let $n$ be an odd integer greater than 1. Determine all continuous functions $f$ : $[0,1] \rightarrow \mathbb{R}$ such that

$$
\int_{0}^{1}\left(f\left(x^{\frac{1}{k}}\right)\right)^{n-k} d x=\frac{k}{n}, \quad k=1,2, \ldots, n-1 .
$$

475. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function such that

$$
\int_{0}^{1} f(x) d x=\int_{0}^{1} x f(x) d x=1 .
$$

Prove that

$$
\int_{0}^{1} f^{2}(x) d x \geq 4 .
$$

476. For each continuous function $f:[0,1] \rightarrow \mathbb{R}$, we define $I(f)=\int_{0}^{1} x^{2} f(x) d x$ and $J(f)=\int_{0}^{1} x(f(x))^{2} d x$. Find the maximum value of $I(f)-J(f)$ over all such functions $f$.

477. Let $a_{1}, a_{2}, \ldots, a_{n}$ be positive real numbers and let $x_{1}, x_{2}, \ldots, x_{n}$ be real numbers such that $a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n}=0$. Prove that

$$
\sum_{i, j} x_{i} x_{j}\left|a_{i}-a_{j}\right| \leq 0 .
$$

Moreover, prove that equality holds if and only if there exists a partition of the set $\{1,2, \ldots, n\}$ into the disjoint sets $A_{1}, A_{2}, \ldots, A_{k}$ such that if $i$ and $j$ are in the same set, then $a_{i}=a_{j}$ and also $\sum_{j \in A_{i}} x_{j}=0$ for $i=1,2, \ldots, k$.

We now list some fundamental inequalities. We will be imprecise as to the classes of functions to which they apply, because we want to avoid the subtleties of Lebesgue's theory of integration. The novice mathematician should think of piecewise continuous, real-valued functions on some domain $D$ that is an interval of the real axis or some region in $\mathbb{R}^{n}$.

The Cauchy-Schwarz inequality. Let $f$ and $g$ be square integrable functions. Then

$$
\left(\int_{D} f(x) g(x) d x\right)^{2} \leq\left(\int_{D} f^{2}(x) d x\right)\left(\int_{D} g^{2}(x) d x\right) .
$$

Minkowski's inequality. If $p>1$, then

$$
\left(\int_{D}|f(x)+g(x)|^{p} d x\right)^{\frac{1}{p}} \leq\left(\int_{D}|f(x)|^{p} d x\right)^{\frac{1}{p}}+\left(\int_{D}|g(x)|^{p} d x\right)^{\frac{1}{p}} .
$$

Hölder's inequality. If $p, q>1$ such that $\frac{1}{p}+\frac{1}{q}=1$, then

$$
\int_{D}|f(x) g(x)| d x \leq\left(\int_{D}|f(x)|^{p} d x\right)^{\frac{1}{p}}\left(\int_{D}|g(x)|^{q} d x\right)^{\frac{1}{q}} .
$$

As an instructive example we present in detail the proof of another famous inequality.

Chebyshev's inequality. Let $f$ and $g$ be two increasing functions on $\mathbb{R}$. Then for any real numbers $a<b$,

$$
(b-a) \int_{a}^{b} f(x) g(x) d x \geq\left(\int_{a}^{b} f(x) d x\right)\left(\int_{a}^{b} g(x) d x\right) .
$$

Proof. Because $f$ and $g$ are both increasing,

$$
(f(x)-f(y))(g(x)-g(y)) \geq 0 .
$$

Integrating this inequality over $[a, b] \times[a, b]$, we obtain

$$
\int_{a}^{b} \int_{a}^{b}(f(x)-f(y))(g(x)-g(y)) d x d y \geq 0 .
$$

Expanding, we obtain

$$
\begin{aligned}
\int_{a}^{b} \int_{a}^{b} f(x) g(x) d x d y &+\int_{a}^{b} \int_{a}^{b} f(y) g(y) d x d y-\int_{a}^{b} \int_{a}^{b} f(x) g(y) d x d y \\
&-\int_{a}^{b} \int_{a}^{b} f(y) g(x) d x d y \geq 0
\end{aligned}
$$

By eventually renaming the integration variables, we see that this is equivalent to

$$
(b-a) \int_{a}^{b} f(x) g(x) d x-\left(\int_{a}^{b} f(x) d x\right) \cdot\left(\int_{a}^{b} g(x) d x\right) \geq 0,
$$

and the inequality is proved.

478. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function. Prove that

$$
\left(\int_{0}^{1} f(t) d t\right)^{2} \leq \int_{0}^{1} f^{2}(t) d t .
$$

479. Find the maximal value of the ratio

$$
\left(\int_{0}^{3} f(x) d x\right)^{3} / \int_{0}^{3} f^{3}(x) d x,
$$

as $f$ ranges over all positive continuous functions on $[0,1]$. 

480. Let $f:[0, \infty) \rightarrow[0, \infty)$ be a continuous, strictly increasing function with $f(0)=$ 0 . Prove that

$$
\int_{0}^{a} f(x) d x+\int_{0}^{b} f^{-1}(x) d x \geq a b
$$

for all positive numbers $a$ and $b$, with equality if and only if $b=f(a)$. Here $f^{-1}$ denotes the inverse of the function $f$.

481. Prove that for any positive real numbers $x, y$ and any positive integers $m, n$,

$$
\begin{aligned}
&(n-1)(m-1)\left(x^{m+n}+y^{m+n}\right)+(m+n-1)\left(x^{m} y^{n}+x^{n} y^{m}\right) \\
&\geq m n\left(x^{m+n-1} y+y^{m+n-1} x\right) .
\end{aligned}
$$

482. Let $f$ be a nonincreasing function on the interval $[0,1]$. Prove that for any $\alpha \in$ $(0,1)$

$$
\alpha \int_{0}^{1} f(x) d x \leq \int_{0}^{\alpha} f(x) d x .
$$

483. Let $f:[0,1] \rightarrow[0, \infty)$ be a differentiable function with decreasing first derivative, and such that $f(0)=0$ and $f^{\prime}(0)>0$. Prove that

$$
\int_{0}^{1} \frac{d x}{f^{2}(x)+1} \leq \frac{f(1)}{f^{\prime}(1)} .
$$

Can equality hold?

484. Prove that any continuously differentiable function $f:[a, b] \rightarrow \mathbb{R}$ for which $f(a)=0$ satisfies the inequality

$$
\int_{a}^{b} f(x)^{2} d x \leq(b-a)^{2} \int_{a}^{b} f^{\prime}(x)^{2} d x .
$$

485. Let $f(x)$ be a continuous real-valued function defined on the interval $[0,1]$. Show that

$$
\int_{0}^{1} \int_{0}^{1}|f(x)+f(y)| d x d y \geq \int_{0}^{1}|f(x)| d x .
$$

\subsubsection{Taylor and Fourier Series}

Some functions, called analytic, can be expanded around each point of their domain in a Taylor series 

$$
f(x)=f(a)+\frac{f^{\prime}(a)}{1 !}(x-a)+\frac{f^{\prime \prime}(a)}{2 !}(x-a)^{2}+\cdots+\frac{f^{(n)}(a)}{n !}(x-a)^{n}+\cdots .
$$

If $a=0$, the expansion is also known as the Maclaurin series. Rational functions, trigonometric functions, the exponential and the natural logarithm are examples of analytic functions. A particular example of a Taylor series expansion is Newton's binomial formula

$$
(x+1)^{a}=\sum_{n=0}^{\infty}\left(\begin{array}{l}
a \\
n
\end{array}\right) x^{n}=\sum_{n=0}^{\infty} \frac{a(a-1) \cdots(a-n+1)}{n !} x^{n},
$$

which holds true for all real numbers $a$ and for $|x|<1$. Here we make the usual convention that $\left(\begin{array}{l}a \\ 0\end{array}\right)=1$.

We begin our series of examples with a widely circulated problem.

Example. Compute the integral

$$
\int_{0}^{1} \ln x \ln (1-x) d x .
$$

Solution. Because

$$
\lim _{x \rightarrow 0} \ln x \ln (1-x)=\lim _{x \rightarrow 1} \ln x \ln (1-x)=0,
$$

this is, in fact, a definite integral.

We will expand one of the logarithms in Taylor series. Recall the Taylor series expansion

$$
\ln (1-x)=-\sum_{n=1}^{\infty} \frac{x^{n}}{n}, \quad \text { for } x \in(-1,1) .
$$

It follows that on the interval $(0,1)$, the antiderivative of the function $f(x)=\ln x \ln (1-$ $x)$ is

$$
\int \ln (1-x) \ln x d x=-\int \sum_{n=1}^{\infty} \frac{x^{n}}{n} \ln x d x=-\sum_{n=1}^{\infty} \frac{1}{n} \int x^{n} \ln x d x
$$

Integrating by parts, we find this is to be equal to

$$
-\sum_{n=1}^{\infty} \frac{1}{n}\left(\frac{x^{n+1}}{n+1} \ln x-\frac{x^{n+1}}{(n+1)^{2}}\right)+C .
$$

Taking the definite integral over an interval $[\epsilon, 1-\epsilon]$, then letting $\epsilon \rightarrow 0$, we obtain 

$$
\int_{0}^{1} \ln x \ln (1-x) d x=\sum_{n=1}^{\infty} \frac{1}{n(n+1)^{2}}
$$

Using a telescopic sum and the well-known formula for the sum of the inverses of squares of positive integers, we compute this as follows:

$$
\begin{aligned}
\sum_{n=1}^{\infty} \frac{1}{n(n+1)^{2}} &=\sum_{n=1}^{\infty}\left(\frac{1}{n(n+1)}-\frac{1}{(n+1)^{2}}\right)=\sum_{n=1}^{\infty}\left(\frac{1}{n}-\frac{1}{n+1}\right)-\sum_{n=2}^{\infty} \frac{1}{n^{2}} \\
&=1-\left(\frac{\pi^{2}}{6}-1\right)=2-\frac{\pi^{2}}{6},
\end{aligned}
$$

which is the answer to the problem.

Next, a problem that we found in S. Rădulescu, M. Rădulescu, Theorems and Problems in Mathematical Analysis (Editura Didactică şi Pedagogică, Bucharest, 1982).

Example. Prove that for $|x|<1$

$$
(\arcsin x)^{2}=\sum_{k=1}^{\infty} \frac{1}{k^{2}\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k-1} x^{2 k}
$$

Solution. The function $g:(-1,1) \rightarrow \mathbb{R}, g(x)=(\arcsin x)^{2}$ satisfies the initial value problem

$$
\left(1-x^{2}\right) y^{\prime \prime}-x y^{\prime}-2=0, \quad y(0)=y^{\prime}(0)=0
$$

Looking for a solution of the form $y(x)=\sum_{k=0}^{\infty} a_{k} x^{k}$, we obtain the recurrence relation

$$
(k+1)(k+2) a_{k+2}-k^{2} a_{k}=0, \quad k \geq 1 .
$$

It is not hard to see that $a_{1}=0$; hence $a_{2 k+1}=0$ for all $k$. Also, $a_{0}=0, a_{2}=1$, and inductively we obtain

$$
a_{2 k}=\frac{1}{k^{2}\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k-1}, \quad k \geq 1 .
$$

The series

$$
\sum_{k=1}^{\infty} \frac{1}{k^{2}\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k-1} x^{2 k}
$$

is dominated by the geometric series $\sum_{k=1}^{\infty} x^{2 k}$, so it converges for $|x|<1$. It therefore defines a solution to the differential equation. The uniqueness of the solution for the initial value problem implies that this function must equal $g$. We conclude the list of examples with the proof of Stirling's formula.

\section{Stirling's formula.}

$$
n !=\sqrt{2 \pi n}\left(\frac{n}{e}\right)^{n} \cdot e^{\frac{\theta_{n}}{12 n}}, \quad \text { for some } 0<\theta_{n}<1 .
$$

Proof. We begin with the Taylor series expansions

$$
\ln (1 \pm x)=\pm x-\frac{x^{2}}{2} \pm \frac{x^{3}}{3}-\frac{x^{4}}{4} \pm \frac{x^{5}}{5}+\cdots, \quad \text { for } x \in(-1,1) .
$$

Combining these two, we obtain the Taylor series expansion

$$
\ln \frac{1+x}{1-x}=2 x+\frac{2}{3} x^{3}+\frac{2}{5} x^{5}+\cdots+\frac{2}{2 m+1} x^{2 m+1}+\cdots,
$$

again for $x \in(-1,1)$. In particular, for $x=\frac{1}{2 n+1}$, where $n$ is a positive integer, we have

$$
\ln \frac{n+1}{n}=\frac{2}{2 n+1}+\frac{2}{3(2 n+1)^{3}}+\frac{2}{5(2 n+1)^{5}}+\cdots,
$$

which can be written as

$$
\left(n+\frac{1}{2}\right) \ln \frac{n+1}{n}=1+\frac{1}{3(2 n+1)^{2}}+\frac{1}{5(2 n+1)^{4}}+\cdots .
$$

The right-hand side is greater than 1 . It can be bounded from above as follows:

$$
\begin{aligned}
1+\frac{1}{3(2 n+1)^{2}}+\frac{1}{5(2 n+1)^{4}}+\cdots &<1+\frac{1}{3} \sum_{k=1}^{\infty} \frac{1}{(2 n+1)^{2 k}} \\
&=1+\frac{1}{3(2 n+1)^{2}} \cdot \frac{1}{1-\frac{1}{(2 n+1)^{2}}} \\
&=1+\frac{1}{12 n(n+1)} .
\end{aligned}
$$

So using Taylor series we have obtained the double inequality

$$
1 \leq\left(n+\frac{1}{2}\right) \ln \frac{n+1}{n}<1+\frac{1}{12 n(n+1)} .
$$

This transforms by exponentiating and dividing through by $e$ into

$$
1<\frac{1}{e}\left(\frac{n+1}{n}\right)^{n+\frac{1}{2}}<e^{\frac{1}{12 n(n+1)}} .
$$

To bring this closer to Stirling's formula, note that the term in the middle is equal to

$$
\frac{e^{-n-1}(n+1)^{n+1}((n+1) !)^{-1} \sqrt{n+1}}{e^{-n} n^{n}(n !)^{-1} \sqrt{n}}=\frac{x_{n+1}}{x_{n}},
$$

where $x_{n}=e^{-n} n^{n} n ! \sqrt{n}$, a number that we want to prove is equal to $\sqrt{2 \pi} e^{-\frac{\theta_{n}}{12 n}}$ with $0<\theta_{n}<1$. In order to prove this, we write the above double inequality as

$$
1 \leq \frac{x_{n}}{x_{n+1}} \leq \frac{e^{\frac{1}{12 n}}}{e^{\frac{1}{12(n+1)}}} .
$$

We deduce that the sequence $x_{n}$ is positive and decreasing, while the sequence $e^{-\frac{1}{12 n}} x_{n}$ is increasing. Because $e^{-\frac{1}{12 n}}$ converges to 1 , and because $\left(x_{n}\right)_{n}$ converges by the Weierstrass criterion, both $x_{n}$ and $e^{-\frac{1}{12 n}} x_{n}$ must converge to the same limit $L$. We claim that $L=\sqrt{2 \pi}$. Before proving this, note that

$$
e^{-\frac{1}{12 n}} x_{n}<L<x_{n},
$$

so by the intermediate value property there exists $\theta_{n} \in(0,1)$ such that $L=e^{-\frac{\theta_{n}}{12 n}} x_{n}$, i.e., $x_{n}=e^{\frac{\theta_{n}}{12 n}} L$.

The only thing left is the computation of the limit $L$. For this we employ the Wallis formula

$$
\lim _{n \rightarrow \infty}\left[\frac{2 \cdot 4 \cdot 6 \cdots 2 n}{1 \cdot 3 \cdot 5 \cdots(2 n-1)}\right]^{2} \frac{1}{n}=\pi,
$$

proved in problem 466 from Section 3.2.8 (the one on definite integrals). We rewrite this limit as

$$
\lim _{n \rightarrow \infty} \frac{2^{2 n}(n !)^{2}}{(2 n) !} \cdot \frac{1}{\sqrt{n}}=\sqrt{\pi} .
$$

Substituting $n$ ! and $(2 n) !$ by the formula found above gives

$$
\lim _{n \rightarrow \infty} \frac{n L^{2}\left(\frac{n}{e}\right)^{2 n} e^{\frac{2 \theta_{n}}{12 n}} 2^{2 n}}{\sqrt{2 n} L\left(\frac{2 n}{e}\right)^{2 n} e^{\frac{\theta_{2 n}}{24 n}}} \cdot \frac{1}{\sqrt{n}}=\lim _{n \rightarrow \infty} \frac{1}{\sqrt{2}} L e^{\frac{4 \theta_{n}-\theta_{2 n}}{24 n}}=\sqrt{\pi} .
$$

Hence $L=\sqrt{2 \pi}$, and Stirling's formula is proved.

Try your hand at the following problems.

486. Prove that for any real number $x$, the series

$$
1+\frac{x^{4}}{4 !}+\frac{x^{8}}{8 !}+\frac{x^{12}}{12 !}+\cdots
$$

is convergent and find its limit. 

487. Compute the ratio

$$
\frac{1+\frac{\pi^{4}}{5 !}+\frac{\pi^{8}}{9 !}+\frac{\pi^{12}}{13 !}+\cdots}{\frac{1}{3 !}+\frac{\pi^{4}}{7 !}+\frac{\pi^{8}}{11 !}+\frac{\pi^{12}}{15 !}+\cdots} .
$$

488. For $a>0$, prove that

$$
\int_{-\infty}^{\infty} e^{-x^{2}} \cos a x d x=\sqrt{\pi} e^{-a^{2} / 4} .
$$

489. Find a quadratic polynomial $P(x)$ with real coefficients such that

$$
\left|P(x)+\frac{1}{x-4}\right| \leq 0.01, \quad \text { for all } x \in[-1,1] .
$$

490. Compute to three decimal places

$$
\int_{0}^{1} \cos \sqrt{x} d x .
$$

491. Prove that for $|x|<1$,

$$
\arcsin x=\sum_{k=0}^{\infty} \frac{1}{2^{2 k}(2 k+1)}\left(\begin{array}{c}
2 k \\
k
\end{array}\right) x^{2 k+1} .
$$

492. (a) Prove that for $|x|<2$,

$$
\sum_{k=1}^{\infty} \frac{1}{\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} x^{2 k}=\frac{x\left(4 \arcsin \left(\frac{x}{2}\right)+x \sqrt{4-x^{2}}\right)}{\left(4-x^{2}\right) \sqrt{4-x^{2}}} .
$$

(b) Prove the identity

$$
\sum_{k=1}^{\infty} \frac{1}{\left(\begin{array}{c}
2 k \\
k
\end{array}\right)}=\frac{2 \pi \sqrt{3}+36}{27} \text {. }
$$

In a different perspective, we have the Fourier series expansions. The Fourier series allows us to write an arbitrary oscillation as a superposition of sinusoidal oscillations. Mathematically, a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that is continuous and periodic of period $T$ admits a Fourier series expansion

$$
f(x)=a_{0}+\sum_{n=1}^{\infty} a_{n} \cos \frac{2 n \pi}{T} x+\sum_{n=1}^{\infty} b_{n} \sin \frac{2 n \pi}{T} x .
$$

This expansion is unique, and

$$
\begin{aligned}
&a_{0}=\frac{1}{2 \pi} \int_{0}^{T} f(x) d x, \\
&a_{n}=\frac{1}{\pi} \int_{0}^{T} f(x) \cos \frac{2 n \pi}{T} x d x, \\
&b_{n}=\frac{1}{\pi} \int_{0}^{T} f(x) \sin \frac{2 n \pi}{T} x d x .
\end{aligned}
$$

Of course, we can require $f$ to be defined only on an interval of length $T$, and then extend it periodically, but if the values of $f$ at the endpoints of the interval differ, then the convergence of the series is guaranteed only in the interior of the interval.

Let us discuss a problem from the Soviet Union University Student Contest.

Example. Compute the sum

$$
\sum_{n=1}^{\infty} \frac{\cos n}{1+n^{2}} .
$$

Solution. The sum looks like a Fourier series evaluated at 1 . For this reason we concentrate on the general series

$$
\sum_{n=0}^{\infty} \frac{1}{n^{2}+1} \cos n x .
$$

The coefficients $\frac{1}{n^{2}+1}$ should remind us of the integration formulas

$$
\begin{aligned}
&\int e^{x} \cos n x d x=\frac{1}{n^{2}+1} e^{x}(\cos n x+n \sin n x), \\
&\int e^{x} \sin n x d x=\frac{n}{n^{2}+1} e^{x}(\sin n x+n \cos n x) .
\end{aligned}
$$

These give rise to the Fourier series expansion

$$
e^{x}=\frac{1}{2 \pi}\left(e^{2 \pi}-1\right)+\frac{1}{\pi}\left(e^{2 \pi}-1\right) \sum_{n=1}^{\infty} \frac{1}{n^{2}+1} \cos n x+\frac{1}{\pi}\left(e^{2 \pi}-1\right) \sum_{n=1}^{\infty} \frac{n}{n^{2}+1} \sin n x,
$$

which holds true for $x \in(0,2 \pi)$. Similarly, for $e^{-x}$ and $x \in(0,2 \pi)$, we have

$$
\begin{aligned}
e^{-x}=\frac{1}{2 \pi}\left(1-e^{-2 \pi}\right) &+\frac{1}{\pi}\left(1-e^{-2 \pi}\right) \sum_{n=1}^{\infty} \frac{1}{n^{2}+1} \cos n x \\
&-\frac{1}{\pi}\left(1-e^{2 \pi}\right) \sum_{n=1}^{\infty} \frac{n}{n^{2}+1} \sin n x .
\end{aligned}
$$

Let $C_{n}(x)=\sum_{n=1}^{\infty} \frac{1}{n^{2}+1} \cos n x$ and $S_{n}(x)=\sum_{n=1}^{\infty} \frac{n}{n^{2}+1} \sin n x$. They satisfy

$$
\begin{aligned}
\frac{1}{2}+C_{n}(x)+S_{n}(x) &=\frac{\pi e^{x}}{e^{2 \pi}-1} \\
\frac{1}{2}+C_{n}(x)-S_{n}(x) &=\frac{\pi e^{-x}}{1-e^{-2 \pi}}
\end{aligned}
$$

Solving this linear system, we obtain

$$
C_{n}(x)=\frac{1}{2}\left[\frac{\pi e^{x}}{e^{2 \pi}-1}+\frac{\pi e^{-x}}{1-e^{-2 \pi}}-1\right] .
$$

The sum from the statement is $C(1)$. The answer to the problem is therefore

$$
C(1)=\frac{1}{2}\left[\frac{\pi e}{e^{2 \pi}-1}+\frac{\pi e^{-1}}{1-e^{-2 \pi}}-1\right]
$$

We find even more exciting a fundamental result of ergodic theory that proves that for an irrational number $\alpha$, the fractional parts of $n \alpha, n \geq 1$, are uniformly distributed in $[0,1]$. For example, when $\alpha=\log _{10} 2$, we obtain as a corollary that on average, the first digit of a power of 2 happens to be 7 as often as it happens to be 1 . Do you know a power of 2 whose first digit is 7 ?

Theorem. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function of period 1 and let $\alpha$ be an irrational number. Then

$$
\lim _{n \rightarrow \infty} \frac{1}{n}(f(\alpha)+f(2 \alpha)+\cdots+f(n \alpha))=\int_{0}^{1} f(x) d x
$$

Proof. If we approximate $f$ by a trigonometric polynomial with error less than $\epsilon$, then both $\frac{1}{n}(f(\alpha)+f(2 \alpha)+\cdots+f(n \alpha))$ and $\int_{0}^{1} f(x) d x$ are evaluated with error less than $\epsilon$. Hence it suffices to check the equality term by term for the Fourier series of $f$. For the constant term the equality is obvious. To check that it holds for $f(x)=\cos 2 \pi m x$ or $f(x)=\sin 2 \pi m x$, with $m \geq 1$, combine these two using Euler's formula into

$$
e^{2 \pi i m x}=\cos 2 \pi m x+i \sin 2 \pi m x .
$$

We then have

$$
\begin{aligned}
&\frac{1}{n}\left(e^{2 \pi i m \alpha}+e^{2 \pi i 2 m \alpha}+\cdots+e^{2 \pi i n m \alpha}\right) \\
&\quad=\frac{e^{2 \pi i(n+1) m \alpha}-1}{n\left(e^{2 \pi i m \alpha}-e^{2 \pi i m \alpha}\right)}=\frac{\cos 2 \pi(n+1) m \alpha+i \sin 2 \pi(n+1) m \alpha-1}{n(\cos 2 \pi m \alpha+i \sin 2 \pi m \alpha-\cos 2 \pi m \alpha+i \sin 2 \pi m \alpha)},
\end{aligned}
$$

which converges to 0 as $n \rightarrow \infty$. And for the right-hand side, 

$$
\int_{0}^{1} e^{2 \pi i m x} d x=\left.\frac{1}{2 \pi i m} e^{2 \pi i m x}\right|_{0} ^{1}=0 .
$$

Therefore, equality holds term by term for the Fourier series. The theorem is proved.

If after this example you don't love Fourier series, you never will. Below are listed more applications of the Fourier series expansion.

493. Prove that for every $0<x<2 \pi$ the following formula is valid:

$$
\frac{\pi-x}{2}=\frac{\sin x}{1}+\frac{\sin 2 x}{2}+\frac{\sin 3 x}{3}+\cdots .
$$

Derive the formula

$$
\frac{\pi}{4}=\sum_{k=1}^{\infty} \frac{\sin (2 k-1) x}{2 k-1}, \quad x \in(0, \pi)
$$

494. Use the Fourier series of the function of period 1 defined by $f(x)=\frac{1}{2}-x$ for $0 \leq x<1$ to prove Euler's formula

$$
\frac{\pi^{2}}{6}=1+\frac{1}{2^{2}}+\frac{1}{3^{2}}+\frac{1}{4^{2}}+\cdots .
$$

495. Prove that

$$
\frac{\pi^{2}}{8}=1+\frac{1}{3^{2}}+\frac{1}{5^{2}}+\frac{1}{7^{2}}+\cdots .
$$

496. For a positive integer $n$ find the Fourier series of the function

$$
f(x)=\frac{\sin ^{2} n x}{\sin ^{2} x} .
$$

497. Let $f:[0, \pi] \rightarrow \mathbb{R}$ be a $C^{\infty}$ function such that $(-1)^{n} f^{(2 n)}(x) \geq 0$ for any $x \in[0, \pi]$ and $f^{(2 n)}(0)=f^{(2 n)}(\pi)=0$ for any $n \geq 0$. Show that $f(x)=a \sin x$ for some $a>0$.

\subsection{Multivariable Differential and Integral Calculus}

\subsubsection{Partial Derivatives and Their Applications}

This section and the two that follow cover differential and integral calculus in two and three dimensions. Most of the ideas generalize easily to the $n$-dimensional situation. All functions below are assumed to be differentiable. For a two-variable function this means that its graph (which is a surface in $\mathbb{R}^{3}$ ) admits a tangent plane at each point. For a three-variable function, the graph is a three-dimensional manifold in a four-dimensional space, and differentiability means that at each point the graph admits a three-dimensional tangent hyperplane.

The tilting of the tangent (hyper)plane is determined by the slopes in the directions of the coordinate axes, and these slopes are the partial derivatives of the function. We denote the partial derivatives of $f$ by $\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}$. They are computed by differentiating with respect to the one variable while keeping the others fixed. This being said, let us start with the examples.

Euler's theorem. A function $z(x, y)$ is called $n$-homogeneous if $z(t x, t y)=t^{n} z(x, y)$ for all $x, y \in \mathbb{R}$ and $t>0$. Assume that $z(x, y)$ is $n$-homogeneous with $n$ an integer. Then for all $k \leq n+1$,

$$
\sum_{j=1}^{k}\left(\begin{array}{l}
k \\
j
\end{array}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}}=n(n-1) \cdots(n-k+1) z
$$

Proof. We first prove the case $k=1$. Differentiating the relation $z(t x, t y)=t^{n} z(x, y)$ with respect to $y$, we obtain

$$
t \frac{\partial z}{\partial y}(t x, t y)=t^{n} \frac{\partial z}{\partial y}(x, y),
$$

which shows that $\frac{\partial z}{\partial y}$ is $(n-1)$-homogeneous.

Replace $x$ by $1, y$ by $\frac{y}{x}$, and $t$ by $x$ in the homogeneity condition, to obtain $z(x, y)=$ $x^{n} z\left(1, \frac{y}{x}\right)$. Differentiating this with respect to $x$ yields

$$
\frac{\partial z}{\partial x}(x, y)=n x^{n-1} z\left(1, \frac{y}{x}\right)+x^{n} \frac{\partial z}{\partial y}\left(1, \frac{y}{x}\right) \cdot\left(-\frac{y}{x^{2}}\right) .
$$

Because $\frac{\partial z}{\partial y}$ is $(n-1)$-homogeneous, the last term is just $-\frac{y}{x} \frac{\partial z}{\partial y}(x, y)$. Moving it to the right and multiplying through by $x$ gives the desired

$$
x \frac{\partial z}{\partial x}+y \frac{\partial z}{\partial y}=n z .
$$

Now we prove the general case by induction on $k$, with $k=1$ the base case. To simplify the notation, set $\left(\begin{array}{l}k \\ j\end{array}\right)=0$ if $j<0$ or $j>k$. The induction hypothesis is

$$
\sum_{j}\left(\begin{array}{l}
k \\
j
\end{array}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}}=n(n-1) \cdots(n-k+1) z
$$

for some $k \leq n$. Multiply this equality by $n$, then apply the operator $x \frac{\partial}{\partial x}+y \frac{\partial}{\partial y}$ to both sides. The left-hand side becomes

$$
\begin{aligned}
\sum_{j}\left(\begin{array}{c}
k \\
j
\end{array}\right)\left(x \frac{\partial}{\partial x}+y \frac{\partial}{\partial y}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}} \\
=& \sum_{j} j\left(\begin{array}{c}
k \\
j
\end{array}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}}+\sum_{j}\left(\begin{array}{c}
k \\
j
\end{array}\right) x^{j+1} y^{k-j} \frac{\partial^{k+1} z}{\partial x^{j+1} \partial y^{k-j}} \\
&+\sum_{j}(k-j)\left(\begin{array}{c}
k \\
j
\end{array}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}}+\sum_{j}\left(\begin{array}{c}
k \\
j
\end{array}\right) x^{j} y^{k-j+1} \frac{\partial^{k+1} z}{\partial x^{j} \partial y^{k-j+1}} \\
=& k \sum_{j}\left(\begin{array}{c}
k \\
j
\end{array}\right) x^{j} y^{k-j} \frac{\partial^{k} z}{\partial x^{j} \partial y^{k-j}}+\sum_{j}\left(\left(\begin{array}{c}
k \\
j-1
\end{array}\right)+\left(\begin{array}{c}
k \\
j
\end{array}\right)\right) x^{j} y^{k+1-j} \frac{\partial^{k+1} z}{\partial x^{j} y^{k+1-j}} \\
=& k \cdot n(n-1) \cdots(n-k+1) z+\sum_{j}\left(\begin{array}{c}
k+1 \\
j
\end{array}\right) x^{j} y^{k+1-j} \frac{\partial^{k+1} z}{\partial x^{j} y^{k+1-j}} .
\end{aligned}
$$

The base case $k=1$ implies that the right side equals $n \cdot n(n-1) \cdots(n-k+1) z$. Equating the two, we obtain

$$
\sum_{j}\left(\begin{array}{c}
k+1 \\
j
\end{array}\right) x^{j} y^{k+1-j} \frac{\partial^{k+1} z}{\partial x^{j} y^{k+1-j}}=n(n-1) \cdots(n-k+1)(n-k) z,
$$

completing the induction. This proves the formula.

498. Prove that if the function $u(x, t)$ satisfies the equation

$$
\frac{\partial u}{\partial t}=\frac{\partial^{2} u}{\partial x^{2}}, \quad(x, t) \in \mathbb{R}^{2},
$$

then so does the function

$$
v(x, t)=\frac{1}{\sqrt{t}} e^{-\frac{x^{2}}{4 t}} u\left(x t^{-1},-t^{-1}\right), \quad x \in \mathbb{R}, \quad t>0 .
$$

499. Assume that a nonidentically zero harmonic function $u(x, y)$ is $n$-homogeneous for some real number $n$. Prove that $n$ is necessarily an integer. (The function $u$ is called harmonic if $\frac{\partial^{2} u}{\partial x^{2}}+\frac{\partial^{2} u}{\partial y^{2}}=0$.)

500. Let $P(x, y)$ be a harmonic polynomial divisible by $x^{2}+y^{2}$. Prove that $P(x, y)$ is identically equal to zero.

501. Let $f: \mathbb{R}^{2} \rightarrow \mathbb{R}$ be a differentiable function with continuous partial derivatives and with $f(0,0)=0$. Prove that there exist continuous functions $g_{1}, g_{2}: \mathbb{R}^{2} \rightarrow \mathbb{R}$ such that

$$
f(x, y)=x g_{1}(x, y)+y g_{2}(x, y) .
$$

If a differentiable multivariable function has a global extremum, then this extremum is found either among the critical points or on the boundary of the domain. We recall that a point is critical if the (hyper)plane tangent to the graph is horizontal, which is equivalent to the fact that all partial derivatives are equal to zero. Because any continuous function on a compact domain attains its extrema, the global maximum and minimum exist whenever the domain is closed and bounded. Let us apply these considerations to the following problems.

Example. Find the triangles inscribed in the unit circle that have maximal perimeter.

Solution. Without loss of generality, we may assume that the vertices of the triangle have the coordinates $(1,0),(\cos s, \sin s),(\cos t, \sin t), 0 \leq s \leq t \leq 2 \pi$. We are supposed to maximize the function

$$
\begin{aligned}
f(s, t)=& \sqrt{(\cos s-1)^{2}+(\sin s)^{2}}+\sqrt{(1-\cos t)^{2}+(\sin t)^{2}} \\
&+\sqrt{(\cos t-\cos s)^{2}+(\sin t-\sin s)^{2}} \\
=& \sqrt{2}(\sqrt{1-\cos s}+\sqrt{1-\cos t}+\sqrt{1-\cos (t-s)}) \\
=& 2\left(\sin \frac{s}{2}+\sin \frac{t}{2}+\sin \frac{t-s}{2}\right)
\end{aligned}
$$

over the domain $0 \leq s \leq t \leq 2 \pi$. To this end, we first find the critical points of $f$ in the interior of the domain. The equation

$$
\frac{\partial f}{\partial s}(s, t)=\cos \frac{s}{2}-\cos \frac{t-s}{2}=0
$$

gives $\cos \frac{s}{2}=\cos \frac{t-s}{2}$, and since both $\frac{s}{2}$ and $\frac{t-s}{2}$ are between 0 and $\pi$, it follows that $\frac{s}{2}=\frac{t-s}{2}$. The equation

$$
\frac{\partial f}{\partial t}(s, t)=\cos \frac{t}{2}+\cos \frac{t-s}{2}=0
$$

implies additionally that $\cos s=-\cos \frac{s}{2}$, and hence $s=\frac{2 \pi}{3}$. Consequently, $t=\frac{4 \pi}{3}$, showing that the unique critical point is the equilateral triangle, with the corresponding value of the perimeter $3 \sqrt{3}$

On the boundary of the domain of $f$ two of the three points coincide, and in that case the maximum is achieved when two sides of the triangle become diameters. The value of this maximum is 4 , which is smaller than $3 \sqrt{3}$. We conclude that equilateral triangles maximize the perimeter.

502. Find the global minimum of the function $f: \mathbb{R}^{2} \rightarrow \mathbb{R}$, 

$$
f(x, y)=x^{4}+6 x^{2} y^{2}+y^{4}-\frac{9}{4} x-\frac{7}{4} y .
$$

503. Find the equation of the smallest sphere that is tangent to both of the lines (i) $x=$ $t+1, y=2 t+4, z=-3 t+5$, and (ii) $x=4 t-12, y=-t+8, z=t+17$.

504. Determine the maximum and the minimum of $\cos A+\cos B+\cos C$ when $A, B$, and $C$ are the angles of a triangle.

505. Prove that for $\alpha, \beta, \gamma \in\left[0, \frac{\pi}{2}\right)$,

$$
\tan \alpha+\tan \beta+\tan \gamma \leq \frac{2}{\sqrt{3}} \sec \alpha \sec \beta \sec \gamma .
$$

506. Prove that any real numbers $a, b, c, d$ satisfy the inequality

$$
3\left(a^{2}-a b+b^{2}\right)\left(c^{2}-c d+d^{2}\right) \geq 2\left(a^{2} c^{2}-a b c d+b^{2} d^{2}\right) .
$$

When does equality hold?

507. Given $n$ points in the plane, suppose there is a unique line that minimizes the sum of the distances from the points to the line. Prove that the line passes through two of the points.

To find the maximum of a function subject to a constraint we employ the following theorem.

The Lagrange multipliers theorem. If a function $f(x, y, z)$ subject to the constraint $g(x, y, z)=C$ has a maximum or a minimum, then this maximum or minimum occurs at a point $(x, y, z)$ of the set $g(x, y, z)=C$ for which the gradients of $f$ and $g$ are parallel.

So in order to find the maximum of $f$ we have to solve the system of equations $\nabla f=\lambda \nabla g$ and $g(x, y, z)=C$. The number $\lambda$ is called the Lagrange multiplier; to understand its significance, imagine that $f$ is the profit and $g$ is the constraint on resources. Then $\lambda$ is the rate of change of the profit as the constraint is relaxed (economists call this the shadow price).

As an application of the method of Lagrange multipliers, we will prove the law of reflection.

Example. For a light ray reflected off a mirror, the angle of incidence equals the angle of reflection.

Solution. Our argument relies on the fundamental principle of optics, which states that light travels always on the fastest path. This is known in physics as Fermat's principle of least time. We consider a light ray that travels from point $A$ to point $B$ reflecting off a horizontal mirror represented schematically in Figure 22 . Denote by $C$ and $D$ the projections of $A$ and $B$ onto the mirror, and by $P$ the point where the ray hits the mirror. The angles of incidence and reflection are, respectively, the angles formed by $A P$ and $B P$ with the normal to the mirror. To prove that they are equal it suffices to show that $\angle A P C=\angle B P D$. Let $x=C P$ and $y=D P$. We have to minimize $f(x, y)=A P+B P$ with the constraint $g(x, y)=x+y=C D$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-186.jpg?height=352&width=619&top_left_y=585&top_left_x=558)

Figure 22

Using the Pythagorean theorem we find that

$$
f(x, y)=\sqrt{x^{2}+A C^{2}}+\sqrt{y^{2}+B D^{2}} .
$$

The method of Lagrange multipliers yields the system of equations

$$
\begin{aligned}
\frac{x}{\sqrt{x^{2}+C P^{2}}} &=\lambda, \\
\frac{y}{\sqrt{y^{2}+D P^{2}}} &=\lambda, \\
x+y &=C D .
\end{aligned}
$$

From the first two equations, we obtain

$$
\frac{x}{\sqrt{x^{2}+C P^{2}}}=\frac{y}{\sqrt{y^{2}+D P^{2}}},
$$

i.e., $\frac{C P}{A P}=\frac{D P}{B P}$. This shows that the right triangles $C A P$ and $D B P$ are similar, so $\angle A P C=\angle B P D$ as desired.

The following example was proposed by C. Niculescu for Mathematics Magazine. Example. Find the smallest constant $k>0$ such that

$$
\frac{a b}{a+b+2 c}+\frac{b c}{b+c+2 a}+\frac{c a}{c+a+2 b} \leq k(a+b+c)
$$

for every $a, b, c>0$. Solution. We will show that the best choice for $k$ is $\frac{1}{4}$. To prove this fact, note that the inequality remains unchanged on replacing $a, b, c$ by $t a, t b, t c$ with $t>0$. Consequently, the smallest value of $k$ is the supremum of

$$
f(a, b, c)=\frac{a b}{a+b+2 c}+\frac{b c}{b+c+2 a}+\frac{c a}{c+a+2 b}
$$

over the domain $\Delta=\{(a, b, c) \mid a, b, c>0, a+b+c=1\}$. Note that on $\Delta$,

$$
f(a, b, c)=\frac{a b}{1+c}+\frac{b c}{1+a}+\frac{c a}{1+b} .
$$

To find the maximum of this function on $\Delta$, we will apply the method of Lagrange multipliers with the constraint $g(a, b, c)=a+b+c=1$. This yields the system of equations

$$
\begin{aligned}
\frac{b}{1+c}+\frac{c}{1+b}-\frac{b c}{(1+a)^{2}} &=\lambda, \\
\frac{c}{1+a}+\frac{a}{1+c}-\frac{c a}{(1+b)^{2}} &=\lambda, \\
\frac{a}{1+b}+\frac{b}{1+a}-\frac{a b}{(1+c)^{2}} &=\lambda, \\
a+b+c &=1 .
\end{aligned}
$$

Subtracting the first two equations, we obtain

$$
\frac{b-a}{1+c}+\frac{c}{1+b}\left[1+\frac{a}{1+b}\right]-\frac{c}{1+a}\left[1+\frac{b}{1+a}\right]=0,
$$

which after some algebraic manipulations transforms into

$$
(b-a)\left[\frac{1}{1+c}+\frac{c(a+b+1)(a+b+2)}{(1+a)^{2}(1+b)^{2}}\right]=0 .
$$

The second factor is positive, so this equality can hold only if $a=b$. Similarly, we prove that $b=c$. So the only extremum of $f$ when restricted to the plane $a+b+c=1$ is

$$
f\left(\frac{1}{3}, \frac{1}{3}, \frac{1}{3}\right)=\frac{1}{4} \text {. }
$$

But is this a maximum? Let us examine the behavior of $f$ on the boundary of $\Delta$ (to which it can be extended). If say $c=0$, then $f(a, b, 0)=a b$. When $a+b=1$, the maximum of this expression is again $\frac{1}{4}$. We conclude that the maximum on $\Delta$ is indeed $\frac{1}{4}$, which is the desired constant. 

508. Using the method of Lagrange multipliers prove Snell's law of optics: If a light ray passes between two media separated by a planar surface, then

$$
\frac{\sin \theta_{1}}{\sin \theta_{2}}=\frac{v_{1}}{v_{2}},
$$

where $\theta_{1}$ and $\theta_{2}$ are, respectively, the angle of incidence and the angle of refraction, and $v_{1}$ and $v_{2}$ are the speeds of light in the first and second media, respectively.

509. Let $A B C$ be a triangle such that

$$
\left(\cot \frac{A}{2}\right)^{2}+\left(2 \cot \frac{B}{2}\right)^{2}+\left(3 \cot \frac{C}{2}\right)^{2}=\left(\frac{6 s}{7 r}\right)^{2},
$$

where $s$ and $r$ denote its semiperimeter and its inradius, respectively. Prove that triangle $A B C$ is similar to a triangle $T$ whose side lengths are all positive integers with no common divisors and determine these integers.

510. Prove that of all quadrilaterals that can be formed from four given sides, the one that is cyclic has the greatest area.

511. Of all triangles circumscribed about a given circle, find the one with the smallest area.

512. Let $a, b, c, d$ be four nonnegative numbers satisfying $a+b+c+d=1$. Prove the inequality

$$
a b c+b c d+c d a+d a b \leq \frac{1}{27}+\frac{176}{27} a b c d .
$$

513. Given two triangles with angles $\alpha, \beta, \gamma$, respectively, $\alpha_{1}, \beta_{1}, \gamma_{1}$, prove that

$$
\frac{\cos \alpha_{1}}{\sin \alpha}+\frac{\cos \beta_{1}}{\sin \beta}+\frac{\cos \gamma_{1}}{\sin \gamma} \leq \cot \alpha+\cot \beta+\cot \gamma,
$$

with equality if and only if $\alpha=\alpha_{1}, \beta=\beta_{1}, \gamma=\gamma_{1}$.

\subsubsection{Multivariable Integrals}

For multivariable integrals, the true story starts with a change of coordinates.

Theorem. Let $f: D \subset \mathbb{R}^{n} \rightarrow \mathbb{R}$ be an integrable function. Let also $x(u)=$ $\left(x_{i}\left(u_{j}\right)\right)_{i, j=1}^{n}$ be a change of coordinates, viewed as a map from some domain $D^{*}$ to $D$, with Jacobian $\frac{\partial x}{\partial u}=\operatorname{det}\left(\frac{\partial x_{i}}{\partial u_{j}}\right)$. Then

$$
\int_{D} f(x) d x=\int_{D^{*}} f(x(u))\left|\frac{\partial x}{\partial u}\right| d u .
$$

There are three special situations worth mentioning:

- The change in two dimensions from Cartesian to polar coordinates $x=r \cos \theta$, $y=r \sin \theta$, with the Jacobian $\frac{\partial(x, y)}{\partial(r, \theta)}=r$.

- The change in three dimensions from Cartesian to cylindrical coordinates $x=r \cos \theta$, $y=r \sin \theta, z=z$, with the Jacobian $\frac{\partial(x, y, z)}{\partial(r, \theta, z)}=r$.

- The change in three dimensions from Cartesian to spherical coordinates $x=$ $\rho \sin \phi \cos \theta, y=\rho \sin \phi \sin \theta, z=\rho \cos \phi$, with the Jacobian $\frac{\partial(x, y, z)}{\partial(\rho, \theta, \phi)}=\rho^{2} \sin \phi$.

As an illustration, we show how multivariable integrals can be used for calculating the Fresnel integrals. These integrals arise in the theory of diffraction of light.

Example. Compute the Fresnel integrals

$$
I=\int_{0}^{\infty} \cos x^{2} d x \quad \text { and } \quad J=\int_{0}^{\infty} \sin x^{2} d x
$$

Solution. For the computation of the first integral, we consider the surface $z=e^{-y^{2}} \cos x^{2}$ and determine the volume of the solid that lies below this surface in the octant $x, y, z \geq 0$. This will be done in both Cartesian and polar coordinates. We will also make use of the Gaussian integral

$$
\int_{0}^{\infty} e^{-t^{2}} d t=\frac{\sqrt{\pi}}{2},
$$

which is the subject of one of the exercises that follow.

In Cartesian coordinates,

$$
\begin{aligned}
V &=\int_{0}^{\infty} \int_{0}^{\infty} e^{-y^{2}} \cos x^{2} d y d x=\int_{0}^{\infty}\left(\int_{0}^{\infty} e^{-y^{2}} d y\right) \cos x^{2} d x \\
&=\int_{0}^{\infty} \frac{\sqrt{\pi}}{2} \cos x^{2} d x=\frac{\sqrt{\pi}}{2} I .
\end{aligned}
$$

In polar coordinates,

$$
\begin{aligned}
V &=\int_{0}^{\frac{\pi}{2}} \int_{0}^{\infty} e^{-\rho^{2} \sin ^{2} \theta} \cos \left(\rho^{2} \cos ^{2} \theta\right) \rho d \rho d \theta \\
&=\int_{0}^{\frac{\pi}{2}} \frac{1}{\cos ^{2} \theta} \int_{0}^{\infty} e^{-u \tan ^{2} \theta} \cos u d u d \theta=\int_{0}^{\frac{\pi}{2}} \frac{1}{\cos ^{2} \theta} \cdot \frac{\tan ^{2} \theta}{1+\tan ^{4} \theta} d \theta,
\end{aligned}
$$

where we made the substitution $u=u(\rho)=\rho^{2} \cos ^{2} \theta$. If in this last integral we substitute $\tan \theta=t$, we obtain 

$$
V=\frac{1}{2} \int_{0}^{\infty} \frac{t^{2}}{t^{4}+1} d t
$$

A routine but lengthy computation using Jacobi's method of partial fraction decomposition shows that the antiderivative of $\frac{t^{2}}{t^{4}+1}$ is

$$
\frac{1}{2 \sqrt{2}} \arctan \frac{x^{2}-1}{x \sqrt{2}}+\frac{1}{4 \sqrt{2}} \ln \frac{x^{2}-x \sqrt{2}+1}{x^{2}+x \sqrt{2}+1}+C,
$$

whence $V=\frac{\pi \sqrt{2}}{8}$. Equating the two values for $V$, we obtain $I=\frac{\sqrt{2 \pi}}{4}$. A similar argument yields $J=\frac{\sqrt{2 \pi}}{4}$.

The solutions to all but last problems below are based on appropriate changes of coordinates.

514. Compute the integral $\iint_{D} x d x d y$, where

$$
D=\left\{(x, y) \in \mathbb{R}^{2} \mid x \geq 0,1 \leq x y \leq 2,1 \leq \frac{y}{x} \leq 2\right\} .
$$

515. Find the integral of the function

$$
f(x, y, z)=\frac{x^{4}+2 y^{4}}{x^{4}+4 y^{4}+z^{4}}
$$

over the unit ball $B=\left\{(x, y, z) \mid x^{2}+y^{2}+z^{2} \leq 1\right\}$.

516. Compute the integral

$$
\iint_{D} \frac{d x d y}{\left(x^{2}+y^{2}\right)^{2}},
$$

where $D$ is the domain bounded by the circles

$$
\begin{array}{ll}
x^{2}+y^{2}-2 x=0, & x^{2}+y^{2}-4 x=0, \\
x^{2}+y^{2}-2 y=0, & x^{2}+y^{2}-6 y=0 .
\end{array}
$$

517. Compute the integral

$$
I=\iint_{D}|x y| d x d y,
$$

where

$$
D=\left\{(x, y) \in \mathbb{R}^{2} \mid x \geq 0, \quad\left(\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}\right)^{2} \leq \frac{x^{2}}{a^{2}}-\frac{y^{2}}{b^{2}}\right\}, \quad a, b>0 .
$$

518. Prove the Gaussian integral formula

$$
\int_{-\infty}^{\infty} e^{-x^{2}} d x=\sqrt{\pi} .
$$

519. Evaluate

$$
\int_{0}^{1} \int_{0}^{1} \int_{0}^{1}\left(1+u^{2}+v^{2}+w^{2}\right)^{-2} d u d v d w
$$

520. Let $D=\left\{(x, y) \in \mathbb{R}^{2} \mid 0 \leq x \leq y \leq \pi\right\}$. Prove that

$$
\iint_{D} \ln |\sin (x-y)| d x d y=-\frac{\pi^{2}}{2} \ln 2 .
$$

Our next topic is the continuous analogue of the change of the order of summation in a double sum.

Fubini's theorem. Let $f: \mathbb{R}^{2} \rightarrow \mathbb{R}$ be a piecewise continuous function such that

$$
\int_{c}^{d} \int_{a}^{b}|f(x, y)| d x d y<\infty .
$$

Then

$$
\int_{c}^{d} \int_{a}^{b} f(x, y) d x d y=\int_{a}^{b} \int_{c}^{d} f(x, y) d y d x .
$$

The matter of convergence can be bypassed for positive functions, in which case we have the following result.

Tonelli's theorem. Let $f: \mathbb{R}^{2} \rightarrow \mathbb{R}$ be a positive piecewise continuous function. Then

$$
\int_{a}^{b} \int_{c}^{d} f(x, y) d x d y=\int_{c}^{d} \int_{a}^{b} f(x, y) d y d x .
$$

The limits of integration can be finite or infinite. In the particular case that $f(x, y)$ is constant on the squares of an integer lattice, we recover the discrete version of Fubini's theorem, the change of order of summation in a double sum

$$
\sum_{m=0}^{\infty} \sum_{n=0}^{\infty} f(m, n)=\sum_{n=0}^{\infty} \sum_{m=0}^{\infty} f(m, n) .
$$

A slightly more general situation occurs when $f$ is a step function in one of the variables. In this case we recover the formula for commuting the sum with the integral: 

$$
\int_{a}^{b} \sum_{n=0}^{\infty} f(n, x)=\sum_{n=0}^{\infty} \int_{a}^{b} f(n, x)
$$

Here we are allowed to commute the sum and the integral if either $f$ is a positive function, or if $\int_{a}^{b} \sum_{n=0}^{\infty}|f(n, x)|$ (or equivalently $\left.\sum_{n=0}^{\infty} \int_{a}^{b}|f(n, x)|\right)$ is finite. It is now time for an application.

Example. Compute the integral

$$
I=\int_{0}^{\infty} \frac{1}{\sqrt{x}} e^{-x} d x
$$

Solution. We will replace $\frac{1}{\sqrt{x}}$ by a Gaussian integral. Note that for $x>0$,

$$
\int_{-\infty}^{\infty} e^{-x t^{2}} d t=\int_{-\infty}^{\infty} e^{-(\sqrt{x} t)^{2}} d t=\frac{1}{\sqrt{x}} \int_{-\infty}^{\infty} e^{-u^{2}} d u=\sqrt{\frac{\pi}{x}}
$$

Returning to the problem, we are integrating the positive function $\frac{1}{\sqrt{x}} e^{-x}$, which is integrable over the positive semiaxis because in a neighborhood of zero it is bounded from above by $\frac{1}{\sqrt{x}}$ and in a neighborhood of infinity it is bounded from above by $e^{-x / 2}$.

Let us consider the two-variable function $f(x, y)=e^{-x t^{2}} e^{-x}$, which is positive and integrable over $\mathbb{R} \times(0, \infty)$. Using the above considerations and Tonelli's theorem, we can write

$$
\begin{aligned}
I &=\int_{0}^{\infty} \frac{1}{\sqrt{x}} e^{-x} d x=\frac{1}{\sqrt{\pi}} \int_{0}^{\infty} \int_{-\infty}^{\infty} e^{-x t^{2}} e^{-x} d t d x=\frac{1}{\sqrt{\pi}} \int_{-\infty}^{\infty} \int_{0}^{\infty} e^{-\left(t^{2}+1\right) x} d x d t \\
&=\frac{1}{\sqrt{\pi}} \int_{-\infty}^{\infty} \frac{1}{t^{2}+1} d t=\frac{\pi}{\sqrt{\pi}}=\sqrt{\pi}
\end{aligned}
$$

Hence the value of the integral in question is $I=\sqrt{\pi}$.

More applications are given below.

521. Let $a_{1} \leq a_{2} \leq \cdots \leq a_{n}=m$ be positive integers. Denote by $b_{k}$ the number of those $a_{i}$ for which $a_{i} \geq k$. Prove that

$$
a_{1}+a_{2}+\cdots+a_{n}=b_{1}+b_{2}+\cdots+b_{m} .
$$

522. Show that for $s>0$

$$
\int_{0}^{\infty} e^{-s x} x^{-1} \sin x d x=\arctan \left(s^{-1}\right)
$$

523. Show that for $a, b>0$,

$$
\int_{0}^{\infty} \frac{e^{-a x}-e^{-b x}}{x} d x=\ln \frac{b}{a} .
$$

524. Let $|x|<1$. Prove that

$$
\sum_{n=1}^{\infty} \frac{x^{n}}{n^{2}}=-\int_{0}^{x} \frac{1}{t} \ln (1-t) d t
$$

525. Let $F(x)=\sum_{n=1}^{\infty} \frac{1}{x^{2}+n^{4}}, x \in \mathbb{R}$. Compute $\int_{0}^{\infty} F(t) d t$.

\subsubsection{The Many Versions of Stokes' Theorem}

We advise you that this is probably the most difficult section of the book. Yet Stokes' theorem plays such an important role in mathematics that it deserves an extensive treatment. As an encouragement, we offer you a quote by Marie Curie: "Nothing in life is to be feared. It is only to be understood.'"

In its general form, Stokes' theorem is known as

$$
\int_{M} d \omega=\int_{\partial M} \omega,
$$

where $\omega$ is a "form," $d \omega$ its differential, and $M$ a domain with boundary $\partial M$. The one-dimensional case is the most familiar; it is the Leibniz-Newton formula

$$
\int_{a}^{b} f^{\prime}(t) d t=f(b)-f(a) .
$$

Three versions of this result are of interest to us.

Green's theorem. Let $D$ be a domain in the plane with boundary $C$ oriented such that $D$ is to the left. If the vector field $\vec{F}(x, y)=P(x, y) \vec{i}+Q(x, y) \vec{j}$ is continuously differentiable on $D$, then

$$
\oint_{C} P d x+Q d y=\iint_{D}\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right) d x d y .
$$

Stokes' Theorem. Let $S$ be an oriented surface with normal vector $\vec{n}$, bounded by a closed, piecewise smooth curve $C$ that is oriented such that if one travels on $C$ with the upward direction $\vec{n}$, the surface is on the left. If $\vec{F}$ is a vector field that is continuously differentiable on $S$, then

$$
\oint_{C} \vec{F} \cdot d \vec{R}=\iint_{S}(\operatorname{curl} \vec{F} \cdot \vec{n}) d S,
$$

where $d S$ is the area element on the surface. The Gauss-Ostrogradsky (Divergence) Theorem. Let $S$ be a smooth, orientable surface that encloses a solid region $V$ in space. If $\vec{F}$ is a continuously differentiable vector field on $V$, then

$$
\iint_{S} \vec{F} \cdot \vec{n} d S=\iiint_{V} \operatorname{div} \vec{F} d V,
$$

where $\vec{n}$ is the outward unit normal vector to the surface $S, d S$ is the area element on the surface, and $d V$ is the volume element inside of $V$.

We recall that for a vector field $\vec{F}=\left(F_{1}, F_{2}, F_{3}\right)$, the divergence is

$$
\operatorname{div} \vec{F}=\nabla \cdot \vec{F}=\frac{\partial F_{1}}{\partial x}+\frac{\partial F_{2}}{\partial y}+\frac{\partial F_{3}}{\partial z},
$$

while the curl is

$$
\begin{aligned}
\operatorname{curl} \vec{F} &=\nabla \times \vec{F}=\left|\begin{array}{ccc}
\vec{i} & \vec{j} & \vec{k} \\
\frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\
F_{1} & F_{2} & F_{3}
\end{array}\right| \\
&=\left(\frac{\partial F_{3}}{\partial y}-\frac{\partial F_{2}}{\partial z}\right) \vec{i}+\left(\frac{\partial F_{1}}{\partial z}-\frac{\partial F_{3}}{\partial x}\right) \vec{j}+\left(\frac{\partial F_{2}}{\partial x}-\frac{\partial F_{1}}{\partial y}\right) \vec{k} .
\end{aligned}
$$

The quantity $\iint_{S} \vec{F} \cdot \vec{n} d S$ is called the flux of $\vec{F}$ across the surface $S$.

Let us illustrate the use of these theorems with some examples. We start with an encouraging problem whose solution is based on Stokes' theorem.

Example. Compute

$$
\oint_{C} y d x+z d y+x d z,
$$

where $C$ is the circle $x^{2}+y^{2}+z^{2}=1, x+y+z=1$, oriented counterclockwise when seen from the positive side of the $x$-axis.

Solution. By Stokes' theorem,

$$
\oint_{C} y d x+z d y+x d z=\iint_{S} \operatorname{curl} \vec{F} \cdot \vec{n} d S,
$$

where $S$ is the disk that the circle bounds. It is straightforward that curl $\vec{F}=$ $(-1,-1,-1)$, while $\vec{n}$, the normal vector to the plane $x+y+z=1$, is equal to $\left(\frac{1}{\sqrt{3}}, \frac{1}{\sqrt{3}}, \frac{1}{\sqrt{3}}\right)$. Therefore, 

$$
\oint_{C} y d x+z d y+x d z=-A \sqrt{3},
$$

where $A$ is the area of the disk bounded by $C$. Observe that $C$ is the circumcircle of the triangle with vertices $(1,0,0),(0,1,0)$, and $(0,0,1)$. The circumradius of this triangle is $\frac{\sqrt{6}}{3}$, so $A=\frac{2}{3} \pi$. The answer to the problem is therefore $-\frac{2 \pi \sqrt{3}}{3}$.

Example. Orthogonal to each face of a polyhedron construct an outward vector with length numerically equal to the area of the face. Prove that the sum of all these vectors is equal to zero.

Solution. We exhibit first an elementary solution based on vector operations. Consider the particular case of a tetrahedron $A B C D$. The four vectors are $\frac{1}{2} \overrightarrow{B C} \times \overrightarrow{B A}, \frac{1}{2} \overrightarrow{B A} \times \overrightarrow{B D}$, $\frac{1}{2} \overrightarrow{B D} \times \overrightarrow{B C}$, and $\frac{1}{2} \overrightarrow{D A} \times \overrightarrow{D C}$. Indeed, the lengths of these vectors are numerically equal to the areas of the corresponding faces, and the cross-product of two vectors is perpendicular to the plane determined by the vectors, and it points outward because of the right-hand rule. We have

$$
\begin{aligned}
\overrightarrow{B C} \times & \overrightarrow{B A}+\overrightarrow{B A} \times \overrightarrow{B D}+\overrightarrow{B D} \times \overrightarrow{B C}+\overrightarrow{D A} \times \overrightarrow{D C} \\
=& \overrightarrow{B C} \times \overrightarrow{B A}+\overrightarrow{B A} \times \overrightarrow{B D}+\overrightarrow{B D} \times \overrightarrow{B C}+(\overrightarrow{B A}-\overrightarrow{B D}) \times(\overrightarrow{B C}-\overrightarrow{B D}) \\
=& \overrightarrow{B C} \times \overrightarrow{B A}+\overrightarrow{B A} \times \overrightarrow{B D}+\overrightarrow{B D} \times \overrightarrow{B C}+\overrightarrow{B A} \times \overrightarrow{B C}-\overrightarrow{B A} \times \overrightarrow{B D} \\
&-\overrightarrow{B D} \times \overrightarrow{B C}+\overrightarrow{0}=\overrightarrow{0} .
\end{aligned}
$$

This proves that the four vectors add up to zero.

In the general case, dissect the polyhedron into tetrahedra cutting the faces into triangles by diagonals and then joining the centroid of the polyhedron with the vertices. Sum up all vectors perpendicular to the faces of these tetrahedra, and note that the vectors corresponding to internal walls cancel out.

The elegant solution uses integrals. Let $S$ be the polyhedron and assume that its interior $V$ is filled with gas at a (not necessarily constant) pressure $p$. The force that the gas exerts on $S$ is $\iint_{S} p \vec{n} d A$, where $\vec{n}$ is the outward normal vector to the surface of the polyhedron and $d A$ is the area element. The divergence theorem implies that

$$
\iint_{S} p \vec{n} d A=\iiint_{V} \nabla p d V
$$

Here $\nabla p$ denotes the gradient of $p$. If the pressure $p$ is constant, then the right-hand side is equal to zero. This is the case with our polyhedron, where $p=1$. The double integral is exactly the sum of the vectors under discussion, these vectors being the forces exerted by pressure on the faces. As a corollary, we obtain the well-known fact that a container filled with gas under pressure is at equilibrium; a balloon will never move as a result of internal pressure.

We conclude our series of examples with an application of Green's theorem, the proof given by D. Pompeiu to Cauchy's formula for holomorphic functions. First, let us introduce some notation for functions of a complex variable $f(z)=f(x+i y)=$ $u(x, y)+i v(x, y)$. If $u$ and $v$ are continuously differentiable, define

$$
\frac{\partial f}{\partial \bar{z}}=\frac{1}{2}\left[\frac{\partial f}{\partial x}+i \frac{\partial f}{\partial y}\right]=\frac{1}{2}\left[\left(\frac{\partial u}{\partial x}-\frac{\partial v}{\partial y}\right)+i\left(\frac{\partial u}{\partial y}+\frac{\partial v}{\partial x}\right)\right] .
$$

The function $f$ is called holomorphic if $\frac{\partial f}{\partial \bar{z}}=0$. Examples are polynomials in $z$ and any absolutely convergent power series in $z$. Also, let $d z=d x+i d y$.

Cauchy's theorem. Let $\Gamma$ be an oriented curve that bounds a region $\Delta$ on its left, and let $a \in \Delta$. If $f(z)=f(x+i y)=u(x, y)+i v(x, y)$ is a holomorphic function on $\Delta$ such that $u$ and $v$ are continuous on $\Delta \cup \Gamma$ and continuously differentiable on $\Delta$, then

$$
f(a)=\frac{1}{2 \pi i} \oint_{\Gamma} \frac{f(z)}{z-a} d z .
$$

Proof. The proof is based on Green's formula, applied on the domain $\Delta_{\epsilon}$ obtained from $\Delta$ by removing a disk of radius $\epsilon$ around $a$ as described in Figure 23 to $P=F$ and $Q=i F$, where $F$ is a holomorphic function to be specified later. Note that the boundary of the domain consists of two curves, $\Gamma$ and $\Gamma_{\epsilon}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-196.jpg?height=273&width=402&top_left_y=1327&top_left_x=666)

Figure 23

Green's formula reads

$$
\begin{aligned}
\oint_{\Gamma} F d z-\oint_{\Gamma_{\epsilon}} F d z &=\oint_{\Gamma} F d x+i F d y-\oint_{\Gamma_{\epsilon}} F d x+i F d y \\
&=\iint_{\Delta_{\epsilon}} i\left(\frac{\partial F}{\partial x}+i \frac{\partial F}{\partial y}\right) d x d y=2 i \iint_{\Delta_{\epsilon}} \frac{\partial F}{\partial \bar{z}} d x d y=0 .
\end{aligned}
$$

Therefore,

$$
\oint_{\Gamma} F(z) d z=\oint_{\Gamma_{\epsilon}} F(z) d z .
$$

We apply this to

$$
F(z)=\frac{f(z)}{z-a}=\frac{(u(x, y)+i v(x, y))(x-i y+\alpha-i \beta)}{(x+\alpha)^{2}+(y+\beta)^{2}},
$$

where $a=\alpha+i \beta$. It is routine to check that $F$ is holomorphic. We thus have

$$
\oint_{\Gamma} \frac{f(z)}{z-a} d z=\oint_{\Gamma_{\epsilon}} \frac{f(z)}{z-a} d z .
$$

The change of variable $z=a+\epsilon e^{i t}$ on the right-hand side yields

$$
\oint_{\Gamma_{\epsilon}} \frac{f(z)}{z-a} d z=\int_{-\pi}^{\pi} \frac{f\left(a+\epsilon e^{i t}\right)}{\epsilon e^{i t}} i \epsilon e^{i t} d t=i \int_{-\pi}^{\pi} f\left(a+\epsilon e^{i t}\right) d t .
$$

When $\epsilon \rightarrow 0$ this tends to $2 \pi i f(a)$, and we obtain

$$
\oint_{\Gamma_{\epsilon}} \frac{f(z)}{z-a} d z=2 \pi i f(a) .
$$

Hence the desired formula.

526. Assume that a curve $(x(t), y(t))$ runs counterclockwise around a region $D$. Prove that the area of $D$ is given by the formula

$$
A=\frac{1}{2} \oint_{\partial D}\left(x y^{\prime}-y x^{\prime}\right) d t .
$$

527. Compute the flux of the vector field

$$
\vec{F}(x, y, z)=x\left(e^{x y}-e^{z x}\right) \vec{i}+y\left(e^{y z}-e^{x y}\right) \vec{j}+z\left(e^{z x}-e^{y z}\right) \vec{k}
$$

across the upper hemisphere of the unit sphere.

528. Compute

$$
\oint_{C} y^{2} d x+z^{2} d y+x^{2} d z,
$$

where $C$ is the Viviani curve, defined as the intersection of the sphere $x^{2}+y^{2}+z^{2}=$ $a^{2}$ with the cylinder $x^{2}+y^{2}=a x$.

529. Let $\phi(x, y, z)$ and $\psi(x, y, z)$ be twice continuously differentiable functions in the region $\left\{(x, y, z) \mid \frac{1}{2}<\sqrt{x^{2}+y^{2}+z^{2}}<2\right\}$. Prove that

$$
\iint_{S}(\nabla \phi \times \nabla \psi) \cdot \vec{n} d S=0,
$$

where $S$ is the unit sphere centered at the origin, $\vec{n}$ is the normal unit vector to this sphere, and $\nabla \phi$ denotes the gradient $\frac{\partial \phi}{\partial x} \mathbf{i}+\frac{\partial \phi}{\partial y} \mathbf{j}+\frac{\partial \phi}{\partial z} \mathbf{k}$. 

530. Let $f, g: \mathbb{R}^{3} \rightarrow \mathbb{R}$ be twice continuously differentiable functions that are constant along the lines that pass through the origin. Prove that on the unit ball $B=$ $\left\{(x, y, z) \mid x^{2}+y^{2}+z^{2} \leq 1\right\}$

$$
\iiint_{B} f \nabla^{2} g d V=\iiint_{B} g \nabla^{2} f d V .
$$

Here $\nabla^{2}=\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}+\frac{\partial^{2}}{\partial z^{2}}$ is the Laplacian.

531. Prove Gauss' law, which states that the total flux of the gravitational field through a closed surface equals $-4 \pi G$ times the mass enclosed by the surface, where $G$ is the constant of gravitation. The mathematical formulation of the law is

$$
\iint_{S} \vec{F} \cdot \vec{n} d S=-4 \pi M G
$$

532. Let

$$
\vec{G}(x, y)=\left(\frac{-y}{x^{2}+4 y^{2}}, \frac{x}{x^{2}+4 y^{2}}, 0\right) .
$$

Prove or disprove that there is a vector field $\vec{F}: \mathbb{R}^{3} \rightarrow \mathbb{R}^{3}$,

$$
\vec{F}(x, y, z)=(M(x, y, z), N(x, y, z), P(x, y, z)),
$$

with the following properties:

(i) $M, N, P$ have continuous partial derivatives for all $(x, y, z) \neq(0,0,0)$;

(ii) $\operatorname{curl} \vec{F}=\overrightarrow{0}$, for all $(x, y, z) \neq(0,0,0)$;

(iii) $\vec{F}(x, y, 0)=\vec{G}(x, y)$.

533. Let $\vec{F}: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}, \vec{F}(x, y)=\left(F_{1}(x, y), F_{2}(x, y)\right)$ be a vector field, and let $G: \mathbb{R}^{3} \rightarrow \mathbb{R}$ be a smooth function whose first two variables are $x$ and $y$, and the third is $t$, the time. Assume that for any rectangular surface $D$ bounded by the curve $C$,

$$
\frac{d}{d t} \iint_{D} G(x, y, t) d x d y=-\oint_{C} \vec{F} \cdot d \vec{R} .
$$

Prove that

$$
\frac{\partial G}{\partial t}+\frac{\partial F_{2}}{\partial x}+\frac{\partial F_{1}}{\partial y}=0 .
$$

534. For two disjoint oriented curves $C_{1}$ and $C_{2}$ in three-dimensional space, parametrized by $\vec{v}_{1}(s)$ and $\vec{v}_{2}(t)$, define the linking number

$$
\operatorname{lk}\left(C_{1}, C_{2}\right)=\frac{1}{4 \pi} \oint_{C_{1}} \oint_{C_{2}} \frac{\vec{v}_{1}-\vec{v}_{2}}{\left\|\vec{v}_{1}-\vec{v}_{2}\right\|^{3}} \cdot\left(\frac{d \vec{v}_{1}}{d s} \times \frac{d \vec{v}_{2}}{d t}\right) d t d s .
$$

Prove that if the oriented curves $C_{1}$ and $-C_{1}^{\prime}$ bound an oriented surface $S$ such that $S$ is to the left of each curve, and if the curve $C_{2}$ is disjoint from $S$, then $\operatorname{lk}\left(C_{1}, C_{2}\right)=\operatorname{lk}\left(C_{1}^{\prime}, C_{2}\right)$.

\subsection{Equations with Functions as Unknowns}

\subsubsection{Functional Equations}

We will now look at equations whose unknowns are functions. Here is a standard example that we found in B.J. Venkatachala, Functional Equations: A Problem Solving Approach (Prism Books PVT Ltd., 2002).

Example. Find all functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying the functional equation

$$
f\left((x-y)^{2}\right)=f(x)^{2}-2 x f(y)+y^{2} .
$$

Solution. For $y=0$, we obtain

$$
f\left(x^{2}\right)=f(x)^{2}-2 x f(0),
$$

and for $x=0$, we obtain

$$
f\left(y^{2}\right)=f(0)^{2}+y^{2} .
$$

Setting $y=0$ in the second equation, we find that $f(0)=0$ or $f(0)=1$. On the other hand, combining the two equalities, we obtain

$$
f(x)^{2}-2 x f(0)=f(0)^{2}+x^{2},
$$

that is,

$$
f(x)^{2}=(x+f(0))^{2} .
$$

Substituting this in the original equation yields

$$
\begin{aligned}
f(y) &=\frac{f(x)^{2}-f\left((x-y)^{2}\right)+y^{2}}{2 x}=\frac{(x+f(0))^{2}-(x-y+f(0))^{2}+y^{2}}{2 x} \\
&=y+f(0)
\end{aligned}
$$

We conclude that the functional equation has the two solutions $f(x)=x$ and $f(x)=$ $x+1$. But we like more the nonstandard functional equations. Here is one, which is a simplified version of a short-listed problem from the 42nd International Mathematical Olympiad. We liked about it the fact that the auxiliary function $h$ from the solution mimics, in a discrete situation, harmonicity-a fundamental concept in mathematics. The solution applies the maximum modulus principle, which states that if $h$ is a harmonic function then the maximum of $|h|$ is attained on the boundary of the domain of definition. Harmonic functions, characterized by the fact that the value at one point is the average of the values in a neighborhood of the point, play a fundamental role in geometry. For example, they encode geometric properties of their domain, a fact made explicit in Hodge theory.

Example. Find all functions $f:\{0,1,2, \ldots\} \times\{0,1,2, \ldots\} \rightarrow \mathbb{R}$ satisfying

$$
f(p, q)= \begin{cases}\frac{1}{2}(f(p+1, q-1)+f(p-1, q+1))+1 & \text { if } p q \neq 0 \\ 0 & \text { if } p q=0 .\end{cases}
$$

Solution. We see that $f(1,1)=1$. The defining relation gives $f(1,2)=1+f(2,1) / 2$ and $f(2,1)=1+f(1,2) / 2$, and hence $f(2,1)=f(1,2)=2$. Then $f(3,1)=$ $1+f(2,2) / 2, f(2,2)=1+f(3,1) / 2+f(1,3) / 2, f(1,3)=1+f(2,2) / 2$. So $f(2,2)=4, f(3,1)=3, f(1,3)=3$. Repeating such computations, we eventually guess the explicit formula $f(p, q)=p q, p, q \geq 0$. And indeed, this function satisfies the condition from the statement. Are there other solutions to the problem? The answer is no, but we need to prove it.

Assume that $f_{1}$ and $f_{2}$ are both solutions to the functional equation. Let $h=f_{1}-f_{2}$. Then $h$ satisfies

$$
h(p, q)= \begin{cases}\frac{1}{2}(h(p+1, q-1)+h(p-1, q+1)) & \text { if } p q \neq 0 \\ 0 & \text { if } p q=0\end{cases}
$$

Fix a line $p+q=n$, and on this line pick $\left(p_{0}, q_{0}\right)$ the point that maximizes the value of h. Because

$$
h\left(p_{0}, q_{0}\right)=\frac{1}{2}\left(h\left(p_{0}+1, q_{0}-1\right)+h\left(p_{0}-1, q_{0}+1\right)\right),
$$

it follows that $h\left(p_{0}+1, q_{0}-1\right)=h\left(p_{0}-1, q_{0}+1\right)=h\left(p_{0}, q_{0}\right)$. Shifting the point, we eventually conclude that $h$ is constant on the line $p+q=n$, and its value is equal to $h(n, 0)=0$. Since $n$ was arbitrary, we see that $h$ is identically equal to 0 . Therefore, $f_{1}=$ $f_{2}$, the problem has a unique solution, and this solution is $f(p, q)=p q, p, q \geq 0$.

And now an example of a problem about a multivariable function, from the same short list, submitted by B. Enescu (Romania). Example. Let $x_{1}, x_{2}, \ldots, x_{n}$ be arbitrary real numbers. Prove the inequality

$$
\frac{x_{1}}{1+x_{1}^{2}}+\frac{x_{2}}{1+x_{1}^{2}+x_{2}^{2}}+\cdots+\frac{x_{n}}{1+x_{1}^{2}+\cdots+x_{n}^{2}}<\sqrt{n} .
$$

Solution. We introduce the function

$$
f_{n}\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\frac{x_{1}}{1+x_{1}^{2}}+\frac{x_{2}}{1+x_{1}^{2}+x_{2}^{2}}+\cdots+\frac{x_{n}}{1+x_{1}^{2}+\cdots+x_{n}^{2}} .
$$

If we set $r=\sqrt{1+x_{1}^{2}}$, then

$$
\begin{aligned}
f_{n}\left(x_{1}, x_{2}, \ldots, x_{n}\right) &=\frac{x_{1}}{r^{2}}+\frac{x_{2}}{r^{2}+x_{2}^{2}}+\cdots+\frac{x_{n}}{r^{2}+x_{2}^{2}+\cdots+x_{n}^{2}} \\
&=\frac{x_{1}}{r^{2}}+\frac{1}{r}\left(\frac{\frac{x_{2}}{r}}{1+\left(\frac{x_{2}}{r}\right)^{2}}+\cdots+\frac{\frac{x_{n}}{r}}{1+\left(\frac{x_{2}}{r}\right)^{2}+\cdots+\left(\frac{x_{n}}{r}\right)^{2}}\right) .
\end{aligned}
$$

We obtain the functional equation

$$
f_{n}\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\frac{x_{1}}{1+x_{1}^{2}}+\frac{1}{\sqrt{1+x_{1}^{2}}} f_{n-1}\left(\frac{x_{2}}{r}, \frac{x_{3}}{r}, \ldots, \frac{x_{n}}{r}\right) .
$$

Writing $M_{n}=\sup f_{n}\left(x_{1}, x_{2}, \ldots, x_{n}\right)$, we observe that the functional equation gives rise to the recurrence relation

$$
M_{n}=\sup _{x_{1}}\left(\frac{x_{1}}{1+x_{1}^{2}}+\frac{M_{n-1}}{\sqrt{1+x_{1}^{2}}}\right) .
$$

We will now prove by induction that $M_{n}<\sqrt{n}$. For $n=1$, this follows from $\frac{x_{1}}{1+x_{1}^{2}} \leq$ $\frac{1}{2}<1$. Assume that the property is true for $k$ and let us prove it for $k+1$. From the induction hypothesis, we obtain

$$
M_{k}<\sup _{x_{1}}\left(\frac{x_{1}}{1+x_{1}^{2}}+\frac{\sqrt{k}}{\sqrt{1+x_{1}^{2}}}\right) .
$$

We need to show that the right-hand side of the inequality is less than or equal to $\sqrt{k+1}$. Rewrite the desired inequality as

$$
\frac{x}{\sqrt{1+x^{2}}}+\sqrt{k} \leq \sqrt{k+k x^{2}+1+x^{2}} .
$$

Increase the left-hand side to $x+\sqrt{k}$; then square both sides. We obtain

$$
x^{2}+k+2 x \sqrt{k} \leq k+k x^{2}+1+x^{2},
$$

which reduces to $0 \leq(x \sqrt{k}-1)^{2}$, and this is obvious. The induction is now complete.

535. Find all functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying

$$
f\left(x^{2}-y^{2}\right)=(x-y)(f(x)+f(y)) .
$$

536. Find all complex-valued functions of a complex variable satisfying

$$
f(z)+z f(1-z)=1+z, \quad \text { for all } z .
$$

537. Find all functions $f: \mathbb{R} \backslash\{1\} \rightarrow \mathbb{R}$, continuous at 0 , that satisfy

$$
f(x)=f\left(\frac{x}{1-x}\right), \quad \text { for } x \in \mathbb{R} \backslash\{1\} .
$$

538. Find all functions $f: \mathbb{R} \rightarrow \mathbb{R}$ that satisfy the inequality

$$
f(x+y)+f(y+z)+f(z+x) \geq 3 f(x+2 y+3 z)
$$

for all $x, y, z \in \mathbb{R}$.

539. Does there exist a function $f: \mathbb{R} \rightarrow \mathbb{R}$ such that $f(f(x))=x^{2}-2$ for all real numbers $x$ ?

540. Find all functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying

$$
f(x+y)=f(x) f(y)-c \sin x \sin y,
$$

for all real numbers $x$ and $y$, where $c$ is a constant greater than 1 .

541. Let $f$ and $g$ be real-valued functions defined for all real numbers and satisfying the functional equation

$$
f(x+y)+f(x-y)=2 f(x) g(y)
$$

for all $x$ and $y$. Prove that if $f(x)$ is not identically zero, and if $|f(x)| \leq 1$ for all $x$, then $|g(y)| \leq 1$ for all $y$.

542. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ that satisfy the relation

$$
3 f(2 x+1)=f(x)+5 x, \quad \text { for all } x .
$$

543. Find all functions $f:(0, \infty) \rightarrow(0, \infty)$ subject to the conditions

(i) $f(f(f(x)))+2 x=f(3 x)$, for all $x>0$;

(ii) $\lim _{x \rightarrow \infty}(f(x)-x)=0$.

544. Suppose that $f, g: \mathbb{R} \rightarrow \mathbb{R}$ satisfy the functional equation

$$
g(x-y)=g(x) g(y)+f(x) f(y)
$$

for $x$ and $y$ in $\mathbb{R}$, and that $f(t)=1$ and $g(t)=0$ for some $t \neq 0$. Prove that $f$ and $g$ satisfy

$$
g(x+y)=g(x) g(y)-f(x) f(y)
$$

and

$$
f(x \pm y)=f(x) g(y) \pm g(x) f(y)
$$

for all real $x$ and $y$.

A famous functional equation, which carries the name of Cauchy, is

$$
f(x+y)=f(x)+f(y) .
$$

We are looking for solutions $f: \mathbb{R} \rightarrow \mathbb{R}$.

It is straightforward that $f(2 x)=2 f(x)$, and inductively $f(n x)=n f(x)$. Setting $y=n x$, we obtain $f\left(\frac{1}{n} y\right)=\frac{1}{n} f(y)$. In general, if $m, n$ are positive integers, then $f\left(\frac{m}{n}\right)=m f\left(\frac{1}{n}\right)=\frac{m}{n} f(1)$.

On the other hand, $f(0)=f(0)+f(0)$ implies $f(0)=0$, and $0=f(0)=$ $f(x)+f(-x)$ implies $f(-x)=-f(x)$. We conclude that for any rational number $x$, $f(x)=f(1) x$.

If $f$ is continuous, then the linear functions of the form

$$
f(x)=c x,
$$

where $c \in \mathbb{R}$, are the only solutions. That is because a solution is linear when restricted to rational numbers and therefore must be linear on the whole real axis. Even if we assume the solution $f$ to be continuous at just one point, it still is linear. Indeed, because $f(x+y)$ is the translate of $f(x)$ by $f(y), f$ must be continuous everywhere.

But if we do not assume continuity, the situation is more complicated. In set theory there is an independent statement called the axiom of choice, which postulates that given a family of nonempty sets $\left(A_{i}\right)_{i \in I}$, there is a function $f: I \rightarrow \cup_{i} A_{i}$ with $f(i) \in A_{i}$. In other words, it is possible to select one element from each set.

Real numbers form an infinite-dimensional vector space over the rational numbers (vectors are real numbers, scalars are rational numbers). A corollary of the axiom of choice (Zorn's lemma) implies the existence of a basis for this vector space. If $\left(e_{i}\right)_{i \in I}$ is this basis, then any real number $x$ can be expressed uniquely as

$$
x=r_{1} e_{i_{1}}+r_{2} e_{i_{2}}+\cdots+r_{n} e_{i_{n}},
$$

where $r_{1}, r_{2}, \ldots, r_{n}$ are nonzero rational numbers. To obtain a solution to Cauchy's equation, make any choice for $f\left(e_{i}\right), i \in I$, and then extend $f$ to all reals in such a way that it is linear over the rationals. Most of these functions are discontinuous. As an example, for a basis that contains the real number 1 , set $f(1)=1$ and $f\left(e_{i}\right)=0$ for all other basis elements. Then this function is not continuous.

The problems below are all about Cauchy's equation for continuous functions.

545. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous nonzero function, satisfying the equation

$$
f(x+y)=f(x) f(y), \quad \text { for all } x, y \in \mathbb{R} .
$$

Prove that there exists $c>0$ such that $f(x)=c^{x}$ for all $x \in \mathbb{R}$.

546. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying

$$
f(x+y)=f(x)+f(y)+f(x) f(y), \quad \text { for all } x, y \in \mathbb{R} .
$$

547. Determine all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying

$$
f(x+y)=\frac{f(x)+f(y)}{1+f(x) f(y)}, \quad \text { for all } x, y \in \mathbb{R} .
$$

548. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying the condition

$$
f(x y)=x f(y)+y f(x), \quad \text { for all } x, y \in \mathbb{R} .
$$

549. Find the continuous functions $\phi, f, g, h: \mathbb{R} \rightarrow \mathbb{R}$ satisfying

$$
\phi(x+y+z)=f(x)+g(y)+h(z),
$$

for all real numbers $x, y, z$.

550. Given a positive integer $n \geq 2$, find the continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$, with the property that for any real numbers $x_{1}, x_{2}, \ldots, x_{n}$,

$$
\begin{aligned}
\sum_{i} f\left(x_{i}\right) &-\sum_{i<j} f\left(x_{i}+x_{j}\right)+\sum_{i<j<k} f\left(x_{i}+x_{j}+x_{k}\right)+\cdots \\
&+(-1)^{n-1} f\left(x_{1}+x_{2}+\cdots+x_{n}\right)=0 .
\end{aligned}
$$

We conclude our discussion about functional equations with another instance in which continuity is important. The intermediate value property implies that a one-to-one continuous function is automatically monotonic. So if we can read from a functional equation that a function, which is assumed to be continuous, is also one-to-one, then we know that the function is monotonic, a much more powerful property to be used in the solution.

Example. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying $(f \circ f \circ f)(x)=x$ for all $x \in \mathbb{R}$.

Solution. For any $x \in \mathbb{R}$, the image of $f(f(x))$ through $f$ is $x$. This shows that $f$ is onto. Also, if $f\left(x_{1}\right)=f\left(x_{2}\right)$ then $x_{1}=f\left(f\left(f\left(x_{1}\right)\right)\right)=f\left(f\left(f\left(x_{2}\right)\right)\right)=x_{2}$, which shows that $f$ is one-to-one. Therefore, $f$ is a continuous bijection, so it must be strictly monotonic. If $f$ is decreasing, then $f \circ f$ is increasing and $f \circ f \circ f$ is decreasing, contradicting the hypothesis. Therefore, $f$ is strictly increasing.

Fix $x$ and let us compare $f(x)$ and $x$. There are three possibilities. First, we could have $f(x)>x$. Monotonicity implies $f(f(x))>f(x)>x$, and applying $f$ again, we have $x=f(f(f(x)))>f(f(x))>f(x)>x$, impossible. Or we could have $f(x)<x$, which then implies $f(f(x))<f(x)<x$, and $x=f(f(f(x)))<f(f(x))<f(x)<$ $x$, which again is impossible. Therefore, $f(x)=x$. Since $x$ was arbitrary, this shows that the unique solution to the functional equation is the identity function $f(x)=x$.

551. Do there exist continuous functions $f, g: \mathbb{R} \rightarrow \mathbb{R}$ such that $f(g(x))=x^{2}$ and $g(f(x))=x^{3}$ for all $x \in \mathbb{R} ?$

552. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ with the property that

$$
f(f(x))-2 f(x)+x=0, \quad \text { for all } x \in \mathbb{R} .
$$

\subsubsection{Ordinary Differential Equations of the First Order}

Of far greater importance than functional equations are the differential equations, because practically every evolutionary phenomenon of the real world can be modeled by a differential equation. This section is about first-order ordinary differential equations, namely equations expressed in terms of an unknown one-variable function, its derivative, and the variable. In their most general form, they are written as $F\left(x, y, y^{\prime}\right)=0$, but we will be concerned with only two classes of such equations: separable and exact.

An equation is called separable if it is of the form $\frac{d y}{d x}=f(x) g(y)$. In this case we formally separate the variables and write

$$
\int \frac{d y}{g(y)}=\int f(x) d x .
$$

After integration, we obtain the solution in implicit form, as an algebraic relation between $x$ and $y$. Here is a problem of I.V. Maftei from the 1971 Romanian Mathematical Olympiad that applies this method. Example. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying the equation

$$
f(x)=\lambda\left(1+x^{2}\right)\left[1+\int_{0}^{x} \frac{f(t)}{1+t^{2}} d t\right],
$$

for all $x \in \mathbb{R}$. Here $\lambda$ is a fixed real number.

Solution. Because $f$ is continuous, the right-hand side of the functional equation is a differentiable function; hence $f$ itself is differentiable. Rewrite the equation as

$$
\frac{f(x)}{1+x^{2}}=\lambda\left[1+\int_{0}^{x} \frac{f(t)}{1+t^{2}} d t\right],
$$

and then differentiate with respect to $x$ to obtain

$$
\frac{f^{\prime}(x)\left(1+x^{2}\right)-f(x) 2 x}{\left(1+x^{2}\right)^{2}}=\lambda \frac{f(x)}{1+x^{2}} .
$$

We can separate the variables to obtain

$$
\frac{f^{\prime}(x)}{f(x)}=\lambda+\frac{2 x}{1+x^{2}},
$$

which, by integration, yields

$$
\ln f(x)=\lambda x+\ln \left(1+x^{2}\right)+c .
$$

Hence $f(x)=a\left(1+x^{2}\right) e^{\lambda x}$ for some constant $a$. Substituting in the original relation, we obtain $a=\lambda$. Therefore, the equation from the statement has the unique solution

$$
f(x)=\lambda\left(1+x^{2}\right) e^{\lambda x} .
$$

A first-order differential equation can be written formally as

$$
p(x, y) d x+q(x, y) d y=0 .
$$

Physicists think of the expression on the left as the potential of a two-dimensional force field, with $p$ and $q$ the $x$ and $y$ components of the potential. Mathematicians call this expression a 1-form. The force field is called conservative if no energy is wasted in moving an object along any closed path. In this case the differential equation is called exact. As a consequence of Green's theorem, the field is conservative precisely when the exterior derivative

$$
\left(\frac{\partial q}{\partial x}-\frac{\partial p}{\partial y}\right) d x d y
$$

is equal to zero. For functions defined on the entire two-dimensional plane, the field is conservative if and only if it has a scalar potential. This means that there exists a scalar function $u(x, y)$ whose differential is the field, i.e.,

$$
\frac{\partial u}{\partial x}=p(x, y) \quad \text { and } \quad \frac{\partial u}{\partial y}=q(x, y) .
$$

For a conservative field, the scalar potential solves the differential equation, giving the solution in implicit form as $u(x, y)=C$, with $C$ a constant. Let us apply this method to a problem by the first author of the book.

Example. Does there exist a differentiable function $y$ defined on the entire real axis that satisfies the differential equation

$$
\left(2 x+y-e^{-x^{2}}\right) d x+\left(x+2 y-e^{-y^{2}}\right) d y=0 ?
$$

Solution. Let us assume that such a $y$ does exist. Because

$$
\frac{\partial}{\partial x}\left(x+2 y-e^{-y^{2}}\right)=\frac{\partial}{\partial y}\left(2 x+y-e^{-x^{2}}\right),
$$

the equation can be integrated. The potential function is

$$
u(x, y)=x^{2}+x y+y^{2}-\int_{0}^{x} e^{-s^{2}} d s-\int_{0}^{y} e^{-t^{2}} d t .
$$

The differential equation translates into the algebraic equation

$$
\left(x+\frac{1}{2} y\right)^{2}+\frac{3}{4} y^{2}=\int_{0}^{x} e^{-s^{2}} d s+\int_{0}^{y} e^{-t^{2}} d t+C
$$

for some real constant $C$. The right-hand side is bounded from above by $\sqrt{8 \pi}+C$ (note the Gaussian integrals). This means that both squares on the left must be bounded. In particular, $y$ is bounded, but then $x+\frac{1}{2} y$ is unbounded, a contradiction. Hence the answer to the question is no; a solution can exist only on a bounded interval.

Sometimes the field is not conservative but becomes conservative after the differential equation is multiplied by a function. This function is called an integrating factor. There is a standard method for finding integrating factors, which can be found in any textbook. In particular, any first-order linear equation

$$
y^{\prime}+p(x) y=q(x)
$$

can be integrated after it is multiplied by the integrating factor $\exp \left(\int p(x) d x\right)$.

It is now time for problems. 

553. A not uncommon mistake is to believe that the product rule for derivatives says that $(f g)^{\prime}=f^{\prime} g^{\prime}$. If $f(x)=e^{x^{2}}$, determine whether there exists an open interval $(a, b)$ and a nonzero function $g$ defined on $(a, b)$ such that this wrong product rule is true for $f$ and $g$ on $(a, b)$.

554. Find the functions $f, g: \mathbb{R} \rightarrow \mathbb{R}$ with continuous derivatives satisfying

$$
f^{2}+g^{2}=f^{\prime 2}+g^{\prime 2}, \quad f+g=g^{\prime}-f^{\prime},
$$

and such that the equation $f=g$ has two real solutions, the smaller of them being zero.

555. Let $f$ and $g$ be differentiable functions on the real line satisfying the equation

$$
\left(f^{2}+g^{2}\right) f^{\prime}+(f g) g^{\prime}=0 .
$$

Prove that $f$ is bounded.

556. Let $A, B, C, D, m, n$ be real numbers with $A D-B C \neq 0$. Solve the differential equation

$$
y\left(B+C x^{m} y^{n}\right) d x+x\left(A+D x^{m} y^{n}\right) d y=0 .
$$

557. Find all continuously differentiable functions $y:(0, \infty) \rightarrow(0, \infty)$ that are solutions to the initial value problem

$$
y^{y^{\prime}}=x, \quad y(1)=1 .
$$

558. Find all differentiable functions $f:(0, \infty) \rightarrow(0, \infty)$ for which there is a positive real number $a$ such that

$$
f^{\prime}\left(\frac{a}{x}\right)=\frac{x}{f(x)},
$$

for all $x>0$.

559. Prove that if the function $f(x, y)$ is continuously differentiable on the whole $x y$ plane and satisfies the equation

$$
\frac{\partial f}{\partial x}+f \frac{\partial f}{\partial y}=0,
$$

then $f(x, y)$ is constant. 

\subsubsection{Ordinary Differential Equations of Higher Order}

The field of higher-order ordinary differential equations is vast, and we assume that you are familiar at least with some of its techniques. In particular, we assume you are familiar with the theory of linear equations with fixed coefficients, from which we recall some basic facts. A linear equation with fixed coefficients has the general form

$$
a_{n} \frac{d^{n} y}{d x^{n}}+\cdots+a_{2} \frac{d^{2} y}{d x^{2}}+a_{1} \frac{d y}{d x}+a_{0}=f(x) .
$$

If $f$ is zero, the equation is called homogeneous. Otherwise, the equation is called inhomogeneous. In this case the general solution is found using the characteristic equation

$$
a_{n} \lambda^{n}+a_{n-1} \lambda^{n-1}+\cdots+a_{0}=0 .
$$

If $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{r}$ are the distinct roots, real or complex, of this equation, then the general solution to the homogeneous differential equation is of the form

$$
y(x)=P_{1}(x) e^{\lambda_{1} x}+P_{2}(x) e^{\lambda_{2} x}+\cdots+P_{r}(x) e^{\lambda_{r} x},
$$

where $P_{i}(x)$ is a polynomial of degree one less than the multiplicity of $\lambda_{i}, i=1,2, \ldots, r$. If the exponents are complex, the exponentials are changed into (damped) oscillations using Euler's formula.

The general solution depends on $n$ parameters (the coefficients of the polynomials), so the space of solutions is an $n$-dimensional vector space $V$. For an inhomogeneous equation, the space of solutions is the affine space $y_{0}+V$ obtained by adding a particular solution. This particular solution is found usually by the method of the variation of the coefficients.

We start with an example that exploits an idea that appeared once on a Putnam exam.

Example. Solve the system of differential equations

$$
\begin{aligned}
&x^{\prime \prime}-y^{\prime}+x=0, \\
&y^{\prime \prime}+x^{\prime}+y=0
\end{aligned}
$$

in real-valued functions $x(t)$ and $y(t)$.

Solution. Multiply the second equation by $i$ then add it to the first to obtain

$$
(x+i y)^{\prime \prime}+i(x+i y)^{\prime}+(x+i y)=0 .
$$

With the substitution $z=x+i y$ this becomes the second-order homogeneous linear differential equation $z^{\prime \prime}+i z^{\prime}+z=0$. The characteristic equation is $\lambda^{2}+i \lambda+1=0$, with solutions $\lambda_{1,2}=\frac{-1 \pm \sqrt{5}}{2} i$. We find the general solution to the equation 

$$
z(t)=(a+i b) \exp \left(\frac{-1+\sqrt{5}}{2} i t\right)+(c+i d) \exp \left(\frac{-1-\sqrt{5}}{2} i t\right),
$$

for arbitrary real numbers $a, b, c, d$. Since $x$ and $y$ are, respectively, the real and complex parts of the solution, they have the general form

$$
\begin{aligned}
&x(t)=a \cos \frac{-1+\sqrt{5}}{2} t-b \sin \frac{-1+\sqrt{5}}{2} t+c \cos \frac{-1-\sqrt{5}}{2} t-d \sin \frac{-1-\sqrt{5}}{2} t, \\
&y(t)=a \sin \frac{-1+\sqrt{5}}{2} t+b \cos \frac{-1+\sqrt{5}}{2} t+c \sin \frac{-1-\sqrt{5}}{2} t+d \cos \frac{-1-\sqrt{5}}{2} t .
\end{aligned}
$$

The problem is solved.

Our second example is an equation published by M. Ghermănescu in the Mathematics Gazette, Bucharest. Its solution combines several useful techniques.

Example. Solve the differential equation

$$
2\left(y^{\prime}\right)^{3}-y y^{\prime} y^{\prime \prime}-y^{2} y^{\prime \prime \prime}=0 .
$$

Solution. In a situation like this, where the variable $x$ does not appear explicitly, one can reduce the order of the equation by taking $y$ as the variable and $p=y^{\prime}$ as the function. The higher-order derivatives of $y^{\prime \prime}$ are

$$
\begin{aligned}
& y^{\prime \prime}=\frac{d}{d x} y^{\prime}=\frac{d}{d y} p \frac{d y}{d x}=p^{\prime} p, \\
& y^{\prime \prime \prime}=\frac{d}{d x} y^{\prime \prime}=\left(\frac{d}{d y} p p^{\prime}\right) \frac{d y}{d x}=\left(\left(p^{\prime}\right)^{2}+p p^{\prime \prime}\right) p .
\end{aligned}
$$

We end up with a second-order differential equation

$$
2 p^{3}-y p^{2} p^{\prime}-y^{2} p p^{\prime \prime}-y^{2} p\left(p^{\prime}\right)^{2}=0 .
$$

A family of solutions is $p=0$, that is, $y^{\prime}=0$. This family consists of the constant functions $y=C$. Dividing the equation by $-p$, we obtain

$$
y^{2} p^{\prime \prime}+y^{2}\left(p^{\prime}\right)^{2}+y p p^{\prime}-2 p^{2}=0 .
$$

The distribution of the powers of $y$ reminds us of the Euler-Cauchy equation, while the last terms suggests the substitution $u=p^{2}$. And indeed, we obtain the Euler-Cauchy equation

$$
y^{2} u^{\prime \prime}+y u^{\prime}-4 u=0,
$$

with general solution $u=C_{1} y^{2}+C_{2} y^{-2}$. Remember that $u=p^{2}=\left(y^{\prime}\right)^{2}$, from which we obtain the first-order differential equation

$$
y^{\prime}=\pm \sqrt{C_{1} y^{2}+C_{2} y^{-2}}=\frac{\sqrt{C_{1} y^{4}+C_{2}}}{y} .
$$

This we solve by separation of variables

$$
d x=\pm \frac{y d y}{\sqrt{C_{1} y^{4}+C_{2}}},
$$

which after integration gives

$$
x=\pm \int \frac{y d y}{\sqrt{C_{1} y^{4}+C_{2}}}=\pm \frac{1}{2} \int \frac{d z}{\sqrt{C_{1} z^{2}+C_{2}}} .
$$

This last integral is standard; it is equal to $\frac{1}{2 \sqrt{C_{1}}} \ln \left|y+\sqrt{y^{2}+C_{2} / C_{1}}\right|$ if $C_{1}>0$ and to $\frac{1}{2 \sqrt{\left|C_{1}\right|}} \arcsin \left(\frac{\left|C_{1}\right| y}{C_{2}}\right)$ if $C_{1}<0$ and $C_{2}>0$. We obtain two other families of solutions given in implicit form by

$$
x=\pm \frac{1}{2 \sqrt{C_{1}}} \ln \left|y+\sqrt{y^{2}+\frac{C_{2}}{C_{1}}}\right|+C_{3} \quad \text { and } \quad x=\pm \frac{1}{2 \sqrt{-C_{1}}} \arcsin \frac{\left|C_{1}\right| y}{C_{2}}+C_{3},
$$

that is,

$$
x=A \ln \left|y+\sqrt{y^{2}+B}\right|+C \quad \text { and } \quad x=E \arcsin F y+G .
$$

Here are more problems.

560. Solve the differential equation

$$
x y^{\prime \prime}+2 y^{\prime}+x y=0 .
$$

561. Find all twice-differentiable functions defined on the entire real axis that satisfy $f^{\prime}(x) f^{\prime \prime}(x)=0$ for all $x$.

562. Find all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ that satisfy

$$
f(x)+\int_{0}^{x}(x-t) f(t) d t=1, \quad \text { for all } x \in \mathbb{R} .
$$

563. Solve the differential equation

$$
(x-1) y^{\prime \prime}+(4 x-5) y^{\prime}+(4 x-6) y=x e^{-2 x} .
$$

564. Let $n$ be a positive integer. Show that the equation

$$
\left(1-x^{2}\right) y^{\prime \prime}-x y^{\prime}+n^{2} y=0
$$

admits as a particular solution an $n$ th-degree polynomial.

565. Find the one-to-one, twice-differentiable solutions $y$ to the equation

$$
\frac{d^{2} y}{d x^{2}}+\frac{d^{2} x}{d y^{2}}=0 .
$$

566. Show that all solutions to the differential equation $y^{\prime \prime}+e^{x} y=0$ remain bounded as $x \rightarrow \infty$.

\subsubsection{Problems Solved with Techniques of Differential Equations}

In this section we illustrate how tricks of differential equations can offer inspiration when one is tackling problems from outside this field.

Example. Let $f:[0, \infty) \rightarrow \mathbb{R}$ be a twice-differentiable function satisfying $f(0) \geq 0$ and $f^{\prime}(x)>f(x)$ for all $x>0$. Prove that $f(x)>0$ for all $x>0$.

Solution. To solve this problem we use an integrating factor. The inequality

$$
f^{\prime}(x)-f(x)>0
$$

can be "integrated" after being multiplied by $e^{-x}$. It simply says that the derivative of the function $e^{-x} f(x)$ is strictly positive on $(0, \infty)$. This function is therefore strictly increasing on $[0, \infty)$. So for $x>0$ we have $e^{-x} f(x)>e^{-0} f(0)=f(0) \geq 0$, which then implies $f(x)>0$, as desired.

Example. Compute the integral

$$
y(x)=\int_{0}^{\infty} e^{-t^{2} / 2} \cos \frac{x^{2}}{2 t^{2}} d t .
$$

Solution. We will show that the function $y(x)$ satisfies the ordinary differential equation $y^{i v}+y=0$. To this end, we compute

$$
y^{\prime}(x)=\int_{0}^{\infty} e^{-t^{2} / 2} \sin \frac{x^{2}}{2 t^{2}} \cdot \frac{-x}{t^{2}} d t=-\int_{0}^{\infty} e^{-x^{2} / 2 u^{2}} \sin \frac{u^{2}}{2} d u
$$

and

$$
y^{\prime \prime}(x)=-\int_{0}^{\infty} e^{-x^{2} / 2 u^{2}} \sin \frac{u^{2}}{2} \cdot \frac{-x}{u^{2}} d u=\int_{0}^{\infty} e^{-t^{2} / 2} \sin \frac{x^{2}}{2 t^{2}} d t .
$$

Iterating, we eventually obtain

$$
y^{i v}(x)=-\int_{0}^{\infty} e^{-t^{2} / 2} \cos \frac{x^{2}}{2 t^{2}} d t=-y(x),
$$

which proves that indeed $y$ satisfies the differential equation $y^{i v}+y=0$. The general solution to this differential equation is

$$
y(x)=e^{\frac{x}{\sqrt{2}}}\left(C_{1} \cos \frac{x}{\sqrt{2}}+C_{2} \sin \frac{x}{\sqrt{2}}\right)+e^{-\frac{x}{\sqrt{2}}}\left(C_{3} \cos \frac{x}{\sqrt{2}}+C_{4} \sin \frac{x}{\sqrt{2}}\right) .
$$

To find which particular solution is the integral in question, we look at boundary values. To compute these boundary values we refer to Section 3.3.2, the one on multivariable integral calculus. We recognize that $y(0)=\int_{0}^{\infty} e^{-t^{2} / 2} d t$ is a Gaussian integral equal to $\sqrt{\frac{\pi}{2}}, y^{\prime}(0)=-\int_{0}^{\infty} \sin \frac{u^{2}}{2} d u$ is a Fresnel integral equal to $-\frac{\sqrt{\pi}}{2}, y^{\prime \prime}(0)=0$, while $y^{\prime \prime \prime}(0)=\int_{0}^{\infty} \cos \frac{u^{2}}{2} d u$ is yet another Fresnel integral equal to $\frac{\sqrt{\pi}}{2}$. We find that $C_{1}=$ $C_{2}=C_{4}=0$ and $C_{3}=\sqrt{\frac{\pi}{2}}$. The value of the integral from the statement is therefore

$$
y(x)=\sqrt{\frac{\pi}{2}} e^{-\frac{x}{\sqrt{2}}} \cos \frac{x}{\sqrt{2}} .
$$

An alternative approach is to view the integral as the real part of a (complex) Gaussian integral.

We leave the following examples to the reader.

567. Show that both functions

$$
y_{1}(x)=\int_{0}^{\infty} \frac{e^{-t x}}{1+t^{2}} d t \quad \text { and } \quad y_{2}(x)=\int_{0}^{\infty} \frac{\sin t}{t+x} d t
$$

satisfy the differential equation $y^{\prime \prime}+y=\frac{1}{x}$. Prove that these two functions are equal.

568. Let $f$ be a real-valued continuous nonnegative function on $[0,1]$ such that

$$
f(t)^{2} \leq 1+2 \int_{0}^{t} f(s) d s, \quad \text { for all } t \in[0,1] .
$$

Show that $f(t) \leq 1+t$ for every $t \in[0,1]$.

569. Let $f:[0,1] \rightarrow \mathbb{R}$ be a continuous function with $f(0)=f(1)=0$. Assume that $f^{\prime \prime}$ exists on $(0,1)$ and $f^{\prime \prime}(x)+2 f^{\prime}(x)+f(x) \geq 0$ for all $x \in(0,1)$. Prove that $f(x) \leq 0$ for all $x \in[0,1]$.

570. Does there exist a continuously differentiable function $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfying $f(x)>0$ and $f^{\prime}(x)=f(f(x))$ for every $x \in \mathbb{R}$ ? 

571. Determine all $n$ th-degree polynomials $P(x)$, with real zeros, for which the equality

$$
\sum_{i=1}^{n} \frac{1}{P(x)-x_{i}}=\frac{n^{2}}{x P^{\prime}(x)}
$$

holds for all nonzero real numbers $x$ for which $P^{\prime}(x) \neq 0$, where $x_{i}, i=1,2, \ldots, n$, are the zeros of $P(x)$.

572. Let $C$ be the class of all real-valued continuously differentiable functions $f$ on the interval $[0,1]$ with $f(0)=0$ and $f(1)=1$. Determine

$$
u=\inf _{f \in C} \int_{0}^{1}\left|f^{\prime}(x)-f(x)\right| d x .
$$



\section{Geometry and Trigonometry}

Geometry is the oldest of the mathematical sciences. Its age-old theorems and the sharp logic of its proofs make you think of the words of Andrew Wiles, "Mathematics seems to have a permanence that nothing else has."

This chapter is bound to take you away from the geometry of the ancients, with figures and pictorial intuition, and bring you to the science of numbers and equations that geometry has become today. In a dense exposition we have packed vectors and their applications, analytical geometry in the plane and in space, some applications of integral calculus to geometry, followed by a list of problems with Euclidean flavor but based on algebraic and combinatorial ideas. Special attention is given to conics and quadrics, for their study already contains the germs of differential and algebraic geometry.

Four subsections are devoted to geometry's little sister, trigonometry. We insist on trigonometric identities, repeated in subsequent sections from different perspectives: Euler's formula, trigonometric substitutions, and telescopic summation and multiplication.

Since geometry lies at the foundation of mathematics, its presence could already be felt in the sections on linear algebra and multivariable calculus. It will resurface again in the chapter on combinatorics.

\subsection{Geometry}

\subsubsection{Vectors}

This section is about vectors in two and three dimensions. Vectors are oriented segments identified under translation.

There are four operations defined for vectors: scalar multiplication $\alpha \vec{v}$, addition $\vec{v}+\vec{w}$, dot product $\vec{v} \cdot \vec{w}$, and cross-product $\vec{v} \times \vec{w}$, the last being defined only in three dimensions. Scalar multiplication dilates or contracts a vector by a scalar. The sum of two vectors is computed with the parallelogram rule; it is the resultant of the vectors acting as forces on an object. The dot product of two vectors is a number equal to the product of the magnitudes of the vectors and the cosine of the angle between them. A dot product equal to zero tells us that the vectors are orthogonal. The cross-product of two vectors is a vector orthogonal to the two vectors and of magnitude equal to the area of the parallelogram they generate. The orientation of the cross-product is determined by the right-hand rule: place your hand so that you can bend your palm from the first vector to the second, and your thumb will point in the direction of the cross-product. A cross-product equal to zero tells us that the vectors are parallel (although they might point in opposite directions).

The dot and cross-products are distributive with respect to sum; the dot product is commutative, while the cross-product is not. For the three-dimensional vectors $\vec{u}, \vec{v}, \vec{w}$, the number $\vec{u} \cdot(\vec{v} \times \vec{w})$ is the volume taken with sign of the parallelepiped constructed with the vectors as edges. The sign is positive if the three vectors determine a frame that is oriented the same way as the orthogonal frame of the three coordinate axes, and negative otherwise. Equivalently, $\vec{u} \cdot(\vec{v} \times \vec{w})$ is the determinant with the coordinates of the three vectors as rows.

A useful computational tool is the $c a b-b a c$ identity:

$$
\vec{a} \times(\vec{b} \times \vec{c})=(\vec{c} \cdot \vec{a}) \vec{b}-(\vec{b} \cdot \vec{a}) \vec{c} .
$$

The quickest way to prove it is to check it for $\vec{a}, \vec{b}, \vec{c}$ chosen among the three unit vectors parallel to the coordinate axes $\vec{i}, \vec{j}$, and $\vec{k}$, and then use the distributivity of the cross-product with respect to addition. Here is an easy application of this identity. Example. Prove that for any vectors $\vec{a}, \vec{b}, \vec{c}, \vec{d}$

$$
(\vec{a} \times \vec{b}) \times(\vec{c} \times \vec{d})=(\vec{a} \cdot(\vec{b} \times \vec{d})) \vec{c}-(\vec{a} \cdot(\vec{b} \times \vec{c})) \vec{d}
$$

Solution. We have

$$
\begin{aligned}
(\vec{a} \times \vec{b}) \times(\vec{c} \times \vec{d}) &=(\vec{d} \cdot(\vec{a} \times \vec{b})) \vec{c}-(\vec{c} \cdot(\vec{a} \times \vec{b})) \vec{d} \\
&=(\vec{a} \cdot(\vec{b} \times \vec{d})) \vec{c}-(\vec{a} \cdot(\vec{b} \times \vec{c})) \vec{d} .
\end{aligned}
$$

In the computation we used the equality $\vec{u} \cdot(\vec{v} \times \vec{w})=\vec{w} \cdot(\vec{u} \times \vec{v})$, which is straightforward if we write these as determinants.

Let us briefly point out a fundamental algebraic property of the cross-product. Denote by so(3) the set of $3 \times 3$ matrices $A$ satisfying $A+A^{t}=\mathcal{O}_{3}$ endowed with the operation $[A, B]=A B-B A$.

Theorem. The map

$$
\left(a_{1}, a_{2}, a_{3}\right) \rightarrow\left(\begin{array}{ccc}
0 & -a_{1} & -a_{2} \\
a_{1} & 0 & -a_{3} \\
a_{2} & a_{3} & 0
\end{array}\right)
$$

establishes an isomorphism between $\left(\mathbb{R}^{3}, \times\right)$ and $(\operatorname{so}(3),[\cdot, \cdot])$.

Proof. The proof is straightforward if we write the cross-product in coordinates. The result shows that the cross-product defines a Lie algebra structure on the set of threedimensional vectors. Note that the isomorphism maps the sum of vectors to the sum of matrices, and the dot product of two vectors to the negative of half the trace of the product of the corresponding matrices.

And now the problems.

573. For any three-dimensional vectors $\vec{u}, \vec{v}, \vec{w}$, prove the identity

$$
\vec{u} \times(\vec{v} \times \vec{w})+\vec{v} \times(\vec{w} \times \vec{u})+\vec{w} \times(\vec{u} \times \vec{v})=\overrightarrow{0}
$$

574. Given three vectors $\vec{a}, \vec{b}, \vec{c}$, define

$$
\begin{aligned}
&\vec{u}=(\vec{b} \cdot \vec{c}) \vec{a}-(\vec{c} \cdot \vec{a}) \vec{b}, \\
&\vec{v}=(\vec{a} \cdot \vec{c}) \vec{b}-(\vec{a} \cdot \vec{b}) \vec{c}, \\
&\vec{w}=(\vec{b} \cdot \vec{a}) \vec{c}-(\vec{b} \cdot \vec{c}) \vec{a} .
\end{aligned}
$$

Prove that if $\vec{a}, \vec{b}, \vec{c}$ form a triangle, then $\vec{u}, \vec{v}, \vec{w}$ also form a triangle, and this triangle is similar to the first.

575. Let $\vec{a}, \vec{b}, \vec{c}$ be vectors such that $\vec{b}$ and $\vec{c}$ are perpendicular, but $\vec{a}$ and $\vec{b}$ are not. Let $m$ be a real number. Solve the system

$$
\begin{aligned}
\vec{x} \cdot \vec{a} &=m, \\
\vec{x} \times \vec{b} &=\vec{c} .
\end{aligned}
$$

576. Consider three linearly independent vectors $\vec{a}, \vec{b}, \vec{c}$ in space, having the same origin. Prove that the plane determined by the endpoints of the vectors is perpendicular to the vector $\vec{a} \times \vec{b}+\vec{b} \times \vec{c}+\vec{c} \times \vec{a}$

577. The vectors $\vec{a}, \vec{b}$, and $\vec{c}$ satisfy

$$
\vec{a} \times \vec{b}=\vec{b} \times \vec{c}=\vec{c} \times \vec{a} \neq \overrightarrow{0} .
$$

Prove that $\vec{a}+\vec{b}+\vec{c}=\overrightarrow{0}$

578. Find the vector-valued functions $\vec{u}$ (t) satisfying the differential equation

$$
\vec{u} \times \vec{u}^{\prime}=\vec{v},
$$

where $\vec{v}=\vec{v}(t)$ is a twice-differentiable vector-valued function such that both $\vec{v}$ and $\vec{v}^{\prime}$ are never zero or parallel. 

579. Does there exist a bijection $f$ of (a) a plane with itself or (b) three-dimensional space with itself such that for any distinct points $A, B$ the lines $A B$ and $f(A) f(B)$ are perpendicular?

580. On so(3) we define the operation $*$ such that if $A$ and $B$ are matrices corresponding to the vectors $\vec{a}=\left(a_{1}, a_{2}, a_{3}\right)$ and $\vec{b}=\left(b_{1}, b_{2}, b_{3}\right)$, then the $i j$ entry of $A * B$ is equal to $(-1)^{i+j} a_{4-j} b_{4-i}$. Prove the identity

$$
C B A-B C A=(A * C) B-(A * B) C .
$$

581. Prove that there is a bijection $f$ from $\mathbb{R}^{3}$ to the set su(2) of $2 \times 2$ matrices with complex entries that are skew symmetric and have trace equal to zero such that

$$
f(\vec{v} \times \vec{w})=[f(\vec{v}), f(\vec{w})] .
$$

We present two applications of vector calculus to geometry, one with the dot product, one with the cross-product.

Example. Given two triangles $A B C$ and $A^{\prime} B^{\prime} C^{\prime}$ such that the perpendiculars from $A, B, C$ onto $B^{\prime} C^{\prime}, C^{\prime} A^{\prime}, A^{\prime} B^{\prime}$ intersect, show that the perpendiculars from $A^{\prime}, B^{\prime}, C^{\prime}$ onto $B C, C A, A B$ also intersect.

Solution. This is the property of orthological triangles. Denote by $O$ the intersection of the first set of three perpendiculars, and by $O^{\prime}$ the intersection of perpendiculars from $A^{\prime}$ and $B^{\prime}$. Note that if the vector $\overrightarrow{X Y}$ is orthogonal to a vector $\overrightarrow{Z W}$, then for any point $P$ in the plane,

$$
(\overrightarrow{P X}-\overrightarrow{P Y}) \cdot \overrightarrow{Z W}=\overrightarrow{X Y} \cdot \overrightarrow{Z W}=0
$$

hence $\overrightarrow{P X} \cdot \overrightarrow{Z W}=\overrightarrow{P Y} \cdot \overrightarrow{Z W}$. Using this fact we can write

$$
\overrightarrow{O^{\prime} C^{\prime}} \cdot \overrightarrow{O B}=\overrightarrow{O^{\prime} A^{\prime}} \cdot \overrightarrow{O B}=\overrightarrow{O^{\prime} A^{\prime}} \cdot \overrightarrow{O C}=\overrightarrow{O^{\prime} B^{\prime}} \cdot \overrightarrow{O C}=\overrightarrow{O^{\prime} B^{\prime}} \cdot \overrightarrow{O A}=\overrightarrow{O^{\prime} C^{\prime}} \cdot \overrightarrow{O A}
$$

Therefore, $\overrightarrow{O^{\prime} C^{\prime}} \cdot(\overrightarrow{O B}-\overrightarrow{O A})=\overrightarrow{O^{\prime} C^{\prime}} \cdot \overrightarrow{A B}=0$, which shows that $O^{\prime} C^{\prime}$ is perpendicular to $A B$. This proves that the second family of perpendiculars are concurrent.

Example. Let $A B C D$ be a convex quadrilateral, $M, N$ on side $A B$ and $P, Q$ on side $C D$. Show that if $A M=N B$ and $C P=Q D$, and if the quadrilaterals $A M Q D$ and $B N P C$ have the same area, then $A B$ is parallel to $C D$.

Solution. Throughout the solution we refer to Figure 24. We decompose the quadrilaterals into triangles, and then use the formula for the area in terms of the cross-product.

In general, the triangle determined by $\vec{v}_{1}$ and $\overrightarrow{v_{2}}$ has area equal to half the magnitude of $\vec{v}_{1} \times \overrightarrow{v_{2}}$. Note also that $\vec{v}_{1} \times \overrightarrow{v_{2}}$ is perpendicular to the plane of the triangle, so for 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-219.jpg?height=386&width=481&top_left_y=241&top_left_x=627)

Figure 24

a problem in plane geometry there is no danger in identifying the areas with the crossproducts, provided that we keep track of the orientation. The hypothesis of the problem implies that

$$
\frac{1}{2}(\overrightarrow{D A} \times \overrightarrow{D Q}+\overrightarrow{A M} \times \overrightarrow{A Q})=\frac{1}{2}(\overrightarrow{C P} \times \overrightarrow{C B}+\overrightarrow{B P} \times \overrightarrow{B N})
$$

Hence

$$
\overrightarrow{D A} \times \overrightarrow{D Q}+\overrightarrow{A M} \times(\overrightarrow{A D}+\overrightarrow{D Q})=\overrightarrow{C P} \times \overrightarrow{C B}+(\overrightarrow{B C}+\overrightarrow{C P}) \times \overrightarrow{B N}
$$

Because $\overrightarrow{B N}=-\overrightarrow{A M}$ and $\overrightarrow{C P}=-\overrightarrow{D Q}$, this equality can be rewritten as

$$
(\overrightarrow{A M}+\overrightarrow{D Q}) \times(\overrightarrow{A D}+\overrightarrow{C B})=2 \overrightarrow{D Q} \times \overrightarrow{A M}
$$

Using the fact that $\overrightarrow{A D}+\overrightarrow{C B}=\overrightarrow{A B}+\overrightarrow{C D}$ (which follows from $\overrightarrow{A B}+\overrightarrow{B C}+\overrightarrow{C D}+\overrightarrow{D A}=$ $\overrightarrow{0}$ ), we obtain

$$
\overrightarrow{A M} \times \overrightarrow{C D}+\overrightarrow{D Q} \times \overrightarrow{A B}=2 \overrightarrow{D Q} \times \overrightarrow{A M}
$$

From here we deduce that $\overrightarrow{A M} \times \overrightarrow{Q C}=\overrightarrow{D Q} \times \overrightarrow{M B}$. These two cross-products point in opposite directions, so equality can hold only if both are equal to zero, i.e., if $A B$ is parallel to $C D$.

More applications of the dot and cross-products to geometry can be found below.

582. Given two triangles $A B C$ and $A^{\prime} B^{\prime} C^{\prime}$ with the same centroid, prove that one can construct a triangle with sides equal to the segments $A A^{\prime}, B B^{\prime}$, and $C C^{\prime}$.

583. Given a quadrilateral $A B C D$, consider the points $A^{\prime}, B^{\prime}, C^{\prime}, D^{\prime}$ on the half-lines (i.e., rays) $|A B| B C,, \mid C D$, and $\mid D A$, respectively, such that $A B=B A^{\prime}, B C=$ $C B^{\prime}, C D=D C^{\prime}, D A=A D^{\prime}$. Suppose now that we start with the quadrilateral $A^{\prime} B^{\prime} C^{\prime} D^{\prime}$. Using a straightedge and a compass only, reconstruct the quadrilateral $A B C D$ 

584. On the sides of the triangle $A B C$ construct in the exterior the rectangles $A B B_{1} A_{2}$, $B C C_{1} B_{2}, C A A_{1} C_{2}$. Prove that the perpendicular bisectors of $A_{1} A_{2}, B_{1} B_{2}$, and $C_{1} C_{2}$ intersect at one point.

585. Let $A B C D$ be a convex quadrilateral. The lines parallel to $A D$ and $C D$ through the orthocenter $H$ of triangle $A B C$ intersect $A B$ and $B C$, respectively, at $P$ and $Q$. Prove that the perpendicular through $H$ to the line $P Q$ passes through the orthocenter of triangle $A C D$.

586. Prove that if the four lines through the centroids of the four faces of a tetrahedron perpendicular to those faces are concurrent, then the four altitudes of the tetrahedron are also concurrent. Prove that the converse is also true.

587. Let $A B C$ be a convex quadrilateral, $M, N \in A B$ such that $A M=M N=N B$, and $P, Q \in C D$ such that $C P=P Q=Q D$. Let $O$ be the intersection of $A C$ and $B D$. Prove that the triangles $M O P$ and $N O Q$ have the same area.

588. Let $A B C$ be a triangle, with $D$ and $E$ on the respective sides $A C$ and $A B$. If $M$ and $N$ are the midpoints of $B D$ and $C E$, prove that the area of the quadrilateral $B C D E$ is four times the area of the triangle $A M N$.

\subsubsection{The Coordinate Geometry of Lines and Circles}

Coordinate geometry was constructed by Descartes to translate Euclid's geometry into the language of algebra. In two dimensions one starts by fixing two intersecting coordinate axes and a unit on each of them. If the axes are perpendicular and the units are equal, the coordinates are called Cartesian (in the honor of Descartes); otherwise, they are called affine. A general affine change of coordinates has the form

$$
\left(\begin{array}{l}
x^{\prime} \\
y^{\prime}
\end{array}\right)=\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)\left(\begin{array}{l}
x \\
y
\end{array}\right)+\left(\begin{array}{l}
e \\
f
\end{array}\right), \quad \text { with }\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right) \text { invertible. }
$$

If the change is between Cartesian systems of coordinates, a so-called Euclidean change of coordinates, it is required additionally that the matrix

$$
\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)
$$

be orthogonal, meaning that its inverse is equal to the transpose.

Properties that can be formulated in the language of lines and ratios are invariant under affine changes of coordinates. Such are the properties of two lines being parallel or of a point to divide a segment in half. All geometric properties are invariant under Euclidean changes of coordinates. Therefore, problems about distances, circles, and angles should be modeled with Cartesian coordinates. In this section we grouped problems that require only the knowledge of the theory of lines and circles. Recall that the general equation of a line (whether in a Cartesian or affine coordinate system) is $a x+b y+c=0$. That of a circle (in a Cartesian coordinate system) is $(x-h)^{2}+(y-k)^{2}=r^{2}$, where $(h, k)$ is the center and $r$ is the radius. Let us see two examples, one in affine and one in Cartesian coordinates. But before we do that let us recall that a complete quadrilateral is a quadrilateral in which the pairs of opposite sides have been extended until they meet. For that reason, a complete quadrilateral has six vertices and three diagonals.

Example. Prove that the midpoints of the three diagonals of a complete quadrilateral are collinear.

Solution. As said, we will work in affine coordinates. Choose the coordinate axes to be sides of the quadrilateral, as shown in Figure 25 .

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-221.jpg?height=522&width=768&top_left_y=909&top_left_x=481)

Figure 25

Five of the vertices have coordinates $(0,0),(a, 0),(b, 0),(0, c)$, and $(0, d)$, while the sixth is found as the intersection of the lines through $(a, 0)$ and $(0, d)$, respectively, $(0, c)$ and $(b, 0)$. For these two lines we know the $x$ - and $y$-intercepts, so their equations are

$$
\frac{1}{a} x+\frac{1}{d} y=1 \quad \text { and } \quad \frac{1}{b} x+\frac{1}{c} y=1 .
$$

The sixth vertex of the complete quadrilateral has therefore the coordinates

$$
\left(\frac{a b(c-d)}{a c-b d}, \frac{c d(a-b)}{a c-b d}\right) .
$$

We find that the midpoints of the diagonals are

$$
\left(\frac{a}{2}, \frac{c}{2}\right), \quad\left(\frac{b}{2}, \frac{d}{2}\right), \quad\left(\frac{a b(c-d)}{2(a c-b d)}, \frac{c d(a-b)}{2(a c-b d)}\right) .
$$

The condition that these three points be collinear translates to

$$
\frac{1}{2(a c-b d)}\left|\begin{array}{ccc}
a & c & 1 \\
b & d & 1 \\
a b(c-d) c d(a-b) a c-b d
\end{array}\right|=0 .
$$

This is verified by direct computation.

Example. In a circle are inscribed a trapezoid with one side as diameter and a triangle with sides parallel to the sides of the trapezoid. Prove that the two have the same area.

Solution. We refer everything to Figure 26 . Assume that the circle has radius 1 , and the trapezoid has vertices $(1,0),(a, b),(-a, b)$ and $(-1,0)$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-222.jpg?height=388&width=420&top_left_y=870&top_left_x=662)

Figure 26

The triangle is isosceles and has one vertex at $(0,1)$. We need to determine the coordinates of the other two vertices. One of them lies where the parallel through $(0,1)$ to the line determined by $(1,0)$ and $(a, b)$ intersects the circle. The equation of the line is

$$
y=\frac{b}{a-1} x+1 .
$$

The relation $a^{2}+b^{2}=1$ yields $b^{2}=(1-a)(1+a)$, or $\frac{b}{1-a}=\frac{1+a}{b}$. So the equation of the line can be rewritten as

$$
y=-\frac{1+a}{b} x+1 .
$$

Now it is easy to guess that the intersection of this line with the circle is $(b,-a)$ (note that this point satisfies the equation of the circle). The other vertex of the triangle is $(-b,-a)$, so the area is $\frac{1}{2}(2 b)(1+a)=b+a b$. And the area of the trapezoid is $\frac{1}{2}(2 a+2) b=b+a b$, the same number.

589. Prove that the midpoints of the sides of a quadrilateral form a parallelogram. 

590. Let $M$ be a point in the plane of triangle $A B C$. Prove that the centroids of the triangles $M A B, M A C$, and $M C B$ form a triangle similar to triangle $A B C$.

591. Find the locus of points $P$ in the interior of a triangle $A B C$ such that the distances from $P$ to the lines $A B, B C$, and $C A$ are the side lengths of some triangle.

592. Let $A_{1}, A_{2}, \ldots, A_{n}$ be distinct points in the plane, and let $m$ be the number of midpoints of all the segments they determine. What is the smallest value that $m$ can have?

593. Given an acute-angled triangle $A B C$ with altitude $A D$, choose any point $M$ on $A D$, and then draw $B M$ and extend until it intersects $A C$ in $E$, and draw $C M$ and extend until it intersects $A B$ in $F$. Prove that $\angle A D E=\angle A D F$.

594. In a planar Cartesian system of coordinates consider a fixed point $P(a, b)$ and a variable line through $P$. Let $A$ be the intersection of the line with the $x$-axis. Connect $A$ with the midpoint $B$ of the segment $O P$ ( $O$ being the origin), and through $C$, which is the point of intersection of this line with the $y$-axis, take the parallel to $O P$. This parallel intersects $P A$ at $M$. Find the locus of $M$ as the line varies.

595. Let $A B C D$ be a parallelogram with unequal sides. Let $E$ be the foot of the perpendicular from $B$ to $A C$. The perpendicular through $E$ to $B D$ intersects $B C$ in $F$ and $A B$ in $G$. Show that $E F=E G$ if and only if $A B C D$ is a rectangle.

596. Find all pairs of real numbers $(p, q)$ such that the inequality

$$
\left|\sqrt{1-x^{2}}-p x-q\right| \leq \frac{\sqrt{2}-1}{2}
$$

holds for every $x \in[0,1]$.

597. On the hyperbola $x y=1$ consider four points whose $x$-coordinates are $x_{1}, x_{2}, x_{3}$, and $x_{4}$. Show that if these points lie on a circle, then $x_{1} x_{2} x_{3} x_{4}=1$.

The points of the plane can be represented as complex numbers. There are two instances in which complex coordinates come in handy: in problems involving "nice" angles (such as $\frac{\pi}{4}, \frac{\pi}{3}, \frac{\pi}{2}$ ), and in problems about regular polygons.

In complex coordinates the line passing through the points $z_{1}$ and $z_{2}$ has the parametric equation $z=t z_{1}+(1-t) z_{2}, t \in \mathbb{R}$. Also, the angle between the line passing through $z_{1}$ and $z_{2}$ and the line passing through $z_{3}$ and $z_{4}$ is the argument of the complex number $\frac{z_{1}-z_{2}}{z_{3}-z_{4}}$. The length of the segment determined by the points $z_{1}$ and $z_{2}$ is $\left|z_{1}-z_{2}\right|$. The vertices of a regular $n$-gon can be chosen, up to a scaling factor, as $1, \epsilon, \epsilon^{2}, \ldots, \epsilon^{n-1}$, where $\epsilon=e^{2 \pi i / n}=\cos \frac{2 \pi}{n}+i \sin \frac{2 \pi}{n}$. Example. Let $A B C$ and $B C D$ be two equilateral triangles sharing one side. A line passing through $D$ intersects $A C$ at $M$ and $A B$ at $N$. Prove that the angle between the lines $B M$ and $C N$ is $\frac{\pi}{3}$.

Solution. In the complex plane, let $B$ have the coordinate 0 , and $C$ the coordinate 1 . Then $A$ and $D$ have the coordinates $e^{i \pi / 3}$ and $e^{-i \pi / 3}$, respectively, and $N$ has the coordinate $t e^{i \pi / 3}$ for some real number $t$.

The parametric equations of $N D$ and $A C$ are, respectively,

$$
z=\alpha t e^{i \pi / 3}+(1-\alpha) e^{-i \pi / 3} \quad \text { and } \quad z=\beta e^{i \pi / 3}+(1-\beta), \quad \alpha, \beta \in \mathbb{R} .
$$

To find their intersection we need to determine the real numbers $\alpha$ and $\beta$ such that

$$
\alpha t e^{i \pi / 3}+(1-\alpha) e^{-i \pi / 3}=\beta e^{i \pi / 3}+(1-\beta) .
$$

Explicitly, this equation is

$$
\alpha t \frac{1+i \sqrt{3}}{2}+(1-\alpha) \frac{1-i \sqrt{3}}{2}=\beta \frac{1+i \sqrt{3}}{2}+(1-\beta) .
$$

Setting the real and imaginary parts equal, we obtain the system

$$
\begin{aligned}
&\alpha t+(1-\alpha)=\beta+2(1-\beta), \\
&\alpha t-(1-\alpha)=\beta .
\end{aligned}
$$

By adding the two equations, we obtain $\alpha=\frac{1}{t}$. So the complex coordinate of $M$ is $e^{i \pi / 3}+\left(1-\frac{1}{t}\right) e^{-i \pi / 3}$.

The angle between the lines $B M$ and $C N$ is the argument of the complex number

$$
\frac{e^{i \pi / 3}+\left(1-\frac{1}{t}\right) e^{-i \pi / 3}}{t e^{i \pi / 3}-1}=\frac{\left(e^{i \pi / 3}+e^{-i \pi / 3}\right)-\frac{1}{t} e^{-i \pi / 3}}{t e^{i \pi / 3}-1}=\frac{1-\frac{1}{t} e^{-i \pi / 3}}{t e^{i \pi / 3}-1}=\frac{1}{t} e^{-i \pi / 3} .
$$

The angle is therefore $\frac{\pi}{3}$, as claimed.

During the Mathematical Olympiad Summer Program of 2006, J. Bland discovered the following simpler solution:

Place the figure in the complex plane so that the coordinates of $A, B, C, D$ are, respectively, $i \sqrt{3},-1,1$, and $-i \sqrt{3}$. Let $M C$ have length $2 t$, where $t$ is a real parameter (positive if $C$ is between $A$ and $M$ and negative otherwise). The triangles $M C D$ and $N B D$ have parallel sides, so they are similar. It follows that $B N=\frac{2}{t}$ (positive if $B$ is between $A$ and $N$ and negative otherwise). The coordinates of $M$ and $N$ are

$$
m=-\left(1+\frac{1}{t}\right)-\frac{1}{t} i \sqrt{3} \text { and } n=(t+1)-t i \sqrt{3} .
$$

We compute

$$
\frac{c-n}{b-m}=t \frac{2 t+1+i \sqrt{3}}{-t-2+t i \sqrt{3}}=-t e^{i \frac{\pi}{3}} .
$$

It follows that the two lines form an angle of $\frac{\pi}{3}$, as desired.

The second example comes from the 15th W.L. Putnam Mathematical Competition, 1955.

Example. Let $A_{1} A_{2} A_{3} \ldots A_{n}$ be a regular polygon inscribed in the circle of center $O$ and radius $r$. On the half-line $\mid O A_{1}$ choose the point $P$ such that $A_{1}$ is between $O$ and $P$. Prove that

$$
\prod_{i=1}^{n} P A_{i}=P O^{n}-r^{n} .
$$

Solution. Place the vertices in the complex plane such that $A_{i}=r \epsilon^{i}, 1 \leq i \leq n$, where $\epsilon$ is an $n$th root of unity. The coordinate of $P$ is a real number $r x$, with $x>1$. We have

$$
\begin{aligned}
\prod_{i=1}^{n} P A_{i} &=\prod_{i=1}^{n}\left|r x-r \epsilon^{i}\right|=r^{n} \prod_{i=1}^{n}\left|x-\epsilon^{i}\right|=r^{n}\left|\prod_{i=1}^{n}\left(x-\epsilon^{i}\right)\right| \\
&=r^{n}\left(x^{n}-1\right)=(r x)^{n}-r^{n}=P O^{n}-r^{n} .
\end{aligned}
$$

The identity is proved.

598. Let $A B C D E F$ be a hexagon inscribed in a circle of radius $r$. Show that if $A B=$ $C D=E F=r$, then the midpoints of $B C, D E$, and $F A$ are the vertices of an equilateral triangle.

599. Prove that in a triangle the orthocenter $H$, centroid $G$, and circumcenter $O$ are collinear. Moreover, $G$ lies between $H$ and $O$, and $\frac{O G}{G H}=\frac{1}{2}$.

600. On the sides of a convex quadrilateral $A B C D$ one draws outside the equilateral triangles $A B M$ and $C D P$ and inside the equilateral triangles $B C N$ and $A D Q$. Describe the shape of the quadrilateral $M N P Q$.

601. Let $A B C$ be a triangle. The triangles $P A B$ and $Q A C$ are constructed outside of the triangle $A B C$ such that $A P=A B, A Q=A C$, and $\angle B A P=\angle C A Q=\alpha$. The segments $B Q$ and $C P$ meet at $R$. Let $O$ be the circumcenter of the triangle $B C R$. Prove that $A O$ and $P Q$ are orthogonal.

602. Let $A_{1} A_{2} \ldots A_{n}$ be a regular polygon with circumradius equal to 1 . Find the maximum value of $\prod_{k=1}^{n} P A_{k}$ as $P$ ranges over the circumcircle. 

603. Let $A_{0}, A_{1}, \ldots, A_{n}$ be the vertices of a regular $n$-gon inscribed in the unit circle. Prove that

$$
A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{n-1}=n .
$$

\subsubsection{Conics and Other Curves in the Plane}

The general equation of a quadratic curve is

$$
a x^{2}+b y^{2}+c x y+d x+e y+f=0 .
$$

Such a curve is called a conic because (except for the degenerate case of two parallel lines) it can be obtained by sectioning a circular cone by a plane.

The degenerate conics are pairs of (not necessarily distinct) lines, single points, the entire plane, and the empty set. We ignore them. There are three types of nondegenerate conics, which up to a change of Cartesian coordinates are described in Figure 27.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-226.jpg?height=321&width=345&top_left_y=1003&top_left_x=304)

$$
\begin{gathered}
y^{2}=4 p x \\
\text { parabola }
\end{gathered}
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-226.jpg?height=226&width=317&top_left_y=1050&top_left_x=718)

$$
\begin{gathered}
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1 \\
\text { ellipse }
\end{gathered}
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-226.jpg?height=330&width=330&top_left_y=994&top_left_x=1100)

$$
\frac{x^{2}}{a^{2}}-\frac{y^{2}}{b^{2}}=1
$$

Figure 27

The parabola is the locus of the points at equal distance from the point $(p, 0)$ (focus) and the line $x=-p$ (directrix). The ellipse is the locus of the points with the sum of distances to the foci $(c, 0)$ and $(-c, 0)$ constant, where $c=\sqrt{\left|a^{2}-b^{2}\right|}$. The hyperbola is the locus of the points with the difference of the distances to the foci $(c, 0)$ and $(-c, 0)$ constant, where $c=\sqrt{a^{2}+b^{2}}$.

Up to an affine change of coordinates, the equations of the parabola, ellipse, and hyperbola are, respectively, $y^{2}=x, x^{2}+y^{2}=1$, and $x^{2}-y^{2}=1$. Sometimes it is more convenient to bring the hyperbola into the form $x y=1$ by choosing its asymptotes as the coordinate axes.

As conic sections, these curves are obtained by sectioning the circular cone $z^{2}=$ $x^{2}+y^{2}$ by the planes $z-x=1$ (parabola), $z=1$ (ellipse), and $y=1$ (hyperbola). The vertex of the cone can be thought of as the viewpoint of a person. The projections through this viewpoint of one plane to another are called projective transformations. Up to a projective transformation there is only one nondegenerate conic-the circle. Any projectively invariant property that can be proved for the circle is true for any conic (and by passing to the limit, even for degenerate conics). Such is the case with Pascal's theorem: The opposite sides of a hexagon inscribed in a conic meet at three collinear points. Note that when the conic degenerates into two parallel lines, this becomes Pappus' theorem.

To conclude our discussion, let us recall that the equation of the tangent line to a conic at a point $\left(x_{0}, y_{0}\right)$ is obtained by replacing in the general equation of the conic $x^{2}$ and $y^{2}$ by $x x_{0}$, respectively, $y y_{0}, x y$ by $\frac{x y_{0}+y x_{0}}{2}$, and $x$ and $y$ in the linear terms by $\frac{x+x_{0}}{2}$, respectively, $\frac{y+y_{0}}{2}$.

We now proceed with an example from A. Myller's Analytical Geometry (3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972).

Example. Find the locus of the centers of the equilateral triangles inscribed in the parabola $y^{2}=4 p x$

Solution. Let us determine first some algebraic conditions that the coordinates $\left(x_{i}, y_{i}\right)$, $i=1,2,3$, of the vertices of a triangle should satisfy in order for the triangle to be equilateral. The equation of the median from $\left(x_{3}, y_{3}\right)$ is

$$
\frac{y-y_{3}}{x-x_{3}}=\frac{y_{1}+y_{2}-2 y_{3}}{x_{1}+x_{2}-2 x_{3}} .
$$

Requiring the median to be orthogonal to the side yields

$$
\frac{y_{1}+y_{2}-2 y_{3}}{x_{1}+x_{2}-2 x_{3}} \cdot \frac{y_{2}-y_{1}}{x_{2}-x_{1}}=-1,
$$

or

$$
\left(x_{1}-x_{2}\right)\left(x_{1}+x_{2}-2 x_{3}\right)+\left(y_{1}-y_{2}\right)\left(y_{1}+y_{2}-2 y_{3}\right)=0 .
$$

So this relation along with the two obtained by circular permutations of the indices are necessary and sufficient conditions for the triangle to be equilateral. Of course, the third condition is redundant. In the case of three points on the parabola, namely $\left(\frac{y_{i}^{2}}{4 p}, y_{i}\right)$, $i=1,2,3$, after dividing by $y_{1}-y_{2}$, respectively, by $y_{2}-y_{3}$ (which are both nonzero), we obtain

$$
\begin{aligned}
&\left(y_{1}+y_{2}\right)\left(y_{1}^{2}+y_{2}^{2}-2 y_{3}^{2}\right)+16 p^{2}\left(y_{1}+y_{2}-2 y_{3}\right)=0, \\
&\left(y_{2}+y_{3}\right)\left(y_{2}^{2}+y_{3}^{2}-2 y_{1}^{2}\right)+16 p^{2}\left(y_{2}+y_{3}-2 y_{1}\right)=0 .
\end{aligned}
$$

Subtracting the two gives 

$$
y_{1}^{3}-y_{3}^{3}+\left(y_{1}-y_{3}\right)\left(y_{2}^{2}-2 y_{1} y_{3}\right)+48 p^{2}\left(y_{1}-y_{3}\right)=0 .
$$

Divide this by $y_{1}-y_{3} \neq 0$ to transform it into

$$
y_{1}^{2}+y_{2}^{2}+y_{3}^{2}+3\left(y_{1} y_{2}+y_{2} y_{3}+y_{3} y_{1}\right)+48 p^{2}=0 .
$$

This is the condition satisfied by the $y$-coordinates of the vertices of the triangle. Keeping in mind that the coordinates of the center of the triangle are

$$
x=\frac{y_{1}^{2}+y_{2}^{2}+y_{3}^{2}}{12 p}, \quad y=\frac{y_{1}+y_{2}+y_{2}}{3},
$$

we rewrite the relation as

$$
-\frac{1}{2}\left(y_{1}^{2}+y_{2}^{2}+y_{3}^{2}\right)+\frac{3}{2}\left(y_{1}+y_{2}+y_{3}\right)^{2}+48 p^{2}=0,
$$

then substitute $12 p x=y_{1}^{2}+y_{2}^{2}+y_{3}^{2}$ and $3 y=y_{1}+y_{2}+y_{3}$ to obtain the equation of the locus

$$
-6 p x+\frac{27}{2} y^{2}+48 p^{2}=0,
$$

or

$$
y^{2}=\frac{4 p}{9}(x-8 p) .
$$

This is a parabola with vertex at $(8 p, 0)$ and focus at $\left(\left(\frac{1}{9}+8\right) p, 0\right)$.

The second problem was given at the 1977 Soviet Union University Student Mathematical Olympiad.

Example. Let $P$ be a point on the hyperbola $x y=4$, and $Q$ a point on the ellipse $x^{2}+4 y^{2}=4$. Prove that the distance from $P$ to $Q$ is greater than 1 .

Solution. We will separate the conics by two parallel lines at a distance greater than 1 . For symmetry reasons, it is natural to try the tangent to the hyperbola at the point $(2,2)$. This line has the equation $y=4-x$.

Let us determine the point in the first quadrant where the tangent to the ellipse has slope $-1$. If $\left(x_{0}, y_{0}\right)$ is a point on the ellipse, then the equation of the tangent at $x$ is $x x_{0}+4 y y_{0}=4$. Its slope is $-x_{0} / 4 y_{0}$. Setting $-x_{0} / 4 y_{0}=-1$ and $x_{0}^{2}+4 y_{0}^{2}=4$, we obtain $x_{0}=4 / \sqrt{5}$ and $y_{0}=1 / \sqrt{5}$. Consequently, the tangent to the ellipse is $y=\sqrt{5}-x$.

The distance between the lines $y=4-x$ and $y=\sqrt{5}-x$ is equal to $(4-\sqrt{5}) / \sqrt{2}$, which is greater than 1 . Hence the distance between the arbitrary points $P$ and $Q$ is also greater than 1 , and we are done. 

604. Consider a circle of diameter $A B$ and center $O$, and the tangent $t$ at $B$. A variable tangent to the circle with contact point $M$ intersects $t$ at $P$. Find the locus of the point $Q$ where the line $O M$ intersects the parallel through $P$ to the line $A B$.

605. On the axis of a parabola consider two fixed points at equal distance from the focus. Prove that the difference of the squares of the distances from these points to an arbitrary tangent to the parabola is constant.

606. With the chord $P Q$ of a hyperbola as diagonal, construct a parallelogram whose sides are parallel to the asymptotes. Prove that the other diagonal of the parallelogram passes through the center of the hyperbola.

607. A straight line cuts the asymptotes of a hyperbola in points $A$ and $B$ and the hyperbola itself in $P$ and $Q$. Prove that $A P=B Q$.

608. Consider the parabola $y^{2}=4 p x$. Find the locus of the points such that the tangents to the parabola from those points make a constant angle $\phi$.

609. Let $T_{1}, T_{2}, T_{3}$ be points on a parabola, and $t_{1}, t_{2}, t_{3}$ the tangents to the parabola at these points. Compute the ratio of the area of triangle $T_{1} T_{2} T_{3}$ to the area of the triangle determined by the tangents.

610. Three points $A, B, C$ are considered on a parabola. The tangents to the parabola at these points form a triangle $M N P(N P$ being tangent at $A, P M$ at $B$, and $M N$ at $C$ ). The parallel through $B$ to the symmetry axis of the parabola intersects $A C$ at $L$.

(a) Show that $L M N P$ is a parallelogram.

(b) Show that the circumcircle of triangle $M N P$ passes through the focus $F$ of the parabola.

(c) Assuming that $L$ is also on this circle, prove that $N$ is on the directrix of the parabola.

(d) Find the locus of the points $L$ if $A C$ varies in such a way that it passes through $F$ and is perpendicular to $B F$.

611. Find all regular polygons that can be inscribed in an ellipse with unequal semiaxes.

612. We are given the parabola $y^{2}=2 p x$ with focus $F$. For an integer $n \geq 3$ consider a regular polygon $A_{1} A_{2} \ldots A_{n}$ whose center is $F$ and such that none of its vertices is on the $x$-axis. The half-lines $\left|F A_{1},\right| F A_{2}, \ldots, \mid F A_{n}$ intersect the parabola at $B_{1}$, $B_{2}, \ldots, B_{n}$. Prove that

$$
F B_{1}+F B_{2}+\cdots+F B_{n} \geq n p .
$$

613. A cevian of a triangle is a line segment that joins a vertex to the line containing the opposite side. An equicevian point of a triangle $A B C$ is a point $P$ (not necessarily inside the triangle) such that the cevians on the lines $A P, B P$, and $C P$ have equal lengths. Let $S B C$ be an equilateral triangle, and let $A$ be chosen in the interior of $S B C$, on the altitude dropped from $S$.

(a) Show that $A B C$ has two equicevian points.

(b) Show that the common length of the cevians through either of the equicevian points is constant, independent of the choice of $A$.

(c) Show that the equicevian points divide the cevian through $A$ in a constant ratio, which is independent of the choice of $A$.

(d) Find the locus of the equicevian points as $A$ varies.

(e) Let $S^{\prime}$ be the reflection of $S$ in the line $B C$. Show that (a), (b), and (c) hold if $A$ varies on any ellipse with $S$ and $S^{\prime}$ as its foci. Find the locus of the equicevian points as $A$ varies on the ellipse.

A planar curve is called rational if it can be parametrized as $(x(t), y(t))$ with $x(t)$ and $y(t)$ rational functions of the real variable $t$. Here we have to pass to the closed real line, so $t$ is allowed to be infinite, while the plane is understood as the projective plane, zero denominators giving rise to points on the line at infinity.

Theorem. All conics are rational curves.

Proof. The case of degenerate conics (i.e., pairs of lines) is trivial. The parabola $y^{2}=4 p x$ is parametrized by $\left(\frac{t^{2}}{4 p}, t\right)$, the ellipse $\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1$ by $\left(a \frac{1-t^{2}}{1+t^{2}}, b \frac{2 t}{1+t^{2}}\right)$, and the hyperbola $\frac{x^{2}}{a^{2}}-\frac{y^{2}}{b^{2}}=1$ by $\left(a \frac{t+t^{-1}}{2}, b \frac{t-t^{-1}}{2}\right)$. The general case follows from the fact that coordinate changes are rational (in fact, linear) transformations.

Compare the standard parametrization of the circle $(\cos x, \sin x)$ to the rational parametrization $\left(\frac{1-t^{2}}{1+t^{2}}, \frac{2 t}{1+t^{2}}\right)$. This gives rise to the trigonometric substitution $\tan \frac{x}{2}=t$ and explains why integrals of the form

$$
\int R(\cos x, \sin x) d x,
$$

with $R$ a two-variable rational function, can be reduced to integrals of rational functions.

Let us change slightly our point of view and take a look at the conic

$$
y^{2}=a x^{2}+b x+c .
$$

If we fix a point $\left(x_{0}, y_{0}\right)$ on this conic, the line $y-y_{0}=t\left(x-x_{0}\right)$ intersects the conic in exactly one more point $(x, y)$. Writing the conditions that this point is both on the line and on the conic and eliminating $y$, we obtain the equation

$$
\left[y_{0}+t\left(x-x_{0}\right)\right]^{2}=a x^{2}+b x+c .
$$

A few algebraic computations yield

$$
2 y_{0} t+t^{2}\left(x-x_{0}\right)=a\left(x+x_{0}\right)+b .
$$

This shows that $x$ is a rational function of the slope $t$. The same is true for $y$. As $t$ varies, $(x, y)$ describes the whole conic. This is a rational parametrization of the conic, giving rise to Euler's substitutions. In their most general form, Euler's substitutions are

$$
\sqrt{a x^{2}+b x+c}-y_{0}=t\left(x-x_{0}\right) \text {. }
$$

They are used for rationalizing integrals of the form

$$
\int R\left(x, \sqrt{a x^{2}+b x+c}\right) d x,
$$

where $R$ is a two-variable rational function.

614. Compute the integral

$$
\int \frac{d x}{a+b \cos x+c \sin x},
$$

where $a, b, c$ are real numbers, not all equal to zero.

615. Consider the system

$$
\begin{gathered}
x+y=z+u, \\
2 x y=z u .
\end{gathered}
$$

Find the greatest value of the real constant $m$ such that $m \leq \frac{x}{y}$ for any positive integer solution $(x, y, z, u)$ of the system, with $x \geq y$.

We conclude our incursion into two-dimensional geometry with an overview of various famous planar curves. The first answers a question of G.W. Leibniz.

Example. What is the path of an object dragged by a string of constant length when the end of the string not joined to the object moves along a straight line?

Solution. Assume that the object is dragged by a string of length 1 , that its initial coordinates are $(0,1)$, and that it is dragged by a vehicle moving along the $x$-axis in the positive direction. Observe that the slope of the tangent to the curve at a point $(x, y)$ points toward the vehicle, while the distance to the vehicle is always equal to 1 . These two facts can be combined in the differential equation

$$
\frac{d y}{d x}=-\frac{y}{\sqrt{1-y^{2}}} .
$$

Separate the variables

$$
d x=-\frac{\sqrt{1-y^{2}}}{y} d y,
$$

and then integrate to obtain

$$
x=-\sqrt{1-y^{2}}-\ln y-\ln \left(1+\sqrt{1-y^{2}}\right)+C .
$$

The initial condition gives $C=0$. The answer to the problem is therefore the curve

$$
x=-\sqrt{1-y^{2}}-\ln y-\ln \left(1+\sqrt{1-y^{2}}\right),
$$

depicted in Figure 28.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-232.jpg?height=508&width=479&top_left_y=970&top_left_x=626)

Figure 28

This curve is called a tractrix, a name given by Ch. Huygens. Clearly, it has the $x$ axis as an asymptote. E. Beltrami has shown that the surface of revolution of the tractrix around its asymptote provides a partial model for hyperbolic geometry. This surface has been used in recent years for the shape of loudspeakers.

A variety of other curves show up in the problems below. In some of the solutions, polar coordinates might be useful. Recall the formulas for changing between Cartesian and polar coordinates: $x=r \cos \theta, y=r \sin \theta$.

616. Find the points where the tangent to the cardioid $r=1+\cos \theta$ is vertical.

617. Given a circle of diameter $A B$, a variable secant through $A$ intersects the circle at $C$ and the tangent through $B$ at $D$. On the half-line $A C$ a point $M$ is chosen such that $A M=C D$. Find the locus of $M$. 

618. Find the locus of the projection of a fixed point on a circle onto the tangents to the circle.

619. On a circle of center $O$ consider a fixed point $A$ and a variable point $M$. The circle of center $A$ and radius $A M$ intersects the line $O M$ at $L$. Find the locus of $L$ as $M$ varies on the circle.

620. The endpoints of a variable segment $A B$ lie on two perpendicular lines that intersect at $O$. Find the locus of the projection of $O$ onto $A B$, provided that the segment $A B$ maintains a constant length.

621. From the center of a rectangular hyperbola a perpendicular is dropped to a variable tangent. Find the locus in polar coordinates of the foot of the perpendicular. (A hyperbola is called rectangular if its asymptotes are perpendicular.)

622. Find a transformation of the plane that maps the unit circle $x^{2}+y^{2}=1$ into a cardioid. (Recall that the general equation of a cardioid is $r=2 a(1+\cos \theta)$.)

623. Prove that the locus described by the equation $x^{3}+3 x y+y^{3}=1$ contains precisely three noncollinear points $A, B, C$, equidistant to one another, and find the area of triangle $A B C$.

624. For $n$ and $p$ two positive integers consider the curve described by the parametric equations

$$
\begin{aligned}
&x=a_{1} t^{n}+b_{1} t^{p}+c_{1}, \\
&y=a_{2} t^{n}+b_{2} t^{p}+c_{2}, \\
&z=a_{3} t^{n}+b_{3} t^{p}+c_{3},
\end{aligned}
$$

where $t$ is a parameter. Prove that the curve is planar.

625. What is the equation that describes the shape of a hanging flexible chain with ends supported at the same height and acted on by its own weight?

\subsubsection{Coordinate Geometry in Three and More Dimensions}

In this section we emphasize quadrics. A quadric is a surface in space determined by a quadratic equation. The degenerate quadrics-linear varieties, cones, or cylinders over conics-add little to the picture from their two-dimensional counterparts, so we skip them. The nondegenerate quadrics are classified, up to an affine change of coordinates, as

- $x^{2}+y^{2}+z^{2}=1$, ellipsoid;

- $x^{2}+y^{2}-z^{2}=1$, hyperboloid of one sheet; - $x^{2}-y^{2}-z^{2}=1$, hyperboloid of two sheets;

- $x^{2}+y^{2}=z$, elliptic paraboloid;

- $x^{2}-y^{2}=z$, hyperbolic paraboloid.

In Cartesian coordinates, in these formulas there is a scaling factor in front of each term. For example, the standard form of an ellipsoid in Cartesian coordinates is

$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1 .
$$

As in the case of conics, the equation of the tangent plane to a quadric at a point $\left(x_{0}, y_{0}, z_{0}\right)$ is obtained by replacing in the equation of the quadric $x^{2}, y^{2}$, and $z^{2}$, respectively, by $x x_{0}, y y_{0}$, and $z z_{0} ; x y, x z$, and $y z$, respectively, by $\frac{x y_{0}+y x_{0}}{2}, \frac{x z_{0}+z x_{0}}{2}$, and $\frac{y z_{0}+z y_{0}}{2}$; and $x, y$, and $z$ in the linear terms, respectively, by $\frac{x+x_{0}}{2}, \frac{y+y_{0}}{2}$, and $\frac{z+z_{0}}{2}$.

Our first example comes from the 6th W.L. Putnam Mathematical Competition.

Example. Find the smallest volume bounded by the coordinate planes and by a tangent plane to the ellipsoid

$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1 .
$$

Solution. The tangent plane to the ellipsoid at $\left(x_{0}, y_{0}, z_{0}\right)$ has the equation

$$
\frac{x x_{0}}{a^{2}}+\frac{y y_{0}}{b^{2}}+\frac{z z_{0}}{c^{2}}=1 .
$$

Its $x, y$, and $z$ intercepts are, respectively, $\frac{a^{2}}{x_{0}}, \frac{b^{2}}{y_{0}}$, and $\frac{c^{2}}{z_{0}}$. The volume of the solid cut off by the tangent plane and the coordinate planes is therefore

$$
V=\frac{1}{6}\left|\frac{a^{2} b^{2} c^{2}}{x_{0} y_{0} z_{0}}\right| .
$$

We want to minimize this with the constraint that $\left(x_{0}, y_{0}, z_{0}\right)$ lie on the ellipsoid. This amounts to maximizing the function $f(x, y, z)=x y z$ with the constraint

$$
g(x, y, z)=\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1 .
$$

Because the ellipsoid is a closed bounded set, $f$ has a maximum and a minimum on it. The maximum is positive, and the minimum is negative. The method of Lagrange multipliers yields the following system of equations in the unknowns $x, y, z$, and $\lambda$ : 

$$
\begin{aligned}
y z &=2 \lambda \frac{x}{a^{2}}, \\
x z &=2 \lambda \frac{y}{b^{2}}, \\
y z &=2 \lambda \frac{z}{c^{2}}, \\
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}} &=1 .
\end{aligned}
$$

Multiplying the first equation by $x$, the second by $y$, and the third by $z$, then summing up the three equations gives

$$
3 x y z=2 \lambda\left(\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}\right)=2 \lambda .
$$

Hence $\lambda=\frac{3}{2} x y z$. Then multiplying the first three equations of the system together, we obtain

$$
(x y z)^{2}=8 \lambda^{3} \frac{x y z}{a^{2} b^{2} c^{2}}=\frac{27(x y z)^{4}}{a^{2} b^{2} c^{2}} .
$$

The solution $x y z=0$ we exclude, since it does not yield a maximum or a minimum. Otherwise, $x y z=\pm \frac{a b c}{\sqrt{27}}$. The equality with the plus sign is the maximum of $f$; the other is the minimum. Substituting in the formula for the volume, we find that the smallest volume is $\frac{\sqrt{3}}{2} a b c$.

Example. Find the nature of the surface defined as the locus of the lines parallel to a given plane and intersecting two given skew lines, neither of which is parallel to the plane.

Solution. We will work in affine coordinates. Call the plane $\pi$ and the two skew lines $l_{1}$ and $l_{2}$. The $x$-and $y$-axes lie in $\pi$ and the $z$-axis is $l_{1}$. The $x$-axis passes through $l_{2} \cap \pi$. The $y$-axis is chosen to make $l_{2}$ parallel to the $y z$-plane. Finally, the orientation and the units are such that $l_{2}$ is given by $x=1, y=z$ (see Figure 29).

A line parallel to $\pi$ and intersecting $l_{1}$ and $l_{2}$ passes through $(1, s, s)$ and $(0,0, s)$, where $s$ is some real parameter playing the role of the "height." Thus the locus consists of all points of the form $t(1, s, s)+(1-t)(0,0, s)$, where $s$ and $t$ are real parameters. The coordinates $(X, Y, Z)$ of such a point satisfy $X=t, Y=t s, Z=s$. By elimination we obtain the equation $X Z=Y$, which is a hyperbolic paraboloid like the one from Figure 30 . We stress once more that the type of a quadric is invariant under affine transformations.

A surface generated by a moving line is called a ruled surface. Ruled surfaces are easy to build in real life. This together with its structural resistance makes the hyperbolic paraboloid popular as a roof in modern architecture (see for example Felix Candela's roof 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-236.jpg?height=477&width=691&top_left_y=245&top_left_x=522)

Figure 29

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-236.jpg?height=491&width=603&top_left_y=798&top_left_x=570)

Figure 30

of the 1968 Olympic stadium in Mexico City). There is one more nondegenerate ruled quadric, which makes the object of the first problem in our list. And if you find some of the problems below too difficult, remember Winston Churchill's words: "Success consists of going from failure to failure without loss of enthusiasm.'"

626. A cube is rotated about the main diagonal. What kind of surfaces do the edges describe?

627. Prove that the plane

$$
\frac{x}{a}+\frac{y}{b}-\frac{z}{c}=1
$$

is tangent to the hyperboloid of one sheet

$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}-\frac{z^{2}}{c^{2}}=1 .
$$

628. Through a point $M$ on the ellipsoid

$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1
$$

take planes perpendicular to the axes $O x, O y, O z$. Let the areas of the planar sections thus obtained be $S_{x}, S_{y}$, respectively, $S_{z}$. Prove that the sum

$$
a S_{x}+b S_{y}+c S_{z}
$$

is independent of $M$.

629. Determine the radius of the largest circle that can lie on the ellipsoid

$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1 \quad(a>b>c) .
$$

630. Let $a, b, c$ be distinct positive numbers. Prove that through each point of the threedimensional space pass three surfaces described by equations of the form

$$
\frac{x^{2}}{a^{2}-\lambda}+\frac{y^{2}}{b^{2}-\lambda}+\frac{z^{2}}{c^{2}-\lambda}=1
$$

Determine the nature of these surfaces and prove that they are pairwise orthogonal along their curves of intersection.

631. Show that the equations

$$
\begin{aligned}
&x=u+v+w, \\
&y=u^{2}+v^{2}+w^{2}, \\
&z=u^{3}+v^{3}+w^{3},
\end{aligned}
$$

where the parameters $u, v, w$ are subject to the constraint $u v w=1$, define a cubic surface.

We conclude our discussion of coordinate geometry with some problems in $n$ dimensions.

Example. Through a fixed point inside an $n$-dimensional sphere, $n$ mutually perpendicular chords are drawn. Prove that the sum of the squares of the lengths of the chords does not depend on their directions.

Solution. We want to prove that the sum in question depends only on the radius of the sphere and the distance from the fixed point to the center of the sphere. Choose a coordinate system in which the chords are the $n$ orthogonal axes and the radius of the sphere is $R>0$. The fixed point, which we call $P$, becomes the origin. The endpoints of each chord have only one nonzero coordinate, and in the appropriate ordering, the $k$ th coordinates of the endpoints $X_{k}$ and $Y_{k}$ of the $k$ th chord are the nonzero numbers $x_{k}$ and $y_{k}, k=1,2, \ldots, n$. The center of the sphere is then

$$
O=\left(\frac{x_{1}+y_{1}}{2}, \frac{x_{2}+y_{2}}{2}, \ldots, \frac{x_{n}+y_{n}}{2}\right) \text {. }
$$

The conditions that the points $X_{k}$ and $Y_{k}$ lie on the sphere can be written as

$$
\begin{aligned}
&\left(x_{k}-\frac{x_{k}+y_{k}}{2}\right)^{2}+\sum_{j \neq k}\left(\frac{x_{j}+y_{j}}{2}\right)^{2}=R^{2}, \\
&\left(y_{k}-\frac{x_{k}+y_{k}}{2}\right)^{2}+\sum_{j \neq k}\left(\frac{x_{j}+y_{j}}{2}\right)^{2}=R^{2},
\end{aligned}
$$

with $k=1,2, \ldots, n$. This implies

$$
\left(\frac{x_{k}-y_{k}}{2}\right)^{2}=R^{2}-\sum_{j \neq k}\left(\frac{x_{j}+y_{j}}{2}\right)^{2}, \quad k=1,2, \ldots, n .
$$

The term on the left is one-fourth of the square of the length of $X_{k} Y_{k}$. Multiplying by 4 and summing up all these relations, we obtain

$$
\begin{aligned}
\sum_{k=1}^{n}\left\|X_{k} Y_{k}\right\|^{2} &=4 n R^{2}-4 \sum_{k=1}^{n} \sum_{j \neq k}\left(\frac{x_{j}+y_{j}}{2}\right)^{2}=4 n R^{2}-4(n-1) \sum_{k=1}^{n}\left(\frac{x_{k}+y_{k}}{2}\right)^{2} \\
&=4 n R^{2}-4(n-1)\|P O\|^{2}
\end{aligned}
$$

Hence the conclusion.

632. Let $n$ be a positive integer. Prove that if the vertices of a $(2 n+1)$-dimensional cube have integer coordinates, then the length of the edge of the cube is an integer.

633. For a positive integer $n$ denote by $\tau$ the permutation cycle $(n, \ldots, 2,1)$. Consider the locus of points in $\mathbb{R}^{n}$ defined by the equation

$$
\sum_{\sigma} \operatorname{sign}(\sigma) x_{\sigma(1)} x_{\tau(\sigma(2))} \cdots x_{\tau^{n-1}(\sigma(n))}=0,
$$

where the sum is over all possible permutations of $\{1,2, \ldots, n\}$. Prove that this locus contains a plane. 

634. Prove that the intersection of an $n$-dimensional cube centered at the origin and with edges parallel to the coordinate axes with the plane determined by the vectors

$$
\vec{a}=\left(\cos \frac{2 \pi}{n}, \cos \frac{4 \pi}{n}, \ldots, \cos \frac{2 n \pi}{n}\right) \text { and } \vec{b}=\left(\sin \frac{2 \pi}{n}, \sin \frac{4 \pi}{n}, \ldots, \sin \frac{2 n \pi}{n}\right)
$$

is a regular $2 n$-gon.

635. Find the maximum number of points on a sphere of radius 1 in $\mathbb{R}^{n}$ such that the distance between any two points is strictly greater than $\sqrt{2}$.

\subsubsection{Integrals in Geometry}

We now present various applications of integral calculus to geometry problems. Here is a classic.

Example. A disk of radius $R$ is covered by $m$ rectangular strips of width 2. Prove that $m \geq R$

Solution. Since the strips have different areas, depending on the distance to the center of the disk, a proof using areas will not work. However, if we move to three dimensions the problem becomes easy. The argument is based on the following property of the sphere.

Lemma. The area of the surface cut from a sphere of radius $R$ by two parallel planes at distance $d$ from each other is equal to $2 \pi R d$.

To prove this result, let us assume that the sphere is centered at the origin and the planes are perpendicular to the $x$-axis. The surface is obtained by rotating the graph of the function $f:[a, b] \rightarrow \mathbb{R}, f(x)=\sqrt{R^{2}-x^{2}}$ about the $x$-axis, where $[a, b]$ is an interval of length $d$. The area of the surface is given by

$$
\begin{aligned}
2 \pi \int_{a}^{b} f(x) \sqrt{\left(f^{\prime}(x)\right)^{2}+1} d x &=2 \pi \int_{a}^{b} \sqrt{R^{2}-x^{2}} \frac{R}{\sqrt{R^{2}-x^{2}}} d x \\
&=2 \pi \int_{a}^{b} R d x=2 \pi R d
\end{aligned}
$$

Returning to the problem, the sphere has area $4 \pi R^{2}$ and is covered by $m$ surfaces, each having area $4 \pi R$. The inequality $4 \pi m R \geq 4 \pi R^{2}$ implies that $m \geq R$, as desired.

The second example, suggested to us by $\mathrm{Zh}$. Wang, is even more famous. We present the proof from H. Solomon, Geometric Probability (SIAM 1978). Crofton's theorem. Let $D$ be a bounded convex domain in the plane. Through each point $P(x, y)$ outside $D$ there pass two tangents to $D$. Let $t_{1}$ and $t_{2}$ be the lengths of the segments determined by $P$ and the tangency points, and let $\alpha$ be the angle between the tangents, all viewed as functions of $(x, y) .{ }^{1}$ Then

$$
\iint_{P \notin D} \frac{\sin \alpha}{t_{1} t_{2}} d x d y=2 \pi^{2} .
$$

Proof. The proof becomes transparent once we examine the particular case in which $D$ is the unit disk $x^{2}+y^{2}<1$. Each point outside the unit disk can be parametrized by the pair of angles $\left(\phi_{1}, \phi_{2}\right)$ where the tangents meet the unit circle $S^{1}$. Since there is an ambiguity in which tangent is considered first, the outside of the disk is in 1-to-2 correspondence with the set $S^{1} \times S^{1}$. It so happens, and we will prove it in general, that on changing coordinates from $(x, y)$ to $\left(\phi_{1}, \phi_{2}\right)$, the integral from the statement becomes $\iint d \phi_{1} d \phi_{2}$ (divided by 2 to take the ambiguity into account). The result follows.

In the general case we mimic the same argument, boosting your intuition with Figure 31. Fix a Cartesian coordinate system with the origin $O$ inside $D$. For a point $(x, y)$ denote by $\left(\phi_{1}, \phi_{2}\right)$ the angles formed by the perpendiculars from $O$ onto the tangents with the positive semiaxis. This is another parametrization of the exterior of $D$, again with the ambiguity of which tangent is considered first. Let $A_{i}\left(\epsilon_{i}, \eta_{i}\right), i=1,2$, be the tangency points.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-240.jpg?height=458&width=612&top_left_y=1228&top_left_x=559)

Figure 31

The main goal is to understand the change of coordinates $(x, y) \rightarrow\left(\phi_{1}, \phi_{2}\right)$ and in particular to write the Jacobian of this transformation. Writing the condition that the slope of the line $A_{1} P$ is $\tan \left(\phi_{1}+\frac{\pi}{2}\right)$, we obtain

$$
\left(x-\epsilon_{1}\right) \cos \phi_{1}+\left(y-\eta_{1}\right) \sin \phi_{1}=0 .
$$

Taking the differential yields

${ }^{1}$ If the boundary of $D$ has some edges, then there are points $P$ for which $t_{1}$ and $t_{2}$ are not well defined, but the area of the set of these points is zero, so they can be neglected in the integral below. 

$$
\begin{aligned}
\cos \phi_{1} d x &-\cos \phi_{1} d \epsilon_{1}-\left(x-\epsilon_{1}\right) \sin \phi_{1} d \phi_{1}+\sin \phi_{1} d y-\sin \phi_{1} d \eta_{1} \\
&+\left(y-\eta_{1}\right) \cos \phi_{1} d \phi_{1}=0 .
\end{aligned}
$$

This expression can be simplified if we note that $\frac{d \eta_{1}}{d \epsilon_{1}}$ is the slope of the tangent, namely $\tan \left(\phi_{1}+\frac{\pi}{2}\right)$. Then $\cos \phi_{1} d \epsilon_{1}+\sin \phi_{1} d \eta_{1}=0$, so

$$
\cos \phi_{1} d x+\sin \phi_{1} d y=\left[\left(x-\epsilon_{1}\right) \sin \phi_{1}-\left(y-\eta_{1}\right) \cos \phi_{1}\right] d \phi_{1} .
$$

And now a little Euclidean geometry. Consider the right triangle $O_{1} A_{1} P$ with legs parallel to the axes. The altitude from $O_{1}$ determines on $A_{1} P$ two segments of lengths $\left(x-\epsilon_{1}\right) \sin \phi_{1}$ and $-\left(y-\eta_{1}\right) \cos \phi_{1}$ (you can see by examining the picture that the signs are right). This allows us to further transform the identity obtained above into

$$
\cos \phi_{1} d x+\sin \phi_{1} d y=t_{1} d \phi_{1} .
$$

The same argument shows that

$$
\cos \phi_{2} d x+\sin \phi_{2} d y=t_{2} d \phi_{2} .
$$

The Jacobian of the transformation is therefore the absolute value of

$$
\frac{1}{t_{1} t_{2}}\left(\cos \phi_{1} \sin \phi_{2}-\sin \phi_{1} \cos \phi_{2}\right)=\frac{1}{t_{1} t_{2}} \sin \left(\phi_{1}-\phi_{2}\right) .
$$

And $\phi_{1}-\phi_{2}$ is, up to a sign, the supplement of $\alpha$. We obtain

$$
2 \pi^{2}=\frac{1}{2} \int_{0}^{2 \pi} \int_{0}^{2 \pi} d \phi_{1} d \phi_{2}=\iint_{P \notin D} \frac{\sin \alpha}{t_{1} t_{2}} d x d y .
$$

The theorem is proved.

636. A ring of height $h$ is obtained by digging a cylindrical hole through the center of a sphere. Prove that the volume of the ring depends only on $h$ and not on the radius of the sphere.

637. A polyhedron is circumscribed about a sphere. We call a face big if the projection of the sphere onto the plane of the face lies entirely within the face. Show that there are at most six big faces.

638. Let $A$ and $B$ be two finite sets of segments in three-dimensional space such that the sum of the lengths of the segments in $A$ is larger than the sum of the lengths of the segments in $B$. Prove that there is a line in space with the property that the sum of the lengths of the projections of the segments in $A$ onto that line is greater than the sum of the lengths of the projections of the segments in $B$. 

639. Two convex polygons are placed one inside the other. Prove that the perimeter of the polygon that lies inside is smaller.

640. There are $n$ line segments in the plane with the sum of the lengths equal to 1 . Prove that there exists a straight line such that the sum of the lengths of the projections of the segments onto the line is equal to $\frac{2}{\pi}$.

641. In a triangle $A B C$ for a variable point $P$ on $B C$ with $P B=x$ let $t(x)$ be the measure of $\angle P A B$. Compute

$$
\int_{0}^{a} \cos t(x) d x
$$

in terms of the sides and angles of triangle $A B C$.

642. Let $f:[0, a] \rightarrow \mathbb{R}$ be a continuous and increasing function such that $f(0)=0$. Define by $R$ the region bounded by $f(x)$ and the lines $x=a$ and $y=0$. Now consider the solid of revolution obtained when $R$ is rotated around the $y$-axis as a sort of dish. Determine $f$ such that the volume of water the dish can hold is equal to the volume of the dish itself, this happening for all $a$.

643. Consider a unit vector starting at the origin and pointing in the direction of the tangent vector to a continuously differentiable curve in three-dimensional space. The endpoint of the vector describes the spherical image of the curve (on the unit sphere). Show that if the curve is closed, then its spherical image intersects every great circle of the unit sphere.

644. With the hypothesis of the previous problem, if the curve is twice differentiable, then the length of the spherical image of the curve is called the total curvature. Prove that the total curvature of a closed curve is at least $2 \pi$.

645. A rectangle $R$ is tiled by finitely many rectangles each of which has at least one side of integral length. Prove that $R$ has at least one side of integral length.

\subsubsection{Other Geometry Problems}

We conclude with problems from elementary geometry. They are less in the spirit of Euclid, being based on algebraic or combinatorial considerations. Here "imagination is more important than knowledge"' (A. Einstein).

Example. Find the maximal number of triangles of area 1 with disjoint interiors that can be included in a disk of radius 1 . Describe all such configurations.

Solution. Let us first solve the following easier problem:

Find all triangles of area 1 that can be placed inside a half-disk of radius 1. We will show that the only possible configuration is that in Figure 32. Consider a triangle that maximizes the area (such a triangle exists since the vertices vary on compact sets and the area depends continuously on the vertices). The vertices of this triangle must lie on the half-circle. If $B$ lies between $A$ and $C$, then $A$ and $C$ must be the endpoints of the diameter. Indeed, if say $C$ is not an endpoint, then by moving it toward the closer endpoint of the diameter we increase both $A C$ and the angle $\angle B A C$; hence we increase the area. Finally, among all triangles inscribed in a semicircle $\overparen{A C}$, the isosceles right triangle has maximal altitude, hence also maximal area. This triangle has area 1 , and the claim is proved.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-243.jpg?height=215&width=436&top_left_y=742&top_left_x=649)

Figure 32

Returning to the problem, let us note that since the two triangles in question are convex sets, they can be separated by a line. That line cuts the disk into two regions, and one of them, containing one of the triangles, is included in a half-disk. By what we just proved, this region must itself be a half-disk. The only possible configuration consists of two isosceles triangles sharing the hypotenuse.

The next problem was published by the first author in the Mathematics Magazine.

Example. Let $A B C$ be a right triangle $\left(\angle A=90^{\circ}\right)$. On the hypotenuse $B C$ construct in the exterior the equilateral triangle $B C D$. Prove that the lengths of the segments $A B$, $A C$, and $A D$ cannot all be rational.

Solution. We will find a relation between $A B, A C$, and $A D$ by placing them in a triangle and using the law of cosines. For this, construct the equilateral triangle $A C E$ in the exterior of $A B C$ (Figure 33). We claim that $B E=A D$. This is a corollary of Napoleon's problem, and can be proved in the following way. Let $M$ be the intersection of the circumcircles of $B C D$ and $A C E$. Then $\angle A M C=120^{\circ}$ and $\angle D M C=60^{\circ}$; hence $M \in A D$. Similarly, $M \in B E$. Ptolemy's theorem applied to quadrilaterals $A M C E$ and $B M C D$ shows that $M E=A M+C M$ and $M D=B M+C M$; hence $A D=$ $A M+B M+C M=B E$.

Applying the law of cosines in triangle $A B E$, we obtain $B E^{2}=A B^{2}+A E^{2}+A B$. $A E \sqrt{3}$, and since $B E=A D$ and $A E=A C$, it follows that

$$
A D^{2}=A B^{2}+A C^{2}+A B \cdot A C \sqrt{3} .
$$



![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-244.jpg?height=574&width=456&top_left_y=246&top_left_x=644)

Figure 33

If all three segments $A B, A C$, and $A D$ had rational lengths, this relation would imply that $\sqrt{3}$ is rational, which is not true. Hence at least one of these lengths is irrational.

646. Three lines passing through an interior point of a triangle and parallel to its sides determine three parallelograms and three triangles. If $S$ is the area of the initial triangle and $S_{1}, S_{2}$, and $S_{3}$ are the areas of the newly formed triangles, prove that $S_{1}+S_{2}+S_{3} \geq \frac{1}{3} S$.

647. Someone has drawn two squares of side $0.9$ inside a disk of radius 1 . Prove that the squares overlap.

648. A surface is generated by a segment whose midpoint rotates along the unit circle in the $x y$-plane such that for each $0 \leq \alpha<2 \pi$, at the point of coordinates $(\cos \alpha, \sin \alpha)$ on the circle the segment is in the same plane with the $z$-axis and makes with it an angle of $\frac{\alpha}{2}$. This surface, called a Möbius band, is depicted in Figure 34. What is the maximal length the segment can have so that the surface does not cross itself?

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-244.jpg?height=323&width=420&top_left_y=1643&top_left_x=662)

Figure 34

649. Let $A B C D$ be a convex quadrilateral and let $O$ be the intersection of its diagonals. Given that the triangles $O A B, O B C, O C D$, and $O D A$ have the same perimeter, prove that the quadrilateral is a rhombus. Does the property hold if $O$ is some other point in the interior of the quadrilateral?

650. Prove that the plane cannot be covered by the interiors of finitely many parabolas.

651. Let $A B C$ be a triangle with the largest angle at $A$. On line $A B$ consider the point $D$ such that $A$ lies between $B$ and $D$, and $A D=A B^{3} / A C^{2}$. Prove that $C D \leq \sqrt{3} B C^{3} / A C^{2}$

652. Show that if all angles of an octagon are equal and all its sides have rational length, then the octagon has a center of symmetry.

653. Show that if each of the three main diagonals of a hexagon divides the hexagon into two parts with equal areas, then the three diagonals are concurrent.

654. Centered at every point with integer coordinates in the plane there is a disk with radius $\frac{1}{1000}$.

(a) Prove that there exists an equilateral triangle whose vertices lie in different disks.

(b) Prove that every equilateral triangle with vertices in different disks has side length greater than 96.

655. On a cylindrical surface of radius $r$, unbounded in both directions, consider $n$ points and a surface $S$ of area strictly less than 1 . Prove that by rotating around the axis of the cylinder and then translating in the direction of the axis by at most $\frac{n}{4 \pi r}$ units one can transform $S$ into a surface that does not contain any of the $n$ points.

\subsection{Trigonometry}

\subsubsection{Trigonometric Identities}

The beauty of trigonometry lies in its identities. There are two fundamental identities,

$$
\sin ^{2} x+\cos ^{2} x=1 \quad \text { and } \quad \cos (x-y)=\cos x \cos y-\sin x \sin y,
$$

both with geometric origins, from which all the others can be derived. Our problems will make use of addition and subtraction formulas for two, three, even four angles, doubleand triple-angle formulas, and product-to-sum formulas.

Example. Find all acute angles $x$ satisfying the equation

$$
2 \sin x \cos 40^{\circ}=\sin \left(x+20^{\circ}\right) \text {. }
$$

Solution. Trying particular values we see that $x=30^{\circ}$ is a solution. Are there other solutions? Use the addition formula for sine to rewrite the equation as 

$$
\tan x=\frac{\sin 20^{\circ}}{2 \cos 40^{\circ}-\cos 20^{\circ}} .
$$

The tangent function is one-to-one on the interval $\left(0,90^{\circ}\right)$, which implies that the solution to the original equation is unique.

\section{Example.}

(a) Prove that if $\cos \pi a=\frac{1}{3}$ then $a$ is an irrational number.

(b) Prove that a regular tetrahedron cannot be dissected into finitely many regular tetrahedra.

Solution. (a) Assume that $a$ is rational, $a=\frac{m}{n}$. Then $\cos n a \pi=\pm 1$. We will prove by induction that for all $k>0, \cos k a \pi=\frac{m_{k}}{3^{k}}$, with $m_{k}$ an integer that is not divisible by 3 . This will then contradict the initial assumption.

The property is true for $k=0$ and 1 . The product-to-sum formula for cosines gives rise to the recurrence

$$
\cos (k+1) a \pi=2 \cos a \pi \cos k a \pi-\cos (k-1) a \pi, \quad k \geq 1 .
$$

Using the induction hypothesis, we obtain $\cos (k+1) a \pi=\frac{m_{k+1}}{3^{k+1}}$, with $m_{k+1}=2 m_{k}-$ $3 m_{k-1}$. Since $m_{k}$ is not divisible by 3 , neither is $m_{k+1}$, and the claim is proved.

Part (b) is just a consequence of (a). To see this, let us compute the cosine of the dihedral angle of two faces of a regular tetrahedron $A B C D$. If $A H$ is an altitude of the tetrahedron and $A E$ is an altitude of the face $A B C$, then $\angle A E H$ is the dihedral angle of the faces $A B C$ and $B C D$ (see Figure 35). In the right triangle $H A E, \cos A E H=\frac{E H}{A D}=\frac{1}{3}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-246.jpg?height=395&width=513&top_left_y=1402&top_left_x=611)

Figure 35

Now assume that there exists a dissection of a regular tetrahedron into regular tetrahedra. Several of these tetrahedra meet along a segment included in one of the faces of the initial tetrahedron. Their dihedral angles must add up to $\pi$, which implies that the dihedral angle of a regular tetrahedron is of the form $\frac{\pi}{n}$, for some integer $n$. This was shown above to be false. Hence no dissection of a regular tetrahedron into regular tetrahedra exists. Remark. It is interesting to know that Leonardo da Vinci's manuscripts contain drawings of such decompositions. Later, however, Leonardo himself realized that the decompositions were impossible, and the drawings were mere optical illusions. Note also that Dehn's invariant mentioned in the first chapter provides an obstruction to the decomposition.

We conclude the introduction with a problem by the second author of the book.

Example. Let $a_{0}=\sqrt{2}+\sqrt{3}+\sqrt{6}$ and let $a_{n+1}=\frac{a_{n}^{2}-5}{2\left(a_{n}+2\right)}$ for $n \geq 0$. Prove that

$$
a_{n}=\cot \left(\frac{2^{n-3} \pi}{3}\right)-2 \text { for all } n .
$$

Solution. We have

$$
\cot \frac{\pi}{24}=\frac{\cos \frac{\pi}{24}}{\sin \frac{\pi}{24}}=\frac{2 \cos ^{2} \frac{\pi}{24}}{2 \sin \frac{\pi}{24} \cos \frac{\pi}{24}}=\frac{1+\cos \frac{\pi}{12}}{\sin \frac{\pi}{12}}=\frac{1+\cos \left(\frac{\pi}{3}-\frac{\pi}{4}\right)}{\sin \left(\frac{\pi}{3}-\frac{\pi}{4}\right)} .
$$

Using the subtraction formulas for sine and cosine we find that this is equal to

$$
\begin{aligned}
\frac{1+\frac{\sqrt{2}}{4}+\frac{\sqrt{6}}{4}}{\frac{\sqrt{6}}{4}-\frac{\sqrt{2}}{4}} &=\frac{4+\sqrt{6}+\sqrt{2}}{\sqrt{6}-\sqrt{2}}=\frac{4(\sqrt{6}+\sqrt{2})+(\sqrt{6}+\sqrt{2})^{2}}{6-2} \\
&=\frac{4(\sqrt{6}+\sqrt{2})+8+4 \sqrt{3}}{4}=2+\sqrt{2}+\sqrt{3}+\sqrt{6}=a_{0}+2 .
\end{aligned}
$$

Hence the equality $a_{n}=\cot \left(\frac{2^{n-3} \pi}{3}\right)-2$ is true at least for $n=0$.

To verify it in general, it suffices to prove that $b_{n}=\cot \left(\frac{2^{n-3} \pi}{3}\right)$, where $b_{n}=a_{n}+2$, $n \geq 1$. The recurrence relation becomes

$$
b_{n+1}-2=\frac{\left(b_{n}-2\right)^{2}-5}{2 b_{n}},
$$

or $b_{n+1}=\frac{b_{n}^{2}-1}{2 b_{n}}$. Assuming inductively that $b_{k}=\cot c_{k}$, where $c_{k}=\frac{2^{k-3} \pi}{3}$, and using the double-angle formula, we obtain

$$
b_{k+1}=\frac{\cot ^{2} c_{k}-1}{2 \cot c_{k}}=\cot \left(2 c_{k}\right)=\cot c_{k+1} .
$$

This completes the proof.

656. Prove that

$$
\sin 70^{\circ} \cos 50^{\circ}+\sin 260^{\circ} \cos 280^{\circ}=\frac{\sqrt{3}}{4}
$$

657. Show that the trigonometric equation

$$
\sin (\cos x)=\cos (\sin x)
$$

has no solutions.

658. Show that if the angles $a$ and $b$ satisfy

$$
\tan ^{2} a \tan ^{2} b=1+\tan ^{2} a+\tan ^{2} b,
$$

then

$$
\sin a \sin b=\pm \sin 45^{\circ} .
$$

659. Find the range of the function $f: \mathbb{R} \rightarrow \mathbb{R}, f(x)=(\sin x+1)(\cos x+1)$.

660. Prove that

$$
\sec ^{2 n} x+\csc ^{2 n} x \geq 2^{n+1},
$$

for all integers $n \geq 0$, and for all $x \in\left(0, \frac{\pi}{2}\right)$.

661. Compute the integral

$$
\int \sqrt{\frac{1-x}{1+x}} d x, \quad x \in(-1,1) .
$$

662. Find all integers $k$ for which the two-variable function $f(x, y)=\cos (19 x+99 y)$ can be written as a polynomial in $\cos x, \cos y, \cos (x+k y)$.

663. Let $a, b, c, d \in[0, \pi]$ be such that

$$
2 \cos a+6 \cos b+7 \cos c+9 \cos d=0
$$

and

$$
2 \sin a-6 \sin b+7 \sin c-9 \sin d=0 .
$$

Prove that $3 \cos (a+d)=7 \cos (b+c)$.

664. Let $a$ be a real number. Prove that

$$
5\left(\sin ^{3} a+\cos ^{3} a\right)+3 \sin a \cos a=0.04
$$

if and only if

$$
5(\sin a+\cos a)+2 \sin a \cos a=0.04 .
$$

665. Let $a_{0}, a_{1}, \ldots, a_{n}$ be numbers from the interval $\left(0, \frac{\pi}{2}\right)$ such that

$$
\tan \left(a_{0}-\frac{\pi}{4}\right)+\tan \left(a_{1}-\frac{\pi}{4}\right)+\cdots+\tan \left(a_{n}-\frac{\pi}{4}\right) \geq n-1 .
$$

Prove that

$$
\tan a_{0} \tan a_{1} \cdots \tan a_{n} \geq n^{n+1} .
$$



\subsubsection{Euler's Formula}

For a complex number $z$

$$
e^{z}=1+\frac{z}{1 !}+\frac{z^{2}}{2 !}+\cdots+\frac{z^{n}}{n !}+\cdots .
$$

In particular, for an angle $x$,

$$
e^{i x}=1+i \frac{x}{1 !}-\frac{x^{2}}{2 !}-i \frac{x^{3}}{3 !}+\frac{x^{4}}{4 !}+i \frac{x^{5}}{5 !}-\frac{x^{6}}{6 !}-i \frac{x^{7}}{7 !}+\cdots
$$

The real part of $e^{i x}$ is

$$
1-\frac{x^{2}}{2 !}+\frac{x^{4}}{4 !}-\frac{x^{6}}{6 !}+\cdots
$$

while the imaginary part is

$$
\frac{x}{1 !}-\frac{x^{3}}{3 !}+\frac{x^{5}}{5 !}-\frac{x^{7}}{7 !}+\cdots .
$$

These are the Taylor series of $\cos x$ and $\sin x$. We obtain Euler's formula

$$
e^{i x}=\cos x+i \sin x .
$$

Euler's formula gives rise to one of the most beautiful identities in mathematics: $e^{i \pi}=$ $-1$, which relates the number $e$ from real analysis, the imaginary unit $i$ from algebra, and $\pi$ from geometry.

The equality $e^{n z}=\left(e^{z}\right)^{n}$ holds at least for $z$ a real number. Two power series are equal for all real numbers if and only if they are equal coefficient by coefficient (since coefficients are computed using the derivatives at 0 ). So equality for real numbers means equality for complex numbers. In particular, $e^{i n x}=\left(e^{i x}\right)^{n}$, from which we deduce the de Moivre formula

$$
\cos n x+i \sin n x=(\cos x+i \sin x)^{n} .
$$

We present an application of the de Moivre formula that we found in Exercises and Problems in Algebra by C. Năstăsescu, C. Niţă, M. Brandiburu, and D. Joiţa (Editura Didactică şi Pedagogică, Bucharest, 1983).

Example. Prove the identity

$$
\left(\begin{array}{l}
n \\
0
\end{array}\right)+\left(\begin{array}{l}
n \\
k
\end{array}\right)+\left(\begin{array}{c}
n \\
2 k
\end{array}\right)+\cdots=\frac{2^{n}}{k} \sum_{j=1}^{k} \cos ^{n} \frac{j \pi}{k} \cos \frac{n j \pi}{k} .
$$

Solution. Let $\epsilon_{1}, \epsilon_{2}, \ldots, \epsilon_{k}$ be the $k$ th roots of unity, that is, $\epsilon_{j}=\cos \frac{2 j \pi}{k}+i \sin \frac{2 j \pi}{k}$, $j=1,2, \ldots, k$. The sum

$$
\epsilon_{1}^{s}+\epsilon_{2}^{s}+\cdots+\epsilon_{k}^{s}
$$

is equal to $k$ if $k$ divides $s$, and to 0 if $k$ does not divide $s$. We have

$$
\sum_{j=1}^{k}\left(1+\epsilon_{j}\right)^{n}=\sum_{s=0}^{n}\left(\begin{array}{l}
n \\
s
\end{array}\right)\left(\sum_{j=1}^{k} \epsilon_{j}^{s}\right)=k \sum_{j=0}^{\left\lfloor\frac{n}{k}\right\rfloor}\left(\begin{array}{c}
n \\
j k
\end{array}\right)
$$

Since

$$
1+\epsilon_{j}=2 \cos \frac{j \pi}{k}\left(\cos \frac{j \pi}{k}+i \sin \frac{j \pi}{k}\right) \text {, }
$$

it follows from the de Moivre formula that

$$
\sum_{j=1}^{k}\left(1+\epsilon_{j}\right)^{n}=\sum_{j=1}^{k} 2^{n} \cos ^{n} \frac{j \pi}{k}\left(\cos \frac{n j \pi}{k}+i \sin \frac{n j \pi}{k}\right) .
$$

Therefore,

$$
\left(\begin{array}{l}
n \\
0
\end{array}\right)+\left(\begin{array}{l}
n \\
k
\end{array}\right)+\left(\begin{array}{c}
n \\
2 k
\end{array}\right)+\cdots=\frac{2^{n}}{k} \sum_{j=1}^{k} \cos ^{n} \frac{j \pi}{k}\left(\cos \frac{n j \pi}{k}+i \sin \frac{n j \pi}{k}\right) .
$$

The left-hand side is real, so we can ignore the imaginary part and obtain the identity from the statement.

And now a problem given at an Indian Team Selection Test for the International Mathematical Olympiad in 2005 , proposed by the first author of the book.

Example. For real numbers $a, b, c, d$ not all equal to zero, let $f: \mathbb{R} \rightarrow \mathbb{R}$,

$$
f(x)=a+b \cos 2 x+c \sin 5 x+d \cos 8 x .
$$

Suppose that $f(t)=4 a$ for some real number $t$. Prove that there exists a real number $s$ such that $f(s)<0$.

Solution. Let $g(x)=b e^{2 i x}-i c e^{5 i x}+d e^{8 i x}$. Then $f(x)=a+\operatorname{Re} g(x)$. Note that

$$
g(x)+g\left(x+\frac{2 \pi}{3}\right)+g\left(x+\frac{4 \pi}{3}\right)=g(x)\left(1+e^{2 \pi i / 3}+e^{4 \pi i / 3}\right)=0
$$

Therefore, 

$$
f(x)+f\left(x+\frac{2 \pi}{3}\right)+f\left(x+\frac{4 \pi}{3}\right)=3 a .
$$

If $a<0$, then $s=t$ would work. If $a=0$, then for some $x$ one of the terms of the above sum is negative. This is because $f(x)$ is not identically zero, since its Fourier series is not trivial. If $a>0$, substituting $x=t$ in the identity deduced above and using the fact that $f(t)=4 a$, we obtain

$$
f\left(t+\frac{2 \pi}{3}\right)+f\left(t+\frac{4 \pi}{3}\right)=-a<0 .
$$

Hence either $f\left(t+\frac{2 \pi}{3}\right)$ or $f\left(t+\frac{4 \pi}{3}\right)$ is negative. The problem is solved.

666. Prove the identity

$$
\left(\frac{1+i \tan t}{1-i \tan t}\right)^{n}=\frac{1+i \tan n t}{1-i \tan n t}, \quad n \geq 1 .
$$

667. Prove the identity

$$
1-\left(\begin{array}{l}
n \\
2
\end{array}\right)+\left(\begin{array}{l}
n \\
4
\end{array}\right)-\left(\begin{array}{l}
n \\
6
\end{array}\right)+\cdots=2^{n / 2} \cos \frac{n \pi}{4}, \quad n \geq 1 .
$$

668. Compute the sum

$$
\left(\begin{array}{l}
n \\
1
\end{array}\right) \cos x+\left(\begin{array}{l}
n \\
2
\end{array}\right) \cos 2 x+\cdots+\left(\begin{array}{l}
n \\
n
\end{array}\right) \cos n x .
$$

669. Find the Taylor series expansion at 0 of the function

$$
f(x)=e^{x \cos \theta} \cos (x \sin \theta),
$$

where $\theta$ is a parameter.

670. Let $z_{1}, z_{2}, z_{3}$ be complex numbers of the same absolute value, none of which is real and all distinct. Prove that if $z_{1}+z_{2} z_{3}, z_{2}+z_{3} z_{1}$ and $z_{3}+z_{1} z_{2}$ are all real, then $z_{1} z_{2} z_{3}=1$.

671. Let $n$ be an odd positive integer and let $\theta$ be a real number such that $\frac{\theta}{\pi}$ is irrational. Set $a_{k}=\tan \left(\theta+\frac{k \pi}{n}\right), k=1,2, \ldots, n$. Prove that

$$
\frac{a_{1}+a_{2}+\cdots+a_{n}}{a_{1} a_{2} \cdots a_{n}}
$$

is an integer and determine its value.

672. Find $(\cos \alpha)(\cos 2 \alpha)(\cos 3 \alpha) \cdots(\cos 999 \alpha)$ with $\alpha=\frac{2 \pi}{1999}$. 

673. For positive integers $n$ define $F(n)=x^{n} \sin (n A)+y^{n} \sin (n B)+z^{n} \sin (n C)$, where $x, y, z, A, B, C$ are real numbers and $A+B+C=k \pi$ for some integer $k$. Prove that if $F(1)=F(2)=0$, then $F(n)=0$ for all positive integers $n$.

674. The continuous real-valued function $\phi(t)$ is defined for $t \geq 0$ and is absolutely integrable on every bounded interval. Define

$$
P=\int_{0}^{\infty} e^{-(t+i \phi(t))} d t \quad \text { and } \quad Q=\int_{0}^{\infty} e^{-2(t+i \phi(t))} d t
$$

Prove that

$$
\left|4 P^{2}-2 Q\right| \leq 3,
$$

with equality if and only if $\phi(t)$ is constant.

\subsubsection{Trigonometric Substitutions}

The fact that the circle $x^{2}+y^{2}=1$ can be parametrized by trigonometric functions as $x=\cos t$ and $y=\sin t$ gives rise to the standard substitution $x=a \cos t$ (or $x=$ $a \sin t$ ) in expressions of the form $\sqrt{a^{2}-x^{2}}$. Our purpose is to emphasize less standard substitutions, usually suggested by the similarity between an algebraic expression and a trigonometric formula. Such is the case with the following problem from the 61st W.L. Putnam Mathematical Competition, 2000.

Example. Let $f:[-1,1] \rightarrow \mathbb{R}$ be a continuous function such that $f\left(2 x^{2}-1\right)=2 x f(x)$ for all $x \in[-1,1]$. Show that $f$ is identically equal to zero.

Solution. Here the expression $2 x^{2}-1$ should remind us of the trigonometric formula $2 \cos ^{2} t-1=\cos 2 t$, suggesting the substitution $x=\cos t, t \in[0, \pi]$. The functional equation from the statement becomes $f(\cos 2 t)=2 \cos t f(\cos t)$.

First, note that setting $x=0$ and $x=1$, we obtain $f(1)=f(-1)=0$. Now let us define $g: \mathbb{R} \rightarrow \mathbb{R}, g(t)=\frac{f(\cos t)}{\sin t}$. Then for any $t$ not a multiple of $\pi$,

$$
g(2 t)=\frac{f\left(2 \cos ^{2} t-1\right)}{\sin (2 t)}=\frac{2 \cos t f(\cos t)}{2 \sin t \cos t}=\frac{f(\cos t)}{\sin t}=g(t) .
$$

Also, $g(t+2 \pi)=g(t)$. In particular, for any integers $n$ and $k$,

$$
g\left(1+\frac{n \pi}{2^{k}}\right)=g\left(2^{k+1}+2 n \pi\right)=g\left(2^{k+1}\right)=g(1) .
$$

Because $f$ is continuous, $g$ is continuous everywhere except at multiples of $\pi$. The set $\left\{1+\frac{n \pi}{2^{k}} \mid n, k \in \mathbf{Z}\right\}$ is dense on the real axis, and so $g$ must be constant on its domain. Then $f(\cos t)=c \sin t$ for some constant $c$ and $t$ in $(0, \pi)$, i.e., $f(x)=c \sqrt{1-x^{2}}$ for all $x \in(-1,1)$. It follows that $f$ is an even function. But then in the equation from the statement $f\left(2 x^{2}-1\right)=2 x f(x)$ the left-hand side is an even function while the righthand side is an odd function. This can happen only if both sides are identically zero. Therefore, $f(x)=0$ for $x \in[-1,1]$ is the only solution to the functional equation.

We continue with a problem that was proposed by Belgium for the 26th International Mathematical Olympiad in 1985.

Example. Let $x, y, z$ be real numbers such that $x+y+z=x y z$. Prove that

$$
x\left(1-y^{2}\right)\left(1-z^{2}\right)+y\left(1-z^{2}\right)\left(1-x^{2}\right)+z\left(1-x^{2}\right)\left(1-y^{2}\right)=4 x y z .
$$

Solution. The conclusion is immediate if $x y z=0$, so we may assume that $x, y, z \neq 0$. Dividing through by $4 x y z$ we transform the desired equality into

$$
\frac{1-y^{2}}{2 y} \cdot \frac{1-z^{2}}{2 z}+\frac{1-z^{2}}{2 x} \cdot \frac{1-x^{2}}{2 x}+\frac{1-x^{2}}{2 x} \cdot \frac{1-y^{2}}{2 y}=1 .
$$

This, along with the condition from the statement, makes us think about the substitutions $x=\tan A, y=\tan B, z=\tan C$, where $A, B, C$ are the angles of a triangle. Using the double-angle formula

$$
\frac{1-\tan ^{2} u}{2 \tan u}=\frac{1}{\tan 2 u}=\cot 2 u
$$

we further transform the equality into

$$
\cot 2 B \cot 2 C+\cot 2 C \cot 2 A+\cot 2 A \cot 2 B=1 .
$$

But this is equivalent to

$$
\tan 2 A+\tan 2 B+\tan 2 C=\tan 2 A \tan 2 B \tan 2 C,
$$

which follows from $\tan (2 A+2 B+2 C)=\tan 2 \pi=0$.

And now the problems.

675. Let $a, b, c \in[0,1]$. Prove that

$$
\sqrt{a b c}+\sqrt{(1-a)(1-b)(1-c)} \leq 1 .
$$

676. Solve the equation $x^{3}-3 x=\sqrt{x+2}$ in real numbers. 

677. Find the maximum value of

$$
S=\left(1-x_{1}\right)\left(1-y_{1}\right)+\left(1-x_{2}\right)\left(1-y_{2}\right)
$$

if $x_{1}^{2}+x_{2}^{2}=y_{1}^{2}+y_{2}^{2}=c^{2}$, where $c$ is some positive number.

678. Prove for all real numbers $a, b, c$ the inequality

$$
\frac{|a-b|}{\sqrt{1+a^{2}} \sqrt{1+b^{2}}} \leq \frac{|a-c|}{\sqrt{1+a^{2}} \sqrt{1+c^{2}}}+\frac{|b-c|}{\sqrt{1+b^{2}} \sqrt{1+c^{2}}} .
$$

679. Let $a, b, c$ be real numbers. Prove that

$$
(a b+b c+c a-1)^{2} \leq\left(a^{2}+1\right)\left(b^{2}+1\right)\left(c^{2}+1\right) .
$$

680. Prove that

$$
\frac{x}{\sqrt{1+x^{2}}}+\frac{y}{\sqrt{1+y^{2}}}+\frac{z}{\sqrt{1+z^{2}}} \leq \frac{3 \sqrt{3}}{2}
$$

if the positive real numbers $x, y, z$ satisfy $x+y+z=x y z$.

681. Prove that

$$
\frac{x}{1-x^{2}}+\frac{y}{1-y^{2}}+\frac{z}{1-z^{2}} \geq \frac{3 \sqrt{3}}{2}
$$

if $0<x, y, z<1$ and $x y+y z+x z=1$.

682. Solve the following system of equations in real numbers:

$$
\begin{aligned}
&\frac{3 x-y}{x-3 y}=x^{2}, \\
&\frac{3 y-z}{y-3 z}=y^{2}, \\
&\frac{3 z-x}{z-3 x}=z^{2} .
\end{aligned}
$$

683. Let $a_{0}=\sqrt{2}, b_{0}=2$, and

$$
a_{n+1}=\sqrt{2-\sqrt{4-a_{n}^{2}}}, \quad b_{n+1}=\frac{2 b_{n}}{2+\sqrt{4+b_{n}^{2}}}, \quad n \geq 0 .
$$

(a) Prove that the sequences $\left(a_{n}\right)_{n}$ and $\left(b_{n}\right)_{n}$ are decreasing and converge to zero.

(b) Prove that the sequence $\left(2^{n} a_{n}\right)_{n}$ is increasing, the sequence $\left(2^{n} b_{n}\right)_{n}$ is decreasing, and these two sequences converge to the same limit. (c) Prove there is a positive constant $C$ such that one has $0<b_{n}-a_{n}<\frac{C}{8^{n}}$ for all $n$.

684. Two real sequences $x_{1}, x_{2}, \ldots$, and $y_{1}, y_{2}, \ldots$ are defined in the following way:

$$
x_{1}=y_{1}=\sqrt{3}, \quad x_{n+1}=x_{n}+\sqrt{1+x_{n}^{2}}, \quad y_{n+1}=\frac{y_{n}}{1+\sqrt{1+y_{n}^{2}}}, \quad \text { for } n \geq 1 .
$$

Prove that $2<x_{n} y_{n}<3$ for all $n>1$.

685. Let $a, b, c$ be real numbers different from $\pm \frac{1}{\sqrt{3}}$. Prove that the equality $a b c=$ $a+b+c$ holds only if

$$
\frac{3 a-a^{3}}{3 a^{2}-1} \cdot \frac{3 b-b^{3}}{3 b^{2}-1} \cdot \frac{3 c-c^{3}}{3 c^{2}-1}=\frac{3 a-a^{3}}{3 a^{2}-1}+\frac{3 b-b^{3}}{3 b^{2}-1}+\frac{3 c-c^{3}}{3 c^{2}-1} .
$$

The parametrization of the hyperbola $x^{2}-y^{2}=1$ by $x=\cosh t, y=\sinh t$ gives rise to the hyperbolic substitution $x=a \cosh t$ in expressions containing $\sqrt{a^{2}-1}$. We illustrate this with an example by the second author.

Example. Let $a_{1}=a_{2}=97$ and

$$
a_{n+1}=a_{n} a_{n-1}+\sqrt{\left(a_{n}^{2}-1\right)\left(a_{n-1}^{2}-1\right)}, \quad \text { for } n>1 .
$$

Prove that

(a) $2+2 a_{n}$ is a perfect square;

(b) $2+\sqrt{2+2 a_{n}}$ is a perfect square.

Solution. We are led to the substitution $a_{n}=\cosh t_{n}$ for some number $t_{n}$ (which for the moment might be complex). The recurrence relation becomes

$$
\cosh t_{n+1}=a_{n+1}=\cosh t_{n} \cosh t_{n-1}+\sinh t_{n} \sinh t_{n-1}=\cosh \left(t_{n}+t_{n-1}\right) .
$$

We deduce that the numbers $t_{n}$ satisfy $t_{0}=t_{1}$, and $t_{n+1}=t_{n}+t_{n-1}$ (in particular they are all real). And so $t_{n}=F_{n} t_{0}$, where $\left(F_{n}\right)_{n}$ is the Fibonacci sequence. Consequently, $a_{n}=\cosh \left(F_{n} t_{0}\right), n \geq 1$.

Using the identity $2(\cosh t)^{2}-1=\cosh 2 t$, we obtain

$$
2+2 a_{n}=\left(2 \cosh F_{n} \frac{t_{0}}{2}\right)^{2} .
$$

The recurrence relation

$$
2 \cosh (k+1) t=(2 \cosh t)(2 \cosh k t)-2 \cosh (k-1) t
$$

allows us to prove inductively that $2 \cosh k \frac{t_{0}}{2}$ is an integer once we show that $2 \cosh \frac{t_{0}}{2}$ is an integer. It would then follow that $2 \cosh F_{n} \frac{t_{0}}{2}$ is an integer as well. And indeed $2 \cosh \frac{t_{0}}{2}=\sqrt{2+2 a_{1}}=14$. This completes the proof of part (a).

To prove (b), we obtain in the same manner

$$
2+\sqrt{2+2 a_{n}}=\left(2 \cosh F_{n} \frac{t_{0}}{4}\right)^{2},
$$

and again we have to prove that $2 \cosh \frac{t_{0}}{4}$ is an integer. We compute $2 \cosh \frac{t_{0}}{4}=$ $\sqrt{2+\sqrt{2+2 a_{n}}}=\sqrt{2+14}=4$. The conclusion follows.

686. Compute the integral

$$
\int \frac{d x}{x+\sqrt{x^{2}-1}} .
$$

687. Let $n>1$ be an integer. Prove that there is no irrational number $a$ such that the number

$$
\sqrt[n]{a+\sqrt{a^{2}-1}}+\sqrt[n]{a-\sqrt{a^{2}-1}}
$$

is rational.

\subsubsection{Telescopic Sums and Products in Trigonometry}

The philosophy of telescopic sums and products in trigonometry is the same as in the general case, just that here we have more identities at hand. Let us take a look at a slightly modified version of an identity of C.A. Laisant.

Example. Prove that

$$
\sum_{k=0}^{n}\left(-\frac{1}{3}\right)^{k} \cos ^{3}\left(3^{k-n} \pi\right)=\frac{3}{4}\left[\left(-\frac{1}{3}\right)^{n+1}+\cos \frac{\pi}{3^{n}}\right] .
$$

Solution. From the identity $\cos 3 x=4 \cos ^{3} x-3 \cos x$, we obtain

$$
\cos ^{3} x=\frac{1}{4}(\cos 3 x+3 \cos x) .
$$

Then

$$
\sum_{k=0}^{n}\left(-\frac{1}{3}\right)^{k} \cos ^{3}\left(3^{k} a\right)=\frac{1}{4} \sum_{k=0}^{n}\left[\left(-\frac{1}{3}\right)^{k} \cos \left(3^{k+1} a\right)-\left(-\frac{1}{3}\right)^{k-1} \cos \left(3^{k} a\right)\right] .
$$

This telescopes to

$$
\frac{1}{4}\left[\left(-\frac{1}{3}\right)^{n} \cos \left(3^{n+1} a\right)-\left(-\frac{1}{3}\right)^{-1} \cos a\right] .
$$

For $a=3^{-n} \pi$, we obtain the identity from the statement.

Test your skills against the following problems.

688. Prove that

$$
27 \sin ^{3} 9^{\circ}+9 \sin ^{3} 27^{\circ}+3 \sin ^{3} 81^{\circ}+\sin ^{3} 243^{\circ}=20 \sin 9^{\circ} .
$$

689. Prove that

$$
\begin{aligned}
\frac{1}{\cot 9^{\circ}-3 \tan 9^{\circ}} &+\frac{3}{\cot 27^{\circ}-3 \tan 27^{\circ}}+\frac{9}{\cot 81^{\circ}-3 \tan 81^{\circ}} \\
&+\frac{27}{\cot 243^{\circ}-3 \tan 243^{\circ}}=10 \tan 9^{\circ}
\end{aligned}
$$

690. Prove that

$$
\frac{1}{\sin 45^{\circ} \sin 46^{\circ}}+\frac{1}{\sin 47^{\circ} \sin 48^{\circ}}+\cdots+\frac{1}{\sin 133^{\circ} \sin 134^{\circ}}=\frac{1}{\sin 1^{\circ}} .
$$

691. Obtain explicit values for the following series:
(a) $\sum_{n=1}^{\infty} \arctan \frac{2}{n^{2}}$,
(b) $\sum_{n=1}^{\infty} \arctan \frac{8 n}{n^{4}-2 n^{2}+5}$.

692. For $n \geq 0$ let

$$
u_{n}=\arcsin \frac{\sqrt{n+1}-\sqrt{n}}{\sqrt{n+2} \sqrt{n+1}} .
$$

Prove that the series

$$
S=u_{0}+u_{1}+u_{2}+\cdots+u_{n}+\cdots
$$

is convergent and find its limit.

Now we turn to telescopic products. Example. Prove that

$$
\prod_{n=1}^{\infty} \frac{1}{1-\tan ^{2} 2^{-n}}=\tan 1 .
$$

Solution. The solution is based on the identity

$$
\tan 2 x=\frac{2 \tan x}{1-\tan ^{2} x} .
$$

Using it we can write

$$
\prod_{n=1}^{N} \frac{1}{1-\tan ^{2} 2^{-n}}=\prod_{n=1}^{N} \frac{\tan 2^{-n+1}}{2 \tan 2^{-n}}=\frac{2^{-N}}{\tan 2^{-N}} \tan 1 .
$$

Since $\lim _{x \rightarrow 0} \frac{\tan x}{x}=1$, when letting $N \rightarrow \infty$ this becomes $\tan 1$, as desired.

693. In a circle of radius 1 a square is inscribed. A circle is inscribed in the square and then a regular octagon in the circle. The procedure continues, doubling each time the number of sides of the polygon. Find the limit of the lengths of the radii of the circles.

694. Prove that

$$
\left(1-\frac{\cos 61^{\circ}}{\cos 1^{\circ}}\right)\left(1-\frac{\cos 62^{\circ}}{\cos 2^{\circ}}\right) \cdots\left(1-\frac{\cos 119^{\circ}}{\cos 59^{\circ}}\right)=1
$$

695. Evaluate the product

$$
\left(1-\cot 1^{\circ}\right)\left(1-\cot 2^{\circ}\right) \cdots\left(1-\cot 44^{\circ}\right) \text {. }
$$

696. Compute the product

$$
\left(\sqrt{3}+\tan 1^{\circ}\right)\left(\sqrt{3}+\tan 2^{\circ}\right) \cdots\left(\sqrt{3}+\tan 29^{\circ}\right) .
$$

697. Prove the identities
(a) $\left(\frac{1}{2}-\cos \frac{\pi}{7}\right)\left(\frac{1}{2}-\cos \frac{3 \pi}{7}\right)\left(\frac{1}{2}-\cos \frac{9 \pi}{7}\right)=-\frac{1}{8}$,
(b) $\left(\frac{1}{2}+\cos \frac{\pi}{20}\right)\left(\frac{1}{2}+\cos \frac{3 \pi}{20}\right)\left(\frac{1}{2}+\cos \frac{9 \pi}{20}\right)\left(\frac{1}{2}+\cos \frac{27 \pi}{20}\right)=\frac{1}{16}$.

698. Prove the identities
(a) $\prod_{n=1}^{24} \sec \left(2^{n}\right)^{\circ}=-2^{24} \tan 2^{\circ}$
(b) $\prod_{n=2}^{25}\left(2 \cos \left(2^{n}\right)^{\circ}-\sec \left(2^{n}\right)^{\circ}\right)=-1$. 

\section{Number Theory}

This chapter on number theory is truly elementary, although its problems are far from easy. (In fact, here, as elsewhere in the book, we tried to follow Felix Klein's advice: "Don't ever be absolutely boring." ${ }^{1}$ We avoided the intricacies of algebraic number theory, and restricted ourselves to some basic facts about residue classes and divisibility: Fermat's little theorem and its generalization due to Euler, Wilson's theorem, the Chinese Remainder Theorem, and Polignac's formula. From all Diophantine equations we discuss linear equations in two variables and two types of quadratic equations: the Pythagorean equation and Pell's equation.

But first, three sections for which not much background is necessary.

\subsection{Integer-Valued Sequences and Functions}

\subsubsection{Some General Problems}

Here are some problems, not necessarily straightforward, that use only the basic properties of integers.

Example. Find all functions $f:\{0,1,2, \ldots\} \rightarrow\{0,1,2, \ldots\}$ with the property that for every $m, n \geq 0$,

$$
2 f\left(m^{2}+n^{2}\right)=(f(m))^{2}+(f(n))^{2} .
$$

Solution. The substitution $m=n=0$ yields

$$
2 f\left(0^{2}+0^{2}\right)=(f(0))^{2}+(f(0))^{2},
$$

and this gives $f(0)^{2}=f(0)$, hence $f(0)=0$ or $f(0)=1$.

${ }^{1}$ Seien Sie niemals absolut langweilig. We pursue the track of $f(0)=0$ first. We have

$$
2 f\left(1^{2}+0^{2}\right)=(f(1))^{2}+(f(0))^{2},
$$

so $2 f(1)=f(1)^{2}$, and hence $f(1)=0$ or $f(1)=2$. Let us see what happens if $f(1)=2$, since this is the most interesting situation. We find immediately

$$
2 f(2)=2 f\left(1^{2}+1^{2}\right)=(f(1))^{2}+(f(1))^{2}=8,
$$

so $f(2)=4$, and then

$$
\begin{aligned}
&2 f(4)=2 f\left(2^{2}+0^{2}\right)=(f(2))^{2}+(f(0))^{2}=16, \\
&2 f(5)=2 f\left(2^{2}+1^{2}\right)=(f(2))^{2}+(f(1))^{2}=20, \\
&2 f(8)=2 f\left(2^{2}+2^{2}\right)=(f(2))^{2}+(f(2))^{2}=32 .
\end{aligned}
$$

So $f(4)=8, f(5)=10, f(8)=16$. In fact, $f(n)=2 n$ for $n \leq 10$, but as we will see below, the proof is more involved. Indeed,

$$
\begin{aligned}
100 &=(f(5))^{2}+(f(0))^{2}=2 f\left(5^{2}\right)=2 f\left(3^{2}+4^{2}\right)=(f(3))^{2}+(f(4))^{2} \\
&=(f(3))^{2}+64,
\end{aligned}
$$

hence $f(3)=6$. Then immediately

$$
\begin{aligned}
2 f(9) &=2 f\left(3^{2}+0^{2}\right)=(f(3))^{2}+(f(0))^{2}=36, \\
2 f(10) &=2 f\left(3^{2}+1^{2}\right)=(f(3))^{2}+(f(1))^{2}=40,
\end{aligned}
$$

so $f(9)=18, f(10)=20$.

Applying an idea used before, we have

$$
\begin{aligned}
400 &=(f(10))^{2}+(f(0))^{2}=2 f\left(10^{2}\right)=2 f\left(6^{2}+8^{2}\right)=(f(6))^{2}+(f(8))^{2} \\
&=(f(6))^{2}+256,
\end{aligned}
$$

from which we obtain $f(6)=12$. For $f(7)$ we use the fact that $7^{2}+1^{2}=5^{2}+5^{2}$ and the equality

$$
(f(7))^{2}+(f(1))^{2}=(f(5))^{2}+(f(5))^{2}
$$

to obtain $f(7)=14$.

We want to prove that $f(n)=2 n$ for $n>10$ using strong induction. The argument is based on the identities

$$
(5 k+1)^{2}+2^{2}=(4 k+2)^{2}+(3 k-1)^{2},
$$



$$
\begin{aligned}
&(5 k+2)^{2}+1^{2}=(4 k+1)^{2}+(3 k+2)^{2}, \\
&(5 k+3)^{2}+1^{2}=(4 k+3)^{2}+(3 k+1)^{2}, \\
&(5 k+4)^{2}+2^{2}=(4 k+2)^{2}+(3 k+4)^{2}, \\
&(5 k+5)^{2}+0^{2}=(4 k+4)^{2}+(3 k+3)^{2} .
\end{aligned}
$$

Note that if $k \geq 2$, then the first term on the left is strictly greater then any of the two terms on the right, and this makes the induction possible. Assume that $f(m)=2 m$ for $m<n$ and let us prove $f(n)=2 n$. Let $n=5 k+j, 1 \leq j \leq 5$, and use the corresponding identity to write $n^{2}+m_{1}^{2}=m_{2}^{2}+m_{3}^{2}$, where $m_{1}, m_{2}, m_{3}$ are positive integers less than $n$. We then have

$$
(f(n))^{2}+\left(f\left(m_{1}\right)\right)^{2}=2 f\left(n^{2}+m_{1}^{2}\right)=2 f\left(m_{2}^{2}+m_{3}^{2}\right)=\left(f\left(m_{2}\right)\right)^{2}+\left(f\left(m_{3}\right)\right)^{2} .
$$

This then gives

$$
(f(n))^{2}=\left(2 m_{2}\right)^{2}+\left(2 m_{3}\right)^{2}-\left(2 m_{1}\right)^{2}=4\left(m_{2}^{2}+m_{3}^{2}-m_{1}^{2}\right)=4 n^{2} .
$$

Hence $f(n)=2 n$, completing the inductive argument. And indeed, this function satisfies the equation from the statement.

If we start with the assumption $f(1)=0$, the exact same reasoning applied mutatis mutandis shows that $f(n)=0, n \geq 0$. And the story repeats if $f(0)=1$, giving $f(n)=1, n \geq 0$. Thus the functional equation has three solutions: $f(n)=2 n, n \geq 0$, and the constant solutions $f(n)=0, n \geq 0$, and $f(n)=1, n \geq 0$.

With the additional hypothesis $f\left(m^{2}\right) \geq f\left(n^{2}\right)$ if $m \geq n$, this problem appeared at the 1998 Korean Mathematical Olympiad. The solution presented above was communicated to us by B.J. Venkatachala.

699. Let $k$ be a positive integer. The sequence $\left(a_{n}\right)_{n}$ is defined by $a_{1}=1$, and for $n \geq 2$, $a_{n}$ is the $n$th positive integer greater than $a_{n-1}$ that is congruent to $n$ modulo $k$. Find $a_{n}$ in closed form.

700. Three infinite arithmetic progressions are given, whose terms are positive integers. Assuming that each of the numbers $1,2,3,4,5,6,7,8$ occurs in at least one of these progressions, show that 1980 necessarily occurs in one of them.

701. Find all functions $f: \mathbb{N} \rightarrow \mathbb{N}$ satisfying

$$
f(n)+2 f(f(n))=3 n+5, \quad \text { for all } n \in \mathbb{N} .
$$

702. Find all functions $f: \mathbb{Z} \rightarrow \mathbb{Z}$ with the property that

$$
2 f(f(x))-3 f(x)+x=0, \quad \text { for all } x \in \mathbb{Z} .
$$

703. Prove that there exists no bijection $f: \mathbb{N} \rightarrow \mathbb{N}$ such that

$$
f(m n)=f(m)+f(n)+3 f(m) f(n),
$$

for all $m, n \geq 1$.

704. Show that there does not exist a sequence $\left(a_{n}\right)_{n \geq 1}$ of positive integers such that

$$
a_{n-1} \leq\left(a_{n+1}-a_{n}\right)^{2} \leq a_{n}, \quad \text { for all } n \geq 2 .
$$

705. Determine all functions $f: \mathbb{Z} \rightarrow \mathbb{Z}$ satisfying

$$
f\left(x^{3}+y^{3}+z^{3}\right)=(f(x))^{3}+(f(y))^{3}+(f(z))^{3}, \quad \text { for all } x, y, z \in \mathbb{Z} .
$$

\subsubsection{Fermat's Infinite Descent Principle}

Fermat's infinite descent principle states that there are no strictly decreasing infinite sequences of positive integers. Alternatively, any decreasing sequence of positive integers becomes stationary. This is a corollary of the fundamental property of the set of positive integers that every subset has a smallest element. To better understand this principle, let us apply it to an easy example.

Example. At each point of integer coordinates in the plane is written a positive integer number such that each of these numbers is the arithmetic mean of its four neighbors. Prove that all the numbers are equal.

Solution. The solution is an application of the maximum modulus principle. For $n \geq 1$, consider the square of side $2 n$ centered at the origin. Among the numbers covered by it, the smallest must lie on its perimeter. Let this minimum be $m(n)$. If it is also attained in the interior of the square, then the four neighbors of that interior point must be equal, and step by step we show that all numbers inside that square are equal. Hence there are two possibilities. Either $m(1)>m(2)>m(3)>\cdots$ or $m(n)=m(n+1)$ for infinitely many $n$. The former case is impossible, since the $m(n)$ 's are positive integers; the latter case implies that all the numbers are equal.

We find even more spectacular this problem from the 2004 USA Mathematical Olympiad.

Example. Suppose that $a_{1}, \ldots, a_{n}$ are integers whose greatest common divisor is 1 . Let $S$ be a set of integers with the following properties:

(i) For $i=1, \ldots, n, a_{i} \in S$.

(ii) For $i, j=1, \ldots, n$ (not necessarily distinct), $a_{i}-a_{j} \in S$.

(iii) For any integers $x, y \in S$, if $x+y \in S$, then $x-y \in S$. Prove that $S$ must equal the set of all integers.

Solution. This problem was submitted by K. Kedlaya and L. Ng. The solution below was discovered by $M$. Ince and earned him the Clay prize.

First thing, note that if $b_{1}, b_{2}, \ldots, b_{m}$ are some integers that generate $S$ and satisfy the three conditions from the statement, then $b_{i}-2 b_{j}$ and $2 b_{i}-b_{j}$ are also in $S$ for any indices $i$ and $j$. Indeed, since $b_{i}, b_{j}$, and $b_{i}-b_{j}$ are in $S$, by (iii) we have that $b_{i}-2 b_{j} \in S$. Moreover, for $i=j$ in (ii) we find that $0=b_{i}-b_{i} \in S$. Hence applying (iii) to $x \in S$ and 0 we have that $-x \in S$ as well, and in particular $2 b_{i}-b_{j} \in S$.

An $n$-tuple $\left(b_{1}, b_{2}, \ldots, b_{n}\right)$ as above can be substituted by $\left(b_{1}, b_{2}-b_{1}, \ldots, b_{n}-b_{1}\right)$, which again generates $S$ and, by what we just proved, satisfies (i), (ii), and (iii). Applying this step to $\left(\left|a_{1}\right|,\left|a_{2}\right|, \ldots,\left|a_{n}\right|\right)$ and assuming that $\left|a_{1}\right|$ is the smallest of these numbers, we obtain another $n$-tuple the sum of whose entries is smaller. Because we cannot have an infinite descent, we eventually reach an $n$-tuple with the first entry equal to 0 . In the process we did not change the greatest common divisor of the entries. Ignoring the zero entries, we can repeat the procedure until there is only one nonzero number left. This number must be 1 .

From the fact that $0,1 \in S$ and then also $-1 \in S$, by applying (iii) to $x=1, y=-1$ we find that $2 \in S$, and inductively we find that all positive, and also all negative, integers are in $S$. We conclude that $S=\mathbb{Z}$. As I. Kaplansky said, "An elegant proof hits you between your eyes with joy."

706. Show that no positive integers $x, y, z$ can satisfy the equation

$$
x^{2}+10 y^{2}=3 z^{2} .
$$

707. Prove that the system of equations

$$
\begin{aligned}
&x^{2}+5 y^{2}=z^{2}, \\
&5 x^{2}+y^{2}=t^{2}
\end{aligned}
$$

does not admit nontrivial integer solutions.

708. Show that the equation

$$
x^{2}-y^{2}=2 x y z
$$

has no solutions in the set of positive integers.

709. Prove that there is no infinite arithmetic progression whose terms are all perfect squares.

710. Let $f$ be a bijection of the set of positive integers. Prove that there exist positive integers $a<a+d<a+2 d$ such that $f(a)<f(a+d)<f(a+2 d)$. 

711. Prove that for no integer $n>1$ does $n$ divide $2^{n}-1$.

712. Find all pairs of positive integers $(a, b)$ with the property that $a b+a+b$ divides $a^{2}+b^{2}+1$.

713. Let $x, y, z$ be positive integers such that $x y-z^{2}=1$. Prove that there exist nonnegative integers $a, b, c, d$ such that

$$
x=a^{2}+b^{2}, \quad y=c^{2}+d^{2}, \quad z=a c+b d .
$$

\subsubsection{The Greatest Integer Function}

The greatest integer function associates to a number $x$ the greatest integer less than or equal to $x$. The standard notation is $\lfloor x\rfloor$. For example, $\lfloor 2\rfloor=2$, $\lfloor 3.2\rfloor=3,\lfloor-2.1\rfloor=-3$. This being said, let us start with the problems.

Beatty's theorem. Let $\alpha$ and $\beta$ be two positive irrational numbers satisfying $\frac{1}{\alpha}+\frac{1}{\beta}=1$. Then the sequences $\lfloor\alpha n\rfloor$ and $\lfloor\beta n\rfloor, n \geq 1$, are strictly increasing and determine a partition of the set of positive integers into two disjoint sets.

Proof. In other words, each positive integer shows up in exactly one of the two sequences. Let us first prove the following result.

Lemma. If $x_{n}, n \geq 1$, is an increasing sequence of positive integers with the property that for every $n$, the number of indices $m$ such that $x_{m}<n$ is equal to $n-1$, then $x_{n}=n$ for all $n$.

Proof. We do the proof by induction. The base case is obvious: because the sequence is increasing, the only $n$ for which $x_{n}<2$ is $n=1$. Now let us assume that $x_{1}=1$, $x_{2}=$ $2, \ldots, x_{n-1}=n-1$. From the hypothesis it also follows that there are no other indices $m$ for which $x_{m}<n$. And because there is exactly one more term of the sequence that is less than $n+1$, this term must be $x_{n}$ and it is equal to $n$.

Returning to the problem, let us write all numbers of the form $\lfloor\alpha n\rfloor$ and $\lfloor\beta n\rfloor$ in an increasing sequence $y_{n}$. For every $n$ there are exactly $\left\lfloor\frac{n}{\alpha}\right\rfloor$ numbers of the form $\lfloor k \alpha\rfloor$, and $\left\lfloor\frac{n}{\beta}\right\rfloor$ numbers of the form $\lfloor k \beta\rfloor$ that are strictly less than $n$ (here we used the fact that $\alpha$ and $\beta$ are irrational). We have

$$
n-1=\left\lfloor\frac{n}{\alpha}+\frac{n}{\beta}\right\rfloor-1 \leq\left\lfloor\frac{n}{\alpha}\right\rfloor+\left\lfloor\frac{n}{\beta}\right\rfloor<\frac{n}{\alpha}+\frac{n}{\beta}=n .
$$

Hence $\left\lfloor\frac{n}{\alpha}\right\rfloor+\left\lfloor\frac{n}{\beta}\right\rfloor=n-1$, which shows that the sequence $y_{n}$ satisfies the condition of the lemma. It follows that this sequence consists of all positive integers written in strictly increasing order. Hence the conclusion. Our second example is a general identity discovered by the second author and $\mathrm{D}$. Andrica. Note the similarity with Young's inequality for integrals (problem 480).

Theorem. Let $a<b$ and $c<d$ be positive real numbers and let $f:[a, b] \rightarrow[c, d]$ be a continuous, bijective, and increasing function. Then

$$
\sum_{a \leq k \leq b}\lfloor f(k)\rfloor+\sum_{c \leq k \leq d}\left\lfloor f^{-1}(k)\right\rfloor-n\left(G_{f}\right)=\lfloor b\rfloor\lfloor d\rfloor-\alpha(a) \alpha(c),
$$

where $k$ is an integer, $n\left(G_{f}\right)$ is the number of points with nonnegative integer coordinates on the graph of $f$, and $\alpha: \mathbb{R} \rightarrow \mathbb{Z}$ is defined by

$$
\alpha(x)= \begin{cases}\lfloor x\rfloor & \text { if } x \in \mathbb{R} \backslash \mathbb{Z}, \\ 0 & \text { if } x=0, \\ x-1 & \text { if } x \in \mathbb{Z} \backslash\{0\} .\end{cases}
$$

Proof. The proof is by counting. For a region $M$ of the plane, we denote by $n(M)$ the number of points with nonnegative integer coordinates in $M$. For our theorem, consider the sets

$$
\begin{aligned}
&M_{1}=\left\{(x, y) \in \mathbb{R}^{2} \mid a \leq x \leq b, 0 \leq y \leq f(x)\right\}, \\
&M_{2}=\left\{(x, y) \in \mathbb{R}^{2} \mid c \leq y \leq d, 0 \leq x \leq f^{-1}(y)\right\}, \\
&M_{3}=\left\{(x, y) \in \mathbb{R}^{2} \mid 0<x \leq b, 0<y \leq d\right\}, \\
&M_{4}=\left\{(x, y) \in \mathbb{R}^{2} \mid 0<x<a, 0<y<c\right\} .
\end{aligned}
$$

Then

$$
\begin{aligned}
& n\left(M_{1}\right)=\sum_{a \leq k \leq b}\lfloor f(k)\rfloor, \quad n\left(M_{2}\right)=\sum_{c \leq k \leq d}\left\lfloor f^{-1}(k)\right\rfloor, \\
& n\left(M_{3}\right)=\lfloor b\rfloor\lfloor d\rfloor, \quad n\left(M_{4}\right)=\alpha(a) \alpha(c) .
\end{aligned}
$$

By the inclusion-exclusion principle,

$$
n\left(M_{1} \cup M_{2}\right)=n\left(M_{1}\right)+n\left(M_{2}\right)-n\left(M_{1} \cap M_{2}\right) .
$$

Note that $n\left(M_{1} \cap M_{2}\right)=n\left(G_{f}\right)$ and $N\left(M_{1} \cup M_{2}\right)=n\left(M_{3}\right)-n\left(M_{4}\right)$. The identity follows.

714. For a positive integer $n$ and a real number $x$, prove the identity

$$
\lfloor x\rfloor+\left\lfloor x+\frac{1}{n}\right\rfloor+\cdots+\left\lfloor x+\frac{n-1}{n}\right\rfloor=\lfloor n x\rfloor .
$$

715. For a positive integer $n$ and a real number $x$, compute the sum

$$
\sum_{0 \leq i<j \leq n}\left\lfloor\frac{x+i}{j}\right\rfloor .
$$

716. Prove that for any positive integer $n$,

$$
\lfloor\sqrt{n}\rfloor=\left\lfloor\sqrt{n}+\frac{1}{\sqrt{n}+\sqrt{n+2}}\right\rfloor .
$$

717. Express $\sum_{k=1}^{n}\lfloor\sqrt{k}\rfloor$ in terms of $n$ and $a=\lfloor\sqrt{n}\rfloor$.

718. Prove the identity

$$
\sum_{k=1}^{\frac{n(n+1)}{2}}\left\lfloor\frac{-1+\sqrt{1+8 k}}{2}\right\rfloor=\frac{n\left(n^{2}+2\right)}{3}, \quad n \geq 1 .
$$

719. Find all pairs of real numbers $(a, b)$ such that $a\lfloor b n\rfloor=b\lfloor a n\rfloor$ for all positive integers $n$.

720. For $p$ and $q$ coprime positive integers prove the reciprocity law

$$
\left\lfloor\frac{p}{q}\right\rfloor+\left\lfloor\frac{2 p}{q}\right\rfloor+\cdots+\left\lfloor\frac{(q-1) p}{q}\right\rfloor=\left\lfloor\frac{q}{p}\right\rfloor+\left\lfloor\frac{2 q}{p}\right\rfloor+\cdots+\left\lfloor\frac{(p-1) q}{p}\right\rfloor .
$$

721. Prove that for any real number $x$ and for any positive integer $n$,

$$
\lfloor n x\rfloor \geq \frac{\lfloor x\rfloor}{1}+\frac{\lfloor 2 x\rfloor}{2}+\frac{\lfloor 3 x\rfloor}{3}+\cdots+\frac{\lfloor n x\rfloor}{n} .
$$

722. Does there exist a strictly increasing function $f: \mathbb{N} \rightarrow \mathbb{N}$ such that $f(1)=2$ and $f(f(n))=f(n)+n$ for all $n$ ?

723. Suppose that the strictly increasing functions $f, g: \mathbb{N} \rightarrow \mathbb{N}$ partition $\mathbb{N}$ into two disjoint sets and satisfy

$$
g(n)=f(f(k n))+1, \quad \text { for all } n \geq 1,
$$

for some fixed positive integer $k$. Prove that $f$ and $g$ are unique with this property and find explicit formulas for them. 

\section{$5.2$ Arithmetic}

\subsubsection{Factorization and Divisibility}

There isn't much to say here. An integer $d$ divides another integer $n$ if there is an integer $d^{\prime}$ such that $n=d d^{\prime}$. In this case $d$ is called a divisor of $n$. We denote by $\operatorname{gcd}(a, b)$ the greatest common divisor of $a$ and $b$. For any positive integers $a$ and $b$, Euclid's algorithm yields integers $x$ and $y$ such that $a x-b y=\operatorname{gcd}(a, b)$. Two numbers are called coprime, or relatively prime, if their greatest common divisor is 1 . The fact that for coprime numbers $a$ and $b$ there exist integers $x$ and $y$ such that $a x-b y=1$ is called the fundamental theorem of arithmetic.

We begin with a problem from the Soviet Union Mathematical Olympiad for University Students in 1976.

Example. Prove that there is no polynomial with integer coefficients $P(x)$ with the property that $P(7)=5$ and $P(15)=9$.

Solution. Assume that such a polynomial $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$ does exist. Then $P(7)=a_{n} 7^{n}+a_{n-1} 7^{n-1}+\cdots+a_{0}$ and $P(15)=a_{n} 15^{n}+a_{n-1} 15^{n-1}+\cdots+a_{0}$. Subtracting, we obtain

$$
4=P(15)-P(7)=a_{n}\left(15^{n}-7^{n}\right)+a_{n-1}\left(15^{n-1}-7^{n-1}\right)+\cdots+a_{1}(15-7) .
$$

Since for any $k, 15^{k}-7^{k}$ is divisible by $15-7=8$, it follows that $P(15)-P(7)=4$ itself is divisible by 8 , a contradiction. Hence such a polynomial does not exist.

The second problem was given at the Asia-Pacific Mathematical Olympiad in 1998.

Example. Show that for any positive integers $a$ and $b$, the product $(36 a+b)(a+36 b)$ cannot be a power of 2 .

Solution. Assume that $(36 a+b)(a+36 b)$ is a power of 2 for some integers $a$ and $b$. Without loss of generality, we may assume that $a$ and $b$ are coprime and $a<b$. Let $36 a+b=2^{m}$ and $a+36 b=2^{n}$. Adding and subtracting, we obtain $37(a+b)=$ $2^{m}\left(2^{n-m}+1\right)$, respectively, 35(a-b) $=2^{m}\left(2^{n-m}-1\right)$. It follows that both $a+b$ and $a-b$ are divisible by $2^{m}$. This can happen only if both $a$ and $b$ are divisible by $2^{m-1}$. Our assumption that $a$ and $b$ are coprime implies that $m=1$. But then $36 a+b=2$, which is impossible. Hence the conclusion.

724. Find the integers $n$ for which $\left(n^{3}-3 n^{2}+4\right) /(2 n-1)$ is an integer.

725. Prove that in the product $P=1 ! \cdot 2 ! \cdot 3 ! \cdots 100$ ! one of the factors can be erased so that the remaining product is a perfect square. 

726. The sequence $a_{1}, a_{2}, a_{3}, \ldots$ of positive integers satisfies $\operatorname{gcd}\left(a_{i}, a_{j}\right)=\operatorname{gcd}(i, j)$ for $i \neq j$. Prove that $a_{i}=i$ for all $i$.

727. Let $n, a, b$ be positive integers. Prove that

$$
\operatorname{gcd}\left(n^{a}-1, n^{b}-1\right)=n^{\operatorname{gcd}(a, b)}-1 .
$$

728. Let $a$ and $b$ be positive integers. Prove that the greatest common divisor of $2^{a}+1$ and $2^{b}+1$ divides $2^{\operatorname{gcd}(a, b)}+1$.

729. Fix a positive integer $k$ and define the sequence $\left(a_{n}\right)_{n}$ by $a_{1}=k+1$ and $a_{n+1}=$ $a_{n}^{2}-k a_{n}+k$ for $n \geq 1$. Prove that for any distinct positive integers $m$ and $n$ the numbers $a_{m}$ and $a_{n}$ are coprime.

730. Let $a, b, c, d, e$, and $f$ be positive integers. Suppose that $S=a+b+c+d+e+f$ divides both $a b c+d e f$ and $a b+b c+c a-d e-e f-f d$. Prove that $S$ is composite.

731. Let $n$ be an integer greater than 2 . Prove that $n(n-1)^{4}+1$ is the product of two integers greater than 1 .

732. Determine the functions $f:\{0,1,2 \ldots\} \rightarrow\{0,1,2, \ldots\}$ satisfying

(i) $f(2 n+1)^{2}-f(2 n)^{2}=6 f(n)+1$ and

(ii) $f(2 n) \geq f(n)$ for all $n \geq 0$.

\subsubsection{Prime Numbers}

A positive integer is called prime if it has no other divisors than 1 and the number itself. Equivalently, a number is prime if whenever it divides a product it divides one of the factors. Any positive integer can be written as a product of primes in a unique way up to a permutation of the factors.

Euclid's theorem. There are infinitely many prime numbers.

Proof. From the more than one hundred proofs of this theorem we selected the fascinating topological proof given in 1955 by H. Furstenberg. By definition, a topology on a set $X$ is a collection $\mathcal{T}$ of sets satisfying

(i) $\emptyset, X \in \mathcal{T}$;

(ii) for any family $\left(U_{i}\right)_{i \in I}$ of sets from $\mathcal{T}$, the union $\cup_{i \in I} U_{i}$ is also in $\mathcal{T}$;

(iii) for any $U_{1}, U_{2}, \ldots, U_{n}$ in $\mathcal{T}$, the intersection $U_{1} \cap U_{2} \cap \cdots \cap U_{n}$ is in $\mathcal{T}$.

The elements of $\mathcal{T}$ are called open sets; their complements are called closed sets. This definition is the abstraction, in the spirit of Bourbaki, of the properties of open sets on the real axis.

Furstenberg's idea was to introduce a topology on $\mathbb{Z}$, namely the smallest topology in which any set consisting of all terms of a nonconstant arithmetic progression is open. As an example, in this topology both the set of odd integers and the set of even integers are open. Because the intersection of two arithmetic progressions is an arithmetic progression, the open sets of $\mathcal{T}$ are precisely the unions of arithmetic progressions. In particular, any open set is either infinite or void.

If we define

$$
A_{a, d}=\{\ldots, a-2 d, a-d, a, a+d, a+2 d, \ldots\}, \quad a \in \mathbb{Z}, \quad d>0,
$$

then $A_{a, d}$ is open by hypothesis, but it is also closed because it is the complement of the open set $A_{a+1, d} \cup A_{a+2, d} \cup \cdots \cup A_{a+d-1, d}$. Hence $\mathbb{Z} \backslash A_{a, d}$ is open.

Now let us assume that only finitely many primes exist, say $p_{1}, p_{2}, \ldots, p_{n}$. Then

$$
A_{0, p_{1}} \cup A_{0, p_{2}} \cup \cdots \cup A_{0, p_{n}}=\mathbb{Z} \backslash\{-1,1\} .
$$

This union of open sets is the complement of the open set

$$
\left(\mathbb{Z} \backslash A_{0, p_{1}}\right) \cup\left(\mathbb{Z} \backslash A_{0, p_{2}}\right) \cup \cdots \cup\left(\mathbb{Z} \backslash A_{0, p_{n}}\right) ;
$$

hence it is closed. The complement of this closed set, namely $\{-1,1\}$, must therefore be open. We have reached a contradiction because this set is neither empty nor infinite. Hence our assumption was false, and so there are infinitely many primes.

Let us begin with the examples.

Example. Prove that for all positive integers $n$, the number

$$
3^{3^{n}}+1
$$

is the product of at least $2 n+1$ not necessarily distinct primes.

Solution. We induct on $n$. The statement is clearly true if $n=1$. Because

$$
3^{3^{n+1}}+1=\left(3^{3^{n}}+1\right)\left(3^{2 \cdot 3^{n}}-3^{3^{n}}+1\right),
$$

it suffices to prove that $3^{2 \cdot 3^{n}}-3^{3^{n}}+1$ is composite for all $n \geq 1$. But this follows from the fact that

$$
3^{2 \cdot 3^{n}}-3^{3^{n}}+1=\left(3^{3^{n}}+1\right)^{2}-3 \cdot 3^{3^{n}}=\left(3^{3^{n}}+1\right)^{2}-\left(3^{\frac{3^{n}+1}{2}}\right)^{2}
$$

is the product of two integers greater than 1 , namely,

$$
3^{3^{n}}+1-3^{\frac{3^{n}+1}{2}} \text { and } 3^{3^{n}}+1-3^{\frac{3^{n}+1}{2}} .
$$

This completes the induction. We proceed with a problem from the 35th International Mathematical Olympiad, 1994, followed by several others that are left to the reader.

Example. Prove that there exists a set $A$ of positive integers with the property that for any infinite set $S$ of primes, there exist two positive integers $m \in A$ and $n \notin A$ each of which is a product of $k$ distinct elements of $S$ for some $k \geq 2$.

Solution. The proof is constructive. Let $p_{1}<p_{2}<\cdots<p_{n}<\cdots$ be the increasing sequence of all prime numbers. Define $A$ to be the set of numbers of the form $p_{i_{1}} p_{i_{2}} \cdots p_{i_{k}}$,

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-270.jpg?height=52&width=1339&top_left_y=674&top_left_x=198)
but $5 \cdot 7 \notin A$.

Let us show that $A$ satisfies the desired condition. Consider an infinite set of prime numbers, say $q_{1}<q_{2}<\cdots<q_{n}<\cdots$. Take $m=q_{2} q_{3} \cdots q_{q_{2}}$ and $n=q_{3} q_{4} \cdots q_{q_{2}+1}$. Then $m \in A$, while $n \notin A$ because $q_{2} \geq 3$ and so $q_{2}+1 \neq q_{3}$.

733. Prove that there are infinitely many prime numbers of the form $4 m+3$, where $m \geq 0$ is an integer.

734. Let $k$ be a positive integer such that the number $p=3 k+1$ is prime and let

$$
\frac{1}{1 \cdot 2}+\frac{1}{3 \cdot 4}+\cdots+\frac{1}{(2 k-1) 2 k}=\frac{m}{n}
$$

for some coprime positive integers $m$ and $n$. Prove that $p$ divides $m$.

735. Solve in positive integers the equation

$$
x^{x+y}=y^{y-x} .
$$

736. Show that each positive integer can be written as the difference of two positive integers having the same number of prime factors.

737. Find all composite positive integers $n$ for which it is possible to arrange all divisors of $n$ that are greater than 1 in a circle such that no two adjacent divisors are relatively prime.

738. Is it possible to place 1995 different positive integers around a circle so that for any two adjacent numbers, the ratio of the greater to the smaller is a prime?

739. Let $p$ be a prime number. Prove that there are infinitely many multiples of $p$ whose last ten digits are all distinct.

740. Let $A$ be the set of positive integers representable in the form $a^{2}+2 b^{2}$ for integers $a, b$ with $b \neq 0$. Show that if $p^{2} \in A$ for a prime $p$, then $p \in A$. 

741. The positive divisors of an integer $n>1$ are $1=d_{1}<d_{2}<\cdots<d_{k}=n$. Let $s=d_{1} d_{2}+d_{2} d_{3}+\cdots+d_{k-1} d_{k}$. Prove that $s<n^{2}$ and find all $n$ for which $s$ divides $n^{2}$.

742. Prove that there exist functions $f, g:\{0,1,2, \ldots\} \times\{0,1,2, \ldots\} \rightarrow\{0,1,2, \ldots\}$ with the property that an odd number $n>1$ is prime if and only if there do not exist nonnegative integers $a$ and $b$ such that $n=f(a, b)-g(a, b)$.

743. Let $n \geq 2$ be an integer. Prove that if $k^{2}+k+n$ is a prime number for all $0 \leq k \leq \sqrt{\frac{n}{3}}$, then $k^{2}+k+n$ is a prime number for all $0 \leq k \leq n-2$.

The following formula is sometimes attributed to Legendre.

Polignac's formula. If $p$ is a prime number and $n$ a positive integer, then the exponent of $p$ in $n !$ is given by

$$
\left\lfloor\frac{n}{p}\right\rfloor+\left\lfloor\frac{n}{p^{2}}\right\rfloor+\left\lfloor\frac{n}{p^{3}}\right\rfloor+\cdots .
$$

Proof. Each multiple of $p$ between 1 and $n$ contributes a factor of $p$ to $n$ !. There are $\lfloor n / p\rfloor$ such factors. But the multiples of $p^{2}$ contribute yet another factor of $p$, so one should add $\left\lfloor n / p^{2}\right\rfloor$. And then come the multiples of $p^{3}$ and so on.

Example. Let $m$ be an integer greater than 1. Prove that the product of $m$ consecutive terms in an arithmetic progression is divisible by $m$ ! if the ratio of the progression is coprime to $m$.

Solution. Let $p$ be a prime that divides $n$ !. The exponent of $p$ in $n$ ! is given by Polignac's formula. On the other hand, in the product $a(a+r)(a+2 r) \cdots(a+(m-1) r)$ of $m$ consecutive terms in a progression of ratio $r$, with $\operatorname{gdc}(r, m)=1$, at least $\left\lfloor m / p^{i}\right\rfloor$ terms are divisible by $p^{i}$. It follows that the power of $p$ in this product is greater than or equal to the power of $p$ in $m$ !. Because this holds true for any prime factor in $m$ !, the conclusion follows.

All problems below are based on Polignac's formula.

744. Find all positive integers $n$ such that $n$ ! ends in exactly 1000 zeros.

745. Prove that $n !$ is not divisible by $2^{n}$ for any positive integer $n$.

746. Show that for each positive integer $n$,

$$
n !=\prod_{i=1}^{n} \operatorname{lcm}(1,2, \ldots,\lfloor n / i\rfloor),
$$

where $\mathrm{lcm}$ denotes the least common multiple. 

747. Prove that the expression

$$
\frac{\operatorname{gcd}(m, n)}{n}\left(\begin{array}{l}
n \\
m
\end{array}\right)
$$

is an integer for all pairs of integers $n \geq m \geq 1$.

748. Let $k$ and $n$ be integers with $0 \leq k \leq n^{2} / 4$. Assume that $k$ has no prime divisor greater than $n$. Prove that $n$ ! is divisible by $k$.

\subsubsection{Modular Arithmetic}

A positive integer $n$ partitions the set of integers $\mathbb{Z}$ into $n$ equivalence classes by the remainders obtained on dividing by $n$. The remainders are called residues modulo $n$. We denote by $\mathbb{Z}_{n}=\{0,1, \ldots, n-1\}$ the set of equivalence classes, indexed by their residues. Two numbers $a$ and $b$ are said to be congruent modulo $n$, which is written $a \equiv b(\bmod n)$, if they give the same remainder when divided by $n$, that is, if $a-b$ is divisible by $n$.

The ring structure of $\mathbb{Z}$ induces a ring structure on $\mathbb{Z}_{n}$. The latter ring is more interesting, since it has zero divisors whenever $n$ is composite, and it has other invertible elements besides $\pm 1$. To make this precise, for any divisor $d$ of $n$ the product of $d$ and $n / d$ is zero. On the other hand, the fundamental theorem of arithmetic, which states that whenever $m$ and $n$ are coprime there exist integers $a$ and $b$ such that $a m-b n=1$, implies that any number coprime to $n$ has a multiplicative inverse modulo $n$. For a prime $p$, every nonzero element in $\mathbb{Z}_{p}$ has an inverse modulo $p$. This means that $\mathbb{Z}_{p}$ is a field. We also point out that the set of invertible elements in $\mathbb{Z}_{n}$ is closed under multiplication; it is an Abelian group.

A well-known property that will be used in some of the problems below is that modulo 9 , a number is congruent to the sum of its digits. This is because the difference of the number and the sum of its digits is equal to 9 times the tens digit plus 99 times the hundreds digit plus 999 times the thousands digit, and so on. Here is an elementary application of this fact.

Example. The number $2^{29}$ has 9 distinct digits. Without using a calculator, tell which digit is missing.

Solution. As we have just observed, a number is congruent to the sum of its digits modulo 9. Note that $0+1+2+\cdots+9=45$, which is divisible by 9 . On the other hand,

$$
2^{29} \equiv 2^{2}(-1)^{9} \equiv-4(\bmod 9) .
$$

So $2^{29}$ is off by 4 from a multiple of 9 . The missing digit is 4 .

We continue with a property of the harmonic series discovered by C. Pinzka. Example. Let $p>3$ be a prime number, and let

$$
\frac{r}{p s}=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{p},
$$

the sum of the first $p$ terms of the harmonic series. Prove that $p^{3}$ divides $r-s$. Solution. The sum of the first $p$ terms of the harmonic series can be written as

$$
\frac{\frac{p !}{1}+\frac{p !}{2}+\cdots+\frac{p !}{p}}{p !} .
$$

Because the denominator is $p$ ! and the numerator is not divisible by $p$, any common prime divisor of the numerator and the denominator is less than $p$. Thus it suffices to prove the property for $r=\frac{p !}{1}+\frac{p !}{2}+\cdots+\frac{p !}{p}$ and $s=(p-1) !$. Note that

$$
r-s=p\left(\frac{(p-1) !}{1}+\frac{(p-1) !}{2}+\cdots+\frac{(p-1) !}{p-1}\right) .
$$

We are left with showing that

$$
\frac{(p-1) !}{1}+\frac{(p-1) !}{2}+\cdots+\frac{(p-1) !}{p-1}
$$

is divisible by $p^{2}$. This sum is equal to

$$
\sum_{k=1}^{\frac{p-1}{2}}(k+p-k) \frac{(p-1) !}{k(p-k)}=p \sum_{k=1}^{\frac{p-1}{2}} \frac{(p-1) !}{k(p-k)} .
$$

So let us show that

$$
\sum_{k=1}^{\frac{p-1}{2}} \frac{(p-1) !}{k(p-k)}
$$

is an integer divisible by $p$. Note that if $k^{-1}$ denotes the inverse of $k$ modulo $p$, then $p-k^{-1}$ is the inverse of $p-k$ modulo $p$. Hence the residue classes of $[k(p-k)]^{-1}$ represent just a permutation of the residue classes of $k(p-k), k=1,2, \ldots, \frac{p-1}{2}$. Using this fact, we have

$$
\begin{aligned}
\sum_{k=1}^{\frac{p-1}{2}} \frac{(p-1) !}{k(p-k)} & \equiv(p-1) ! \sum_{k=1}^{\frac{p-1}{2}}[k(p-k)]^{-1} \equiv(p-1) ! \sum_{k=1}^{\frac{p-1}{2}} k(p-k) \\
& \equiv-(p-1) ! \sum_{k=1}^{\frac{p-1}{2}} k^{2}=-(p-1) ! \frac{\frac{p-1}{2} \cdot \frac{p+1}{2} \cdot p}{6} \equiv 0(\bmod p) .
\end{aligned}
$$

This completes the proof. We left the better problems as exercises.

749. Prove that among any three distinct integers we can find two, say $a$ and $b$, such that the number $a^{3} b-a b^{3}$ is a multiple of 10 .

750. Show that the number $2002^{2002}$ can be written as the sum of four perfect cubes, but not as the sum of three perfect cubes.

751. The last four digits of a perfect square are equal. Prove that they are all equal to zero.

752. Solve in positive integers the equation

$$
2^{x} \cdot 3^{y}=1+5^{z} .
$$

753. Define the sequence $\left(a_{n}\right)_{n}$ recursively by $a_{1}=2, a_{2}=5$, and

$$
a_{n+1}=\left(2-n^{2}\right) a_{n}+\left(2+n^{2}\right) a_{n-1} \text { for } n \geq 2 .
$$

Do there exist indices $p, q, r$ such that $a_{p} \cdot a_{q}=a_{r}$ ?

754. For some integer $k>0$, assume that an arithmetic progression $a n+b, n \geq 1$, with $a$ and $b$ positive integers, contains the $k$ th power of an integer. Prove that for any integer $m>0$ there exist an infinite number of values of $n$ for which $a n+b$ is the sum of $m k$ th powers of nonzero integers.

755. Given a positive integer $n>1000$, add the residues of $2^{n}$ modulo each of the numbers $1,2,3, \ldots, n$. Prove that this sum is greater than $2 n$.

756. Prove that if $n \geq 3$ prime numbers form an arithmetic progression, then the common difference of the progression is divisible by any prime number $p<n$.

757. Let $P(x)=a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{0}$ and $Q(x)=b_{n} x^{n}+b_{n-1} x^{n-1}+\cdots+b_{0}$ be two polynomials with each coefficient $a_{i}$ and $b_{i}$ equal to either 1 or 2002 . Assuming that $P(x)$ divides $Q(x)$, show that $m+1$ is a divisor of $n+1$.

758. Prove that if $n$ is a positive integer that is divisible by at least two primes, then there exists an $n$-gon with all angles equal and with side lengths the numbers $1,2, \ldots, n$ in some order.

759. Find all prime numbers $p$ having the property that when divided by every prime number $q<p$ yield a remainder that is a square-free integer.

\subsubsection{Fermat's Little Theorem}

A useful tool for solving problems about prime numbers is a theorem due to P. Fermat. Fermat's little theorem. Let $p$ be a prime number, and $n$ a positive integer. Then

$$
n^{p}-n \equiv 0(\bmod p) .
$$

Proof. We give a geometric proof. Consider the set $M$ of all possible colorings of the vertices of a regular $p$-gon by $n$ colors (see Figure 36). This set has $n^{p}$ elements. The group $\mathbb{Z}_{p}$ acts on this set by rotations of angles $\frac{2 k \pi}{p}, k=0,1, \ldots, p-1$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-275.jpg?height=357&width=366&top_left_y=587&top_left_x=684)

Figure 36

Consider the quotient space $M / \mathbb{Z}_{p}$ obtained by identifying colorings that become the same through a rotation. We want to count the number of elements of $M / \mathbb{Z}_{p}$. For that we need to understand the orbits of the action of the group, i.e., the equivalence classes of rotations under this identification.

The orbit of a monochromatic coloring has just one element: the coloring itself. There are $n$ such orbits.

What if the coloring is not monochromatic? We claim that in this case its orbit has exactly $p$ elements. Here is the place where the fact that $p$ is prime comes into play. The additive group $\mathbb{Z}_{p}$ of residues modulo $p$ is generated by any of its nonzero elements. Hence if the coloring coincided with itself under a rotation of angle $2 k \pi / p$ for some $0<k<p$, then it would coincide with itself under multiples of this rotation, hence under all rotations in $\mathbb{Z}_{p}$. But this is not possible, unless the coloring is monochromatic. This proves that rotations produce distinct colorings, so the orbit has $p$ elements. We deduce that the remaining $n^{p}-n$ elements of $M$ are grouped in (disjoint) equivalence classes each containing $p$ elements. The counting of orbits gives

$$
|M| \mathbb{Z}_{p} \mid=n+\frac{n^{p}-n}{p},
$$

which shows that $\left(n^{p}-n\right) / p$ must be an integer. The theorem is proved.

In particular, if $n$ and $p$ are coprime, then $n^{p-1}-1$ is divisible by $p$. However, this result alone cannot be used as a primality test for $p$. For example, L. Euler found that 341 divides $2^{340}-1$, while $341=31 \times 11$. So the converse of Fermat's little theorem fails.

We illustrate the use of Fermat's little theorem with a short-listed problem from the 46th International Mathematical Olympiad, 2005. Example. Show that for every prime $p$ there is an integer $n$ such that $2^{n}+3^{n}+6^{n}-1$ is divisible by $p$.

Solution. The property is true for $p=2$ and $p=3$, since $2^{2}+3^{2}+6^{2}-1=48$. Let $p$ be a prime greater than 3 . By Fermat's little theorem, $2^{p-1}, 3^{p-1}$, and $6^{p-1}$ are all congruent to 1 modulo $p$. Hence

$$
3 \cdot 2^{p-1}+2 \cdot 3^{p-1}+6^{p-1} \equiv 3+2+1=6(\bmod p) .
$$

It follows that

$$
6 \cdot 2^{p-2}+6 \cdot 3^{p-2}+6 \cdot 6^{p-2} \equiv 6(\bmod p)
$$

Dividing by 6 , we find that $2^{p-2}+3^{p-2}+6^{p-2}-1$ is divisible by $p$, and we are done.

And here is a problem from the 2005 USA Mathematical Olympiad, proposed by the first author of the book. ${ }^{2}$

Example. Prove that the system

$$
\begin{aligned}
x^{6}+x^{3}+x^{3} y+y &=147^{157}, \\
x^{3}+x^{3} y+y^{2}+y+z^{9} &=157^{147}
\end{aligned}
$$

has no solutions in integers $x, y$, and $z$.

Solution. Add the two equations, then add 1 to each side to obtain the Diophantine equation

$$
\left(x^{3}+y+1\right)^{2}+z^{9}=147^{157}+157^{147}+1 .
$$

The right-hand side is rather large, and it is natural to reduce modulo some number. And since the left-hand side is a sum of a square and a ninth power, it is natural to reduce modulo 19 because $2 \times 9+1=19$. By Fermat's little theorem, $a^{18} \equiv 1(\bmod 19)$ whenever $a$ is not a multiple of 19 , and so the order of a square is either 1,3 , or 9 , while the order of a ninth-power is either 1 or 2 .

Computed by hand, the quadratic residues mod 19 are $-8,-3,-2,0,1,4,5,6,7$, 9 , while the residues of ninth powers are $-1,0,1$. Also, applying Fermat's little theorem we see that

$$
147^{157}+157^{147}+1 \equiv 14^{13}+5^{3}+1 \equiv 14(\bmod 19) .
$$

An easy verification shows that 14 cannot be obtained as a sum of a quadratic residue and a ninth-power residue. Thus the original system has no solution in integers $x, y$, and $z$.

${ }^{2}$ The statement was improved by $\mathrm{R}$. Stong and $\mathrm{E}$. Johnston to prevent a simpler solution. A different solution is possible using reduction modulo 13. Fermat's little theorem implies $a^{12} \equiv 1(\bmod 13)$ when $a$ is not a multiple of 13 .

We start by producing the same Diophantine equation. Applying Fermat's little theorem, we can reduce the right-hand side modulo 13. We find that

$$
147^{157}+157^{147}+1 \equiv 4^{1}+1^{2} \equiv 6(\bmod 13) .
$$

The cubes modulo 13 are $0, \pm 1$, and $\pm 5$. Writing the first equation of the original system as

$$
\left(x^{3}+1\right)\left(x^{3}+y\right) \equiv 4(\bmod 13),
$$

it follows that $x^{3}+y$ must be congruent to $4,2,5$, or $-1$. Hence

$$
\left(x^{3}+y+1\right)^{2} \equiv 12,9,10 \quad \text { or } 0(\bmod 13) \text {. }
$$

Note also that $z^{9}$ is a cube; hence $z^{9}$ must be $0,1,5,8$, or 12 modulo 13 . It is easy to check that $6(\bmod 13)$ cannot be obtained by adding one of $0,9,10,12$ to one of $0,1,5,8,12$. As a remark, the second solution also works if $z^{9}$ is replaced by $z^{3}$.

When solving the following problems, think that "work done with passion brings results" (Virgil).

760. Show that if $n$ has $p-1$ digits all equal to 1 , where $p$ is a prime not equal to 2,3 , or 5 , then $n$ is divisible by $p$.

761. Prove that for any prime $p>17$, the number

$$
p^{32}-1
$$

is divisible by 16320 .

762. Let $p$ be an odd prime number. Show that if the equation $x^{2} \equiv a(\bmod p)$ has a solution, then $a^{\frac{p-1}{2}} \equiv 1(\bmod p)$. Conclude that there are infinitely many primes of the form $4 m+1$.

763. Prove that the equation $x^{2}=y^{3}+7$ has no integer solutions.

764. Let $n>1$ be a positive integer. Prove that the equation $(x+1)^{n}-x^{n}=n y$ has no positive integer solutions.

765. Prove that the sequence $2^{n}-3, n \geq 1$, contains an infinite subsequence whose terms are pairwise relatively prime.

766. Let $\left(x_{n}\right)_{n}$ be a sequence of positive integers satisfying the recurrence relation $x_{n+1}=$ $5 x_{n}-6 x_{n-1}$. Prove that infinitely many terms of the sequence are composite. 

767. Let $f\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ be a polynomial with integer coefficients of total degree less than $n$. Show that the number of ordered $n$-tuples $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ with $0 \leq x_{i} \leq 12$ such that $f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \equiv 0(\bmod 13)$ is divisible by 13 .

768. Determine all integers $a$ such that $a^{k}+1$ is divisible by 12321 for some appropriately chosen positive integer $k>1$.

\subsubsection{Wilson's Theorem}

Another result about prime numbers is known as Wilson's theorem.

Wilson's theorem. For every prime $p$, the number $(p-1) !+1$ is divisible by $p$.

Proof. We group the residue classes $1,2, \ldots, p-1$ in pairs $(a, b)$ such that $a b \equiv$ $1(\bmod p)$. Let us see when $a=b$ in such a pair. The congruence $a^{2} \equiv 1(\bmod p)$ is equivalent to the fact that $a^{2}-1=(a-1)(a+1)$ is divisible by $p$. This happens only when $a=1$ or $a=p-1$. For all other residue classes the pairs contain distinct elements. So in the product $2 \cdot 3 \cdots(p-2)$ the factors can be paired such that the product of the numbers in each pair is congruent to 1 . Therefore,

$$
1 \cdot 2 \cdots(p-2) \cdot(p-1) \equiv 1 \cdot(p-1) \equiv-1(\bmod p) .
$$

The theorem is proved.

The converse is also true, since $n$ must divide ( $n-1)$ ! for composite $n$. And now an application.

Example. Let $p$ be an odd prime. Prove that

$$
1^{2} \cdot 3^{2} \cdots(p-2)^{2} \equiv(-1)^{\frac{p+1}{2}}(\bmod p)
$$

and

$$
2^{2} \cdot 4^{2} \cdots(p-1)^{2} \equiv(-1)^{\frac{p+1}{2}}(\bmod p) .
$$

Solution. By Wilson's theorem,

$$
(1 \cdot 3 \cdots(p-2))(2 \cdot 4 \cdots(p-1)) \equiv-1(\bmod p) .
$$

On the other hand,

$1 \equiv-(p-1)(\bmod p), 3 \equiv-(p-3)(\bmod p), \ldots, p-2 \equiv-(p-(p-2))(\bmod p)$.

Therefore,

$$
1 \cdot 3 \cdots(p-2) \equiv(-1)^{\frac{p-1}{2}}(2 \cdot 4 \cdots(p-1))(\bmod p)
$$

Multiplying the two congruences and canceling out the product $2 \cdot 4 \cdots(p-1)$, we obtain the first congruence from the statement. Switching the sides in the second and multiplying the congruences again, we obtain the second congruence from the statement. Here are more examples.

769. For each positive integer $n$, find the greatest common divisor of $n !+1$ and $(n+1) !$.

770. Prove that there are no positive integers $n$ such that the set $\{n, n+1, n+2, n+$ $3, n+4, n+5\}$ can be partitioned into two sets with the product of the elements of one set equal to the product of the elements of the other set.

771. Let $p$ be an odd prime. Show that if the equation $x^{2} \equiv a(\bmod p)$ has no solution then $a^{\frac{p-1}{2}} \equiv-1(\bmod p)$

772. Let $p$ be an odd prime number. Show that the equation $x^{2} \equiv-1(\bmod p)$ has a solution if and only if $p \equiv 1(\bmod 4)$.

773. Let $p$ be a prime number and $n$ an integer with $1 \leq n \leq p$. Prove that

$$
(p-n) !(n-1) ! \equiv(-1)^{n}(\bmod p) .
$$

774. Let $p$ be an odd prime and $a_{1}, a_{2}, \ldots, a_{p}$ an arithmetic progression whose common difference is not divisible by $p$. Prove that there exists an index $i$ such that the number $a_{1} a_{2} \cdots a_{p}+a_{i}$ is divisible by $p^{2}$.

\subsubsection{Euler's Totient Function}

Euler's totient function associates to a positive integer $n$ the number $\phi(n)$ of positive integers less than or equal to $n$ that are coprime to $n$. It has a simple formula in terms of the prime factorization of $n$.

Proposition. If the distinct prime factors of $n$ are $p_{1}, p_{2}, \ldots, p_{k}$, then

$$
\phi(n)=n\left(1-\frac{1}{p_{1}}\right)\left(1-\frac{1}{p_{2}}\right) \cdots\left(1-\frac{1}{p_{k}}\right) .
$$

Proof. This is just an easy application of the inclusion-exclusion principle. From the $n$ numbers between 1 and $n$, we eliminate the $n / p_{i}$ numbers that are divisible by $p_{i}$, for each $1 \leq i \leq n$. We are left with

$$
n-n\left(\frac{1}{p_{1}}+\frac{1}{p_{2}}+\cdots+\frac{1}{p_{k}}\right)
$$

numbers. But those divisible by both $p_{i}$ and $p_{j}$ have been subtracted twice, so we have to add them back, obtaining

$$
n-n\left(\frac{1}{p_{1}}+\frac{1}{p_{2}}+\cdots+\frac{1}{p_{k}}\right)+n\left(\frac{1}{p_{1} p_{2}}+\frac{1}{p_{3}}+\cdots+\frac{1}{p_{k-1} p_{k}}\right) .
$$

Again, we see that the numbers divisible by $p_{i}, p_{j}$, and $p_{l}$ have been subtracted and then added back, so we need to subtract these once more. Repeating the argument, we obtain in the end

$$
n-n\left(\frac{1}{p_{1}}+\frac{1}{p_{2}}+\cdots+\frac{1}{p_{k}}\right)+n\left(\frac{1}{p_{1} p_{2}}+\frac{1}{p_{3}}+\cdots+\frac{1}{p_{k-1} p_{k}}\right)-\cdots \pm \frac{n}{p_{1} p_{2} \cdots p_{k}} .
$$

Factoring this, we obtain the formula from the statement.

In particular, $n$ is prime if and only if $\phi(n)=n-1$, and if $n=p_{1} p_{2} \cdots p_{k}$, where $p_{i}$ are distinct primes, $1 \leq i \leq k$, then $\phi(n)=\left(p_{1}-1\right)\left(p_{2}-1\right) \cdots\left(p_{n}-1\right)$. Also, if $m$ and $n$ are coprime, then $\phi(m n)=\phi(m) \phi(n)$.

Fermat's little theorem admits the following generalization.

Euler's theorem. Let $n>1$ be an integer and a an integer coprime to $n$. Then

$$
a^{\phi(n)} \equiv 1(\bmod n) .
$$

Proof. The group of units $\mathbb{Z}_{n}^{*}$ in the ring $\mathbb{Z}_{n}$ consists of the residue classes coprime to $n$. Its order is $\phi(n)$. By the Lagrange theorem, the order of an element divides the order of the group. Hence the conclusion.

Here is a more elementary argument. Consider the set $S=\left\{a_{1}, a_{2}, \ldots, a_{\phi(n)}\right\}$ of all residue classes modulo $n$ that are coprime to $n$. Because $\operatorname{gcd}(a, n)=1$, it follows that, modulo $n, a a_{1}, a a_{2}, \ldots, a a_{\phi(n)}$ is a permutation of $a_{1}, a_{2}, \ldots, a_{\phi(n)}$. Then

$$
\left(a a_{1}\right)\left(a a_{2}\right) \cdots\left(a a_{\phi(n)}\right) \equiv a_{1} a_{2} \cdots a_{\phi(n)}(\bmod n) .
$$

Since $\operatorname{gcd}\left(a_{k}, n\right)=1$, for $k=1,2, \ldots, \phi(n)$, we can divide both sides by $a_{1} a_{2} \cdots a_{\phi(n)}$ to obtain $a^{\phi(n)} \equiv 1(\bmod n)$, as desired.

We apply Euler's theorem to a problem by I. Cucurezeanu.

Example. Let $n$ be an even positive integer. Prove that $n^{2}-1$ divides $2^{n !}-1$.

Solution. Let $n=m-1$, so that $m$ is odd. We must show that $m(m-2)$ divides $2^{(m-1) !}-1$. Because $\phi(m)<m, \phi(m)$ divides $(m-1)$ !, so $2^{\phi(m)}-1$ divides $2^{(m-1) !}-1$. Euler's theorem implies that $m$ divides $2^{\phi(m)}-1$. Therefore, $m$ divides $2^{(m-1) !}-1$. Arguing similarly for $m-2$, we see that $m-2$ divides $2^{(m-1) !}-1$ as well. The numbers $m$ and $m-2$ are relatively prime, so $m(m-2)$ divides $2^{(m-1) !}-1$, as desired.

A second example comes from the 1997 Romanian Mathematical Olympiad.

Example. Let $a>1$ be an integer. Show that the set

$$
S=\left\{a^{2}+a-1, a^{3}+a^{2}-1, a^{4}+a^{3}-1, \ldots\right\}
$$

contains an infinite subset whose elements are pairwise coprime. Solution. We show that any subset of $S$ having $n$ elements that are pairwise coprime can be extended to a set with $n+1$ elements. Indeed, if $N$ is the product of the elements of the subset, then since the elements of $S$ are coprime to $a$, so must be $N$. By Euler's theorem,

$$
a^{\phi(N)+1}+a^{\phi(N)}-1 \equiv a+1-1 \equiv a(\bmod N) .
$$

It follows that $a^{\phi(N)+1}+a^{\phi(N)}-1$ is coprime to $N$ and can be added to $S$. We are done.

We now challenge you with the following problems.

775. Prove that for any positive integer $n$,

$$
\sum_{k \mid n} \phi(k)=n .
$$

Here $k \mid n$ means $k$ divides $n$.

776. Prove that for any positive integer $n$ other than 2 or 6 ,

$$
\phi(n) \geq \sqrt{n} .
$$

777. Prove that there are infinitely many positive integers $n$ such that $(\phi(n))^{2}+n^{2}$ is a perfect square.

778. Prove that there are infinitely many even positive integers $m$ for which the equation $\phi(n)=m$ has no solutions.

779. Prove that for every positive integer $s$ there exists a positive integer $n$ divisible by $s$ and with the sum of the digits equal to $s$.

780. Prove that the equation

$$
2^{x}+3=z^{3}
$$

does not admit positive integer solutions.

781. Prove for every positive integer $n$ the identity

$$
\phi(1)\left\lfloor\frac{n}{1}\right\rfloor+\phi(2)\left\lfloor\frac{n}{2}\right\rfloor+\phi(3)\left\lfloor\frac{n}{3}\right\rfloor+\cdots+\phi(n)\left\lfloor\frac{n}{n}\right\rfloor=\frac{n(n+1)}{2} .
$$

782. Given the nonzero integers $a$ and $d$, show that the sequence

$$
a, a+d, a+2 d, \ldots, a+n d, \ldots
$$

contains infinitely many terms that have the same prime factors. Euler's theorem is widely used in cryptography. The encryption scheme used nowadays, called the RSA algorithm, works as follows:

A merchant wants to obtain the credit card number of a customer over the Internet. The information traveling between the two can be viewed by anyone. The merchant is in possession of two large prime numbers $p$ and $q$. It transmits to the customer the product $n=p q$ and a positive integer $k$ coprime to $\phi(n)=(p-1)(q-1)$. The customer raises the credit card number $\alpha$ to the $k$ th power, then reduces it modulo $n$ and transmits the answer $\beta$ to the merchant. Using the Euclidean algorithm for the greatest common divisor, the merchant determines positive integers $m$ and $a$ satisfying

$$
m k-a(p-1)(q-1)=1 .
$$

Then he computes the residue of $\beta^{m}$ modulo $n$. By Euler's theorem,

$$
\beta^{m} \equiv \alpha^{m k}=\alpha^{a(p-1)(q-1)+1}=\left(\alpha^{(p-1)(q-1)}\right)^{a} \cdot \alpha=\left(\alpha^{\phi(n)}\right)^{a} \cdot \alpha \equiv \alpha(\bmod n) .
$$

For $n$ sufficiently large, the residue class of $\alpha$ modulo $n$ is $\alpha$ itself. The merchant was able to retrieve the credit card number.

As of this date there is no known algorithm for factoring numbers in polynomial time, while large primes can be found relatively quickly, and for this reason an eavesdropper cannot determine $p$ and $q$ from $n$ in a reasonable amount of time, and hence cannot break the encryption.

783. Devise a scheme by which a bank can transmit to its customers secure information over the Internet. Only the bank (and not the customers) is in the possession of the secret prime numbers $p$ and $q$.

784. A group of United Nations experts is investigating the nuclear program of a country. While they operate in that country, their findings should be handed over to the Ministry of Internal Affairs of the country, which verifies the document for leaks of classified information, then submits it to the United Nations. Devise a scheme by which the country can read the document but cannot modify its contents without destroying the information.

\subsubsection{The Chinese Remainder Theorem}

Mentioned for the first time in a fourth-century book of Sun Tsu Suan-Ching, this result can be stated as follows.

The Chinese Remainder Theorem. Let $m_{1}, m_{2}, \ldots, m_{k}$ be pairwise coprime positive integers greater than 1 . Then for any integers $a_{1}, a_{2}, \ldots, a_{k}$, the system of congruences

$$
x \equiv a_{1}\left(\bmod m_{1}\right), x \equiv a_{2}\left(\bmod m_{2}\right), \ldots, x \equiv a_{n}\left(\bmod m_{k}\right)
$$

has solutions, and any two such solutions are congruent modulo $m=m_{1} m_{2} \ldots m_{k}$. Proof. For any $j, 1 \leq j \leq k$, the number $m / m_{j}$ is coprime to $m_{j}$ and hence invertible with respect to $m_{j}$. Let $b_{j}$ be the inverse. Then

$$
x_{0}=\frac{m}{m_{1}} b_{1} a_{1}+\frac{m}{m_{2}} b_{2} a_{2}+\cdots+\frac{m}{m_{k}} b_{k} a_{k}
$$

is a solution to the system. For any other solution $x$, the difference $x-x_{0}$ is divisible by $m$. It follows that the general solution is of the form $x_{0}+m t$, with $t$ an integer.

We illustrate the use of the Chinese Remainder Theorem with an example from the classic book of W. Sierpiński, 250 Problems in Elementary Number Theory (Państwowe Wydawnictwo Naukowe, Warsawa, 1970).

Example. Prove that the system of Diophantine equations

$$
\begin{aligned}
&x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}=y^{5}, \\
&x_{1}^{3}+x_{2}^{3}+x_{3}^{3}+x_{4}^{3}=z^{2}, \\
&x_{1}^{5}+x_{2}^{5}+x_{3}^{5}+x_{4}^{5}=t^{3}
\end{aligned}
$$

has infinitely many solutions.

Solution. Let $a=1^{2}+2^{2}+3^{2}+4^{2}, b=1^{3}+2^{3}+3^{3}+4^{3}, c=1^{5}+2^{5}+3^{5}+4^{5}$. We look for solutions of the form $x_{1}=a^{m} b^{n} c^{p}, x_{2}=2 a^{m} b^{n} c^{p}, x_{3}=3 a^{m} b^{n} c^{p}, x_{4}=4 a^{m} b^{n} c^{p}$. These satisfy

$$
\begin{aligned}
&x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}=a^{2 m+1} b^{2 n} c^{2 p}, \\
&x_{1}^{3}+x_{2}^{3}+x_{3}^{3}+x_{4}^{3}=a^{3 m} b^{3 n+1} c^{3 p}, \\
&x_{1}^{5}+x_{2}^{5}+x_{3}^{5}+x_{4}^{5}=a^{5 m} b^{5 n} c^{5 p+1} .
\end{aligned}
$$

We would like the right-hand sides to be a fifth, second, and third power, respectively. Reformulating, we want to show that there exist infinitely many $m, n, p$ such that

$$
\begin{aligned}
&2 m+1 \equiv 2 n \equiv 2 p \equiv 0(\bmod 5), \\
&3 m \equiv 3 n+1 \equiv 3 p \equiv 0(\bmod 2), \\
&5 m \equiv 5 n \equiv 5 p+1 \equiv 0(\bmod 3)
\end{aligned}
$$

But this follows from the Chinese Remainder Theorem, and we are done.

785. An old woman went to the market and a horse stepped on her basket and smashed her eggs. The rider offered to pay for the eggs and asked her how many there were. She did not remember the exact number, but when she had taken them two at a time there was one egg left, and the same happened when she took three, four, five, and six at a time. But when she took them seven at a time, they came out even. What is the smallest number of eggs she could have had? 

786. Prove that for every $n$, there exist $n$ consecutive integers each of which is divisible by two different primes.

787. Let $P(x)$ be a polynomial with integer coefficients. For any positive integer $m$, let $N(m)$ denote the number of solutions to the equation $P(x) \equiv 0(\bmod m)$. Show that if $m_{1}$ and $m_{2}$ are coprime integers, then $N\left(m_{1} m_{2}\right)=N\left(m_{1}\right) N\left(m_{2}\right)$.

788. Alice and Bob play a game in which they take turns removing stones from a heap that initially has $n$ stones. The number of stones removed at each turn must be one less than a prime number. The winner is the player who takes the last stone. Alice plays first. Prove that there are infinitely many $n$ such that Bob has a winning strategy. (For example, if $n=17$, then Alice might take 6 leaving 11; then Bob might take 1 leaving 10; then Alice can take the remaining stones to win.)

789. Show that there exists an increasing sequence $\left(a_{n}\right)_{n \geq 1}$ of positive integers such that for any $k \geq 0$, the sequence $k+a_{n}, n \geq 1$, contains only finitely many primes.

790. Is there a sequence of positive integers in which every positive integer occurs exactly once and for every $k=1,2,3, \ldots$ the sum of the first $k$ terms is divisible by $k$ ?

791. Prove that there exists a positive integer $k$ such that $k \cdot 2^{n}+1$ is composite for every positive integer $n$.

792. Let $a$ and $b$ be two positive integers such that for any positive integer $n, a^{n}+n$ divides $b^{n}+n$. Prove that $a=b$.

793. A lattice point $(x, y) \in \mathbb{Z}^{2}$ is visible from the origin if $x$ and $y$ are coprime. Prove that for any positive integer $n$ there exists a lattice point $(a, b)$ whose distance from every visible point is greater than $n$.

\subsection{Diophantine Equations}

\subsubsection{Linear Diophantine Equations}

A linear Diophantine equation (named in the honor of Diophantus, who studied equations over the integers) is an equation of the form

$$
a_{1} x_{1}+\cdots+a_{n} x_{n}=b,
$$

where $a_{1}, \ldots, a_{n}$, and $b$ are integers. We will discuss only the Diophantine equation

$$
a x-b y=c .
$$

Theorem. The equation $a x-b y=c$ has solutions if and only if $\operatorname{gcd}(a, b)$ divides c. If $\left(x_{0}, y_{0}\right)$ is a solution, then all other solutions are of the form $x=x_{0}+\frac{b}{\operatorname{gcd}(a, b)} t$, $y=y_{0}+\frac{a}{\operatorname{gcd}(a, b)} t, t \in \mathbb{Z}$ Proof. For the equation to have solutions it is clearly necessary that $c$ be divisible by $\operatorname{gcd}(a, b)$. Dividing through by $\operatorname{gcd}(a, b)$ we can assume that $a$ and $b$ are coprime.

To show that the equation has solutions, we first examine the case $c=1$. The method of solving this equation is a consequence of Euclid's algorithm for finding the greatest common divisor. This algorithm consists of a successive series of divisions

$$
\begin{aligned}
& a=q_{1} b+r_{1}, \\
& b=q_{2} r_{1}+r_{2} \text {, } \\
& r_{1}=q_{3} r_{2}+r_{3}, \\
& r_{n-2}=q_{n} r_{n-1}+r_{n},
\end{aligned}
$$

where $r_{n}$ is the greatest common divisor of $a$ and $b$, which in our case is 1 . If we work backward, we obtain

$$
1=r_{n-1}\left(-q_{n}\right)-\left(-r_{n-2}\right)=r_{n-2}\left(1-q_{n-1}\right)-r_{n-3} q_{n}=\cdots=a x_{0}-b y_{0}
$$

for whatever numbers $x_{0}$ and $y_{0}$ arise at the last stage. This yields a particular solution $\left(x_{0}, y_{0}\right)$.

For a general $c$, just multiply this solution by $c$. If $\left(x_{1}, y_{1}\right)$ is another solution, then by subtracting $a x_{0}-b y_{0}=c$ from $a x_{1}-b y_{1}=c$, we obtain $a\left(x_{1}-x_{0}\right)-b\left(y_{1}-y_{0}\right)=0$, hence $x_{1}-x_{0}=\frac{b}{\operatorname{gcd}(a, b)} t$, and $y_{1}-y_{0}=\frac{a}{\operatorname{gcd}(a, b)} t$ for some integer number $t$. This shows that the general solution is of the form $\left(x_{0}+\frac{b}{\operatorname{gcd}(a, b)} t, y_{0}+\frac{a}{\operatorname{gcd}(a, b)} t\right), t$ an integer. The theorem is proved.

The algorithm for finding a particular solution can be better visualized if we use the continued fraction expansion

$$
\frac{a}{b}=-a_{1}+\frac{1}{-a_{2}+\frac{1}{-a_{3}+\cdots+\frac{1}{-a_{n-1}+\frac{1}{-a_{n}}}} .}
$$

In this, if we delete $\frac{1}{-a_{n}}$, we obtain a simpler fraction, and this fraction is nothing but $\frac{y_{0}}{x_{0}}$.

The equality $a x-b y=1$ shows that the matrix with integer entries

$$
\left(\begin{array}{ll}
a & y \\
b & x
\end{array}\right)
$$

has determinant 1 . The matrices with this property form the special linear group $\operatorname{SL}(2, \mathbb{Z})$. This group is generated by the matrices

$$
S=\left(\begin{array}{rr}
0 & -1 \\
1 & 0
\end{array}\right) \quad \text { and } \quad T=\left(\begin{array}{ll}
1 & 1 \\
0 & 1
\end{array}\right) .
$$

Explicitly,

$$
\left(\begin{array}{ll}
a & y \\
b & x
\end{array}\right)=S T^{a_{1}} S T^{a_{2}} S \cdots S T^{a_{n}} S,
$$

since matrix multiplication mimics the (backward) calculation of the continued fraction. We thus have a method of expressing the elements of $\mathrm{SL}(2, \mathbb{Z})$ in terms of generators.

The special linear group $\operatorname{SL}(2, \mathbb{Z})$ arises in non-Euclidean geometry. It acts on the upper half-plane, on which Poincaré modeled the "plane" of Lobachevskian geometry. The "lines" of this "plane" are the semicircles and half-lines orthogonal to the real axis. A matrix

$$
A\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)
$$

acts on the Lobachevski plane by

$$
z \rightarrow \frac{a z+b}{c z+d}, \quad a d-b c=1 .
$$

All these transformations form a group of isometries of the Lobachevski plane. Note that $A$ and $-A$ induce the same transformations; thus this group of isometries of the Lobachevski plane, also called the modular group, is isomorphic to $\operatorname{PSL}(2, \mathbb{Z})=$ $\mathrm{SL}(2, \mathbb{Z}) /\left\{-\mathcal{I}_{2}, \mathcal{I}_{2}\right\}$. The matrices $S$ and $T$ become the inversion with respect to the unit circle $z \rightarrow-\frac{1}{z}$ and the translation $z \rightarrow z+1$.

We stop here with the discussion and list some problems.

794. Write the matrix

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-286.jpg?height=119&width=143&top_left_y=1768&top_left_x=839)

as the product of several copies of the matrices

$$
\left(\begin{array}{ll}
0 & 1 \\
1 & 0
\end{array}\right) \text { and }\left(\begin{array}{ll}
1 & 1 \\
0 & 1
\end{array}\right) .
$$

(No, there is no typo in the matrix on the left.) 

795. Let $a, b, c, d$ be integers with the property that for any two integers $m$ and $n$ there exist integers $x$ and $y$ satisfying the system

$$
\begin{aligned}
&a x+b y=m, \\
&c x+d y=n .
\end{aligned}
$$

Prove that $a d-b c=\pm 1$.

796. Let $a, b, c, d$ be positive integers with $\operatorname{gcd}(a, b)=1$. Prove that the system of equations

$$
\left\{\begin{array}{l}
a x-y z-c=0, \\
b x-y t+d=0
\end{array}\right.
$$

has infinitely many solutions in positive integers $(x, y, z, t)$.

We now ask for the nonnegative solutions to the equation $a x+b y=c$, where $a, b, c$ are positive numbers. This is a particular case, solved by Sylvester, of the Frobenius coin problem: what is the largest amount of money that cannot be paid using coins worth $a_{1}, a_{2}, \ldots, a_{n}$ cents? Here is the answer.

Sylvester's theorem. Let $a$ and $b$ be coprime positive integers. Then $a b-a-b$ is the largest positive integer $c$ for which the equation

$$
a x+b y=c
$$

is not solvable in nonnegative integers.

Proof. Let $N>a b-a-b$. The integer solutions to the equation $a x+b y=N$ are of the form $(x, y)=\left(x_{0}+b t, y_{0}-a t\right)$, with $t$ an integer. Choose $t$ such that $0 \leq y_{0}-a t \leq a-1$. Then

$$
\left(x_{0}+b t\right) a=N-\left(y_{0}-a t\right) b>a b-a-b-(a-1) b=-a,
$$

which implies that $x_{0}+b t>-1$, and so $x_{0}+b t \geq 0$. Hence in this case the equation $a x+b y=N$ admits nonnegative integer solutions.

On the other hand, if there existed $x, y \geq 0$ such that

$$
a x+b y=a b-a-b,
$$

then we would have $a b=a(x+1)+b(y+1)$. Since $a$ and $b$ are coprime, this would imply that $a$ divides $y+1$ and $b$ divides $x+1$. But then $y+1 \geq a$ and $x+1 \geq b$, which would then lead to the contradiction

$$
a b=a(x+1)+b(y+1) \geq 2 a b .
$$

This proves the theorem. And now the problems.

797. Given a piece of paper, we can cut it into 8 or 12 pieces. Any of these pieces can be cut into 8 or 12 , and so on. Show that we can obtain any number of pieces greater than 60 . Can we obtain exactly 60 pieces?

798. Let $a$ and $b$ be positive integers. For a nonnegative integer $n$ let $s(n)$ be the number of nonnegative integer solutions to the equation $a x+b y=n$. Prove that the generating function of the sequence $(s(n))_{n}$ is

$$
f(x)=\frac{1}{\left(1-x^{a}\right)\left(1-x^{b}\right)} .
$$

799. Let $n>6$ be a positive integer. Prove that the equation

$$
x+y=n
$$

admits a solution with $x$ and $y$ coprime positive integers both greater than 1 .

800. Prove that the $d$-dimensional cube can be dissected into $n d$-dimensional cubes for all sufficiently large values of $n$.

\subsubsection{The Equation of Pythagoras}

The Diophantine equation

$$
x^{2}+y^{2}=z^{2},
$$

has as solutions triples of positive integers that are the side lengths of a right triangle, whence the name. Let us solve it.

If $x$ and $z$ have a common factor, this factor divides $y$ as well. Let us assume first that $x$ and $z$ are coprime. We can also assume that $x$ and $z$ have the same parity (both are odd); otherwise, exchange $x$ and $y$.

In this situation, write the equation as

$$
y^{2}=(z+x)(z-x) .
$$

The factors $z+x$ and $z-x$ are both divisible by 2 . Moreover, 2 is their greatest common divisor, since it is the greatest common divisor of their sum $2 z$ and their difference $2 x$. We deduce that $y$ is even, and there exist coprime integers $u$ and $v$ such that $y=2 u v$, $z+x=2 u^{2}$ and $z-x=2 v^{2}$. We obtain $x=u^{2}-v^{2}$ and $z=u^{2}+v^{2}$. Incorporating the common factor of $x, y$, and $z$, we find that the solutions to the equation are parametrized by triples of integers $(u, v, k)$ as $x=k\left(u^{2}-v^{2}\right), y=2 k u v$, and $z=k\left(u^{2}+v^{2}\right)$ or $x=2 k u v, y=k\left(u^{2}-v^{2}\right)$, and $z=k\left(u^{2}+v^{2}\right)$. The positive solutions are called Pythagorean triples. There is a more profound way to look at this equation. Dividing through by $z^{2}$, we obtain the equivalent form

$$
\left(\frac{x}{z}\right)^{2}+\left(\frac{y}{z}\right)^{2}=1 .
$$

This means that we are supposed to find the points of rational coordinates on the unit circle. Like any conic, the circle can be parametrized by rational functions. A parametrization is $\left(\frac{1-t^{2}}{1+t^{2}}, \frac{2 t}{1+t^{2}}\right), t \in \mathbb{R} \cup\{\infty\}$. The fractions $\frac{1-t^{2}}{1+t^{2}}$ and $\frac{2 t}{1+t^{2}}$ are simultaneously rational if and only if $t$ itself is rational. In that case $t=\frac{u}{v}$ for some coprime integers $u$ and $v$. Thus we should have

$$
\frac{x}{z}=\frac{1-\left(\frac{u}{v}\right)^{2}}{1+\left(\frac{u}{v}\right)^{2}} \quad \text { and } \quad \frac{y}{z}=\frac{2 \frac{u}{v}}{1+\left(\frac{u}{v}\right)^{2}} \text {, }
$$

where again we look at the case in which $x, y$, and $z$ have no common factor, and $x$ and $z$ are both odd. Then $y$ is necessarily even and

$$
\frac{y}{z}=\frac{2 u v}{u^{2}+v^{2}} .
$$

Because $u$ and $v$ are coprime, and because $y$ is even, the fraction on the right-hand side is irreducible. Hence $y=2 u v, z=u^{2}+v^{2}$, and consequently $x=u^{2}-v^{2}$. Exchanging $x$ and $y$, we obtain the other parametrization. In conclusion, we have the following theorem.

Theorem. Any solution $x, y, z$ to the equation $x^{2}+y^{2}=z^{2}$ in positive integers is of the form $x=k\left(u^{2}-v^{2}\right), y=2 k u v, z=k\left(u^{2}+v^{2}\right)$, or $x=2 k u v, y=k\left(u^{2}-v^{2}\right)$, $z=k\left(u^{2}+v^{2}\right)$, where $k$ is an integer and $u, v$ are coprime integers with $u>v$ not both odd.

We now describe an occurrence of Pythagorean triples within the Fibonacci sequence

$$
1,1, \underbrace{2, \underbrace{3,5}}, 8,13,21,34,55,89,144,233, \ldots
$$

Take the terms $F_{4}=3$ and $F_{5}=5$, multiply them, and double the product. Then take the product of $F_{3}=2$ and $F_{6}=8$. You obtain the numbers 30 and 16 , and $30^{2}+16^{2}=1156$, which is the square of $F_{9}=34$.

Similarly, the double product of $F_{5}=5$ and $F_{6}=8$ is 80 , and the product of $F_{4}=3$ and $F_{7}=13$ is 39. And $80^{2}+39^{2}=7921=F_{11}^{2}$. One more check: the double product of $F_{6}=8$ and $F_{7}=13$ is 208 , the product of $F_{5}=5$ and $F_{8}=21$ is 105 , and $105^{2}+208^{2}=54289=F_{13}^{2}$. In general, we may state the following. Example. The numbers $2 F_{n} F_{n+1}, F_{n-1} F_{n+2}$ and $F_{2 n+1}$ form a Pythagorean triple.

Solution. In our parametrization, it is natural to try $u=F_{n+1}$ and $v=F_{n}$. And indeed,

$$
u^{2}-v^{2}=(u-v)(u+v)=\left(F_{n+1}-F_{n}\right)\left(F_{n+1}+F_{n}\right)=F_{n-1} F_{n+2},
$$

while the identity

$$
F_{2 n+1}=u^{2}+v^{2}=F_{n+1}^{2}+F_{n}^{2}
$$

was established in Section 2.3.1. This proves our claim.

801. Given that the sides of a right triangle are coprime integers and the sum of the legs is a perfect square, show that the sum of the cubes of the legs can be written as the sum of two perfect squares.

802. Find all positive integers $x, y, z$ satisfying the equation $3^{x}+y^{2}=5^{z}$.

803. Show that for no positive integers $x$ and $y$ can $2^{x}+25^{y}$ be a perfect square.

804. Solve the following equation in positive integers:

$$
x^{2}+y^{2}=1997(x-y) .
$$

\subsubsection{Pell's Equation}

Euler, after reading Wallis' Opera Mathematica, mistakenly attributed the first serious study of nontrivial solutions to the equation

$$
x^{2}-D y^{2}=1
$$

to John Pell. However, there is no evidence that Pell, who taught at the University of Amsterdam, had ever considered solving such an equation. It should more aptly be called Fermat's equation, since it was Fermat who first investigated it. Nevertheless, equations of Pell type can be traced back to the Greeks. Theon of Smyrna used the ratio $\frac{x}{y}$ to approximate $\sqrt{2}$, where $x$ and $y$ are solutions to $x^{2}-2 y^{2}=1$. A more famous equation is Archimedes' problema bovinum (cattle problem) posed as a challenge to Apollonius, which received a complete solution only in the twentieth century.

Indian mathematicians of the sixth century devised a method for finding solutions to Pell's equation. But the general solution was first explained by Lagrange in a series of papers presented to the Berlin Academy between 1768 and 1770.

Lagrange's theorem. If $D$ is a positive integer that is not a perfect square, then the equation 

$$
x^{2}-D y^{2}=1
$$

has infinitely many solutions in positive integers and the general solution $\left(x_{n}, y_{n}\right)_{n \geq 1}$ is computed from the relation

$$
\left(x_{n}, y_{n}\right)=\left(x_{1}+y_{1} \sqrt{D}\right)^{n},
$$

where $\left(x_{1}, y_{1}\right)$ is the fundamental solution (the minimal solution different from the trivial solution $(1,0))$.

The fundamental solution can be obtained by trial and error. But there is an algorithm to find it. The continued fraction expansion or $\sqrt{D}$ is periodic:

$$
\sqrt{D}=a_{0}+\frac{1}{a_{1}+\frac{1}{a_{2}+\cdots+\frac{1}{a_{n}+\frac{1}{a_{1}+\frac{1}{a_{2}+\cdots}}}}}
$$

When $n$ is even, the fundamental solution is given by the numerator and the denominator of the fraction

$$
a_{0}+\frac{1}{a_{1}+\frac{1}{a_{2}+\cdots+\frac{1}{a_{n-1}}},}
$$

while when $n$ is odd, the fundamental solution is given by the numerator and the denominator of the fraction

$$
a_{0}+\frac{1}{a_{1}+\frac{1}{a_{2}+\cdots+\frac{1}{a_{n}+\frac{1}{a_{1}+\frac{1}{a_{2}+\cdots+\frac{1}{a_{n-1}}}}}}}
$$

This algorithm is not as simple as it seems. The smallest solution $\left(x_{1}, y_{1}\right)$ can depend exponentially on $D$. From the computational point of view, the challenge is to determine the number $R=\ln \left(x_{1}+y_{1} \sqrt{D}\right)$, called the regulator, with a certain accuracy. At the time of the writing this book no algorithm has been found to solve the problem in polynomial time on a classical computer. If a computer governed by the laws of quantum physics could be built, then such an algorithm exists and was discovered by S. Hallgren.

We found the following application of Pell's equation published by M.N. Deshpande in the American Mathematical Monthly.

Example. Find infinitely many triples $(a, b, c)$ of positive integers such that $a, b, c$ are in arithmetic progression and such that $a b+1, b c+1$, and $c a+1$ are perfect squares.

Solution. A slick solution is based on Pell's equation

$$
x^{2}-3 y^{2}=1 .
$$

Pell's equation, of course, has infinitely many solutions. If $(r, s)$ is a solution, then the triple $(a, b, c)=(2 s-r, 2 s, 2 s+r)$ is in arithmetic progression and satisfies $(2 s-$ $r) 2 s+1=(r-s)^{2},(2 s-r)(2 s+r)+1=s^{2}$, and $2 s(2 s+r)+1=(r+s)^{2}$.

More examples follow.

805. Find a solution to the Diophantine equation

$$
x^{2}-\left(m^{2}+1\right) y^{2}=1,
$$

where $m$ is a positive integer.

806. Prove that there exist infinitely many squares of the form

$$
1+2^{x^{2}}+2^{y^{2}},
$$

where $x$ and $y$ are positive integers.

807. Prove that there exist infinitely many integers $n$ such that $n, n+1, n+2$ are each the sum of two perfect squares. (Example: $0=0^{2}+0^{2}, 1=0^{2}+1^{2}, 2=1^{2}+1^{2}$.)

808. Prove that for no integer $n$ can $n^{2}-2$ be a power of 7 with exponent greater than 1 .

809. Find the positive solutions to the Diophantine equation

$$
(x+1)^{3}-x^{3}=y^{2} .
$$

810. Find the positive integer solutions to the equation

$$
(x-y)^{5}=x^{3}-y^{3} .
$$

811. Prove that the equation

$$
x^{3}+y^{3}+z^{3}+t^{3}=1999
$$

has infinitely many integer solutions.

812. Prove that for every pair of positive integers $m$ and $n$, there exists a positive integer $p$ satisfying

$$
(\sqrt{m}+\sqrt{m-1})^{n}=\sqrt{p}+\sqrt{p-1} .
$$

\subsubsection{Other Diophantine Equations}

In conclusion, try your hand at the following Diophantine equations. Any method is allowed!

813. Find all integer solutions $(x, y)$ to the equation

$$
x^{2}+3 x y+4006(x+y)+2003^{2}=0 .
$$

814. Prove that there do not exist positive integers $x$ and $y$ such that $x^{2}+x y+y^{2}=x^{2} y^{2}$.

815. Prove that there are infinitely many quadruples $x, y, z, w$ of positive integers such that

$$
x^{4}+y^{4}+z^{4}=2002^{w} .
$$

816. Find all nonnegative integers $x, y, z, w$ satisfying

$$
4^{x}+4^{y}+4^{z}=w^{2} .
$$

817. Prove that the equation

$$
x^{2}+y^{2}+z^{2}+3(x+y+z)+5=0
$$

has no solutions in rational numbers.

818. Find all positive integers $x, y$ such that $7^{x}-3^{y}=4$.

819. Find all positive integers $x$ satisfying

$$
3^{2^{x !}}=2^{3^{x !}}+1 .
$$

820. Find all quadruples $(u, v, x, y)$ of positive integers, where $u$ and $v$ are consecutive in some order, satisfying

$$
u^{x}-v^{y}=1 .
$$



\section{Combinatorics and Probability}

We conclude the book with combinatorics. First, we train combinatorial skills in set theory and geometry, with a glimpse at permutations. Then we turn to some specific techniques: generating functions, counting arguments, the inclusion-exclusion principle. A strong accent is placed on binomial coefficients.

This is followed by probability, which, in fact, should be treated separately. But the level of this book restricts us to problems that use counting, classical schemes such as the Bernoulli and Poisson schemes and Bayes' theorem, recurrences, and some minor geometric considerations. It is only later in the development of mathematics that probability loses its combinatorial flavor and borrows the analytical tools of Lebesgue integration.

\subsection{Combinatorial Arguments in Set Theory and Geometry}

\subsubsection{Set Theory and Combinatorics of Sets}

A first example comes from the 1971 German Mathematical Olympiad.

Example. Given $2^{n-1}$ subsets of a set with $n$ elements with the property that any three have nonempty intersection, prove that the intersection of all the sets is nonempty.

Solution. Let $S=\left\{A_{1}, A_{2}, \ldots, A_{2^{n-1}}\right\}$ be the family of subsets of the set $A$ with $n$ elements. Because $S$ has $2^{n-1}$ elements, for any subset $B$ of $A$, either $B$ or its complement $B^{c}$ is in $S$. (They cannot both be in $S$ by the other hypothesis.)

So if $A_{i}$ and $A_{j}$ are in $S$, then either $A_{i} \cap A_{j}$ is in $S$, or its complement is in $S$. If the complement is in $S$ then $A_{i} \cap A_{j} \cap\left(A_{i} \cap A_{j}\right)^{c}$ is empty, contradicting the fact that the intersection of any three elements of $S$ is nonempty. Hence $A_{i} \cap A_{j} \in S$.

We will now show by induction on $k$ that the intersection of any $k$ sets in $S$ is nontrivial. We just proved the base case $k=2$. Assume that the property is true for any $k-1$ elements of $S$, and let us prove it for $A_{i_{1}}, A_{i_{2}}, \ldots, A_{i_{k}} \in S$. By the induction hypothesis, $A_{i_{1}} \cap \cdots \cap A_{i_{k-1}} \in S$, and also $A_{i_{k}} \in S$, so $\left(A_{i_{1}} \cap \cdots \cap A_{i_{k-1}}\right) \cap A_{i_{k}}$ is in $S$. This completes the induction. For $k=2^{n-1}$, we obtain that the intersection of all sets in $S$ is nontrivial.

We found the following problem in the Mathematics Magazine for High Schools (Budapest).

Example. Let $A$ be a nonempty set and let $f: \mathcal{P}(A) \rightarrow \mathcal{P}(A)$ be an increasing function on the set of subsets of $A$, meaning that

$$
f(X) \subset f(Y) \text { if } X \subset Y .
$$

Prove that there exists $T$, a subset of $A$, such that $f(T)=T$.

Solution. Consider the family of sets

$$
\mathcal{F}=\{K \in \mathcal{P}(A) \mid f(K) \subset K\} .
$$

Because $A \in \mathcal{F}$, the family $\mathcal{F}$ is not empty. Let $T$ be the intersection of all sets in $\mathcal{F}$. We will show that $f(T)=T$.

If $K \in \mathcal{F}$, then $f(T) \subset f(K) \subset K$, and by taking the intersection over all $K \in \mathcal{F}$, we obtain that $f(T) \subset T$. Hence $T \in \mathcal{F}$.

Because $f$ is increasing it follows that $f(f(T)) \subset f(T)$, and hence $f(T) \in \mathcal{F}$. Since $T$ is included in every element of $\mathcal{F}$, we have $T \subset f(T)$. The double inclusion proves that $f(T)=T$, as desired.

Since it will be needed below, let us recall that a graph consists of a set of vertices connected by edges. Unless otherwise specified, our graphs have finitely many edges, there is at most one edge connecting two vertices, and the endpoints of each edge are distinct.

821. Let $A$ and $B$ be two sets. Find all sets $X$ with the property that

$$
\begin{aligned}
A \cap X &=B \cap X=A \cap B, \\
A \cup B \cup X=A \cup B .
\end{aligned}
$$

822. Prove that every graph has two vertices that are endpoints of the same number of edges.

823. Prove that a list can be made of all the subsets of a finite set such that

(i) the empty set is the first set;

(ii) each subset occurs once;

(iii) each subset is obtained from the preceding by adding or deleting an element. 

824. Let $M$ be a subset of $\{1,2,3, \ldots, 15\}$ such that the product of any three distinct elements of $M$ is not a square. Determine the maximum number of elements in $M$.

825. Let $S$ be a nonempty set and $\mathcal{F}$ a family of $m \geq 2$ subsets of $S$. Show that among the sets of the form $A \Delta B$ with $A, B \in \mathcal{F}$ there are at least $m$ that are distinct. (Here $A \Delta B=(A \backslash B) \cup(B \backslash A)$. $)$

826. Consider the sequence of functions and sets

$$
\cdots \rightarrow A_{n} \stackrel{f_{n-1}}{\rightarrow} A_{n-1} \stackrel{f_{n-2}}{\rightarrow} A_{n-2} \stackrel{f_{n-3}}{\rightarrow} \cdots \stackrel{f_{3}}{\rightarrow} A_{3} \stackrel{f_{2}}{\rightarrow} A_{2} \stackrel{f_{1}}{\rightarrow} A_{1} .
$$

Prove that if the sets $A_{n}$ are nonempty and finite for all $n$, then there exists a sequence of elements $x_{n} \in A_{n}, n=1,2,3, \ldots$, with the property that $f_{n}\left(x_{n+1}\right)=x_{n}$ for all $n \geq 1$

827. In a society of $n$ people, any two persons who do not know each other have exactly two common acquaintances, and any two persons who know each other don't have other common acquaintances. Prove that in this society every person has the same number of acquaintances.

828. Let $A$ be a finite set and let $f: A \rightarrow A$ be a function. Prove that there exist the pairwise disjoint sets $A_{0}, A_{1}, A_{2}, A_{3}$ such that $A=A_{0} \cup A_{1} \cup A_{2} \cup A_{3}, f(x)=x$ for any $x \in A_{0}$ and $f\left(A_{i}\right) \cap A_{i}=\emptyset, i=1,2,3$. What if the set $A$ is infinite?

\subsubsection{Permutations}

A permutation of a set $S$ is a bijection $\sigma: S \rightarrow S$. Composition induces a group structure on the set of all permutations. We are concerned only with the finite case $S=\{1,2, \ldots, n\}$. The standard notation for a permutation is

$$
\sigma=\left(\begin{array}{ccccc}
1 & 2 & 3 & \cdots & n \\
a_{1} & a_{2} & a_{3} & \cdots & a_{n}
\end{array}\right),
$$

with $a_{i}=\sigma(i), i=1,2, \ldots, n$.

A permutation is a cycle $\left(i_{1} i_{2} \ldots i_{n}\right)$ if $\sigma\left(i_{1}\right)=i_{2}, \sigma\left(i_{2}\right)=i_{3}, \ldots, \sigma\left(i_{n}\right)=i_{1}$, and $\sigma(j)=j$ for $j \neq i_{1}, i_{2}, \ldots, i_{n}$. Any permutation is a product of disjoint cycles. A cycle of length two $\left(i_{1} i_{2}\right)$ is called a transposition. Any permutation is a product of transpositions. For a given permutation $\sigma$, the parity of the number of transpositions in this product is always the same; the signature of $\sigma$, denoted by $\operatorname{sign}(\sigma)$, is 1 if this number is even and $-1$ if this number is odd. An inversion is a pair $(i, j)$ with $i<j$ and $\sigma(i)>\sigma(j)$

Let us look at a problem from the 1979 Romanian Mathematical Olympiad, proposed by I. Raşa. Example. Consider the permutations

$$
\begin{aligned}
& \sigma_{1}=\left(\begin{array}{ccccccc}1 & 2 & 3 & 4 & \cdots & 19 & 20 \\a_{1} & a_{2} & a_{3} & a_{4} & \cdots & a_{19} & a_{20}\end{array}\right), \\
& \sigma_{2}=\left(\begin{array}{ccccccc}1 & 2 & 3 & 4 & \cdots & 19 & 20 \\a_{19} & a_{20} & a_{17} & a_{18} & \cdots & a_{1} & a_{2}\end{array}\right) .
\end{aligned}
$$

Prove that if $\sigma_{1}$ has 100 inversions, then $\sigma_{2}$ has at most 100 inversions.

Solution. Let us see what an inversion $\left(a_{i}, a_{j}\right)$ of $\sigma_{1}$ becomes in $\sigma_{2}$. If $i$ and $j$ have the same parity, then $a_{i}$ and $a_{j}$ are switched in $\sigma_{2}$, and so $\left(a_{j}, a_{i}\right)$ is no longer an inversion. If $i$ is even and $j$ is odd, then $a_{i}$ and $a_{j}$ are also switched in $\sigma_{2}$, so the inversion again disappears.

We investigate the case $i$ odd and $j$ even more closely. If $j>i+1$, then in $\sigma_{2}$ the two elements appear in the order $\left(a_{j}, a_{i}\right)$, which is again not an inversion. However, if $i$ and $j$ are consecutive, then the pair is not permuted in $\sigma_{2}$; the inversion is preserved. There are at most 10 such pairs, because $i$ can take only the values $1,3, \ldots, 19$. So at most 10 inversions are "transmitted" from $\sigma_{1}$ to $\sigma_{2}$. From the 100 inversions of $\sigma_{1}$, at most 10 become inversions of $\sigma_{2}$, while 90 are "lost": they are no longer inversions in $\sigma_{2}$.

It follows that from the $\left(\begin{array}{c}20 \\ 2\end{array}\right)=190$ pairs $\left(a_{i}, a_{j}\right)$ in $\sigma_{2}$ with $i<j$, at least 90 are not inversions, which means that at most $190-90=100$ are inversions. This completes the proof.

Here is a different way of saying this. Define

$$
\sigma_{3}=\left(\begin{array}{ccccccc}
1 & 2 & 3 & 4 & \cdots & 19 & 20 \\
a_{20} & a_{19} & a_{18} & a_{17} & \cdots & a_{2} & a_{1}
\end{array}\right) .
$$

Then between them $\sigma_{1}$ and $\sigma_{3}$ have exactly $\left(\begin{array}{c}20 \\ 2\end{array}\right)$ inversions, since each pair is an inversion in exactly one. Hence $\sigma_{3}$ has at most 90 inversions. Because $\sigma_{2}$ differs from $\sigma_{3}$ by swapping 10 pairs of adjacent outputs, these are the only pairs in which it can differ from $\sigma_{3}$ in whether it has has an inversion. Hence $\sigma_{2}$ has at most 100 inversions.

And now an example with a geometric flavor.

Example. Let $\sigma$ be a permutation of the set $\{1,2, \ldots, n\}$. Prove that there exist permutations $\sigma_{1}$ and $\sigma_{2}$ of the same set such that $\sigma=\sigma_{1} \sigma_{2}$ and $\sigma_{1}^{2}$ and $\sigma_{2}^{2}$ are both equal to the identity permutation.

Solution. Decompose the permutation $\sigma$ into a product of disjoint cycles. It suffices to prove the property for each of these cycles; therefore, we can assume from the beginning that $\sigma$ itself is a cycle of length $n$. If $n=1$ or 2 , then we choose $\sigma_{1}=\sigma$ and $\sigma_{2}$ the identity permutation. Otherwise, we think of $\sigma$ as the rotation of a regular $n$-gon $A_{1} A_{2} \ldots A_{n}$ by an angle of $\frac{2 \pi}{n}$ around its center. Such a rotation can be written as the composition of two reflections that map the $n$-gon to itself, namely the reflection with respect to the perpendicular bisector of $A_{1} A_{3}$ and the reflection with respect to the perpendicular bisector of $A_{2} A_{3}$ (see Figure 37). These reflections define the permutations $\sigma_{1}$ and $\sigma_{2}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-298.jpg?height=325&width=513&top_left_y=497&top_left_x=611)

Figure 37

The following problems are left to the reader.

829. For each permutation $a_{1}, a_{2}, \ldots, a_{10}$ of the integers $1,2,3, \ldots, 10$, form the sum

$$
\left|a_{1}-a_{2}\right|+\left|a_{3}-a_{4}\right|+\left|a_{5}-a_{6}\right|+\left|a_{7}-a_{8}\right|+\left|a_{9}-a_{10}\right| .
$$

Find the average value of all such sums.

830. Find the number of permutations $a_{1}, a_{2}, a_{3}, a_{4}, a_{5}, a_{6}$ of the numbers $1,2,3,4,5,6$ that can be transformed into $1,2,3,4,5,6$ through exactly four transpositions (and not fewer).

831. Let $f(n)$ be the number of permutations $a_{1}, a_{2}, \ldots, a_{n}$ of the integers $1,2, \ldots, n$ such that (i) $a_{1}=1$ and (ii) $\left|a_{i}-a_{i+1}\right| \leq 2, i=1,2, \ldots, n-1$. Determine whether $f$ (1996) is divisible by 3 .

832. Consider the sequences of real numbers $x_{1}>x_{2}>\cdots>x_{n}$ and $y_{1}>y_{2}>\cdots>$ $y_{n}$, and let $\sigma$ be a nontrivial permutation of the set $\{1,2, \ldots, n\}$. Prove that

$$
\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}<\sum_{i=1}^{n}\left(x_{i}-y_{\sigma(i)}\right)^{2} .
$$

833. Let $a_{1}, a_{2}, \ldots, a_{n}$ be a permutation of the numbers $1,2, \ldots, n$. We call $a_{i}$ a large integer if $a_{i}>a_{j}$ for all $i<j<n$. Find the average number of large integers over all permutations of the first $n$ positive integers.

834. Given some positive real numbers $a_{1}<a_{2}<\cdots<a_{n}$ find all permutations $\sigma$ with the property that

$$
a_{1} a_{\sigma(1)}<a_{2} a_{\sigma(2)}<\cdots<a_{n} a_{\sigma(n)} .
$$

835. Determine the number of permutations $a_{1}, a_{2}, \ldots, a_{2004}$ of the numbers $1,2, \ldots$, 2004 for which

$$
\left|a_{1}-1\right|=\left|a_{2}-2\right|=\cdots=\left|a_{2004}-2004\right|>0 .
$$

836. Let $n$ be an odd integer greater than 1 . Find the number of permutations $\sigma$ of the set $\{1,2, \ldots, n\}$ for which

$$
|\sigma(1)-1|+|\sigma(2)-2|+\cdots+|\sigma(n)-n|=\frac{n^{2}-1}{2} .
$$

\subsubsection{Combinatorial Geometry}

We grouped under this title problems that are solved by analyzing configurations of geometric objects. We start with an easy problem that was proposed in 1999 for the Junior Balkan Mathematical Olympiad.

Example. In a regular $2 n$-gon, $n$ diagonals intersect at a point $S$, which is not a vertex. Prove that $S$ is the center of the $2 n$-gon.

Solution. Fix one of the $n$ diagonals. The other $n-1$ diagonals intersect it, so there are $n-1$ vertices on one side and $n-1$ vertices on the other side of this diagonal. Hence this was a main diagonal. Repeating the argument we conclude that all $n$ diagonals are main diagonals, so they meet at the center.

We continue with an example suggested to us by G. Galperin.

Example. Show that from any finitely many (closed) hemispheres that cover a sphere one can choose four that cover the sphere.

Solution. In what follows, by a half-line, half-plane, and half-space we will understand a closed half-line, half-plane, respectively, half-space. The hemispheres are obtained by intersecting the sphere with half-spaces passing through the origin. This observation allows us to modify the statement so as to make an inductive argument on the dimension possible.

Alternative problem. Show that from any finitely many half-spaces that cover the threedimensional space one can choose four that cover the space.

Let us analyze first the one- and two-dimensional cases. Among any finite set of half-lines covering a certain line one can choose two that cover it. Indeed, identifying the line with the real axis, the first of them can be chosen to be of the form $[a, \infty)$, with $a$ smallest among the half-lines of this type in our set, and the other to be of the form $(-\infty, b]$, with $b$ largest among the half-lines of this type in our set. The two-dimensional analogue of this property states that from finitely many halfplanes covering the two-dimensional plane one can choose three that cover the plane. We prove this by induction on the number $n$ of half-planes. For $n=3$ there is nothing to prove. Assume that the property is true for $n$ half-planes and let us prove it for $n+1$. Choose $h_{1}$ to be one of these half-planes.

If the boundary $\partial h_{1}$ of $h_{1}$ is contained in some other half-plane $h_{2}$, then either $h_{1}$ and $h_{2}$ cover the plane, or $h_{2}$ contains $h_{1}$. In the latter case we dispose of $h_{1}$ and use the induction hypothesis.

If the boundary $\partial h_{1}$ is not contained in any half-plane, then any other half-plane intersects it along a half-line. From the one-dimensional situation we know that two of these half-lines cover it completely. Let $h_{2}$ and $h_{3}$ be the half-planes corresponding to these two half-lines. There are two possibilities, described in Figure 38. In the first case $h_{1}$ is contained in the union of $h_{2}$ and $h_{3}$, so it can be removed, and then we can use the induction hypothesis. In the second case, $h_{1}, h_{2}$, and $h_{3}$ cover the plane. This completes the two-dimensional case.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-300.jpg?height=318&width=956&top_left_y=1011&top_left_x=396)

Figure 38

The proof can be extended to three dimensions. As before, we use induction on the number $n \geq 4$ of half-spaces. For the base case $n=4$ there is nothing to prove. Now let us assume that the property is true for $n$ half-spaces, and let us prove it for $n+1$. Let $H_{1}$ be one of the half-spaces. If the boundary of $H_{1}, \partial H_{1}$, is included in another half-space $\mathrm{H}_{2}$, then either $H_{1}$ and $H_{2}$ cover three-dimensional space, or $H_{1}$ is included in $H_{2}$ and then we can use the induction hypothesis.

In the other case we use the two-dimensional version of the result to find three halfspaces $H_{2}, H_{3}$, and $H_{4}$ that determine half-planes on $\partial H_{1}$ that cover $\partial H_{1}$. To simplify the discussion let us assume that the four boundary planes $\partial H_{i}, i=1,2,3,4$, are in general position. Then they determine a tetrahedron. If $H_{1}$ contains this tetrahedron, then $H_{1}, H_{2}, H_{3}, H_{4}$ cover three-dimensional space. If $H_{1}$ does not contain this tetrahedron, then it is contained in the union of $H_{2}, H_{3}$, and $H_{4}$, so it can be removed and we can apply the induction hypothesis to complete the argument.

Our third example was published by V.I. Arnol'd in the Russian journal Quantum. Example. Prove that any $n$ points in the plane can be covered by finitely many disks with the sum of the diameters less than $n$ and the distance between any two disks greater than 1.

Solution. First, note that if two disks of diameters $d_{1}$ and $d_{2}$ intersect, then they can be included in a disk of diameter $d_{1}+d_{2}$.

Let us place $n$ disks centered at our points, of some radius $a>1$ the size of which will be specified later. Whenever two disks intersect, we replace them with a disk that covers them, of diameter equal to the sum of their diameters. We continue this procedure until we have only disjoint disks.

We thus obtained a family of $k \leq n$ disks with the sum of diameters equal to $n a$ and such that they cover the disks of diameter $a$ centered at the points. Now let us shrink the diameters of the disks by $b$, with $1<b<a$. Then the new disks cover our points, the sum of their diameters is $n a-k b \leq n a-b$, and the distances between disks are at least $b$. Choosing $a$ and $b$ such that $1<b<a$ and $n a-b \leq n$ would then lead to a family of circles with the sum of diameters less than $n$ and at distance greater than 1 from each other. For example, we can let $a=1+\frac{1}{n}$ and $b=1+\frac{1}{2 n}$.

837. In how many regions do $n$ great circles, any three nonintersecting, divide the surface of a sphere?

838. In how many regions do $n$ spheres divide the three-dimensional space if any two intersect along a circle, no three intersect along a circle, and no four intersect at one point?

839. Given $n>4$ points in the plane such that no three are collinear, prove that there are at least $\left(\begin{array}{c}n-3 \\ 2\end{array}\right)$ convex quadrilaterals whose vertices are four of the given points.

840. An equilateral triangle of side length $n$ is drawn with sides along a triangular grid of side length 1 . What is the maximum number of grid segments on or inside the triangle that can be marked so that no three marked segments form a triangle?

841. 1981 points lie inside a cube of side length 9. Prove that there are two points within a distance less than 1.

842. What is the largest number of internal right angles that an $n$-gon (convex or not, with non-self-intersecting boundary) can have?

843. A circle of radius 1 rolls without slipping on the outside of a circle of radius $\sqrt{2}$. The contact point of the circles in the initial position is colored. Any time a point of one circle touches a colored point of the other, it becomes itself colored. How many colored points will the moving circle have after 100 revolutions?

844. Several chords are constructed in a circle of radius 1 . Prove that if every diameter intersects at most $k$ chords, then the sum of the lengths of the chords is less than $k \pi$. 

845. Inside a square of side 38 lie 100 convex polygons, each with an area at most $\pi$ and the perimeter at most $2 \pi$. Prove that there exists a circle of radius 1 inside the square that does not intersect any of the polygons.

846. Given a set $M$ of $n \geq 3$ points in the plane such that any three points in $M$ can be covered by a disk of radius 1 , prove that the entire set $M$ can be covered by a disk of radius 1 .

847. Prove that if a convex polyhedron has the property that every vertex belongs to an even number of edges, then any section determined by a plane that does not pass through a vertex is a polygon with an even number of sides.

\subsubsection{Euler's Formula for Planar Graphs}

This section is about a graph-theoretical result with geometric flavor, the famous Euler's formula. Recall that a graph is a collection of points, called vertices, some of which are joined by arcs, called edges. A planar graph is a graph embedded in the plane in such a way that edges do not cross. The connected components of the complement of a planar graph are called faces. For example, the graph in Figure 39 has four faces (this includes the infinite face). Unless otherwise specified, all our graphs are assumed to be connected.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-302.jpg?height=327&width=802&top_left_y=1201&top_left_x=466)

Figure 39

Euler's theorem. Given a connected planar graph, denote by $V$ the number of vertices, by $E$ the number of edges, and by $F$ the number of faces (including the infinite face). Then

$$
V-E+F=2 .
$$

Proof. The proof is an easy induction on $F$. If $F=1$ the graph is a tree, and the number of vertices exceeds that of edges by 1 . The formula is thus verified in this case.

Let us now consider some $F>1$ and assume that the formula holds for all graphs with at most $F-1$ faces. Since there are at least two faces, the graph is not a tree. Therefore, it must contain cycles. Remove one edge from a cycle. The new graph is still connected. The number of edges has decreased by 1 ; that of faces has also decreased by 1. By the induction hypothesis,

$$
V-(E-1)+(F-1)=2
$$

hence Euler's formula holds for the original graph, too. This completes the proof.

This method of proof is called reduction of complexity, and is widely applied in a combinatorial branch of geometry called low-dimensional topology.

As a corollary, if $V, E$, and $F$ are the numbers of vertices, edges, and faces of a convex polyhedron, then $V-E+F=2$. As you can see, it was much easier to prove this formula for general planar graphs. The number 2 in Euler's formula is called the Euler (or Euler-Poincaré) characteristic of the sphere, since any convex polyhedron has the shape of a sphere. If a polyhedron has the shape of a sphere with $g$ handles (a so-called surface of genus $g$ ), this number should be replaced by $2-2 g$. The faces of such a graph should be planar polygons (no holes or handles). The Euler characteristic is an example of a "topological invariant"; it detects the number of handles of a polyhedral surface.

As an application of Euler's formula, let us determine the Platonic solids. Recall that a Platonic solid (i.e., a regular polyhedron) is a polyhedron whose faces are congruent regular polygons and such that each vertex belongs to the same number of edges.

Example. Find all Platonic solids.

Solution. Let $m$ be the number of edges that meet at a vertex and let $n$ be the number of edges of a face. With the usual notation, when counting vertices by edges, we obtain $2 E=m V$. When counting faces by edges, we obtain $2 E=n F$. Euler's formula becomes

$$
\frac{2}{m} E-E+\frac{2}{n} E=2,
$$

or

$$
E=\left(\frac{1}{m}+\frac{1}{n}-\frac{1}{2}\right)^{-1} .
$$

The right-hand side must be a positive integer. In particular, $\frac{1}{m}+\frac{1}{n}>\frac{1}{2}$. The only possibilities are the following:

1. $m=3, n=3$, in which case $E=6, V=4, F=4$; this is the regular tetrahedron.

2. $m=3, n=4$, in which case $E=12, V=8, F=6$; this is the cube.

3. $m=3, n=5$, in which case $E=30, V=20, F=12$; this is the regular dodecahedron. 4. $m=4, n=3$, in which case $E=12, V=6, F=8$; this is the regular octahedron.

5. $m=5, n=3$, in which case $E=30, V=12, F=20$; this is the regular icosahedron.

We have proved the well-known fact that there are five Platonic solids.

848. In the plane are given $n>2$ points joined by segments, such that the interiors of any two segments are disjoint. Find the maximum possible number of such segments as a function of $n$.

849. Three conflicting neighbors have three common wells. Can one draw nine paths connecting each of the neighbors to each of the wells such that no two paths intersect?

850. Consider a polyhedron with at least five faces such that exactly three edges emerge from each vertex. Two players play the following game: the players sign their names alternately on precisely one face that has not been previously signed. The winner is the player who succeeds in signing the name on three faces that share a common vertex. Assuming optimal play, prove that the player who starts the game always wins.

851. Denote by $V$ the number of vertices of a convex polyhedron, and by $\Sigma$ the sum of the (planar) angles of its faces. Prove that $2 \pi V-\Sigma=4 \pi$.

852. (a) Given a connected planar graph whose faces are polygons with at least three sides (no loops or bigons), prove that there is a vertex that belongs to at most five edges.

(b) Prove that any map in the plane can be colored by five colors such that adjacent regions have different colors (the regions are assumed to be polygons, two regions are adjacent if they share at least one side).

853. Consider a convex polyhedron whose faces are triangles and whose edges are oriented. A singularity is a face whose edges form a cycle, a vertex that belongs only to incoming edges, or a vertex that belongs only to outgoing edges. Show that the polyhedron has at least two singularities.

\subsubsection{Ramsey Theory}

Ramsey theory is a difficult branch of combinatorics, which gathers results that show that when a sufficiently large set is partitioned into a fixed number of subsets, one of the subsets has a certain property. Finding sharp bounds on how large the set should be is a truly challenging question, unanswered in most cases.

The origins of this field lie in Ramsey's theorem, which states that for every pair of positive integers $(p, q)$ there is a smallest integer $R(p, q)$, nowadays called the Ramsey number, such that whenever the edges of a complete graph are colored red and blue, there is either a complete subgraph with $p$ vertices whose edges are all red, or a complete subgraph with $q$ vertices whose edges are all blue. (Recall that a complete graph is an unoriented graph in which any two vertices are connected by an edge.)

Here is a simple problem in Ramsey theory.

Example. Show that if the points of the plane are colored black or white, then there exists an equilateral triangle whose vertices are colored by the same color.

Solution. Suppose that there exists a configuration in which no monochromatic equilateral triangle is formed.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-305.jpg?height=533&width=689&top_left_y=784&top_left_x=523)

Figure 40

Start with two points of the same color, say black. Without loss of generality, we may assume that they are $(1,0)$ and $(-1,0)$. Then $(0, \sqrt{3})$ and $(0,-\sqrt{3})$ must both be white. Consequently, $(2,0)$ is black, and so $(1, \sqrt{3})$ is white. Then on the one hand, $(1,2 \sqrt{3})$ cannot be black, and on the other hand it cannot be white, a contradiction. Hence the conclusion. This argument can be followed easily on Figure 40 .

We now present a problem from the 2000 Belarus Mathematical Olympiad, which we particularly liked because the solution contains a nice interplay between combinatorics and number theory.

Example. Let $M=\{1,2, \ldots, 40\}$. Find the smallest positive integer $n$ for which it is possible to partition $M$ into $n$ disjoint subsets such that whenever $a, b$, and $c$ (not necessarily distinct) are in the same subset, $a \neq b+c$.

Solution. We will show that $n=4$. Assume first that it is possible to partition $M$ into three such sets $X, Y$, and $Z$. First trick: order the sets in decreasing order of their cardinalities as $|X| \geq|Y| \geq|Z|$. Let $x_{1}, x_{2}, \ldots, x_{|X|}$ be the elements of $X$ in increasing order. These numbers, together with the differences $x_{i}-x_{1}, i=2,3, \ldots,|X|$, must all be distinct elements of $M$. Altogether, there are $2|X|-1$ such numbers, implying that $2|X|-1 \leq 40$, or $|X| \leq 20$. Also, $3|X| \geq|X|+|Y|+|Z|=40$, so $|X| \geq 14$.

There are $|X| \cdot|Y| \geq|X| \times \frac{1}{2}(40-|X|)$ pairs in $X \times Y$. The sum of the numbers in each pair is at least 2 and at most 80 , a total of 79 possible values. Because $14 \leq|X| \leq 20$ and the function $f(t)=\frac{1}{2} t(40-t)$ is concave on the interval [14, 20], we have that

$$
\frac{|X|(40-|X|)}{2} \geq \min \left\{\frac{14 \cdot 26}{2}, \frac{20 \cdot 20}{2}\right\}=182>2 \cdot 79 .
$$

We can use the pigeonhole principle to find three distinct pairs $\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right),\left(x_{3}, y_{3}\right) \in$ $X \times Y$ with $x_{1}+y_{1}=x_{2}+y_{2}=x_{3}+y_{3}$.

If any of the $x_{i}$ 's were equal, then the corresponding $y_{i}$ 's would be equal, which is impossible because the pairs $\left(x_{i}, y_{i}\right)$ are distinct. We may thus assume, without loss of generality, that $x_{1}<x_{2}<x_{3}$. For $1 \leq j<k \leq 3$, the value $x_{k}-x_{j}$ is in $M$ but cannot be in $X$ because otherwise $x_{j}+\left(x_{k}-x_{j}\right)=x_{k}$. Similarly, $y_{j}-y_{k} \notin Y$ for $1 \leq j<k \leq 3$. Therefore, the three common differences $x_{2}-x_{1}=y_{1}-y_{2}, x_{3}-x_{2}=y_{2}-y_{3}$, and $x_{3}-x_{1}=y_{1}-y_{3}$ are in $M \backslash(X \cup Y)=Z$. However, setting $a=x_{2}-x_{1}, b=x_{3}-x_{2}$, and $c=x_{3}-x_{1}$, we have $a+b=c$ with $a, b, c \in Z$, a contradiction.

Therefore, it is impossible to partition $M$ into three sets with the desired property. Let us show that this can be done with four sets. The question is how to organize the 40 numbers.

We write the numbers in base 3 as $\ldots a_{t} \ldots a_{3} a_{2} a_{1}$ with only finitely many digits not equal to 0 . The sets $A_{1}, A_{2}, A_{3}, \ldots$ are constructed inductively as follows. $A_{1}$ consists of all numbers for which $a_{1}=1$. For $k>1$ the set $A_{k}$ consists of all numbers with $a_{k}=0$ that were not already placed in other sets, together with the numbers that have $a_{k}=1$ and $a_{i}=0$ for $i<k$. An alternative description is that $A_{k}$ consists of those numbers that are congruent to some integer in the interval $\left(\frac{1}{2} 3^{k-1}, 3^{k-1}\right.$ ] modulo $3^{k}$. For our problem,

$$
\begin{aligned}
&A_{1}=\{1,11,21,101,111,121,201,211,221,1001,1011,1021,1101,1111\}, \\
&A_{2}=\{2,10,102,110,202,210,1002,1010,1102,1110\}, \\
&A_{3}=\{12,20,22,100,1012,1020,1022,1100\}, \\
&A_{4}=\{112,120,122,200,212,220,222,1000\} .
\end{aligned}
$$

Using the first description of these sets, we see that they exhaust all positive integers. Using the second description we see that $\left(A_{k}+A_{k}\right) \cap A_{k}=\emptyset, k \geq 1$. Hence $A_{1}, A_{2}, A_{3}$, $A_{4}$ provide the desired example, showing that the answer to the problem is $n=4$.

Remark. In general, for positive integers $n$ and $k$ and a partition of $\{1,2, \ldots, k\}$ into $n$ sets, a triple $(a, b, c)$ such that $a, b$, and $c$ are in the same set and $a+b=c$ is called a Schur triple. Schur's theorem proves that for each $n$ there exists a minimal number $S(n)$ such that for any partition of $\{1,2, \ldots, S(n)\}$ into $n$ sets one of the sets will contain a Schur triple. No general formula for $S(n)$ exists although upper and lower bounds have been found. Our problem proves that $S(4)>40$. In fact, $S(4)=45$.

854. What is the largest number of vertices that a complete graph can have so that its edges can be colored by two colors in such a way that no monochromatic triangle is formed?

855. For the Ramsey numbers defined above, prove that $R(p, q) \leq R(p-1, q)+$ $R(p, q-1)$. Conclude that for $p, q \geq 2$,

$$
R(p, q) \leq\left(\begin{array}{c}
p+q-2 \\
p-1
\end{array}\right) .
$$

856. The edges of a complete graph with $\lfloor k ! e\rfloor+1$ edges are colored by $k$ colors. Prove that there is a triangle whose edges are colored by the same color.

857. An international society has members from six different countries. The list of members contains 1978 names, numbered 1, 2, .., 1978. Prove that there exists at least one member whose number is the sum of the numbers of two members from his/her own country, or twice as large as the number of one member from his/her country.

858. Let $n$ be a positive integer satisfying the following property: If $n$ dominoes are placed on a $6 \times 6$ chessboard with each domino covering exactly two unit squares, then one can always place one more domino on the board without moving any other dominoes. Determine the maximum value of $n$.

\subsection{Binomial Coefficients and Counting Methods}

\subsubsection{Combinatorial Identities}

The binomial coefficient $\left(\begin{array}{l}n \\ k\end{array}\right)$ counts the number of ways one can choose $k$ objects from given $n$. Binomial coefficients show up in Newton's binomial expansion

$$
(x+1)^{n}=\left(\begin{array}{l}
n \\
0
\end{array}\right) x^{n}+\left(\begin{array}{l}
n \\
1
\end{array}\right) x^{n-1}+\cdots+\left(\begin{array}{c}
n \\
n-1
\end{array}\right) x+\left(\begin{array}{l}
n \\
n
\end{array}\right) .
$$

Explicitly,

$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)=\frac{n !}{k !(n-k) !}=\frac{n(n-1) \cdots(n-k+1)}{k !} \quad \text { if } 0 \leq k \leq n .
$$

The recurrence relation 

$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)=\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)+\left(\begin{array}{l}
n-1 \\
k-1
\end{array}\right)
$$

allows the binomial coefficients to be arranged in Pascal's triangle:

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-308.jpg?height=332&width=729&top_left_y=426&top_left_x=503)

Here every entry is obtained by summing the two entries just above it.

This section presents applications of the basic properties of binomial coefficients. Here is a problem from the 2001 Hungarian Mathematical Olympiad.

Example. Let $m$ and $n$ be integers such that $1 \leq m \leq n$. Prove that $m$ divides the number

$$
n \sum_{k=0}^{m-1}(-1)^{k}\left(\begin{array}{l}
n \\
k
\end{array}\right) \text {. }
$$

Solution. We would like to express the sum in closed form. To this end, we apply the recurrence formula for binomial coefficients and obtain

$$
\begin{aligned}
n \sum_{k=0}^{m-1}(-1)^{k}\left(\begin{array}{l}
n \\
k
\end{array}\right) &=n \sum_{k=0}^{m-1}(-1)^{k}\left(\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)+\left(\begin{array}{c}
n-1 \\
k-1
\end{array}\right)\right) \\
&=n \sum_{k=0}^{m-1}(-1)^{k}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)-n \sum_{k=0}^{m-2}(-1)^{k}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \\
&=n(-1)^{m-1}\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)=m(-1)^{m-1}\left(\begin{array}{c}
n \\
m
\end{array}\right)
\end{aligned}
$$

The answer is clearly divisible by $m$.

The methods used in proving combinatorial identities can be applied to problems outside the field of combinatorics. As an example, let us take a fresh look at a property that we encountered elsewhere in the solution to a problem about polynomials.

Example. If $k$ and $m$ are positive integers, prove that the polynomial

$$
\left(x^{k+m}-1\right)\left(x^{k+m-1}-1\right) \cdots\left(x^{k+1}-1\right)
$$

is divisible by

$$
\left(x^{m}-1\right)\left(x^{m-1}-1\right) \cdots(x-1)
$$

in the ring of polynomials with integer coefficients. Solution. Let us analyze the quotient

$$
p_{k, m}(x)=\frac{\left(x^{k+m}-1\right)\left(x^{k+m-1}-1\right) \cdots\left(x^{k+1}-1\right)}{\left(x^{m}-1\right)\left(x^{m-1}-1\right) \cdots(x-1)},
$$

which conjecturally is a polynomial with integer coefficients. The main observation is that

$$
\begin{aligned}
\lim _{x \rightarrow 1} p_{k, m}(x) &=\lim _{x \rightarrow 1} \frac{\left(x^{k+m}-1\right)\left(x^{k+m-1}-1\right) \cdots\left(x^{k+1}-1\right)}{\left(x^{m}-1\right)\left(x^{m-1}-1\right) \cdots(x-1)} \\
&=\lim _{x \rightarrow 1} \frac{x^{k+m}-1}{x-1} \cdots \frac{x^{k+1}-1}{x-1} \cdot \frac{x-1}{x^{m}-1} \cdots \frac{x-1}{x-1} \\
&=\frac{(k+m)(k+m-1) \cdots(k+1)}{m \cdot(m-1) \cdots 1}=\left(\begin{array}{c}
k+m \\
m
\end{array}\right)
\end{aligned}
$$

With this in mind, we treat $p_{k, m}(x)$ as some kind of binomial coefficient. Recall that one way of showing that $\left(\begin{array}{l}n \\ m\end{array}\right)=\frac{n !}{m !(n-m) !}$ is an integer number is by means of Pascal's triangle. We will construct a Pascal's triangle for the polynomials $p_{k, m}(x)$. The recurrence relation

$$
\left(\begin{array}{c}
k+m+1 \\
m
\end{array}\right)=\left(\begin{array}{c}
k+m \\
m
\end{array}\right)+\left(\begin{array}{c}
k+m \\
m-1
\end{array}\right)
$$

has the polynomial analogue

$$
\begin{aligned}
\frac{\left(x^{k+m+1}-1\right) \cdots\left(x^{k+2}-1\right)}{\left(x^{m}-1\right) \cdots(x-1)}=& \frac{\left(x^{k+m}-1\right) \cdots\left(x^{k+1}-1\right)}{\left(x^{m}-1\right) \cdots(x-1)} \\
&+x^{k+1} \frac{\left(x^{k+m}-1\right) \cdots\left(x^{k+2}-1\right)}{\left(x^{m-1}-1\right) \cdots(x-1)} .
\end{aligned}
$$

Now the conclusion follows by induction on $m+k$, with the base case the obvious $\frac{x^{k+1}-1}{x-1}=x^{k}+x^{k-1}+\cdots+1$.

In quantum physics the variable $x$ is replaced by $q=e^{i \hbar}$, where $\hbar$ is Planck's constant, and the polynomials $p_{n-m, m}(q)$ are denoted by $\left(\begin{array}{l}n \\ m\end{array}\right)_{q}$ and called quantum binomial coefficients (or Gauss polynomials). They arise in the context of the Heisenberg uncertainty principle. Specifically, if $P$ and $Q$ are the linear transformations that describe, respectively, the time evolution of the momentum and the position of a particle, then $P Q=q Q P$. The binomial formula for them reads

$$
(Q+P)^{n}=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) Q_{q} Q^{k} P^{n-k} .
$$

The recurrence relation we obtained a moment ago, 

$$
\left(\begin{array}{l}
n \\
m
\end{array}\right)_{q}=\left(\begin{array}{c}
n-1 \\
m
\end{array}\right)_{q}+q^{n-m}\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)_{q}
$$

gives rise to what is called the $q$-Pascal triangle.

859. Prove that

$$
\left(\begin{array}{c}
2 k \\
k
\end{array}\right)=\frac{2}{\pi} \int_{0}^{\frac{\pi}{2}}(2 \sin \theta)^{2 k} d \theta
$$

860. Consider the triangular $n \times n$ matrix

$$
A=\left(\begin{array}{ccccc}
1 & 1 & 1 & \cdots & 1 \\
0 & 1 & 1 & \cdots & 1 \\
0 & 0 & 1 & \cdots & 1 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{array}\right) .
$$

Compute the matrix $A^{k}, k \geq 1$.

861. Let $\left(F_{n}\right)_{n}$ be the Fibonacci sequence, $F_{1}=F_{2}=1, F_{n+1}=F_{n}+F_{n-1}$. Prove that for any positive integer $n$

$$
F_{1}\left(\begin{array}{l}
n \\
1
\end{array}\right)+F_{2}\left(\begin{array}{l}
n \\
2
\end{array}\right)+\cdots+F_{n}\left(\begin{array}{l}
n \\
n
\end{array}\right)=F_{2 n} .
$$

862. For an arithmetic sequence $a_{1}, a_{2}, \ldots, a_{n}, \ldots$, let $S_{n}=a_{1}+a_{2}+\cdots+a_{n}, n \geq 1$.

Prove that

$$
\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) a_{k+1}=\frac{2^{n}}{n+1} S_{n+1}
$$

863. Show that for any positive integer $n$, the number

$$
S_{n}=\left(\begin{array}{c}
2 n+1 \\
0
\end{array}\right) \cdot 2^{2 n}+\left(\begin{array}{c}
2 n+1 \\
2
\end{array}\right) \cdot 2^{2 n-2} \cdot 3+\cdots+\left(\begin{array}{c}
2 n+1 \\
2 n
\end{array}\right) \cdot 3^{n}
$$

is the sum of two consecutive perfect squares.

864. For a positive integer $n$ define the integers $a_{n}, b_{n}$, and $c_{n}$ by

$$
a_{n}+b_{n} \sqrt[3]{2}+c_{n} \sqrt[3]{4}=(1+\sqrt[3]{2}+\sqrt[3]{4})^{n}
$$

Prove that

$$
2^{-\frac{n}{3}} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) a_{k}= \begin{cases}a_{n} & \text { if } n \equiv 0(\bmod 3) \\
b_{n} \sqrt[3]{2} & \text { if } n \equiv 2(\bmod 3) \\
c_{n} \sqrt[3]{4} & \text { if } n \equiv 1(\bmod 3)\end{cases}
$$

865. Prove the analogue of Newton's binomial formula

$$
[x+y]_{n}=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{k}[y]_{n-k},
$$

where $[x]_{n}=x(x-1) \cdots(x-n+1)$.

866. Prove that the quantum binomial coefficients $\left(\begin{array}{l}n \\ k\end{array}\right)$ previously defined satisfy

$$
\sum_{k=0}^{n}(-1)^{k} q^{\frac{k(k-1)}{2}}\left(\begin{array}{l}
n \\
k
\end{array}\right)_{q}=0 .
$$

\subsubsection{Generating Functions}

The terms of a sequence $\left(a_{n}\right)_{n \geq 0}$ can be combined into a function

$$
G(x)=a_{0}+a_{1} x+a_{2} x^{2}+\cdots+a_{n} x^{n}+\cdots,
$$

called the generating function of the sequence. Sometimes this function can be written in closed form and carries useful information about the sequence. For example, if the sequence satisfies a second-order linear recurrence, say $a_{n+1}+u a_{n}+v a_{n-1}=0$, then the generating function satisfies the functional equation

$$
G(x)-a_{0}-a_{1} x+u x\left(G(x)-a_{0}\right)+v x^{2} G(x)=0 .
$$

This equation can be solved easily, giving

$$
G(x)=\frac{a_{0}+\left(u a_{0}+a_{1}\right) x}{1+u x+v x^{2}} .
$$

If $r_{1}$ and $r_{2}$ are the roots of the characteristic equation $\lambda^{2}+u \lambda+v=0$, then by using the partial fraction decomposition, we obtain

$$
G(x)=\frac{a_{0}+\left(u a_{0}+a_{1}\right) x}{\left(1-r_{1} x\right)\left(1-r_{2} x\right)}=\frac{\alpha}{1-r_{1} x}+\frac{\beta}{1-r_{2} x}=\sum_{n=0}^{\infty}\left(\alpha r_{1}^{n}+\beta r_{2}^{n}\right) x^{n} .
$$

And we recover the general-term formula $a_{n}=\alpha r_{1}^{n}+\beta r_{2}^{n}, n \geq 0$, where $\alpha$ and $\beta$ depend on the initial condition.

It is useful to notice the analogy with the method of the Laplace transform used for solving linear ordinary differential equations. Recall that the Laplace transform of a function $y(t)$ is defined as

$$
\mathcal{L} y(s)=\int_{0}^{\infty} y(t) e^{t s} d t
$$

The Laplace transform applied to the differential equation

$$
y^{\prime \prime}+u y^{\prime}+v y=0
$$

produces the algebraic equation

$$
s^{2} \mathcal{L}(y)-y^{\prime}(0)-s y(0)+u(s \mathcal{L}(y)-y(0))-v \mathcal{L}(y)=0,
$$

with the solution

$$
\mathcal{L}(y)=\frac{s y(0)+u y(0)+y^{\prime}(0)}{s^{2}+u s+v} .
$$

Again the partial fraction decomposition comes in handy, since we know that the inverse Laplace transforms of $\frac{1}{s-r_{1}}$ and $\frac{1}{s-r_{2}}$ are $e^{r_{1} x}$ and $e^{r_{2} x}$. The similarity of these two methods is not accidental, for recursive sequences are discrete approximations of differential equations.

Let us return to problems and look at the classical example of the Catalan numbers.

Example. Prove that the number of ways one can insert parentheses into a product of $n+1$ factors is the Catalan number $C_{n}=\frac{1}{n+1}\left(\begin{array}{c}2 n \\ n\end{array}\right)$.

Solution. Alternatively, the Catalan number $C_{n}$ is the number of ways the terms of the product can be grouped for performing the multiplication. This is a better point of view, because the location of the final multiplication splits the product in two, giving rise to the recurrence relation

$$
C_{n}=C_{0} C_{n-1}+C_{1} C_{n-2}+\cdots+C_{n-1} C_{0}, \quad n \geq 1 .
$$

Indeed, for every $k=0,1, \ldots, n-1$, the first $k+1$ terms can be grouped in $C_{k}$ ways, while the last $n-k$ terms can be grouped in $C_{n-k-1}$ ways. You can recognize that the expression on the right shows up when the generating function is squared. We deduce that the generating function satisfies the equation

$$
G(x)=x G(x)^{2}+1 .
$$

This is a quadratic equation, with two solutions. And because $\lim _{x \rightarrow 0} G(x)=a_{0}$, we know precisely which solution to choose, namely

$$
G(x)=\frac{1-\sqrt{1-4 x}}{2 x} .
$$

Expanding the square root with Newton's binomial formula, we have

$$
\sqrt{1-4 x}=(1-4 x)^{1 / 2}=\sum_{n=0}^{\infty}\left(\begin{array}{c}
1 / 2 \\
n
\end{array}\right)(-4 x)^{n}=\sum_{n=0}^{\infty} \frac{\left(\frac{1}{2}\right)\left(\frac{1}{2}-1\right) \cdots\left(\frac{1}{2}-n+1\right)}{n !}(-4 x)^{n}
$$



$$
\begin{aligned}
&=1-\sum_{n=1}^{\infty} \frac{(2 n-3)(2 n-5) \cdots 1}{n !}(2 x)^{n}=1-2 \sum_{n=1}^{\infty} \frac{(2 n-2) !}{(n-1) !(n-1) !} \frac{x^{n}}{n} \\
&=1-2 \sum_{n=1}^{\infty}\left(\begin{array}{c}
2 n-2 \\
n-1
\end{array}\right) \frac{x^{n}}{n} .
\end{aligned}
$$

Substituting in the expression for the generating function and shifting the index, we obtain

$$
G(x)=\sum_{n=0}^{\infty} \frac{1}{n+1}\left(\begin{array}{c}
2 n \\
n
\end{array}\right) x^{n},
$$

which gives the formula for the Catalan number $C_{n}=\frac{1}{n+1}\left(\begin{array}{c}2 n \\ n\end{array}\right)$.

The binomial coefficients $\left(\begin{array}{l}n \\ k\end{array}\right)$ are generated by a very simple function, $G(x)=$ $(x+1)^{n}$, and variations of this fact can be exploited to obtain combinatorial identities. This is the case with a problem published in the American Mathematical Monthly by N. Gonciulea.

Example. Prove that

$$
\sum_{j=0}^{n}\left(\begin{array}{l}
n \\
j
\end{array}\right) 2^{n-j}\left(\begin{array}{c}
j \\
\lfloor j / 2\rfloor
\end{array}\right)=\left(\begin{array}{c}
2 n+1 \\
n
\end{array}\right)
$$

Solution. Observe that $\left(\begin{array}{c}j \\ \lfloor j / 2\rfloor\end{array}\right)$ is the constant term in $(1+x)\left(x^{-1}+x\right)^{j}$. It follows that the sum is equal to the constant term in

$$
\begin{aligned}
&\sum_{j=0}^{n}\left(\begin{array}{l}
n \\
j
\end{array}\right) 2^{n-j}(1+x)\left(x^{-1}+x\right)^{j} \\
&\quad=(1+x) \sum_{j=0}^{n}\left(\begin{array}{c}
n \\
j
\end{array}\right)\left(x^{-1}+x\right)^{j} 2^{n-j}=(1+x)\left(2+x^{-1}+x\right)^{n} \\
&\quad=\frac{1}{x^{n}}(1+x)\left(2 x+1+x^{2}\right)^{n}=\frac{1}{x^{n}}(1+x)^{2 n+1} .
\end{aligned}
$$

And the constant term in this last expression is $\left(\begin{array}{c}2 n+1 \\ n\end{array}\right)$.

867. Find the general-term formula for the sequence $\left(y_{n}\right)_{n \geq 0}$ with $y_{0}=1$ and $y_{n}=$ $a y_{n-1}+b^{n}$ for $n \geq 1$, where $a$ and $b$ are two fixed distinct real numbers.

868. Compute the sums

$$
\sum_{k=1}^{n} k\left(\begin{array}{l}
n \\
k
\end{array}\right) \text { and } \sum_{k=1}^{n} \frac{1}{k+1}\left(\begin{array}{l}
n \\
k
\end{array}\right) \text {. }
$$

869. (a) Prove the identity

$$
\left(\begin{array}{c}
m+n \\
k
\end{array}\right)=\sum_{j=0}^{k}\left(\begin{array}{c}
m \\
j
\end{array}\right)\left(\begin{array}{c}
n \\
k-j
\end{array}\right) .
$$

(b) Prove that the quantum binomial coefficients defined in the previous section satisfy the identity

$$
\left(\begin{array}{c}
m+n \\
k
\end{array}\right)_{q}=\sum_{j=0}^{k} q^{(m-j)(k-j)}\left(\begin{array}{c}
m \\
j
\end{array}\right)_{q}\left(\begin{array}{c}
n \\
k-j
\end{array}\right)_{q} .
$$

870. Compute the sum

$$
\left(\begin{array}{l}
n \\
0
\end{array}\right)-\left(\begin{array}{l}
n \\
1
\end{array}\right)+\left(\begin{array}{l}
n \\
2
\end{array}\right)-\cdots+(-1)^{m}\left(\begin{array}{l}
n \\
m
\end{array}\right) .
$$

871. Write in short form the sum

$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)+\left(\begin{array}{c}
n+1 \\
k
\end{array}\right)+\left(\begin{array}{c}
n+2 \\
k
\end{array}\right)+\cdots+\left(\begin{array}{c}
n+m \\
k
\end{array}\right) .
$$

872. Prove that the Fibonacci numbers satisfy

$$
F_{n}=\left(\begin{array}{l}
n \\
0
\end{array}\right)+\left(\begin{array}{c}
n-1 \\
1
\end{array}\right)+\left(\begin{array}{c}
n-2 \\
2
\end{array}\right)+\cdots .
$$

873. Denote by $P(n)$ the number of partitions of the positive integer $n$, i.e., the number of ways of writing $n$ as a sum of positive integers. Prove that the generating function of $P(n), n \geq 1$, is given by

$$
\sum_{n=0}^{\infty} P(n) x^{n}=\frac{1}{(1-x)\left(1-x^{2}\right)\left(1-x^{3}\right) \cdots}
$$

with the convention $P(0)=1$.

874. Prove that the number of ways of writing $n$ as a sum of distinct positive integers is equal to the number of ways of writing $n$ as a sum of odd positive integers.

875. Let $p$ be an odd prime number. Find the number of subsets of $\{1,2, \ldots, p\}$ with the sum of elements divisible by $p$.

876. For a positive integer $n$, denote by $S(n)$ the number of choices of the signs "+" or "-" such that $\pm 1 \pm 2 \pm \cdots \pm n=0$. Prove that

$$
S(n)=\frac{2^{n-1}}{\pi} \int_{0}^{2 \pi} \cos t \cos 2 t \cdots \cos n t d t .
$$

877. The distinct positive integers $a_{1}, a_{2}, \ldots, a_{n}, b_{1}, b_{2}, \ldots, b_{n}$, with $n \geq 2$, have the property that the $\left(\begin{array}{l}n \\ 2\end{array}\right)$ sums $a_{i}+a_{j}$ are the same as the $\left(\begin{array}{l}n \\ 2\end{array}\right)$ sums $b_{i}+b_{j}$ (in some order). Prove that $n$ is a power of 2 .

878. Let $A_{1}, A_{2}, \ldots, A_{n}, \ldots$ and $B_{1}, B_{2}, \ldots, B_{n}, \ldots$ be sequences of sets defined by $A_{1}=\emptyset, B_{1}=\{0\}, A_{n+1}=\left\{x+1 \mid x \in B_{n}\right\}, B_{n+1}=\left(A_{n} \cup B_{n}\right) \backslash\left(A_{n} \cap B_{n}\right)$. Determine all positive integers $n$ for which $B_{n}=\{0\}$.

\subsubsection{Counting Strategies}

We illustrate how some identities can be proved by counting the number of elements of a set in two different ways. For example, we give a counting argument to the well-known reciprocity law, which we have already encountered in Section 5.1.3, of the greatest integer function.

Example. Given $p$ and $q$ coprime positive integers, prove that

$$
\left\lfloor\frac{p}{q}\right\rfloor+\left\lfloor\frac{2 p}{q}\right\rfloor+\cdots+\left\lfloor\frac{(q-1) p}{q}\right\rfloor=\left\lfloor\frac{q}{p}\right\rfloor+\left\lfloor\frac{2 q}{p}\right\rfloor+\cdots+\left\lfloor\frac{(p-1) q}{p}\right\rfloor .
$$

Solution. Let us look at the points of integer coordinates that lie inside the rectangle with vertices $O(0,0), A(q, 0), B(q, p), C(0, p)$ (see Figure 41). There are $(p-1)(q-1)$ such points. None of them lies on the diagonal $O B$ because $p$ and $q$ are coprime. Half of them lie above the diagonal and half below.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-315.jpg?height=414&width=621&top_left_y=1302&top_left_x=557)

Figure 41

Now let us count by a different method the points underneath the line $O B$. The equation of this line is $y=\frac{p}{q} x$. For each $0<k<q$ on the vertical segment $x=k$ there are $\lfloor k p / q\rfloor$ points below $O B$. Summing up, we obtain

$$
\left\lfloor\frac{p}{q}\right\rfloor+\left\lfloor\frac{2 p}{q}\right\rfloor+\cdots+\left\lfloor\frac{(q-1) p}{q}\right\rfloor=\frac{(p-1)(q-1)}{2} .
$$

The expression on the right remains unchanged if we switch $p$ and $q$, which proves the identity. Next, a combinatorial identity.

Example. Let $m$ and $n$ be two integers, $m \leq \frac{n-1}{2}$. Prove the identity

$$
\sum_{k=m}^{\frac{n-1}{2}}\left(\begin{array}{c}
n \\
2 k+1
\end{array}\right)\left(\begin{array}{l}
k \\
m
\end{array}\right)=2^{n-2 m-1}\left(\begin{array}{c}
n-m-1 \\
m
\end{array}\right) .
$$

Solution. The solution is a Fubini-type argument. Consider the set $\mathcal{P}$ of pairs $(A, B)$, where $A$ is a subset of $\{1,2, \ldots, n\}$ with an odd number of elements $a_{1}<a_{2}<\cdots<$ $a_{2 k+1}$ and $B$ is a subset of $\left\{a_{2}, a_{4}, \ldots, a_{2 k-2}, a_{2 k}\right\}$ with $m$ elements $b_{1}<b_{2}<\cdots<b_{m}$.

For a given $k$ there are $\left(\begin{array}{c}n \\ 2 k+1\end{array}\right)$ such subsets $A$, and for each $A$ there are $\left(\begin{array}{l}k \\ m\end{array}\right)$ subsets $B$, so the left-hand side of the identity is the number of elements of $\mathcal{P}$ counted by choosing A first.

Let us count the same number choosing $B$ first. Note that if $(A, B) \in \mathcal{P}$, then $B$ contains no pairs of consecutive numbers. More precisely, $B=\left\{b_{1}, b_{2}, \ldots, b_{m}\right\} \subset$ $\{2,3, \ldots, n-1\}$ with $b_{i+1}-b_{i} \geq 2$.

Fix $B_{0}$, a set with this property. We want to count the number of pairs $\left(A, B_{0}\right)$ in $X$. Choose $c_{0}, c_{1}, \ldots, c_{m}$ such that

$$
1 \leq c_{0}<b_{1}, b_{1}<c_{1}<b_{2}, \ldots, b_{i}<c_{i}<b_{i+1}, \ldots, b_{m}<c_{m} \leq n .
$$

Then for any subset $E$ of $\{1,2, \ldots, n\} \backslash\left\{c_{0}, b_{1}, c_{1}, b_{2}, \ldots, b_{m}, c_{m}\right\}$ there is a unique $A$ such that $\left(A, B_{0}\right) \in \mathcal{P}$ and $E \subset A$.

Indeed, if $\left(A, B_{0}\right) \in \mathcal{P}$ and $E \subset A$ we have to decide which $c_{i}$ 's are in $A$. Since the set $D_{i}=\left\{x \in A \mid b_{i}<x<b_{i+1}\right\}$ must contain an odd number of elements for each $0 \leq i \leq m+1$ (with $b_{0}=0, b_{m+1}=n+1$ ), and the set $D_{i}$ is either $\left\{x \in E \mid b_{i}<x<b_{i+1}\right\}$ or $\left\{x \in E \mid b_{i}<x<b_{i+1}\right\} \cup\left\{c_{i}\right\}$, the parity condition on the cardinality of $D_{i}$ decides whether $c_{i}$ belongs to $A$. It is now clear that the number of pairs ( $\left.A, B_{0}\right)$ in $\mathcal{P}$ is the same as the number of subsets of $\{1,2, \ldots, n\} \backslash\left\{c_{0}, b_{1}, \ldots, b_{m}, c_{m}\right\}$, and the latter is $2^{n-2 m-1}$.

How many subsets $B$ with $m$ elements of $\{2,3, \ldots, n-1\}$ do not contain consecutive numbers? If $B=\left\{b_{1}<b_{2}<\cdots<b_{m}\right\}$ is such a set, let $B^{\prime}=\left\{b_{1}-1, b_{2}-\right.$ $\left.2, \ldots, b_{m}-m\right\}$. It is easy to see that $B^{\prime}$ is an (arbitrary) subset of $\{1,2, \ldots, n-m-1\}$ with $m$ elements, and for each such subset $B^{\prime}=\left\{b_{1}^{\prime}<b_{2}^{\prime}<\cdots<b_{m}^{\prime}\right\}$, by letting $b_{i}=b_{i}^{\prime}+i$, we obtain a set $B$ as above. Hence the number of such $B$ 's is $\left(\begin{array}{c}n-m-1 \\ m\end{array}\right)$, and by choosing $B$ first we count the number of elements in $\mathcal{P}$ as $2^{n-2 m-1}\left(\begin{array}{c}n-m-1 \\ m\end{array}\right)$. The identity is proved.

Using similar ideas solve the following problems.

879. Find in closed form

$$
1 \cdot 2\left(\begin{array}{l}
n \\
2
\end{array}\right)+2 \cdot 3\left(\begin{array}{l}
n \\
3
\end{array}\right)+\cdots+(n-1) \cdot n\left(\begin{array}{l}
n \\
n
\end{array}\right) .
$$

880. Prove the combinatorial identity

$$
\sum_{k=1}^{n} k\left(\begin{array}{l}
n \\
k
\end{array}\right)^{2}=n\left(\begin{array}{c}
2 n-1 \\
n-1
\end{array}\right) .
$$

881. Prove the identity

$$
\sum_{k=0}^{m}\left(\begin{array}{c}
m \\
k
\end{array}\right)\left(\begin{array}{c}
n+k \\
m
\end{array}\right)=\sum_{k=0}^{m}\left(\begin{array}{c}
m \\
k
\end{array}\right)\left(\begin{array}{l}
n \\
k
\end{array}\right) 2^{k} .
$$

882. For integers $0 \leq k \leq n, 1 \leq m \leq n$, prove the identity

$$
\sum_{j=0}^{m}\left(\begin{array}{c}
m \\
i
\end{array}\right)\left(\begin{array}{c}
n-i \\
k
\end{array}\right)=\sum_{i=0}^{m}\left(\begin{array}{c}
m \\
i
\end{array}\right)\left(\begin{array}{c}
n-m \\
k-i
\end{array}\right) 2^{m-i} .
$$

883. Show that for any positive integers $p$ and $q$,

$$
\sum_{k=0}^{q} \frac{1}{2^{p+k}}\left(\begin{array}{c}
p+k \\
k
\end{array}\right)+\sum_{k=0}^{p} \frac{1}{2^{q+k}}\left(\begin{array}{c}
q+k \\
k
\end{array}\right)=2 .
$$

884. Let $c_{n}=\left(\begin{array}{c}n \\ \lfloor n / 2\rfloor\end{array}\right)$. Prove that

$$
\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) c_{k} c_{n-k}=c_{n} c_{n+1} .
$$

885. Let $p$ and $q$ be odd, coprime positive integers. Set $p^{\prime}=\frac{p-1}{2}$ and $q^{\prime}=\frac{q-1}{2}$. Prove the identity

$$
\left(\left\lfloor\frac{q}{p}\right\rfloor+\left\lfloor\frac{2 q}{p}\right\rfloor+\cdots+\left\lfloor\frac{p^{\prime} q}{p}\right\rfloor\right)+\left(\left\lfloor\frac{p}{q}\right\rfloor+\left\lfloor\frac{2 p}{q}\right\rfloor+\cdots+\left\lfloor\frac{q^{\prime} p}{p}\right\rfloor\right)=p^{\prime} q^{\prime} .
$$

Now we turn to more diverse counting arguments.

Example. What is the number of ways of writing the positive integer $n$ as an ordered sum of $m$ positive integers?

Solution. This is a way of saying that we have to count the number of $m$-tuples of positive integers $\left(x_{1}, x_{2}, \ldots, x_{m}\right)$ satisfying the equation $x_{1}+x_{2}+\cdots+x_{m}=n$. These $m$-tuples are in one-to-one correspondence with the strictly increasing sequences $0<$ $y_{1}<y_{2}<\cdots<y_{m}=n$ of positive integers, with the correspondence given by $y_{1}=x_{1}$, $y_{2}=x_{1}+x_{2}, \ldots, y_{m}=x_{1}+x_{2}+\cdots+x_{m}$. The numbers $y_{1}, y_{2}, \ldots, y_{m-1}$ can be chosen in $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)$ ways from $1,2, \ldots, n-1$. Hence the answer to the question is $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)$. This formula can also be proved using induction on $m$ for arbitrary $n$. The case $m=1$ is obvious. Assume that the formula is valid for partitions of any positive integer into $k \leq m$ positive integers, and let us prove it for partitions into $m+1$ positive integers. The equation $x_{1}+x_{2}+\cdots+x_{m}+x_{m+1}=n$ can be written as

$$
x_{1}+x_{2}+\cdots+x_{m}=n-x_{m+1} .
$$

As $x_{m+1}$ ranges among $1,2, \ldots, n-m$, we are supposed to count the total number of solutions of the equations $x_{1}+x_{2}+\cdots+x_{m}=r$, with $r=m, m+1, \ldots, n-1$. By the induction hypothesis, this number is

$$
\sum_{r=m}^{n-1}\left(\begin{array}{l}
r-1 \\
m-1
\end{array}\right) .
$$

We have seen in Section 6.2.2 that this number is equal to $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)$. This equality can also be proved using Pascal's triangle as follows:

$$
\begin{aligned}
&\left(\begin{array}{l}
m-1 \\
m-1
\end{array}\right)+\left(\begin{array}{c}
m \\
m-1
\end{array}\right)+\cdots+\left(\begin{array}{c}
n-2 \\
m-1
\end{array}\right) \\
&\quad=\left(\begin{array}{c}
m \\
m
\end{array}\right)+\left(\begin{array}{c}
m \\
m-1
\end{array}\right)+\cdots+\left(\begin{array}{c}
n-2 \\
m-1
\end{array}\right)=\left(\begin{array}{c}
m+1 \\
m
\end{array}\right)+\left(\begin{array}{c}
m+1 \\
m-1
\end{array}\right)+\cdots+\left(\begin{array}{c}
n-2 \\
m-1
\end{array}\right) \\
&\quad=\left(\begin{array}{c}
m+2 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
n-2 \\
m-1
\end{array}\right)=\cdots=\left(\begin{array}{c}
n-2 \\
m
\end{array}\right)+\left(\begin{array}{c}
n-2 \\
m-1
\end{array}\right)=\left(\begin{array}{c}
n-1 \\
m
\end{array}\right) .
\end{aligned}
$$

This proves that the formula is true for $m+1$, and the induction is complete.

Example. There are $n$ students at a university, $n$ an odd number. Some students join together to form several clubs (a student may belong to different clubs). Some clubs join together to form several societies (a club may belong to different societies). There are $k$ societies. Suppose that the following hold:

(i) each pair of students is in exactly one club,

(ii) for each student and each society, the student is in exactly one club of the society,

(iii) each club has an odd number of students; in addition, a club with $2 m+1$ students $(m>0)$ is in exactly $m$ societies.

Find all possible values of $k$.

Solution. This is a short-listed problem from the 45th International Mathematical Olympiad, 2004, proposed by Puerto Rico, which was given a year later at an Indian team selection test. Here is an ingenious approach found by one of the Indian students, R. Shah.

Fix a student $x$ and list the clubs to which the student belongs: $C_{1}, C_{2}, \ldots, C_{r}$. If $C_{i}$ has $2 m_{i}+1$ students, then it belongs to $m_{i}$ societies. Condition (ii) implies that for $i \neq j$ the societies to which $C_{i}$ belongs are all different from the societies to which $C_{j}$ belongs. Moreover, condition (ii) guarantees that any society will contain one of the clubs $C_{i}$. Therefore, $m_{1}+m_{2}+\cdots+m_{r}=k$.

From condition (i) we see that any two clubs $C_{i}$ and $C_{j}$ have in common exactly the student $x$. Therefore, in $C_{1}, C_{2}, \ldots, C_{r}$ there are altogether $2\left(m_{1}+m_{2}+\cdots+m_{r}\right)+1$ students. But these are all the students, because by condition (i) any other student is in some club with $x$. We obtain

$$
2\left(m_{1}+m_{2}+\cdots+m_{r}\right)+1=2 k+1=n .
$$

Hence $k=\frac{n-1}{2}$ is the only possibility. And this situation can be achieved when all students belong to one club, which then belongs to $\frac{n-1}{2}$ societies.

Here is a third example.

Example. On an $8 \times 8$ chessboard whose squares are colored black and white in an arbitrary way we are allowed to simultaneously switch the colors of all squares in any $3 \times 3$ and $4 \times 4$ region. Can we transform any coloring of the board into one where all the squares are black?

Solution. We claim that the answer is no. It is a matter of counting into how many regions can an all-black board be transformed by applying the two moves several times. The total number of $3 \times 3$ regions is $(8-2) \times(8-2)=36$, which is the same as the number of moves in which the colors in a $3 \times 3$ region are switched. As for the $4 \times 4$ regions, there are $(8-3) \times(8-3)=25$ of them. Hence the total number of colorings that can be obtained from an all-black coloring by applying the specified operations does not exceed

$$
2^{36} \times 2^{25}=2^{61} .
$$

This number is less than the total number of colorings, which is $2^{64}$. Hence there are colorings that cannot be achieved. Since the operations are reversible, this actually proves our claim.

And now the problems.

886. Two hundred students took part in a mathematics contest. They had 6 problems to solve. It is known that each problem was correctly solved by at least 120 participants. Prove that there exist two participants such that every problem was solved by at least one of them.

887. Prove that the number of nonnegative integer solutions to the equation

$$
x_{1}+x_{2}+\cdots+x_{m}=n
$$

is equal to $\left(\begin{array}{c}m+n-1 \\ m-1\end{array}\right)$ 

888. A number $n$ of tennis players take part in a tournament in which each of them plays exactly one game with each of the others. If $x_{i}$ and $y_{i}$ denote the number of victories, respectively, losses, of the $i$ th player, $i=1,2, \ldots, n$, show that

$$
x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}=y_{1}^{2}+y_{2}^{2}+\cdots+y_{n}^{2} .
$$

889. Let $A$ be a finite set and $f$ and $g$ two functions on $A$. Let $m$ be the number of pairs $(x, y) \in A \times A$ for which $f(x)=g(y), n$ the number of pairs for which $f(x)=f(y)$, and $k$ the number of pairs for which $g(x)=g(y)$. Prove that

$$
2 m \leq n+k .
$$

890. A set $S$ containing four positive integers is called connected if for every $x \in S$ at least one of the numbers $x-1$ and $x+1$ belongs to $S$. Let $C_{n}$ be the number of connected subsets of the set $\{1,2, \ldots, n\}$.

(a) Evaluate $C_{7}$.

(b) Find a general formula for $C_{n}$.

891. Prove that the set of numbers $\{1,2, \ldots, 2005\}$ can be colored with two colors such that any of its 18-term arithmetic sequences contains both colors.

892. For $A=\{1,2, \ldots, 100\}$ let $A_{1}, A_{2}, \ldots, A_{m}$ be subsets of $A$ with four elements with the property that any two have at most two elements in common. Prove that if $m \geq 40425$ then among these subsets there exist 49 whose union is equal to $A$ but with the union of any 48 of them not equal to $A$.

893. Let $S$ be a finite set of points in the plane. A linear partition of $S$ is an unordered pair $\{A, B\}$ of subsets of $S$ such that $A \cup B=S, A \cap B=\emptyset$, and $A$ and $B$ lie on opposite sides of some straight line disjoint from $S$ ( $A$ or $B$ may be empty). Let $L_{S}$ be the number of linear partitions of $S$. For each positive integer $n$, find the maximum of $L_{S}$ over all sets $S$ of $n$ points.

894. Let $A$ be a 101-element subset of the set $S=\{1,2, \ldots, 1000000\}$. Prove that there exist numbers $t_{1}, t_{2}, \ldots, t_{100}$ in $S$ such that the sets

$$
A_{j}=\left\{x+t_{j} \mid x \in A\right\}, \quad j=1,2, \ldots, 100,
$$

are pairwise disjoint.

895. Given a set $A$ with $n^{2}$ elements, $n \geq 2$, and $\mathcal{F}$ a family of subsets of $A$ each of which has $n$ elements, suppose that any two sets of $\mathcal{F}$ have at most one element in common.

(a) Prove that there are at most $n^{2}+n$ sets in $\mathcal{F}$.

(b) In the case $n=3$, show with an example that this bound can be reached. 

896. A sheet of paper in the shape of a square is cut by a line into two pieces. One of the pieces is cut again by a line, and so on. What is the minimum number of cuts one should perform such that among the pieces one can find one hundred polygons with twenty sides.

897. Twenty-one girls and twenty-one boys took part in a mathematics competition. It turned out that

(i) each contestant solved at most six problems, and

(ii) for each pair of a girl and a boy, there was at least one problem that was solved by both the girl and the boy.

Show that there is a problem that was solved by at least three girls and at least three boys.

\subsubsection{The Inclusion-Exclusion Principle}

A particular counting method that we emphasize is the inclusion-exclusion principle, also known as the Boole-Sylvester formula. It concerns the counting of the elements in a union of sets $A_{1} \cup A_{2} \cup \cdots \cup A_{n}$, and works as follows. If we simply wrote

$$
\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right|=\left|A_{1}\right|+\left|A_{2}\right|+\cdots+\left|A_{n}\right|,
$$

we would overcount the elements in the intersections $A_{i} \cap A_{j}$. Thus we have to subtract $\left|A_{1} \cap A_{2}\right|+\left|A_{1} \cap A_{3}\right|+\cdots+\left|A_{n-1} \cap A_{n}\right|$. But then the elements in the triple intersections $A_{i} \cap A_{j} \cap A_{k}$ were both added and subtracted. We have to put them back. Therefore, we must add $\left|A_{1} \cap A_{2} \cap A_{3}\right|+\cdots+\left|A_{n-2} \cap A_{n-1} \cap A_{n}\right|$. And so on. The final formula is

$\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right|=\sum_{i}\left|A_{i}\right|-\sum_{i, j}\left|A_{i} \cap A_{j}\right|+\cdots+(-1)^{n-1}\left|A_{1} \cap A_{2} \cap \cdots \cap A_{n}\right|$.

Example. How many integers less than 1000 are not divisible by 2,3 , or 5 ?

Solution. To answer the question, we will count instead how many integers between 1 and 1000 are divisible by 2,3 , or 5 . Denote by $A_{2}, A_{3}$, and $A_{5}$ be the sets of integers divisible by 2,3 , respectively, 5. The Boole-Sylvester formula counts $\left|A_{2} \cup A_{3} \cup A_{5}\right|$ as

$$
\begin{aligned}
\left|A_{2}\right| &+\left|A_{3}\right|+\left|A_{5}\right|-\left|A_{2} \cap A_{3}\right|-\left|A_{2} \cap A_{5}\right|-\left|A_{3} \cap A_{5}\right|+\left|A_{2} \cap A_{3} \cap A_{5}\right| \\
&=\left\lfloor\frac{1000}{2}\right\rfloor+\left\lfloor\frac{1000}{3}\right\rfloor+\left\lfloor\frac{1000}{5}\right\rfloor-\left\lfloor\frac{1000}{6}\right\rfloor-\left\lfloor\frac{1000}{10}\right\rfloor-\left\lfloor\frac{1000}{15}\right\rfloor+\left\lfloor\frac{1000}{30}\right\rfloor \\
&=500+333+200-166-100-66+33=734 .
\end{aligned}
$$

It follows that there are $1000-734=266$ integers less than 1000 that are not divisible by 2,3 , or 5 . The second example comes from I. Tomescu's book Problems in Combinatorics (Wiley, 1985).

Example. An alphabet consists of the letters $a_{1}, a_{2}, \ldots, a_{n}$. Prove that the number of all words that contain each of these letters twice, but with no consecutive identical letters, is equal to

$$
\frac{1}{2^{n}}\left[(2 n) !-\left(\begin{array}{l}
n \\
1
\end{array}\right) 2(2 n-1) !+\left(\begin{array}{l}
n \\
2
\end{array}\right) 2^{2}(2 n-2) !-\cdots+(-1)^{n} 2^{n} n !\right] .
$$

Solution. The number of such words without imposing the restriction about consecutive letters is

$$
\frac{(2 n) !}{(2 !)^{n}}=\frac{(2 n) !}{2^{n}} .
$$

This is so because the identical letters can be permuted.

Denote by $A_{i}$ the number of words formed with the $n$ letters, each occurring twice, for which the two letters $a_{i}$ appear next to each other. The answer to the problem is then

$$
\frac{(2 n) !}{2^{n}}-\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right| .
$$

We evaluate $\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right|$ using the inclusion-exclusion principle. To this end, let us compute $\left|A_{i_{1}} \cap A_{i_{2}} \cap \cdots \cap A_{i_{k}}\right|$ for some indices $i_{1}, i_{2}, \ldots, i_{k}, k \leq n$. Collapse the consecutive letters $a_{i j}, j=1,2, \ldots, k$. As such, we are, in fact, computing the number of words made of the letters $a_{1}, a_{2}, \ldots, a_{n}$ in which $a_{i_{1}}, a_{i_{2}}, \ldots, a_{i_{k}}$ appear once and all other letters appear twice. This number is clearly equal to

$$
\frac{(2 n-k) !}{2^{n-k}},
$$

since such a word has $2 n-k$ letters, and identical letters can be permuted. There are $\left(\begin{array}{l}n \\ k\end{array}\right)$ $k$-tuples $\left(i_{1}, i_{2}, \ldots, i_{k}\right)$. We thus have

$$
\begin{aligned}
\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right| &=\sum_{k} \sum_{i_{1}, \ldots, i_{k}}(-1)^{k-1}\left|A_{i_{1}} \cap A_{i_{2}} \cap \cdots \cap A_{i_{k}}\right| \\
&=\sum_{k}(-1)^{k-1}\left(\begin{array}{l}
n \\
k
\end{array}\right) \frac{(2 n-k) !}{2^{n-k}},
\end{aligned}
$$

and the formula is proved.

898. Let $m, n, p, q, r, s$ be positive integers such that $p<r<m$ and $q<s<n$. In how many ways can one travel on a rectangular grid from $(0,0)$ to $(m, n)$ such that at each step one of the coordinates increases by one unit and such that the path avoids the points $(p, q)$ and $(r, s)$ ? 

899. Let $E$ be a set with $n$ elements and $F$ a set with $p$ elements, $p \leq n$. How many surjective (i.e., onto) functions $f: E \rightarrow F$ are there?

900. A permutation $\sigma$ of a set $S$ is called a derangement if it does not have fixed points, i.e., if $\sigma(x) \neq x$ for all $x \in S$. Find the number of derangements of the set $\{1,2, \ldots, n\}$.

901. Given a graph with $n$ vertices, prove that either it contains a triangle, or there exists a vertex that is the endpoint of at most $\left\lfloor\frac{n}{2}\right\rfloor$ edges.

902. Let $m \geq 5$ and $n$ be given positive integers, and suppose that $\mathcal{P}$ is a regular ( $2 n+1)$ gon. Find the number of convex $m$-gons having at least one acute angle and having vertices exclusive among the vertices of $\mathcal{P}$.

903. Let $S^{1}=\{z \in \mathbb{C}|| z \mid=1\}$. For all functions $f: S^{1} \rightarrow S^{1}$ set $f^{1}=f$ and $f^{n+1}=f \circ f^{n}, n \geq 1$. Call $w \in S^{1}$ a periodic point of $f$ of period $n$ if $f^{i}(w) \neq w$ for $i=1, \ldots, n-1$ and $f^{n}(w)=w$. If $f(z)=z^{m}, m$ a positive integer, find the number of periodic points of $f$ of period 1989.

904. For positive integers $x_{1}, x_{2}, \ldots, x_{n}$ denote by $\left[x_{1}, x_{2}, \ldots, x_{n}\right]$ their least common multiple and by $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ their greatest common divisor. Prove that for positive integers $a, b, c$,

$$
\frac{[a, b, c]^{2}}{[a, b][b, c][c, a]}=\frac{(a, b, c)^{2}}{(a, b)(b, c)(c, a)} .
$$

905. A $150 \times 324 \times 375$ rectangular solid is made by gluing together $1 \times 1 \times 1$ cubes. An internal diagonal of this solid passes through the interiors of how many of the $1 \times 1 \times 1$ cubes?

\subsection{Probability}

\subsubsection{Equally Likely Cases}

In this section we consider experiments with finitely many outcomes each of which can occur with equal probability. In this case the probability of an event $A$ is given by

$$
P(A)=\frac{\text { number of favorable outcomes }}{\text { total number of possible outcomes }} .
$$

The computation of the probability is purely combinatorial; it reduces to a counting problem.

We start with the example that gave birth to probability theory. Example. Show that the probability of getting a six when a die is rolled four times is greater than the probability of getting a double six when two dice are rolled 24 times.

Here is a brief history of the problem. Chevalier de Méré, a gambler of the seventeenth century, observed while gambling that the odds of getting a six when rolling a die four times seem to be greater than $\frac{1}{2}$, while the odds of getting a double six when rolling two dice 24 times seem to be less than $\frac{1}{2}$. De Méré thought that this contradicted mathematics because $\frac{4}{6}=\frac{24}{36}$. He posed this question to B. Pascal and P. Fermat. They answered the question....and probability theory was born. Let us see the solution.

Solution. The probability that a six does not occur when rolling a die four times is $\left(\frac{5}{6}\right)^{4}$, and so the probability that a six occurs is $1-\left(\frac{5}{6}\right)^{4} \approx 0.5177$. The probability that a double six does not occur when rolling two dice 24 times is $\left(\frac{35}{36}\right)^{24}$, whence the probability that a double six occurs is $1-\left(\frac{35}{36}\right)^{24} \approx 0.4914$. The second number is smaller.

Example. Consider $n$ indistinguishable balls randomly distributed in $m$ boxes. What is the probability that exactly $k$ boxes remain empty?

Solution. Number the boxes $1,2, \ldots, m$ and let $x_{i}$ be the number of balls in the $i$ th box. The number of ways one can distribute $n$ balls in $m$ boxes is equal to the number of nonnegative integer solutions to the equation

$$
x_{1}+x_{2}+\cdots+x_{m}=n .
$$

These solutions were counted in problem 887 from Section 6.2.3 and were found to be $\left(\begin{array}{c}m+n-1 \\ m-1\end{array}\right)$. This is the total number of cases.

If we fix $k$ boxes and distribute the balls in the remaining $n-k$ boxes such that each box receives at least one ball, then the number of ways to do this is equal to the number of positive integer solutions to the equation

$$
x_{1}+x_{2}+\cdots+x_{m-k}=n .
$$

This was also computed in one of the examples from Section $6.2 .3$ and was shown to be $\left(\begin{array}{c}n-1 \\ m-k-1\end{array}\right)$. The $k$ boxes can be chosen in $\left(\begin{array}{c}m \\ k\end{array}\right)$ ways. We find the number of favorable cases to be $\left(\begin{array}{c}m \\ k\end{array}\right)\left(\begin{array}{c}n-1 \\ m-k-1\end{array}\right)$. The required probability is therefore

$$
\frac{\left(\begin{array}{c}
m \\
k
\end{array}\right)\left(\begin{array}{c}
n-1 \\
m-k-1
\end{array}\right)}{\left(\begin{array}{c}
m+n-1 \\
m-1
\end{array}\right)} \text {. }
$$

If you grab $n$ balls and place them one at a time randomly in boxes, you will find that they do not seem to fit the probabilities just calculated. This is because they are not really indistinguishable balls: the order of placement and the fact that they are macroscopic balls makes them distinguishable. However, the example above does correspond to a real world situation, namely that about particles and states. The above considerations apply to bosons, particles that obey the Bose-Einstein statistics, which allows several particles to occupy the same state. Examples of bosons are photons, gluons, and the helium- 4 atom. Electrons and protons, on the other hand, are fermions. They are subject to the Pauli exclusion principle: at most one can occupy a certain state. As such, fermions obey what is called the Fermi-Dirac statistics.

A third problem comes from C. Reischer, A. Sâmboan, Collection of Problems in Probability Theory and Mathematical Statistics (Editura Didactică şi Pedagogică, Bucharest, 1972). It shows how probabilities can be used to prove combinatorial identities.

Example. Prove the identity

$$
1+\frac{n}{m+n-1}+\cdots+\frac{n(n-1) \cdots 1}{(m+n-1)(m+n-2) \cdots m}=\frac{m+n}{m} .
$$

Solution. Consider a box containing $n$ white balls and $m$ black balls. Let $A_{i}$ be the event of extracting the first white ball at the $i$ th extraction. We compute

$$
\begin{aligned}
P\left(A_{1}\right) &=\frac{m}{m+n}, \\
P\left(A_{2}\right) &=\frac{n}{m+n} \cdot \frac{m}{m+n-1}, \\
P\left(A_{3}\right) &=\frac{n}{m+n} \cdot \frac{n-1}{m+n-1} \cdot \frac{m}{m+n-2}, \\
& \cdots \\
P\left(A_{m}\right) &=\frac{n}{m+n} \cdot \frac{n-1}{m+n-1} \cdots \frac{1}{m} .
\end{aligned}
$$

The events $A_{1}, A_{2}, A_{3}, \ldots$ are disjoint, and therefore

$$
\begin{aligned}
1 &=P\left(A_{1}\right)+P\left(A_{2}\right)+\cdots+P\left(A_{m}\right) \\
&=\frac{m}{m+n}\left[1+\frac{n}{m+n-1}+\cdots+\frac{n(n-1) \cdots 1}{(m+n-1)(m+n-2) \cdots 1}\right] .
\end{aligned}
$$

The identity follows.

Because it will be needed below, let us recall that the expected value of an experiment with possible outcomes $a_{1}, a_{2}, \ldots, a_{n}$ is the weighted mean

$$
a_{1} P\left(X=a_{1}\right)+a_{2} P\left(X=a_{2}\right)+\cdots+a_{n} P\left(X=a_{n}\right) .
$$

So let us see the problems. 

906. Let $v$ and $w$ be distinct, randomly chosen roots of the equation $z^{1997}-1=0$. Find the probability that $\sqrt{2+\sqrt{3}} \leq|v+w|$.

907. Find the probability that in a group of $n$ people there are two with the same birthday. Ignore leap years.

908. A solitaire game is played as follows. Six distinct pairs of matched tiles are placed in a bag. The player randomly draws tiles one at a time from the bag and retains them, except that matching tiles are put aside as soon as they appear in the player's hand. The game ends if the player ever holds three tiles, no two of which match; otherwise, the drawing continues until the bag is empty. Find the probability that the bag will be emptied.

909. An urn contains $n$ balls numbered $1,2, \ldots, n$. A person is told to choose a ball and then extract $m$ balls among which is the chosen one. Suppose he makes two independent extractions, where in each case he chooses the remaining $m-1$ balls at random. What is the probability that the chosen ball can be determined?

910. A bag contains 1993 red balls and 1993 black balls. We remove two balls at a time repeatedly and

(i) discard them if they are of the same color,

(ii) discard the black ball and return to the bag the red ball if they are of different colors.

What is the probability that this process will terminate with one red ball in the bag?

911. The numbers $1,2,3,4,5,6,7$, and 8 are written on the faces of a regular octahedron so that each face contains a different number. Find the probability that no two consecutive numbers are written on faces that share an edge, where 8 and 1 are considered consecutive.

912. What is the probability that a permutation of the first $n$ positive integers has the numbers 1 and 2 within the same cycle.

913. An unbiased coin is tossed $n$ times. Find a formula, in closed form, for the expected value of $|H-T|$, where $H$ is the number of heads, and $T$ is the number of tails.

914. Prove the identities

$$
\begin{aligned}
&\sum_{k=1}^{n} \frac{1}{(k-1) !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !}=1, \\
&\sum_{k=1}^{n} \frac{k}{(k-1) !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !}=2 .
\end{aligned}
$$



\subsubsection{Establishing Relations Among Probabilities}

We adopt the usual notation: $P(A)$ is the probability of the event $A, P(A \cap B)$ is the probability that $A$ and $B$ occur simultaneously, $P(A \cup B)$ is the probability that either $A$ or $B$ occurs, $P(A-B)$ is the probability that $A$ occurs but not $B$, and $P(A / B)$ is the probability that $A$ occurs given that $B$ also occurs.

Recall the classical formulas:

- addition formula:

$$
P(A \cup B)=P(A)+P(B)-P(A \cap B) ;
$$

- multiplication formula:

$$
P(A \cap B)=P(A) P(B / A)
$$

- total probability formula: if $B_{i} \cap B_{j}=\emptyset, i, j=1,2, \ldots, n$ (meaning that they are independent), and $A \subset B_{1} \cup B_{2} \cup \cdots \cup B_{n}$, then

$$
P(A)=P\left(A / B_{1}\right) P\left(B_{1}\right)+P\left(A / B_{2}\right) P\left(B_{2}\right)+\cdots+P\left(A / B_{n}\right) P\left(B_{n}\right) ;
$$

- Bayes' formula: with the same hypothesis,

$$
P\left(B_{i} / A\right)=\frac{P\left(A / B_{i}\right) P\left(B_{i}\right)}{P\left(A / B_{1}\right) P\left(B_{1}\right)+P\left(A / B_{2}\right) P\left(B_{2}\right)+\cdots+P\left(A / B_{n}\right) P\left(B_{n}\right)} .
$$

In particular, if $B_{1}, B_{2}, \ldots, B_{n}$ cover the entire probability field, then

$$
P\left(B_{i} / A\right)=\frac{P\left(B_{i}\right)}{P(A)} P\left(A / B_{i}\right) .
$$

The Bernoulli scheme. As a result of an experiment either the event $A$ occurs with probability $p$ or the contrary event $\bar{A}$ occurs with probability $q=1-p$. We repeat the experiment $n$ times. The probability that $A$ occurs exactly $m$ times is $\left(\begin{array}{c}n \\ m\end{array}\right) p^{m} q^{n-m}$. This is also called the binomial scheme because the generating function of these probabilities is $(q+p x)^{n}$.

The Poisson scheme. We perform $n$ independent experiments. For each $k, 1 \leq k \leq n$, in the $k$ th experiment the event $A$ can occur with probability $p_{k}$, or $\bar{A}$ can occur with probability $q_{k}=1-p_{k}$. The probability that $A$ occurs exactly $m$ times while the $n$ experiments are performed is the coefficient of $x^{m}$ in the expansion of

$$
\left(p_{1} x+q_{1}\right)\left(p_{2} x+q_{2}\right) \cdots\left(p_{n} x+q_{n}\right) .
$$

Here is a problem from the 1970 Romanian Mathematical Olympiad that applies the Poisson scheme. Example. In a selection test, each of three candidates receives a problem sheet with $n$ problems from algebra and geometry. The three problem sheets contain, respectively, one, two, and three algebra problems. The candidates choose randomly a problem from the sheet and answer it at the blackboard. What is the probability that

(a) all candidates answer geometry problems;

(b) all candidates answer algebra problems;

(c) at least one candidate answers an algebra problem?

Solution. We apply the Poisson scheme. Define the polynomial

$$
\begin{aligned}
P(x) &=\left(\frac{1}{n} x+\frac{n-1}{n}\right)\left(\frac{2}{n} x+\frac{n-2}{n}\right)\left(\frac{3}{n} x+\frac{n-3}{n}\right) \\
&=\frac{1}{n^{3}}\left[6 x^{3}+(11 n-18) x^{2}+\left(6 n^{2}-22 n+18\right) x+(n-1)(n-2)(n-3)\right] \\
&=P_{3} x^{3}+P_{2} x^{2}+P_{1} x+P_{0} .
\end{aligned}
$$

The answer to question (a) is the free term $P_{0}=\frac{(n-1)(n-2)(n-3)}{n^{3}}$. The answer to (b) is the coefficient of $x^{3}$, namely, $P_{3}=\frac{6}{n^{3}}$. The answer to (c) is $P=1-P_{0}=\frac{6 n^{2}-11 n+6}{n^{3}}$.

And now another problem posed to Pascal and Fermat by the Chevalier de Méré.

Example. Two players repeatedly play a game in which the first wins with probability $p$ and the second wins with probability $q=1-p$. They agree to stop when one of them wins a certain number of games. They are forced to interrupt their game when the first player has $a$ more games to win and the second player has $b$ more games to win. How should they divide the stakes correctly? Use the answer to prove the combinatorial identities

$$
\begin{aligned}
&p^{a} \sum_{k=0}^{b-1}\left(\begin{array}{c}
a-1+k \\
a-1
\end{array}\right) q^{k}+q^{b} \sum_{k=0}^{a-1}\left(\begin{array}{c}
b-1+k \\
b-1
\end{array}\right) p^{k}=1, \\
&p^{a} \sum_{k=0}^{b-1}\left(\begin{array}{c}
a-1+k \\
a-1
\end{array}\right) q^{k}=\frac{(a+b-1) !}{a !(b-1) !} p^{a} q^{b-1}\left[1+\sum_{k=1}^{b-1} \frac{(b-1) \cdots(b-k)}{(a+1) \cdots(a+k)}\left(\frac{p}{q}\right)^{k}\right] .
\end{aligned}
$$

Solution. Call $P$ the probability that the first player wins the $a$ remaining games before the second player wins the $b$ games he needs, and $Q=1-P$, the probability that the second player wins $b$ games before the first wins $a$. The players should divide the stakes in the ratio $\frac{P}{Q}$.

We proceed with the computation of $P$. The first player could have won the $a$ games in several mutually exclusive ways: in exactly $a$ games, in exactly $a+1$ games, $\ldots$, in exactly $a+b-1$ games. In all cases the last game should be won by the first player. Let us find the probability that the first player wins in exactly $a+k$ games, $k=$ $0,1, \ldots, b-1$. The probability that the first player wins $a-1$ games out of $a+k-1$ is computed using the Bernoulli scheme and is equal to $\left(\begin{array}{c}a+k-1 \\ a-1\end{array}\right) p^{a-1} q^{k}$, and the probability of winning the $(a+k)$ th is $p$. The probability of winning in exactly $a+k$ games is the product of the two, namely $\left(\begin{array}{c}a+k-1 \\ a-1\end{array}\right) p^{a} q^{k}$.

We deduce that the probability of the first player winning the stakes is

$$
P=\sum_{k=0}^{b-1}\left(\begin{array}{c}
a+k-1 \\
a-1
\end{array}\right) p^{a} q^{k},
$$

while for the second player this is

$$
Q=q^{b} \sum_{k=0}^{a-1}\left(\begin{array}{c}
b-1+k \\
b-1
\end{array}\right) p^{k} .
$$

The stakes should be divided in the ratio

$$
\frac{P}{Q}=\frac{p^{a} \sum_{k=0}^{b-1}\left(\begin{array}{c}
a-1+k \\
a-1
\end{array}\right) q^{k}}{q^{b} \sum_{k=0}^{a-1}\left(\begin{array}{c}
b-1+k \\
b-1
\end{array}\right) p^{k}} .
$$

The first combinatorial identity is equivalent to $P+Q=1$. For the second combinatorial identity, we look for a different way to compute $P$. Observe that after at most $a+b-1$ games have been played, the winner is known. Let us assume that regardless of the results, the players kept playing all the $a+b-1$ games. If the first player had won at least $a$ of these games, he would have won the stakes as well. Hence $P$ is the probability that the first player won $a, a+1, \ldots, a+b-1$ of the final $a+b-1$ games. Each of these is computed using the Bernoulli scheme, and $P$ is their sum, since the events are incompatible. We obtain

$$
\begin{aligned}
P &=\sum_{k=0}^{b-1}\left(\begin{array}{c}
a+b-1 \\
a+k
\end{array}\right) p^{a+k} q^{b-1-k} \\
&=\frac{(a+b-1) !}{a !(b-1) !} p^{a} q^{b-1}\left[1+\sum_{k=1}^{b-1} \frac{(b-1) \cdots(b-k)}{(a+1) \cdots(a+k)}\left(\frac{p}{q}\right)^{k}\right] .
\end{aligned}
$$

The second identity follows by equating the two formulas that we obtained for $P$.

This is yet another example of how probability theory can be used to prove identities. Since "wisdom is the daughter of experience"' (Leonardo da Vinci), we let you train your probabilistic skills with the following problems. 

915. An exam consists of 3 problems selected randomly from a list of $2 n$ problems, where $n$ is an integer greater than 1 . For a student to pass, he needs to solve correctly at least two of the three problems. Knowing that a certain student knows how to solve exactly half of the $2 n$ problems, find the probability that the student will pass the exam.

916. The probability that a woman has breast cancer is $1 \%$. If a woman has breast cancer, the probability is $60 \%$ that she will have a positive mammogram. However, if a woman does not have breast cancer, the mammogram might still come out positive, with a probability of $7 \%$. What is the probability for a woman with positive mammogram to actually have cancer?

917. Find the probability that in the process of repeatedly flipping a coin, one will encounter a run of 5 heads before one encounters a run of 2 tails.

918. The temperatures in Chicago and Detroit are $x^{\circ}$ and $y^{\circ}$, respectively. These temperatures are not assumed to be independent; namely, we are given the following:

(i) $P\left(x^{\circ}=70^{\circ}\right)=a$, the probability that the temperature in Chicago is $70^{\circ}$,

(ii) $P\left(y^{\circ}=70^{\circ}\right)=b$, and

(iii) $P\left(\max \left(x^{\circ}, y^{\circ}\right)=70^{\circ}\right)=c$.

Determine $P\left(\min \left(x^{\circ}, y^{\circ}\right)=70^{\circ}\right)$ in terms of $a, b$, and $c$.

919. An urn contains both black and white marbles. Each time you pick a marble you return it to the urn. Let $p$ be the probability of drawing a white marble and $q=1-p$ the probability of drawing a black marble. Marbles are drawn until $n$ black marbles have been drawn. If $n+x$ is the total number of draws, find the probability that $x=m$.

920. Three independent students took an exam. The random variable $X$, representing the students who passed, has the distribution

$$
\left(\begin{array}{cccc}
0 & 1 & 2 & 3 \\
\frac{2}{5} & \frac{13}{30} & \frac{3}{20} & \frac{1}{60}
\end{array}\right) .
$$

Find each student's probability of passing the exam.

921. Given the independent events $A_{1}, A_{2}, \ldots, A_{n}$ with probabilities $p_{1}, p_{2}, \ldots, p_{n}$, find the probability that an odd number of these events occurs.

922. Out of every batch of 100 products of a factory, 5 are quality checked. If one sample does not pass the quality check, then the whole batch of one hundred will be rejected. What is the probability that a batch is rejected if it contains $5 \%$ faulty products.

923. There are two jet planes and a propeller plane at the small regional airport of Gauss City. A plane departs from Gauss City and arrives in Eulerville, where there were already five propeller planes and one jet plane. Later, a farmer sees a jet plane flying out of Eulerville. What is the probability that the plane that arrived from Gauss City was a propeller plane, provided that all events are equiprobable?

924. A coin is tossed $n$ times. What is the probability that two heads will turn up in succession somewhere in the sequence?

925. Two people, $A$ and $B$, play a game in which the probability that $A$ wins is $p$, the probability that $B$ wins is $q$, and the probability of a draw is $r$. At the beginning, $A$ has $m$ dollars and $B$ has $n$ dollars. At the end of each game, the winner takes a dollar from the loser. If $A$ and $B$ agree to play until one of them loses all his/her money, what is the probability of $A$ winning all the money?

926. We play the coin tossing game in which if tosses match, I get both coins; if they differ, you get both. You have $m$ coins, I have $n$. What is the expected length of the game (i.e., the number of tosses until one of us is wiped out)?

\subsubsection{Geometric Probabilities}

In this section we look at experiments whose possible outcomes are parametrized by the points of a geometric region. Here we interpret "at random" to mean that the probability that a point lies in a certain region is proportional to the area or volume of the region. The probability of a certain event is then computed by taking the ratio of the area (volume) of the favorable region to the area (volume) of the total region. We start with the game of franc-carreau investigated by George-Louis Leclerc, Comte de Buffon, in his famous Essai d'arithmétique morale.

Example. A coin of diameter $d$ is thrown randomly on a floor tiled with squares of side $l$. Two players bet that the coin will land on exactly one, respectively, more than one, square. What relation should $l$ and $d$ satisfy for the game to be fair?

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-331.jpg?height=403&width=438&top_left_y=1662&top_left_x=648)

Figure 42 Solution. The center of the coin falls on some tile. For the coin to lie entirely on that tile, its center must fall inside the dotted square of side length $l-2 \cdot \frac{d}{2}=l-d$ shown in Figure 42. This happens with probability

$$
P=\frac{(l-d)^{2}}{l^{2}} .
$$

For the game to be fair, $P$ must be equal to $\frac{1}{2}$, whence the relation that $d$ and $l$ should satisfy is

$$
d=\frac{1}{2}(2-\sqrt{2}) l .
$$

Example. What is the probability that three randomly chosen points on a circle form an acute triangle?

Solution. The fact that the triangle is acute is equivalent to the fact that each of the arcs determined by the vertices is less than a semicircle.

Because of the rotational symmetry of the figure, we can assume that one of the points is fixed. Cut the circle at that point to create a segment. In this new framework, the problem asks us to find the probability that two randomly chosen points on a segment cut it in three parts, none of which is larger than half of the original segment.

Identify the segment with the interval $[0,1]$, and let the coordinates of the two points be $x$ and $y$. Then the possible choices can be identified with points $(x, y)$ randomly distributed in the interior of the square $[0,1] \times[0,1]$. The area of the total region is therefore 1 . The favorable region, namely, the set of points inside the square that yield an acute triangle, is

$$
\left\{(x, y) \mid 0<x<\frac{1}{2}, \frac{1}{2}<y<\frac{1}{2}+x\right\} \cup\left\{(x, y) \mid \frac{1}{2}<x<1, x-\frac{1}{2}<y<\frac{1}{2}\right\} .
$$

The area of this region is $\frac{1}{4}$. Hence the probability in question is $\frac{1}{4}$.

As an outcome of the solution we find that when cutting a segment into three random parts, the probability that the three segments can be the sides of an acute triangle is $\frac{1}{4}$.

927. What is the probability that the sum of two randomly chosen numbers in the interval $[0,1]$ does not exceed 1 and their product does not exceed $\frac{2}{9}$ ?

928. Let $\alpha$ and $\beta$ be given positive real numbers, with $\alpha<\beta$. If two points are selected at random from a straight line segment of length $\beta$, what is the probability that the distance between them is at least $\alpha$ ?

929. A husband and wife agree to meet at a street corner between 4 and 5 o'clock to go shopping together. The one who arrives first will await the other for 15 minutes, and then leave. What is the probability that the two meet within the given time interval, assuming that they can arrive at any time with the same probability? 

930. Two airplanes are supposed to park at the same gate of a concourse. The arrival times of the airplanes are independent and randomly distributed throughout the 24 hours of the day. What is the probability that both can park at the gate, provided that the first to arrive will stay for a period of two hours, while the second can wait behind it for a period of one hour?

931. What is the probability that three points selected at random on a circle lie on a semicircle?

932. Let $n \geq 4$ be given, and suppose that the points $P_{1}, P_{2}, \ldots, P_{n}$ are randomly chosen on a circle. Consider the convex $n$-gon whose vertices are these points. What is the probability that at least one of the vertex angles of this polygon is acute?

933. Let $C$ be the unit circle $x^{2}+y^{2}=1$. A point $p$ is chosen randomly on the circumference of $C$ and another point $q$ is chosen randomly from the interior of $C$ (these points are chosen independently and uniformly over their domains). Let $R$ be the rectangle with sides parallel to the $x$-and $y$-axes with diagonal $p q$. What is the probability that no point of $R$ lies outside of $C$ ?

934. If a needle of length 1 is dropped at random on a surface ruled with parallel lines at distance 2 apart, what is the probability that the needle will cross one of the lines?

935. Four points are chosen uniformly and independently at random in the interior of a given circle. Find the probability that they are the vertices of a convex quadrilateral. 

\section{SOLUTIONS}



\section{Methods of Proof}

1. Assume the contrary, namely that $\sqrt{2}+\sqrt{3}+\sqrt{5}=r$, where $r$ is a rational number. Square the equality $\sqrt{2}+\sqrt{3}=r-\sqrt{5}$ to obtain $5+2 \sqrt{6}=r^{2}+5-2 r \sqrt{5}$. It follows that $2 \sqrt{6}+2 r \sqrt{5}$ is itself rational. Squaring again, we find that $24+20 r^{2}+8 r \sqrt{30}$ is rational, and hence $\sqrt{30}$ is rational, too. Pythagoras' method for proving that $\sqrt{2}$ is irrational can now be applied to show that this is not true. Write $\sqrt{30}=\frac{m}{n}$ in lowest terms; then transform this into $m^{2}=30 n^{2}$. It follows that $m$ is divisible by 2 and because $2\left(\frac{m}{2}\right)^{2}=15 n^{2}$ it follows that $n$ is divisible by 2 as well. So the fraction was not in lowest terms, a contradiction. We conclude that the initial assumption was false, and therefore $\sqrt{2}+\sqrt{3}+\sqrt{5}$ is irrational.

2. Assume that such numbers do exist, and let us look at their prime factorizations. For primes $p$ greater than 7 , at most one of the numbers can be divisible by $p$, and the partition cannot exist. Thus the prime factors of the given numbers can be only $2,3,5$, and 7 .

We now look at repeated prime factors. Because the difference between two numbers divisible by 4 is at least 4 , at most three of the nine numbers are divisible by 4 . Also, at most one is divisible by 9 , at most one by 25 , and at most one by 49 . Eliminating these at most $3+1+1+1=6$ numbers, we are left with at least three numbers among the nine that do not contain repeated prime factors. They are among the divisors of $2 \cdot 3 \cdot 5 \cdot 7$, and so among the numbers

$2,3,5,6,7,10,14,15,21,30,35,42,70,105,210$.

Because the difference between the largest and the smallest of these three numbers is at most 9 , none of them can be greater than 21 . We have to look at the sequence $1,2,3, \ldots, 29$. Any subsequence of consecutive integers of length 9 that has a term greater than 10 contains a prime number greater than or equal to 11 , which is impossible. And from $1,2, \ldots, 10$ we cannot select nine consecutive numbers with the required property. This contradicts our assumption, and the problem is solved. 

3. The example $2^{2}, 3^{2}, 5^{2}, \ldots, 43^{2}$, where we considered the squares of the first 14 prime numbers, shows that $n \geq 15$.

Assume that there exist $a_{1}, a_{2}, \ldots, a_{16}$, pairwise relatively prime integers greater than 1 and less than 2005 , none of which is a prime. Let $q_{k}$ be the least prime number in the factorization of $a_{k}, k=1,2, \ldots, 16$. Let $q_{i}$ be the maximum of $q_{1}, q_{2}, \ldots, q_{15}$. Then $q_{i} \geq p_{16}=47$. Because $a_{i}$ is not a prime, $\frac{a_{i}}{q_{i}}$ is divisible by a prime number greater than or equal to $q_{i}$. Hence $a_{i} \geq q_{i}^{2}=47^{2}>2005$, a contradiction. We conclude that $n=15$.

4. Arguing by contradiction, we assume that none of the colors has the desired property. Then there exist distances $r \geq g \geq b$ such that $r$ is not attained by red points, $g$ by green points, and $b$ by blue points (for these inequalities to hold we might have to permute the colors).

Consider a sphere of radius $r$ centered at a red point. Its surface has green and blue points only. Since $g, b \leq r$, the surface of the sphere must contain both green and blue points. Choose $M$ a green point on the sphere. There exist two points $P$ and $Q$ on the sphere such that $M P=M Q=g$ and $P Q=b$. So on the one hand, either $P$ or $Q$ is green, or else $P$ and $Q$ are both blue. Then either there exist two green points at distance $g$, namely $M$ and $P$, or $Q$, or there exist two blue points at distance $b$. This contradicts the initial assumption. The conclusion follows.

(German Mathematical Olympiad, 1985)

5. Arguing by contradiction, let us assume that the area of the overlap of any two surfaces is less than $\frac{1}{9}$. In this case, if $S_{1}, S_{2}, \ldots, S_{n}$ denote the nine surfaces, then the area of $S_{1} \cup S_{2}$ is greater than $1+\frac{8}{9}$, the area of $S_{1} \cup S_{2} \cup S_{3}$ is greater than $1+\frac{8}{9}+\frac{7}{9}, \ldots$, and the area of $S_{1} \cup S_{2} \cup \cdots \cup S_{9}$ is greater than

$$
1+\frac{8}{9}+\frac{7}{9}+\cdots+\frac{1}{9}=\frac{45}{9}=5,
$$

a contradiction. Hence the conclusion.

(L. Panaitopol, D. Şerbănescu, Probleme de Teoria Numerelor şi Combinatorica pentru Juniori (Problems in Number Theory and Combinatorics for Juniors), GIL, 2003)

6. Assume that such an $f$ exists. We focus on some particular values of the variable. Let $f(0)=a$ and $f(5)=b, a, b \in\{1,2,3\}, a \neq b$. Because $|5-2|=3,|2-0|=2$, we have $f(2) \neq a, b$, so $f(2)$ is the remaining number, say $c$. Finally, because $|3-0|=3$, $|3-5|=2$, we must have $f(3)=c$. Therefore, $f(2)=f(3)$. Translating the argument to an arbitrary number $x$ instead of 0 , we obtain $f(x+2)=f(x+3)$, and so $f$ is constant. But this violates the condition from the definition. It follows that such a function does not exist.

7. Arguing by contradiction, let us assume that such a function exists. Set $f(3)=k$. Using the inequality $2^{3}<3^{2}$, we obtain 

$$
3^{3}=f(2)^{3}=f\left(2^{3}\right)<f\left(3^{2}\right)=f(3)^{2}=k^{2},
$$

hence $k>5$. Similarly, using $3^{3}<2^{5}$, we obtain

$$
k^{3}=f(3)^{3}=f\left(3^{3}\right)<f\left(2^{5}\right)=f(2)^{5}=3^{5}=243<343=7^{3} .
$$

This implies that $k<7$, and consequently $k$ can be equal only to 6 . Thus we should have $f(2)=3$ and $f(3)=6$. The monotonicity of $f$ implies that $2^{u}<3^{v}$ if and only if $3^{u}<6^{v}, u, v$ being positive integers. Taking logarithms this means that $\frac{v}{u}>\log _{2} 3$ if and only if $\frac{v}{u}>\log _{3} 6$. Since rationals are dense, it follows that $\log _{2} 3=\log _{3} 6$. This can be written as $\log _{2} 3=\frac{1}{\log _{2} 3}+1$, and so $\log _{2} 3$ is the positive solution of the quadratic equation $x^{2}-x-1=0$, which is the golden ratio $\frac{1+\sqrt{5}}{2}$. The equality

$$
2^{\frac{1+\sqrt{5}}{2}}=3
$$

translates to $2^{1+\sqrt{5}}=9$. But this would imply

$$
65536=2^{5 \times 3.2}<2^{5(1+\sqrt{5})}=9^{5}=59049 .
$$

We have reached a contradiction, which proves that the function $f$ cannot exist.

(B.J. Venkatachala, Functional Equations: A Problem Solving Approach, Prism Books PVT Ltd., Bangalore, 2002)

8. The constant function $f(x)=k$, where $k$ is a positive integer, is the only possible solution. That any such function satisfies the given condition is easy to check.

Now suppose there exists a nonconstant solution $f$. There must exist two positive integers $a$ and $b$ such that $f(a)<f(b)$. This implies that $(a+b) f(a)<a f(b)+b f(a)<$ $(a+b) f(b)$, which by the given condition is equivalent to $(a+b) f(a)<(a+b) f\left(a^{2}+\right.$ $\left.b^{2}\right)<(a+b) f(b)$. We can divide by $a+b>0$ to find that $f(a)<f\left(a^{2}+b^{2}\right)<f(b)$. Thus between any two different values of $f$ we can insert another. But this cannot go on forever, since $f$ takes only integer values. The contradiction shows that such a function cannot exist. Thus constant functions are the only solutions.

(Canadian Mathematical Olympiad, 2002)

9. Assume that $A, B$, and $a$ satisfy $A \cup B=[0,1], A \cap B=\emptyset, B=A+a$. We can assume that $a$ is positive; otherwise, we can exchange $A$ and $B$. Then $(1-a, 1] \subset B$; hence $(1-2 a, 1-a] \subset A$. An inductive argument shows that for any positive integer $n$, the interval $(1-(2 n+1) a, 1-2 n a]$ is in $B$, while the interval $(1-(2 n+2) a, 1-(2 n+1) a]$ is in $A$. However, at some point this sequence of intervals leaves $[0,1]$. The interval of the form $(1-n a, 1-(n-1) a]$ that contains 0 must be contained entirely in either $A$ or $B$, which is impossible since this inteval exits $[0,1]$. The contradiction shows that the assumption is wrong, and hence the partition does not exist.

(Austrian-Polish Mathematics Competition, 1982) 

10. Assume the contrary. Our chosen numbers $a_{1}, a_{2}, \ldots, a_{k+1}$ must have a total of at most $k$ distinct prime factors (the primes less than or equal to $n$ ). Let $o_{p}(q)$ denote the highest value of $d$ such that $p^{d} \mid q$. Also, let $a=a_{1} a_{2} \cdots a_{k+1}$ be the product of the numbers. Then for each prime $p, o_{p}(a)=\sum_{i=1}^{k+1} o_{p}\left(a_{i}\right)$, and it follows that there can be at most one hostile value of $i$ for which $o_{p}\left(a_{i}\right)>\frac{o_{p}(a)}{2}$. Because there are at most $k$ primes that divide $a$, there is some $i$ that is not hostile for any such prime. Then $2 o_{p}\left(a_{i}\right) \leq o_{p}(a)$, so $o_{p}\left(a_{i}\right) \leq o_{p}\left(\frac{a}{a_{i}}\right)$ for each prime $p$ dividing $a$. This implies that $a_{i}$ divides $\frac{a}{a_{i}}$, which contradicts the fact that the $a_{i}$ does not divide the product of the other $a_{j}$ 's. Hence our assumption was false, and the conclusion follows.

(Hungarian Mathematical Olympiad, 1999)

11. The base case $n=1$ is $\frac{1}{2}=1-\frac{1}{2}$, true. Now the inductive step. The hypothesis is that

$$
\frac{1}{k+1}+\frac{1}{k+2}+\cdots+\frac{1}{2 k}=1-\frac{1}{2}+\cdots+\frac{1}{2 k-1}-\frac{1}{2 k}
$$

We are to prove that

$$
\frac{1}{k+2}+\cdots+\frac{1}{2 k}+\frac{1}{2 k+1}+\frac{1}{2 k+2}=1-\frac{1}{2}+\cdots-\frac{1}{2 k}+\frac{1}{2 k+1}-\frac{1}{2 k+2} .
$$

Using the induction hypothesis, we can rewrite this as

$$
\begin{aligned}
&\frac{1}{k+2}+\cdots+\frac{1}{2 k}+\frac{1}{2 k+1}+\frac{1}{2 k+2} \\
&\quad=\frac{1}{k+1}+\frac{1}{k+2}+\cdots+\frac{1}{2 k}+\frac{1}{2 k+1}-\frac{1}{2 k+2},
\end{aligned}
$$

which reduces to

$$
\frac{1}{2 k+2}=\frac{1}{k+1}-\frac{1}{2 k+2},
$$

obvious. This completes the induction.

12. The base case is trivial. However, as I.M. Vinogradov once said, "it is the first nontrivial example that matters." And this is $n=2$, in which case we have

$$
|\sin 2 x|=2|\sin x||\cos x| \leq 2|\sin x| .
$$

This suggests to us to introduce cosines as factors in the proof of the inductive step. Assuming the inequality for $n=k$, we can write

$$
\begin{aligned}
|\sin (k+1) x| &=|\sin k x \cos x+\sin x \cos k x| \leq|\sin k x||\cos x|+|\sin x||\cos k x| \\
& \leq|\sin k x|+|\sin x| \leq k|\sin x|+|\sin x|=(k+1)|\sin x| .
\end{aligned}
$$

The induction is complete.

13. As in the solution to the previous problem we argue by induction on $n$ using trigonometric identities. The base case holds because

$$
\left|\sin x_{1}\right|+\left|\cos x_{1}\right| \geq \sin ^{2} x_{1}+\cos ^{2} x_{1}=1 .
$$

Next, assume that the inequality holds for $n=k$ and let us prove it for $n=k+1$. Using the inductive hypothesis, it suffices to show that

$$
\left|\sin x_{n+1}\right|+\left|\cos \left(x_{1}+x_{2}+\cdots+x_{n+1}\right)\right| \geq\left|\cos \left(x_{1}+x_{2}+\cdots+x_{n}\right)\right| .
$$

To simplify notation let $x_{n+1}=x$ and $x_{1}+x_{2}+\cdots+x_{n}+x_{n+1}=y$, so that the inequality to be proved is $|\sin x|+|\cos y| \geq|\cos (y-x)|$. The subtraction formula gives

$$
\begin{aligned}
|\cos (y-x)| &=|\cos y \cos x+\sin y \sin x| \leq|\cos y||\cos x|+|\sin y||\sin x| \\
& \leq|\cos y|+|\sin x| .
\end{aligned}
$$

This completes the inductive step, and concludes the solution.

(Revista Mathematica din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

14. We expect an inductive argument, with a possible inductive step given by

$$
3^{n+1}=3 \cdot 3^{n} \geq 3 n^{3} \geq(n+1)^{3} .
$$

In order for this to work, the inequality $3 n^{3} \geq(n+1)^{3}$ needs to be true. This inequality is equivalent to $2 n^{3} \geq 3 n^{2}+3 n+1$, which would, for example, follow from the separate inequalities $n^{3} \geq 3 n^{2}$ and $n^{3} \geq 3 n+1$. These are both true for $n \geq 3$. Thus we can argue by induction starting with the base case $n=3$, where equality holds. The cases $n=0, n=1$, and $n=2$ can be checked by hand.

15. The base case $2^{6}<6 !<3^{6}$ reduces to $64<720<729$, which is true. Assuming the double inequality true for $n$ we are to show that

$$
\left(\frac{n+1}{3}\right)^{n+1}<(n+1) !<\left(\frac{n+1}{2}\right)^{n+1} .
$$

Using the inductive hypothesis we can reduce the inequality on the left to

$$
\left(\frac{n+1}{3}\right)^{n+1}<(n+1)\left(\frac{n}{3}\right)^{n},
$$

or 

$$
\left(1+\frac{1}{n}\right)^{n}<3
$$

while the inequality on the right can be reduced to

$$
\left(1+\frac{1}{n}\right)^{n}>2
$$

These are both true for all $n \geq 1$ because the sequence $\left(1+\frac{1}{n}\right)^{n}$ is increasing and converges to $e$, which is less than 3 . Hence the conclusion.

16. The left-hand side grows with $n$, while the right-hand side stays constant, so apparently a proof by induction would fail. It works, however, if we sharpen the inequality to

$$
1+\frac{1}{2^{3}}+\frac{1}{3^{3}}+\cdots+\frac{1}{n^{3}}<\frac{3}{2}-\frac{1}{n}, \quad n \geq 2 .
$$

As such, the cases $n=1$ and $n=2$ need to be treated separately, and they are easy to check.

The base case is for $n=3: 1+\frac{1}{2^{3}}+\frac{1}{3^{3}}<1+\frac{1}{8}+\frac{1}{27}<\frac{3}{2}-\frac{1}{3}$. For the inductive step, note that from

$$
1+\frac{1}{2^{3}}+\frac{1}{3^{3}}+\cdots+\frac{1}{n^{3}}<\frac{3}{2}-\frac{1}{n}, \quad \text { for some } n \geq 3
$$

we obtain

$$
1+\frac{1}{2^{3}}+\frac{1}{3^{3}}+\cdots+\frac{1}{n^{3}}+\frac{1}{(n+1)^{3}}<\frac{3}{2}-\frac{1}{n}+\frac{1}{(n+1)^{3}} .
$$

All we need to check is

$$
\frac{3}{2}-\frac{1}{n}+\frac{1}{(n+1)^{3}}<\frac{3}{2}-\frac{1}{(n+1)},
$$

which is equivalent to

$$
\frac{1}{(n+1)^{3}}<\frac{1}{n}-\frac{1}{(n+1)},
$$

or

$$
\frac{1}{(n+1)^{3}}<\frac{1}{n(n+1)} \text {. }
$$

This is true, completing the inductive step. This proves the inequality. 

17. We prove both parts by induction on $n$. For (a), the case $n=1$ is straightforward. Assume now that we have found an $n$-digit number $m$ divisible by $2^{n}$ made out of the digits 2 and 3 only. Let $m=2^{n} k$ for some integer $k$. If $n$ is even, then

$$
2 \times 10^{n}+m=2^{n}\left(2 \cdot 5^{n}+k\right)
$$

is an $(n+1)$-digit number written only with 2's and 3's, and divisible by $2^{n+1}$. If $k$ is odd, then

$$
3 \times 10^{n}+m=2^{n}\left(3 \cdot 5^{n}+k\right)
$$

has this property.

The idea of part (b) is the same. The base case is trivial, $m=5$. Now if we have found an $n$-digit number $m=5^{n} k$ with this property, then looking modulo 5 , one of the $(n+1)$-digit numbers

$$
\begin{aligned}
&5 \times 10^{n}+m=5^{n}\left(5 \cdot 2^{n}+k\right), \\
&6 \times 10^{n}+m=5^{n}\left(6 \cdot 2^{n}+k\right), \\
&7 \times 10^{n}+m=5^{n}\left(7 \cdot 2^{n}+k\right), \\
&8 \times 10^{n}+m=5^{n}\left(8 \cdot 2^{n}+k\right), \\
&9 \times 10^{n}+m=5^{n}\left(9 \cdot 2^{n}+k\right)
\end{aligned}
$$

has the required property, and the problem is solved.

(USA Mathematical Olympiad, 2003, proposed by T. Andreescu)

18. We proceed by induction on $n$. The base case is obvious; the decomposition consists of just one piece. For the induction step, let us assume that the tiling is possible for such a $2^{n} \times 2^{n}$ board and consider a $2^{n+1} \times 2^{n+1}$ board. Start by placing a piece in the middle of the board as shown in Figure 43. The remaining surface decomposes into four $2^{n} \times 2^{n}$ boards with corner squares removed, each of which can be tiled by the induction hypothesis. Hence we are done.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-341.jpg?height=318&width=330&top_left_y=1612&top_left_x=702)

Figure 43

19. The property is clearly true for a single number. Now assume that it is true whenever we have such a sequence of length $k$ and let us prove it for a sequence of length $k+1$ : $x_{1}, x_{2}, \ldots, x_{k+1}$. Call a cyclic shift with all partial sums positive "good." With indices taken modulo $k+1$, there exist two terms $x_{j}$ and $x_{j+1}$ such that $x_{j}>0$, $x_{j+1}<0$, and $x_{j}+x_{j+1}>0$. Without loss of generality, we may assume that these terms are $x_{k}$ and $x_{k+1}$. Define a new sequence by $y_{j}=x_{j}, j \leq k-1, y_{k}=x_{k}+x_{k+1}$. By the inductive hypothesis, $y_{1}, y_{2}, \ldots, y_{k}$ has a unique good cyclic shift. Expand $y_{k}$ into $x_{k}, x_{k+1}$ to obtain a good cyclic shift of $x_{1}, x_{2}, \ldots, x_{k+1}$. This proves the existence. To prove uniqueness, note that a good cyclic shift of $x_{1}, x_{2}, \ldots, x_{k+1}$ can start only with one of $x_{1}, x_{2}, \ldots, x_{k}$ (since $x_{k+1}<0$ ). It induces a good cyclic shift of $y_{1}, y_{2}, \ldots, y_{k}$ that starts at the same term; hence two good cyclic shifts of the longer sequence would produce two good cyclic shifts of the shorter. This is ruled out by the induction hypothesis, and the uniqueness is proved.

(G. Raney)

20. We induct on $m+n$. The base case $m+n=4$ can be verified by examining the equalities

$$
1+1=1+1 \text { and } 1+2=1+2 .
$$

Now let us assume that the property is true for $m+n=k$ and prove it for $m+n=k+1$. Without loss of generality, we may assume that $x_{1}=\max _{i} x_{i}$ and $y_{1}=\max _{i} y_{i}, x_{1} \geq y_{1}$. If $m=2$, then

$$
y_{1}+y_{2}=x_{1}+x_{2}+\cdots+x_{n} \geq x_{1}+n-1 \geq y_{1}+n-1 .
$$

It follows that $y_{1}=x_{1}=n$ or $n-1, y_{2}=n-1, x_{2}=x_{3}=\cdots=x_{n}=1$. Consequently, $y_{2}=x_{2}+x_{3}+\cdots+x_{n}$, and we are done. If $m>2$, rewrite the original equality as

$$
\left(x_{1}-y_{1}\right)+x_{2}+\cdots+x_{n}=y_{2}+\cdots+y_{m} .
$$

This is an equality of the same type, with the observation that $x_{1}-y_{1}$ could be zero, in which case $x_{1}$ and $y_{1}$ are the numbers to be suppressed.

We could apply the inductive hypothesis if $y_{1} \geq n$, in which case $y_{2}+\cdots+y_{m}$ were less than $m n-y_{1}<(m-1) n$. In this situation just suppress the terms provided by the inductive hypothesis; then move $y_{1}$ back to the right-hand side.

Let us analyze the case in which this argument does not work, namely when $y_{1}<n$. Then $y_{2}+y_{3}+\cdots+y_{m} \leq(m-1) y_{1}<(m-1) n$, and again the inductive hypothesis can be applied. This completes the solution.

21. Let $f$ be the function. We will construct $g$ and $h$ such that $f=g+h$, with $g$ an odd function and $h$ a function whose graph is symmetric with respect to the point $(1,0)$.

Let $g$ be any odd function on the interval $[-1,1]$ for which $g(1)=f(1)$. Define $h(x)=f(x)-g(x), x \in[-1,1]$. Now we proceed inductively as follows. For $n \geq 1$, let $h(x)=-h(2-x)$ and $g(x)=f(x)-h(x)$ for $x \in(2 n-1,2 n+1]$, and then extend these functions such that $g(x)=-g(-x)$ and $h(x)=f(x)-g(x)$ for $x \in[-2 n-1,-2 n+1)$. It is straightforward to check that the $g$ and $h$ constructed this way satisfy the required condition.

$$
\text { (Kvant (Quantum) }
$$

22. We prove the property by induction on $n$. For $n=2$, any number of the form $n=2 t^{2}$, $t$ an integer, would work.

Let us assume that for $n=k$ there is a number $m$ with the property from the statement, and let us find a number $m^{\prime}$ that fulfills the requirement for $n=k+1$. We assume in addition that $m \geq 7$; thus we strengthen somewhat the conclusion of the problem.

We need the fact that every integer $p \geq 2$ can be represented as $a^{2}+b^{2}-c^{2}$, where $a, b, c$ are positive integers. Indeed, if $p$ is even, say $p=2 q$, then

$$
p=2 q=(3 q)^{2}+(4 q-1)^{2}-(5 q-1)^{2},
$$

while if $p$ is odd, $p=2 q+1$, then

$$
p=2 q+1=(3 q-1)^{2}+(4 q-4)^{2}-(5 q-4)^{2},
$$

if $q>1$, while if $q=1$, then $p=3=4^{2}+5^{2}-6^{2}$.

Returning to the inductive argument, let

$$
m=a_{1}^{2}+a_{2}^{2}=b_{1}^{2}+b_{2}^{2}+b_{3}^{2}=\cdots=l_{1}^{2}+l_{2}^{2}+\cdots+l_{k}^{2},
$$

and also $m=a^{2}+b^{2}-c^{2}$. Taking $m^{\prime}=m+c^{2}$ we have

$$
m^{\prime}=a^{2}+b^{2}=a_{1}^{2}+a_{2}^{2}+c^{2}=b_{1}^{2}+b_{2}+c^{2}=\cdots=l_{1}^{2}+l_{2}^{2}+\cdots+l_{k}^{2}+c^{2} .
$$

This completes the induction.

(Gazeta Matematică (Mathematics Gazette, Bucharest), 1980, proposed by M. Cavachi)

23. The property can be checked easily for small integers, which will constitute the base case. Assuming the property true for all integers less than $n$, let $F_{k}$ be the largest term of the Fibonacci sequence that does not exceed $n$. The number $n-F_{k}$ is strictly less than $n$, so by the induction hypothesis it can be written as a sum of distinct terms of the Fibonacci sequence, say $n-F_{k}=\sum_{j} F_{i_{j}}$. The assumption on the maximality of $F_{k}$ implies that $n-F_{k}<F_{k}$ (this because $F_{k+1}=F_{k}+F_{k-1}<2 F_{k}$ for $k \geq 2$ ). It follows that $F_{k} \neq F_{i j}$, for all $j$. We obtain $n=\sum_{j} F_{i_{j}}+F_{k}$, which gives a way of writing $n$ as a sum of distinct terms of the Fibonacci sequence.

24. We will prove a more general identity, namely,

$$
F_{m+n+1}=F_{m+1} F_{n+1}+F_{m} F_{n}, \quad \text { for } m, n \geq 0 .
$$

We do so by induction on $n$. The inductive argument will assume the property to be true for $n=k-1$ and $n=k$, and prove it for $n=k+1$. Thus the base case consists of $n=0, F_{m+1}=F_{m+1}$; and $n=1, F_{m+2}=F_{m+1}+F_{m}$-both of which are true.

Assuming that $F_{m+k}=F_{m+1} F_{k}+F_{m} F_{k-1}$ and $F_{m+k+1}=F_{m+1} F_{k+1}+F_{m} F_{k}$, we obtain by addition,

$$
F_{m+k}+F_{m+k+1}=F_{m+1}\left(F_{k}+F_{k+1}\right)+F_{m}\left(F_{k-1}+F_{k}\right),
$$

which is, in fact, the same as $F_{m+k+2}=F_{m+1} F_{k+2}+F_{m} F_{k+1}$. This completes the induction. For $m=n$, we obtain the identity in the statement.

25. Inspired by the previous problem, we generalize the identity to

$$
F_{m+n+p}=F_{m+1} F_{n+1} F_{p+1}+F_{m} F_{n} F_{p}-F_{m-1} F_{n-1} F_{p-1},
$$

which should hold for $m, n, p \geq 1$. In fact, we can augment the Fibonacci sequence by $F_{-1}=1$ (so that the recurrence relation still holds), and then the above formula makes sense for $m, n, p \geq 0$. We prove it by induction on $p$. Again for the base case we consider $p=0$, with the corresponding identity

$$
F_{m+n}=F_{m+1} F_{n+1}-F_{m-1} F_{n-1},
$$

and $p=1$, with the corresponding identity

$$
F_{m+n+1}=F_{m+1} F_{n+1}+F_{m} F_{n} .
$$

Of the two, the second was proved in the solution to the previous problem. And the first identity is just a consequence of the second, obtained by subtracting $F_{m+n-1}=$ $F_{m} F_{n}+F_{m-1} F_{n-1}$ from $F_{m+n+1}=F_{m+1} F_{n+1}+F_{m} F_{n}$. So the base case is verified. Now we assume that the identity holds for $p=k-1$ and $p=k$, and prove it for $p=k+1$. Indeed, adding

$$
F_{m+n+k-1}=F_{m+1} F_{n+1} F_{k}+F_{m} F_{n} F_{k-1}-F_{m-1} F_{n-1} F_{k-2}
$$

and

$$
F_{m+n+k}=F_{m+1} F_{n+1} F_{k+1}+F_{m} F_{n} F_{k}-F_{m-1} F_{n-1} F_{k-1},
$$

we obtain

$$
\begin{aligned}
F_{m+n+k+1} &=F_{m+n+k-1}+F_{m+n+k} \\
&=F_{m+1} F_{n+1}\left(F_{k}+F_{k+1}\right)+F_{m} F_{n}\left(F_{k-1}+F_{k}\right)-F_{m-1} F_{n-1}\left(F_{k-2}+F_{k-1}\right) \\
&=F_{m+1} F_{n+1} F_{k+2}+F_{m} F_{n} F_{k+1}-F_{m-1} F_{n-1} F_{k} .
\end{aligned}
$$


![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-345.jpg?height=140&width=1268&top_left_y=251&top_left_x=234)

Figure 44

This proves the identity. Setting $m=n=p$, we obtain the identity in the statement.

26. The base case consists of the dissections for $n=4,5$, and 6 shown in Figure 44. The induction step jumps from $P(k)$ to $P(k+3)$ by dissecting one of the triangles into four triangles similar to it.

\section{(R. Gelca)}

27. First, we explain the inductive step, which is represented schematically in Figure 45 . If we assume that such a $k$-gon exists for all $k<n$, then the $n$-gon can be obtained by cutting off two vertices of the ( $n-2)$-gon by two parallel lines. The sum of the distances from an interior point to the two parallel sides does not change while the point varies, and of course the sum of distances to the remaining sides is constant by the induction hypothesis. Choosing the parallel sides unequal, we can guarantee that the resulting polygon is not regular.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-345.jpg?height=329&width=605&top_left_y=1161&top_left_x=569)

Figure 45

The base case consists of a rectangle $(n=4)$ and an equilateral triangle with two vertices cut off by parallel lines $(n=5)$. Note that to obtain the base case we had to apply the idea behind the inductive step.

28. The property is obviously true for the triangle since there is nothing to dissect. This will be our base case. Let us assume that the property is true for any coloring of a $k$-gon, for all $k<n$, and let us prove that it is true for an arbitrary coloring of an $n$-gon. Because at least three colors were used, there is a diagonal whose endpoints have different colors, say red $(r)$ and blue $(b)$. If on both sides of the diagonal a third color appears, then we can apply the induction hypothesis to two polygons and solve the problem.

If this is not the case, then on one side there will be a polygon with an even number of sides and with vertices colored in cyclic order $r b r b \ldots r b$. Pick a blue point among them that is not an endpoint of the initially chosen diagonal and connect it to a vertex colored by a third color (Figure 46). The new diagonal dissects the polygon into two polygons satisfying the property from the statement, and having fewer sides. The induction hypothesis can be applied again, solving the problem.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-346.jpg?height=426&width=494&top_left_y=433&top_left_x=625)

Figure 46

29. We prove the property by induction on the number of vertices. The base case is the triangle, where there is nothing to prove.

Let us assume now that the property holds for polygons with fewer than $n$ vertices and prove it for a polygon with $n$ vertices. The inductive step consists in finding one interior diagonal.

We commence with an interior angle less than $\pi$ (which does exist because the sum of all $n$ angles is $(n-2) \pi)$. Let the polygon be $A_{1} A_{2} \ldots A_{n}$, with $\angle A_{n} A_{1} A_{2}$ the chosen interior angle. Rotate the ray $\mid A_{1} A_{n}$ toward $\mid A_{1} A_{2}$ continuously inside the angle as shown in Figure 47. For each position of the ray, strictly between $A_{1} A_{n}$ and $A_{1} A_{2}$, consider the point on the polygon that is the closest to $A_{1}$. If for some position of the ray this point is a vertex, then we have obtained a diagonal that divides the polygon into two polygons with fewer sides. Otherwise, $A_{2} A_{n}$ is the diagonal.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-346.jpg?height=371&width=436&top_left_y=1556&top_left_x=649)

Figure 47

Dividing by the interior diagonal, we obtain two polygons with fewer vertices, which by hypothesis can be divided into triangles. This completes the induction.

30. We induct on the number to be represented. For the base case, we have 

$$
\begin{aligned}
&1=1^{2}, \\
&2=-1^{2}-2^{2}-3^{2}+4^{2}, \\
&3=-1^{2}+2^{2} \\
&4=-1^{2}-2^{2}+3^{2} .
\end{aligned}
$$

The inductive step is " $P(n)$ implies $P(n+4)$ "; it is based on the identity

$$
m^{2}-(m+1)^{2}-(m+2)^{2}+(m+3)^{2}=4 .
$$

Remark. This result has been generalized by J. Mitek, who proved that every integer $k$ can be represented in the form $k=\pm 1^{s} \pm 2^{s} \pm \cdots \pm m^{s}$ for a suitable choice of signs, where $s$ is a given integer $\geq 2$. The number of such representations is infinite.

(P. Erdős, J. Surányi)

31. First, we show by induction on $k$ that the identity holds for $n=2^{k}$. The base case is contained in the statement of the problem. Assume that the property is true for $n=2^{k}$ and let us prove it for $n=2^{k+1}$. We have

$$
\begin{aligned}
f\left(\frac{x_{1}+\cdots+x_{2^{k}}+x_{2^{k}+1}+\cdots+x_{2^{k+1}}}{2^{k+1}}\right) &=\frac{f\left(\frac{x_{1}+\cdots+x_{2^{k}}}{2^{k}}\right)+f\left(\frac{x_{2^{k}+1}+\cdots+x_{2^{k+1}}}{2^{k}}\right)}{2} \\
=& \frac{\frac{f\left(x_{1}\right)+\cdots+f\left(x_{2^{k}}\right)}{2^{k}}+\frac{f\left(x_{2^{k}+1}\right)+\cdots+f\left(x_{2^{k+1}}\right)}{2^{k}}}{2} \\
=& \frac{f\left(x_{1}\right)+\cdots+f\left(x_{2^{k}}\right)+f\left(x_{2^{k}+1}\right)+\cdots+f\left(x_{2^{k+1}}\right)}{2^{k+1}},
\end{aligned}
$$

which completes the induction. Now we work backward, showing that if the identity holds for some $n$, then it holds for $n-1$ as well. Consider the numbers $x_{1}, x_{2}, \ldots, x_{n-1}$ and $x_{n}=\frac{x_{1}+x_{2}+\cdots+x_{n-1}}{n-1}$. Using the hypothesis, we have

$$
f\left(\frac{x_{1}+\cdots+x_{n-1}+\frac{x_{1}+\cdots+x_{n-1}}{n-1}}{n}\right)=\frac{f\left(x_{1}\right)+\cdots+f\left(x_{n-1}\right)+f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right)}{n},
$$

which is the same as

$$
f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right)=\frac{f\left(x_{1}\right)+\cdots+f\left(x_{n-1}\right)}{n}+\frac{1}{n} f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right) .
$$

Moving the last term on the right to the other side gives

$$
\frac{n-1}{n} f\left(\frac{x_{1}+x_{2}+\cdots+x_{n-1}}{n-1}\right)=\frac{f\left(x_{1}\right)+f\left(x_{2}\right)+\cdots+f\left(x_{n-1}\right)}{n} .
$$

This is clearly the same as

$$
f\left(\frac{x_{1}+x_{2}+\cdots+x_{n-1}}{n-1}\right)=\frac{f\left(x_{1}\right)+x_{2}+\cdots+f\left(x_{n-1}\right)}{n-1},
$$

and the argument is complete.

32. This is a stronger form of the inequality discussed in the beginning, which can be obtained from it by applying the AM-GM inequality.

We first prove that the property holds for $n$ a power of 2 . The base case

$$
\left(1+a_{1}\right)\left(1+a_{2}\right) \geq\left(1+\sqrt{a_{1} a_{2}}\right)^{2}
$$

reduces to the obvious $a_{1}+a_{2} \geq 2 \sqrt{a_{1} a_{2}}$.

If

$$
\left(1+a_{1}\right)\left(1+a_{2}\right) \cdots\left(1+a_{2^{k}}\right) \geq\left(1+\sqrt[2^{k}]{a_{1} a_{2} \cdots a_{2^{k}}}\right)^{2^{k}}
$$

for every choice of nonnegative numbers, then

$$
\begin{aligned}
\left(1+a_{1}\right) \cdots\left(1+a_{2^{k+1}}\right) &=\left(1+a_{1}\right) \cdots\left(1+a_{2^{k}}\right)\left(1+a_{2^{k}+1}\right) \cdots\left(1+a_{2^{k+1}}\right) \\
& \geq\left(1+\sqrt[2^{k}]{a_{1} \cdots a_{2^{k}}}\right)^{2^{k}}\left(1+\sqrt[2^{k}]{a_{2^{k}+1} \cdots a_{2^{k+1}}}\right)^{2^{k}} \\
& \geq\left[\left(1+\sqrt{2^{k}} \sqrt{a_{1} \cdots a_{2^{k}}} \sqrt[2^{k}]{a_{2^{k}+1} \cdots a_{2^{k+1}}}\right)^{2^{k}}\right.\\
&=\left(1+\sqrt[2^{k+1}]{a_{1} \cdots a_{2^{k+1}}}\right)^{2^{k+1}} .
\end{aligned}
$$

This completes the induction.

Now we work backward. If the inequality holds for $n+1$ numbers, then choosing $a_{n+1}=\sqrt[n]{a_{1} a_{2} \cdots a_{n}}$, we can write

$$
\left(1+a_{1}\right) \cdots\left(1+a_{n}\right)\left(1+\sqrt[n]{a_{1} \cdots a_{n}}\right) \geq\left(1+\sqrt[n+1]{a_{1} \cdots a_{n} \sqrt[n]{a_{1} \cdots a_{n}}}\right)^{n+1},
$$

which is the same as

$$
\left(1+a_{1}\right) \cdots\left(1+a_{n}\right)\left(1+\sqrt[n]{a_{1} \cdots a_{n}}\right) \geq\left(1+\sqrt[n]{a_{1} \cdots a_{n}}\right)^{n+1} .
$$

Canceling the common factor, we obtain the inequality for $n$ numbers. The inequality is proved.

33. The "pigeons" are the numbers. The "holes" are the 49 sets

$$
\{1,98\},\{2,97\}, \ldots,\{49,50\} \text {. }
$$

Two of the numbers fall in the same set; their sum is equal to 99 . We are done.

34. As G. Pólya said, "a trick applied twice becomes a technique." Here we repeat the idea of the Mongolian problem from the 26th International Mathematical Olympiad.

Let $b_{1}, b_{2}, \ldots, b_{m}$ be the sequence, where $b_{i} \in\left\{a_{1}, a_{2}, \ldots, a_{n}\right\}, 1 \leq i \leq m$. For each $j \leq m$ define the $n$-tuple $K_{j}=\left(k_{1}, k_{2}, \ldots, k_{n}\right)$, where $k_{i}=0$ if $a_{i}$ appears an even number of times in $b_{1}, b_{2}, \ldots, b_{j}$ and $k_{i}=1$ otherwise.

If there exists $j \leq m$ such that $K_{j}=(0,0, \ldots, 0)$ then $b_{1} b_{2} \cdots b_{j}$ is a perfect square and we are done. Otherwise, there exist $j<l$ such that $K_{j}=K_{l}$. Then in the sequence $b_{j+1}, b_{j+2}, \ldots, b_{l}$ each $a_{i}$ appears an even number of times. The product $b_{j+1} b_{j+2} \cdots b_{l}$ is a perfect square.

35. The sequence has the property that for any $n$ the first $n+1$ terms are less than or equal to $2 n$. The problem would be solved if we showed that given a positive integer $n$, from any $n+1$ distinct integer numbers between 1 and $2 n$ we can choose two whose difference is $n$. This is true, indeed, since the pigeonhole principle implies that one of the $n$ pairs $(1, n+1),(2, n+2), \ldots,(n, 2 n)$ contains two terms of the sequence.

(Austrian-Polish Mathematics Competition, 1980)

36. The "holes" will be the residue classes, and the pigeons, the numbers $a x^{2}, c-b y^{2}$, $x, y=0,1, \ldots, p-1$. There are $2 p$ such numbers. Any residue class, except for 0 , can have at most two elements of the form $a x^{2}$ and at most two elements of the form $c-b y^{2}$ from the ones listed above. Indeed, $a x_{1}^{2} \equiv a x_{2}^{2}$ implies $x_{1}^{2} \equiv x_{2}^{2}$, so $\left(x_{1}-x_{2}\right)\left(x_{1}+x_{2}\right) \equiv 0$. This can happen only if $x_{1}=\pm x_{2}$. Also, $a x^{2} \equiv 0$ only when $x=0$.

We distinguish two cases. If $c-b y_{0}^{2} \equiv 0$ for some $y_{0}$, then $\left(0, y_{0}\right)$ is a solution. Otherwise, the $2 p-1$ numbers $a x^{2}, c-b y^{2}, x=1,2, \ldots, p-1, y=0,1, \ldots, p-1$ are distributed into $p-1$ "holes," namely the residue classes $1,2, \ldots, p-1$. Three of them must lie in the same residue class, so there exist $x_{0}$ and $y_{0}$ with $a x_{0}^{2} \equiv c-b y_{0}^{2}(\bmod p)$. The pair $\left(x_{0}, y_{0}\right)$ is a solution to the equation from the statement.

Remark. A more advanced solution can be produced based on the theory of quadratic residues.

37. In any $2 \times 2$ square, only one of the four numbers can be divisible by 2 , and only one can be divisible by 3 . Tiling the board by $2 \times 2$ squares, we deduce that at most 25 numbers are divisible by 2 and at most 25 numbers are divisible by 3 . There are at least 50 remaining numbers that are not divisible by 2 or 3 , and thus must equal one of the numbers 1,5 , or 7 . By the pigeonhole principle, one of these numbers appears at least 17 times.

(St. Petersburg City Mathematical Olympiad, 2001)

38. A more general property is true, namely that for any positive integer $n$ there exist infinitely many terms of the Fibonacci sequence divisible by $n$. We apply now the pigeonhole principle, letting the "objects" be all pairs of consecutive Fibonacci numbers $\left(F_{n}, F_{n+1}\right), n \geq 1$, and the "boxes" the pairs of residue classes modulo $n$. There are infinitely many objects, and only $n^{2}$ boxes, and so there exist indices $i>j>1$ such that $F_{i} \equiv F_{j}(\bmod n)$ and $F_{i+i} \equiv F_{j+1}(\bmod n)$.

In this case

$$
F_{i-1}=F_{i+1}-F_{i} \equiv F_{j+1}-F_{j}=F_{j-1}(\bmod n),
$$

and hence $F_{i-1} \equiv F_{j-1}(\bmod n)$ as well. An inductive argument proves that $F_{i-k} \equiv$ $F_{j-k}(\bmod n), k=1,2, \ldots, j$. In particular, $F_{i-j} \equiv F_{0}=0(\bmod n)$. This means that $F_{i-j}$ is divisible by $n$. Moreover, the indices $i$ and $j$ range in an infinite family, so the difference $i-j$ can assume infinitely many values. This proves our claim, and as a particular case, we obtain the conclusion of the problem.

(Irish Mathematical Olympiad, 1999)

39. We are allowed by the recurrence relation to set $x_{0}=0$. We will prove that there is an index $k \leq m^{3}$ such that $x_{k}$ divides $m$. Let $r_{t}$ be the remainder obtained by dividing $x_{t}$ by $m$ for $t=0,1, \ldots, m^{3}+2$. Consider the triples $\left(r_{0}, r_{1}, r_{2}\right),\left(r_{1}, r_{2}, r_{3}\right), \ldots$, $\left(r_{m^{3}}, r_{m^{3}+1}, r_{m^{3}+2}\right)$. Since $r_{t}$ can take $m$ values, the pigeonhole principle implies that at least two triples are equal. Let $p$ be the smallest number such that the triple $\left(r_{p}, r_{p+1}, r_{p+2}\right)$ is equal to another triple $\left(r_{q}, r_{q+1}, r_{q+2}\right), p<q \leq m^{3}$. We claim that $p=0$.

Assume by way of contradiction that $p \geq 1$. Using the hypothesis, we have

$$
r_{p+2} \equiv r_{p-1}+r_{p} r_{p+1}(\bmod m) \quad \text { and } \quad r_{q+2} \equiv r_{q-1}+r_{q} r_{q+1}(\bmod m) .
$$

Because $r_{p}=r_{q}, r_{p+1}=r_{q+1}$, and $r_{p+2}=r_{q+2}$, it follows that $r_{p-1}=r_{q-1}$, so $\left(r_{p-1}, r_{p}, r_{p+1}\right)=\left(r_{q-1}, r_{q}, r_{q+1}\right)$, contradicting the minimality of $p$. Hence $p=0$, so $r_{q}=r_{0}=0$, and therefore $x_{q}$ is divisible by $m$.

$$
\text { (T. Andreescu, D. Miheţ) }
$$

40. We focus on 77 consecutive days, starting on a Monday. Denote by $a_{n}$ the number of games played during the first $n$ days, $n \geq 1$. We consider the sequence of positive integers

$$
a_{1}, a_{2}, \ldots, a_{77}, a_{1}+20, a_{2}+20, \ldots, a_{77}+20 \text {. }
$$

Altogether there are $2 \times 77=154$ terms not exceeding $11 \times 12+20=152$ (here we took into account the fact that during each of the 11 weeks there were at most 12 games). The pigeonhole principle implies right away that two of the above numbers are equal. They cannot both be among the first 77 , because by hypothesis, the number of games increases by at least 1 each day. For the same reason the numbers cannot both be among the last 77. Hence there are two indices $k$ and $m$ such that $a_{m}=a_{k}+20$. This implies that in the time interval starting with the $(k+1)$ st day and ending with the $n$th day, exactly 20 games were played, proving the conclusion. Remark. In general, if a chess player decides to play $d$ consecutive days, playing at least one game a day and a total of no more than $m$ with $d<m<2 d$, then for each $i \leq 2 d-n-1$ there is a succession of days on which, in total, the chess player played exactly $i$ games.

(D.O. Shklyarskyi, N.N. Chentsov, I.M. Yaglom, Izbrannye Zadachi i Theoremy Elementarnoy Matematiki (Selected Problems and Theorems in Elementary Mathematics), Nauka, Moscow, 1976)

41. The solution combines the induction and pigeonhole principles. We commence with induction. The base case $m=1$ is an easy check, the numbers can be only $-1,0,1$.

Assume now that the property is true for any $2 m-1$ numbers of absolute value not exceeding $2 m-3$. Let $A$ be a set of $2 m+1$ numbers of absolute value at most $2 m-1$. If $A$ contains $2 m-1$ numbers of absolute value at most $2 m-3$, then we are done by the induction hypothesis. Otherwise, $A$ must contain three of the numbers $\pm(2 m-1), \pm(2 m-2)$. By eventually changing signs we distinguish two cases.

Case I. $2 m-1,-2 m+1 \in A$. Pair the numbers from 1 through $2 m-2$ as $(1,2 m-$ $2),(2,2 m-3), \ldots,(m-1, m)$, so that the sum of each pair is equal to $2 m-$ 1 , and the numbers from 0 through $-2 m+1$ as $(0,-2 m+1),(-1,-2 m+$ $2), \ldots,(-m+1,-m)$, so that the sum of each pair is $-2 m+1$. There are $2 m-1$ pairs, and $2 m$ elements of $A$ lie in them, so by the pigeonhole principle there exists a pair with both elements in $A$. Those elements combined with either $2 m-1$ or $-2 m+1$ give a triple whose sum is equal to zero.

Case II. $2 m-1,2 m-2,-2 m+2 \in A$ and $-2 m+1 \notin A$. If $0 \in A$, then $0-2 m+$ $2+2 m-2=0$ and we are done. Otherwise, consider the pairs $(1,2 m-$ $3),(2,2 m-4), \ldots,(m-2, m)$, each summing up to $2 m-2$, and the pairs $(1,-2 m), \ldots,(-m+1,-m)$, each summing up to $-2 m+1$. Altogether there are $2 m-2$ pairs containing $2 m-1$ elements from $A$, so both elements of some pair must be in $A$. Those two elements combined with either $-2 m+2$ or $2 m-1$ give a triple with the sum equal to zero. This concludes the solution.

\section{(Kvant (Quantum)}

42. Denote by $\Delta$ the set of ordered triples of people $(a, b, c)$ such that $c$ is either a common acquaintance of both $a$ and $b$ or unknown to both $a$ and $b$. If $c$ knows exactly $k$ participants, then there exist exactly $2 k(n-1-k)$ ordered pairs in which $c$ knows exactly one of $a$ and $b$ (the factor 2 shows up because we work with ordered pairs). There will be

$$
(n-1)(n-2)-2 k(n-1-k) \geq(n-1)(n-2)-2\left(\frac{n-1}{2}\right)^{2}=\frac{(n-1)(n-3)}{2}
$$

ordered pairs $(a, b)$ such that $c$ knows either both or neither of $a$ and $b$. Counting by the $c$ 's, we find that the number of elements of $\Delta$ satisfies 

$$
|\Delta| \geq \frac{n(n-1)(n-3)}{2} .
$$

To apply the pigeonhole principle, we let the "holes" be the ordered pairs of people $(a, b)$, and the "pigeons"' be the triples $(a, b, c) \in \Delta$. Put the pigeon $(a, b, c)$ in the hole $(a, b)$ if $c$ knows either both or neither of $a$ and $b$. There are $\frac{n(n-1)(n-3)}{2}$ pigeons distributed in $n(n-1)$ holes. So there will be at least

$$
\left\lceil\frac{n(n-1)(n-3)}{2} / n(n-1)\right]=\left\lfloor\frac{n}{2}\right\rfloor-1
$$

pigeons in one hole, where $\lceil x\rceil$ denotes the least integer greater than or equal to $x$. To the "hole" corresponds a pair of people satisfying the required condition.

(USA Mathematical Olympiad, 1985)

43. The beautiful observation is that if the sequence $a_{n}=\cos \left(n \pi x_{1}\right)+\cos \left(n \pi x_{2}\right)+\cdots+$ $\cos \left(n \pi x_{k}\right), n \geq 1$, assumes finitely many distinct values, then so does the sequence of $k$-tuples $u_{n}=\left(a_{n}, a_{2 n}, \ldots, a_{k n}\right), n \geq 1$. By the pigeonhole principle there exist $m<n$ such that $a_{n}=a_{m}, a_{2 n}=a_{2 m}, \ldots, a_{k n}=a_{k m}$. Let us take a closer look at these relations. We know that $\cos (n x)$ is a polynomial of degree $n$ with integer coefficients in $\cos (x)$, namely the Chebyshev polynomial. If $A_{i}=\cos \left(n \pi x_{i}\right)$ and $B_{i}=\cos \left(m \pi x_{i}\right)$, then the previous relations combined with this observation show that $A_{1}^{j}+A_{2}^{j}+\cdots+A_{k}^{j}=$ $B_{1}^{j}+B_{2}^{j}+\cdots+B_{k}^{j}$ for all $j=1,2, \ldots, k$. Using Newton's formulas, we deduce that the polynomials having the zeros $A_{1}, A_{2}, \ldots, A_{k}$, respectively, $B_{1}, B_{2}, \ldots, B_{k}$ are equal (they have equal coefficients). Hence there is a permutation $\sigma$ of $1,2, \ldots, n$ such that $A_{i}=B_{\sigma(i)}$. Thus $\cos \left(n \pi x_{i}\right)=\cos \left(m \pi x_{\sigma(i)}\right)$, which means that $n x_{i}-m x_{\sigma(i)}$ is a rational number $r_{i}$ for $1 \leq i \leq k$. We want to show that the $x_{i}$ 's are themselves rational. If $\sigma(i)=i$, this is obvious. On the other hand, if we consider a cycle of $\sigma,\left(i_{1} i_{2} i_{3} \ldots i_{s}\right)$, we obtain the linear system

$$
\begin{gathered}
m x_{i_{1}}-n x_{i_{2}}=r_{i_{1}}, \\
m x_{i_{2}}-n x_{i_{3}}=r_{i_{2}}, \\
\cdots \\
m x_{i_{s}}-n x_{i_{1}}=r_{i_{s}} .
\end{gathered}
$$

It is not hard to compute the determinant of the coefficient matrix, which is $n^{s}-m^{s}$ (for example, by expanding by the first row, then by the first column, and then noting that the new determinants are triangular). The determinant is nonzero; hence the system has a unique solution. By applying Cramer's rule we determine that this solution consists of rational numbers. We conclude that the $x_{i}$ 's are all rational, and the problem is solved.

\section{(V. Pop)}

44. Place the circle at the origin of the coordinate plane and consider the rectangular grid determined by points of integer coordinates, as shown in Figure 48. The circle is inscribed in an $8 \times 8$ square decomposed into 64 unit squares. Because $3^{2}+3^{2}>4^{2}$, the four unit squares at the corners lie ouside the circle. The interior of the circle is therefore covered by 60 squares, which are our "holes."' The 61 points are the "pigeons," and by the pigeonhole principle two lie inside the same square. The distance between them does not exceed the length of the diagonal, which is $\sqrt{2}$. The problem is solved.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-353.jpg?height=520&width=456&top_left_y=526&top_left_x=644)

Figure 48

45. If $r=1$, all lines pass through the center of the square. If $r \neq 1$, a line that divides the square into two quadrilaterals with the ratio of their areas equal to $r$ has to pass through the midpoint of one of the four segments described in Figure 49 (in that figure the endpoints of the segments divide the sides of the square in the ratio $r$ ). Since there are four midpoints and nine lines, by the pigeonhole principle three of them have to pass through the same point.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-353.jpg?height=351&width=350&top_left_y=1496&top_left_x=697)

Figure 49

46. Choose a face with maximal number of edges, and let $n$ be this number. The number of edges of each of the $n$ adjacent faces ranges between 3 and $n$, so by the pigeonhole principle, two of these faces have the same number of edges.

(Moscow Mathematical Olympiad) 

47. An $n$-gon has $\left(\begin{array}{l}n \\ 2\end{array}\right)-n=\frac{1}{2} n(n-3)$ diagonals. For $n=21$ this number is equal to 189. If through a point in the plane we draw parallels to these diagonals, $2 \times 189=378$ adjacent angles are formed. The angles sum up to $360^{\circ}$, and thus one of them must be less than $1^{\circ}$.

48. The geometric aspect of the problem is only apparent. If we number the vertices of the polygon counterclockwise $1,2, \ldots, 2 n$, then $P_{1}, P_{2}, \ldots, P_{2 n}$ is just a permutation of these numbers. We regard indices modulo $2 n$. Then $P_{i} P_{i+1}$ is parallel to $P_{j} P_{j+1}$ if and only if $P_{i}-P_{j} \equiv P_{j+1}-P_{i+1}(\bmod 2 n)$, that is, if and only if $P_{i}+P_{i+1} \equiv P_{j}+P_{j+1}(\bmod 2 n)$. Because

$$
\sum_{i=1}^{2 n}\left(P_{i}+P_{i+1}\right) \equiv 2 \sum_{i=1}^{2 n} P_{i} \equiv 2 n(2 n-1) \equiv 0(\bmod 2 n)
$$

and

$$
\sum_{i=1}^{2 n} i=n(2 n-1) \equiv n(\bmod 2 n),
$$

it follows that $P_{i}+P_{i+1}, i=1,2, \ldots, 2 n$, do not exhaust all residues modulo $2 n$. By the pigeonhole principle there exist $i \neq j$ such that $P_{i}+P_{i+1} \equiv P_{j}+P_{j+1}(\bmod 2 n)$. Consequently, the sides $P_{i} P_{i+1}$ and $P_{j} P_{j+1}$ are parallel, and the problem is solved.

(German Mathematical Olympiad, 1976)

49. Let $C$ be a circle inside the triangle formed by three noncollinear points in $S$. Then $C$ is contained entirely in $S$. Set $m=n p+1$ and consider a regular polygon $A_{1} A_{2} \ldots A_{m}$ inscribed in $C$. By the pigeonhole principle, some $n$ of its vertices are colored by the same color. We have thus found a monochromatic $n$-gon. Now choose $\alpha$ an irrational multiple of $\pi$. The rotations of $A_{1} A_{2} \cdots A_{m}$ by $k \alpha, k=0,1,2, \ldots$, are all disjoint. Each of them contains an $n$-gon with vertices colored by $n$ colors. Only finitely many incongruent $n$-gons can be formed with the vertices of $A_{1} A_{2} \cdots A_{m}$. So again by the pigeonhole principle, infinitely many of the monochromatic $n$-gons are congruent. Of course, they might have different colors. But the pigeonhole principle implies that one color occurs infinitely many times. Hence the conclusion.

(Romanian Mathematical Olympiad, 1995)

50. This is an example in Ramsey theory (see Section 6.1.5) that applies the pigeonhole principle. Pick two infinite families of lines, $\left\{A_{i}, i \geq 1\right\}$, and $\left\{B_{j}, j \geq 1\right\}$, such that for any $i$ and $j, A_{i}$ and $B_{j}$ are orthogonal. Denote by $M_{i j}$ the point of intersection of $A_{i}$ and $B_{j}$. By the pigeonhole principle, infinitely many of the $M_{1 j}$ 's, $j \geq 1$, have the same color. Keep only the lines $B_{j}$ corresponding to these points, and delete all the others. So again we have two families of lines, but such that $M_{1 j}$ are all of the same color; call this color $c_{1}$. Next, look at the line $A_{2}$. Either there is a rectangle of color $c_{1}$, or at most one point $M_{2 j}$ is colored by $c_{1}$. Again by the pigeonhole principle, there is a color $c_{2}$ that occurs infinitely many times among the $M_{2 j}$ 's. We repeat the reasoning. Either at some step we encounter a rectangle, or after finitely many steps we exhaust the colors, with infinitely many lines $A_{i}$ still left to be colored. The impossibility to continue rules out this situation, proving the existence of a rectangle with vertices of the same color.

Here is another solution. Consider a $(p+1) \times\left(n\left(\begin{array}{c}p+1 \\ 2\end{array}\right)+1\right)$ rectangular grid. By the pigeonhole principle, each of the $n\left(\begin{array}{c}p+1 \\ 2\end{array}\right)+1$ horizontal segments contains two points of the same color. Since there are at most $n\left(\begin{array}{c}p+1 \\ 2\end{array}\right)$ possible configurations of such monochromatic pairs, two must repeat. The two pairs are the vertices of a monochromatic rectangle.

51. We place the unit square in standard position. The "boxes" are the vertical lines crossing the square, while the "objects" are the horizontal diameters of the circles (Figure 50). Both the boxes and the objects come in an infinite number, but what we use for counting is length on the horizontal. The sum of the diameters is

$$
\frac{10}{\pi}=3 \times 1+\epsilon, \quad \epsilon>0 .
$$

Consequently, there is a segment on the lower side of the square covered by at least four diameters. Any vertical line passing through this segment intersects the four corresponding circles.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-355.jpg?height=443&width=368&top_left_y=1265&top_left_x=683)

Figure 50

52. If three points are collinear then we are done. Thus we can assume that no three points are collinear. The convex hull of all points is a polygon with at most $n$ sides, which has therefore an angle not exceeding $\frac{(n-2) \pi}{n}$. All other points lie inside this angle. Ordered counterclockwise around the vertex of the angle they determine $n-2$ angles that sum up to at most $\frac{(n-2) \pi}{n}$. It follows that one of these angles is less than or equal to $\frac{(n-2) \pi}{n(n-2)}=\frac{\pi}{n}$. The three points that form this angle have the required property.

53. Denote by $D(O, r)$ the disk of center $O$ and radius $r$. Order the disks 

$$
D\left(O_{1}, r_{1}\right), D\left(O_{2}, r_{2}\right), \ldots, D\left(O_{n}, r_{n}\right),
$$

in decreasing order of their radii.

Choose the disk $D\left(O_{1}, r_{1}\right)$, and then delete all disks that lie entirely inside the disk of center $O_{1}$ and radius $3 r_{1}$. The remaining disks are disjoint from $D\left(O_{1}, r_{1}\right)$. Among them choose the first in line (i.e., the one with maximal radius), and continue the process with the remaining circles.

The process ends after finitely many steps. At each step we deleted less than eight times the area of the chosen circle, so in the end we are left with at least $\frac{1}{9}$ of the initial area. The chosen circles satisfy the desired conditions.

(M. Pimsner, S. Popa, Probleme de geometrie elementară (Problems in elementary geometry), Editura Didactică şi Pedagogică, Bucharest, 1979)

54. Given a circle of radius $r$ containing $n$ points of integer coordinates, we must prove that $n<2 \pi \sqrt[3]{r^{2}}$. Because $r>1$ and $2 \pi>6$ we may assume $n \geq 7$.

Label the $n$ lattice points counterclockwise $P_{1}, P_{2}, \ldots, P_{n}$. The (counterclockwise)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-356.jpg?height=64&width=1339&top_left_y=971&top_left_x=198)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-356.jpg?height=61&width=630&top_left_y=1036&top_left_x=200)

Consider the triangle $P_{1} P_{2} P_{3}$, which is inscribed in an arc of measure $\frac{4 \pi}{n}$. Because $n \geq 7$, the arc is less than a quarter of the circle. The area of $P_{1} P_{2} P_{3}$ will be maximized if $P_{1}$ and $P_{3}$ are the endpoints and $P_{2}$ is the midpoint of the arc. In that case,

$$
\operatorname{Area}\left(P_{1} P_{2} P_{3}\right)=\frac{a b c}{4 r}=\frac{2 r \sin \frac{\pi}{n} \cdot 2 r \sin \frac{\pi}{n} \cdot 2 r \sin \frac{2 \pi}{n}}{4 r} \leq \frac{2 r \frac{\pi}{n} \cdot 2 r \frac{\pi}{n} \cdot 2 r \frac{2 \pi}{n}}{4 r}=\frac{4 r^{2} \pi^{3}}{n^{3}} .
$$

And in general, the area of $P_{1} P_{2} P_{3}$ cannot exceed $\frac{4 r^{2} \pi^{3}}{n^{3}}$. On the other hand, if the coordinates of the points $P_{1}, P_{2}, P_{3}$ are, respectively, $\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right)$, and $\left(x_{3}, y_{3}\right)$, then

$$
\begin{aligned}
\operatorname{Area}\left(P_{1} P_{2} P_{3}\right) &=\pm \frac{1}{2}\left|\begin{array}{lll}
1 & 1 & 1 \\
x_{1} & x_{2} & x_{3} \\
y_{1} & y_{2} & y_{3}
\end{array}\right| \\
&=\frac{1}{2}\left|x_{1} y_{2}-x_{2} y_{1}+x_{2} y_{3}-x_{3} y_{2}+x_{3} y_{1}-x_{1} y_{3}\right| .
\end{aligned}
$$

Because the coordinates are integers, the area cannot be less than $\frac{1}{2}$. We obtain the inequality $\frac{1}{2} \leq \frac{4 r^{2} \pi^{3}}{n^{3}}$, which proves that $2 \pi \sqrt[3]{r^{2}} \geq n$, as desired.

Remark. The weaker inequality $n(r)<6 \sqrt[3]{\pi r^{2}}$ was given in 1999 at the Iranian Mathematical Olympiad.

55. Order the eight integers $a_{1}<a_{2}<\cdots<a_{8} \leq 2004$. We argue by contradiction. Assume that for any choice of the integers $a, b, c, d$, either $a+b+c<d+4$ or $a+b+c>4 d$. Let us look at the situation in which $d$ is $a_{3}$ and $a, b$, and $c$ are $a_{1}, a_{2}$, and $a_{4}$. The inequality $a_{1}+a_{2}+a_{4}<4+a_{3}$ is impossible because $a_{4} \geq a_{3}+1$ and $a_{1}+a_{2} \geq 3$. Thus with our assumption, $a_{1}+a_{2}+a_{4}>4 a_{3}$, or

$$
a_{4}>4 a_{3}-a_{2}-a_{1} .
$$

By similar logic,

$$
\begin{aligned}
&a_{5}>4 a_{4}-a_{2}-a_{1}>16 a_{3}-5 a_{2}-5 a_{1}, \\
&a_{6}>4 a_{5}-a_{2}-a_{1}>64 a_{3}-21 a_{2}-21 a_{1}, \\
&a_{7}>4 a_{6}-a_{2}-a_{1}>256 a_{3}-85 a_{2}-85 a_{1}, \\
&a_{8}>4 a_{7}-a_{2}-a_{1}>1024 a_{3}-341 a_{2}-341 a_{1} .
\end{aligned}
$$

We want to show that if this is the case, then $a_{8}$ should exceed 2004. The expression $1024 a_{3}-341 a_{2}-341 a_{1}$ can be written as $683 a_{3}+341\left(a_{3}-a_{2}\right)+341\left(a_{3}-a_{1}\right)$, so to minimize it we have to choose $a_{1}=1, a_{2}=2, a_{3}=3$. But then the value of the expression would be 2049 , which, as predicted, exceeds 2004 . This contradiction shows that our assumption was false, proving the existence of the desired four numbers.

(Mathematical Olympiad Summer Program, 2004, proposed by T. Andreescu)

56. There is no loss of generality in supposing that $a_{1}<a_{2}<\cdots<a_{n}<\cdots$. Now proceed by induction on $n$. For $n=1, a_{1}^{2} \geq \frac{2 \times 1+1}{3} a_{1}$ follows from $a_{1} \geq 1$. The inductive step reduces to

$$
a_{n+1}^{2} \geq \frac{2}{3}\left(a_{1}+a_{2}+\cdots+a_{n}\right)+\frac{2 n+3}{3} a_{n+1} .
$$

An equivalent form of this is

$$
3 a_{n+1}^{2}-(2 n+3) a_{n+1} \geq 2\left(a_{1}+a_{2}+\cdots+a_{n}\right) .
$$

At this point there is an interplay between the indices and the terms of the sequence, namely the observation that $a_{1}+a_{2}+\cdots+a_{n}$ does not exceed the sum of integers from 1 to $a_{n}$. Therefore,

$$
2\left(a_{1}+a_{2}+\cdots+a_{n}\right) \leq 2\left(1+2+\cdots+a_{n}\right)=a_{n}\left(a_{n}+1\right) \leq\left(a_{n+1}-1\right) a_{n+1} .
$$

We are left to prove the sharper, yet easier, inequality

$$
3 a_{n+1}^{2}-(2 n+3) a_{n+1} \geq\left(a_{n+1}-1\right) a_{n+1} .
$$

This is equivalent to $a_{n+1} \geq n+1$, which follows from the fact that $a_{n+1}$ is the largest of the numbers.

(Romanian Team Selection Test for the International Mathematical Olympiad, proposed by L. Panaitopol) 

57. Again, there will be an interplay between the indices and the values of the terms.

We start by ordering the $a_{i}$ 's increasingly $a_{1}<a_{2}<\cdots<a_{n}$. Because the sum of two elements of $X$ is in $X$, given $a_{i}$ in the complement of $X$, for each $1 \leq m \leq \frac{a_{i}}{2}$, either $m$ or $a_{i}-m$ is not in $X$. There are $\left\lceil\frac{a_{i}}{2}\right\rceil$ such pairs and only $i-1$ integers less than $a_{i}$ and not in $X$; hence $a_{i} \leq 2 i-1$. Summing over $i$ gives $a_{1}+a_{2}+\cdots+a_{n} \leq n^{2}$ as desired. (In the solution we denoted by $\lceil x\rceil$ the least integer greater than or equal to $x$.)

(proposed by R. Stong for the USAMO, 2000)

58. Call the elements of the $4 \times 4$ tableau $a_{i j}, i, j=1,2,3,4$, according to their location. As such, $a_{13}=2, a_{22}=5, a_{34}=8$ and $a_{41}=3$. Look first at the row with the largest sum, namely, the fourth. The unknown entries sum up to 27 ; hence all three of them, $a_{42}, a_{43}$, and $a_{44}$, must equal 9. Now we consider the column with smallest sum. It is the third, with

$$
a_{13}+a_{23}+a_{33}+a_{43}=2+a_{23}+a_{33}+9=13 .
$$

We see that $a_{23}+a_{33}=2 ;$ therefore, $a_{23}=a_{33}=1$. We than have

$$
a_{31}+a_{32}+a_{33}+a_{34}=a_{31}+a_{32}+1+8=26 .
$$

Therefore, $a_{31}+a_{32}=17$, which can happen only if one of them is 8 and the other is 9 . Checking the two cases separately, we see that only $a_{31}=8, a_{32}=9$ yields a solution, which is described in Figure 51.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-358.jpg?height=378&width=461&top_left_y=1347&top_left_x=644)

Figure 51

(such puzzles appear in the Sunday edition of the San Francisco Chronicle)

59. There are only finitely many polygonal lines with these points as vertices. Choose the one of minimal length $P_{1} P_{2} \ldots P_{n}$. If two sides, say $P_{i} P_{i+1}$ and $P_{j} P_{j+1}$, intersect at some point $M$, replace them by $P_{i} P_{j}$ and $P_{i+1} P_{j+1}$ to obtain the closed polygonal line $P_{1} \ldots P_{i} P_{j} P_{j-1} \ldots P_{i+1} P_{j+1} \ldots P_{n}$ (Figure 52). The triangle inequality in triangles $M P_{i} P_{j}$ and $M P_{i+1} P_{j+1}$ shows that this polygonal line has shorter length, a contradiction. It follows that $P_{1} P_{2} \ldots P_{n}$ has no self-intersections, as desired. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-359.jpg?height=307&width=654&top_left_y=242&top_left_x=538)

Figure 52

60. Let $A_{i} A_{i+1}$ be the longest side of the polygon (or one of them if more such sides exist). Perpendicular to it and at the endpoints $A_{i}$ and $A_{i+1}$ take the lines $L$ and $L^{\prime}$, respectively. We argue on the configuration from Figure 53.

If all other vertices of the polygon lie to the right of $L^{\prime}$, then $A_{i-1} A_{i}>A_{i} A_{i+1}$, because the distance from $A_{i}$ to a point in the half-plane determined by $L^{\prime}$ and opposite to $A_{i}$ is greater than the distance from $A_{i}$ to $L^{\prime}$. This contradicts the maximality, so it cannot happen. The same argument shows than no vertex lies to the left of $L$. So there exists a vertex that either lies on one of $L$ and $L^{\prime}$, or is between them. That vertex projects onto the (closed) side $A_{i} A_{i+1}$, and the problem is solved.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-359.jpg?height=359&width=545&top_left_y=1099&top_left_x=595)

Figure 53

Remark. It is possible that no vertex projects in the interior of a side, as is the case with rectangles or with the regular hexagon.

(M. Pimsner, S. Popa, Probleme de geometrie elementară (Problems in elementary geometry), Editura Didactică şi Pedagogică, Bucharest, 1979)

61. First solution: Consider the oriented graph of roads and cities. By hypothesis, the graph has no cycles. Define a partial order of the cities, saying that $A<B$ if one can travel from $A$ to $B$. A partial order on a finite set has maximal and minimal elements. In a maximal city all roads enter, and from a minimal city all roads exit.

Second solution: Pick an itinerary that travels through a maximal number of cities (more than one such itinerary may exist). No roads enter the starting point of the itinerary, while no roads exit the endpoint.

(Kvant (Quantum) 

62. Let $b$ be a boy dancing with the maximal number of girls. There is a girl $g^{\prime}$ he does not dance with. Choose as $b^{\prime}$ a boy who dances with $g^{\prime}$. Let $g$ be a girl who dances with $b$ but not with $b^{\prime}$. Such a girl exists because of the maximality of $b$, since $b^{\prime}$ already dances with a girl who does not dance with $b$. Then the pairs $(b, g),\left(b^{\prime}, g^{\prime}\right)$ satisfy the requirement.

(26th W.L. Putnam Mathematical Competition, 1965)

63. Let $\left(a_{i j}\right)_{i j}, 1 \leq i \leq m, 1 \leq j \leq n$, be the matrix. Denote the sum of the elements in the $i$ th row by $s_{i}, i=1,2, \ldots, m$. We will show that among all matrices obtained by permuting the elements of each column, the one for which the sum $\left|s_{1}\right|+\left|s_{2}\right|+\cdots+\left|s_{m}\right|$ is minimal has the desired property.

If this is not the case, then $\left|s_{k}\right| \geq 2$ for some $k$. Without loss of generality, we can assume that $s_{k} \geq 2$. Since $s_{1}+s_{2}+\cdots+s_{m}=0$, there exists $j$ such that $s_{j}<0$. Also, there exists an $i$ such that $a_{i k}>a_{i j}$, for otherwise $s_{j}$ would be larger than $s_{k}$. When exchanging $a_{i k}$ and $a_{i j}$ the sum $\left|s_{1}\right|+\left|s_{2}\right|+\cdots+\left|s_{m}\right|$ decreases. Indeed,

$$
\begin{aligned}
\left|s_{k}-a_{i k}+a_{i j}\right|+\left|s_{j}+a_{i k}-a_{i j}\right| &=s_{k}-a_{i k}+a_{i j}+\left|s_{j}+a_{i k}-a_{i j}\right| \\
&<s_{k}-a_{i k}+a_{i j}+\left|s_{j}\right|+a_{i k}-a_{i j},
\end{aligned}
$$

where the equality follows from the fact that $s_{k} \geq 2 \geq a_{i k}-a_{i j}$, while the strict inequality follows from the triangle inequality and the fact that $s_{j}$ and $a_{i k}-a_{i j}$ have opposite signs. This shows that any minimal configuration must satisfy the condition from the statement. Note that a minimal configuration always exists, since the number of possible permutations is finite.

(Austrian-Polish Mathematics Competition, 1984)

64. We call a number good if it satisfies the given condition. It is not difficult to see that all powers of primes are good. Suppose $n$ is a good number that has at least two distinct prime factors. Let $n=p^{r} s$, where $p$ is the smallest prime dividing $n$ and $s$ is not divisible by $p$. Because $n$ is good, $p+s-1$ must divide $n$. For any prime $q$ dividing $s, s<p+s-1<s+q$, so $q$ does not divide $p+s-1$. Therefore, the only prime factor of $p+s-1$ is $p$. Then $s=p^{c}-p+1$ for some integer $c>1$. Because $p^{c}$ must also divide $n, p^{c}+s-1=2 p^{c}-p$ divides $n$. Because $2 p^{c-1}-1$ has no factors of $p$, it must divide $s$. But

$$
\begin{aligned}
\frac{p-1}{2}\left(2 p^{c-1}-1\right) &=p^{c}-p^{c-1}-\frac{p-1}{2}<p^{c}-p+1<\frac{p+1}{2}\left(2 p^{c-1}-1\right) \\
&=p^{c}+p^{c-1}-\frac{p+1}{2},
\end{aligned}
$$

a contradiction. It follows that the only good integers are the powers of primes.

(Russian Mathematical Olympiad, 2001)

65. Let us assume that no infinite monochromatic sequence exists with the desired property, and consider a maximal white sequence $2 k_{1}<k_{1}+k_{2}<\cdots<2 k_{n}$ and a maximal black sequence $2 l_{1}<l_{1}+l_{2}<\cdots<2 l_{m}$. By maximal we mean that these sequences cannot be extended any further. Without loss of generality, we may assume that $k_{n}<l_{m}$.

We look at all white even numbers between $2 k_{n}+1$ and some arbitrary $2 x$; let $W$ be their number. If for one of these white even numbers $2 k$ the number $k+k_{n}$ were white as well, then the sequence of whites could be extended, contradicting maximality. Hence $k+k_{n}$ must be black. Therefore, the number $b$ of blacks between $2 k_{n}+1$ and $x+k_{n}$ is at least $W$.

Similarly, if $B$ is the number of black evens between $2 l_{m}+1$ and $2 x$, the number $w$ of whites between $2 l_{m}+1$ and $x+l_{m}$ is at least $B$. We have $B+W \geq x-l_{m}$, the latter being the number of even integers between $2 l_{m}+1$ and $2 x$, while $b+w \leq x-k_{n}$, since $x-k_{n}$ is the number of integers between $2 k_{n}+1$ and $x+k_{n}$. Subtracting, we obtain

$$
0 \leq(b-W)+(w-B) \leq l_{m}-k_{n},
$$

and this inequality holds for all $x$. This means that as $x$ varies there is an upper bound for $b-W$ and $w-B$. Hence there can be only a finite number of black squares that cannot be written as $k_{n}+k$ for some white $2 k$ and there can only be a finite number of white squares which cannot be written as $l_{m}+l$ for some black $2 l$. Consequently, from a point onward all white squares are of the form $l_{m}+l$ for some black $2 l$ and from a point onward all black squares are of the form $k_{n}+k$ for some white $2 k$.

We see that for $k$ sufficiently large, $k$ is black if and only if $2 k-2 k_{n}$ is white, while $k$ is white if and only if $2 k-2 l_{m}$ is black. In particular, for each such $k, 2 k-2 k_{n}$ and $2 k-2 l_{m}$ have the same color, opposite to the color of $k$. So if we let $l_{m}-k_{n}=a>0$, then from some point onward $2 x$ and $2 x+2 a$ are of the same color. The arithmetic sequence $2 x+2 n a, n \geq 0$, is thus monochromatic. It is not hard to see that it also satisfies the condition from the statement, a contradiction. Hence our assumption was false, and sequences with the desired property do exist.

(communicated by A. Neguţ)

66. We begin with an observation that will play an essential role in the solution. Given a triangle $X Y Z$, if $\angle X Y Z \leq \frac{\pi}{3}$, then either the triangle is equilateral or else $\max \{Y X, Y Z\}>X Z$, and if $\angle X Y Z \geq \frac{\pi}{3}$, then either the triangle is equilateral or else $\min \{Y X, Y Z\}<X Z$

Choose vertices $A$ and $B$ that minimize the distance between vertices. If $C$ is a vertex such that $\angle A C B=\frac{\pi}{3}$, then $\max \{C A, C B\} \leq A B$, so by our observation the triangle $A B C$ is equilateral. So there exists an equilateral triangle $A B C$ formed by vertices of the polygon and whose side length is the minimal distance between two vertices of the polygon. By a similar argument there exists a triangle $A_{1} B_{1} C_{1}$ formed by vertices whose side length is the maximal distance between two vertices of the polygon. We will prove that the two triangles are congruent.

The lines $A B, B C, C A$ divide the plane into seven open regions. Denote by $R_{A}$ the region distinct from the interior of $A B C$ and bounded by side $B C$, plus the boundaries of this region except for the vertices $B$ and $C$. Define $R_{B}$ and $R_{C}$ analogously. These regions are illustrated in Figure 54. Because the given polygon is convex, each of $A_{1}$, $B_{1}$, and $C_{1}$ lies in one of these regions or coincides with one of $A, B$, and $C$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-362.jpg?height=417&width=479&top_left_y=424&top_left_x=628)

Figure 54

If two of $A_{1}, B_{1}, C_{1}$, say $A_{1}$ and $B_{1}$, are in the same region $R_{X}$, then $\angle A_{1} X B_{1}<$ $\frac{\pi}{3}$. Hence $\max \left\{X A_{1}, X B_{1}\right\}>A_{1} B_{1}$, contradicting the maximality of the length $A_{1} B_{1}$. Therefore, no two of $A_{1}, B_{1}, C_{1}$ are in the same region.

Suppose now that one of $A_{1}, B_{1}, C_{1}$ (say $A_{1}$ ) lies in one of the regions (say $R_{A}$ ). Because $\min \left\{A_{1} B, A_{1} C\right\} \geq B C$, we have that $\angle B A_{1} C \leq \frac{\pi}{3}$. We know that $B_{1}$ does not lie in $R_{A}$. Also, because the polygon is convex, $B$ does not lie in the interior of the triangle $A A_{1} B_{1}$, and $C$ does not lie in the interior of triangle $A A_{1} B_{1}$. It follows that $B_{1}$ lies in the closed region bounded by the rays $\mid A_{1} B$ and $\mid A_{1} C$. So does $C_{1}$. Therefore, $\frac{\pi}{3}=\angle B_{1} A_{1} C_{1} \leq \angle B A_{1} C \leq \frac{\pi}{3}$, with equalities if $B_{1}$ and $C_{1}$ lie on rays $\mid A_{1} B$ and $\mid A_{1} C$. Because the given polygon is convex, this is possible only if $B_{1}$ and $C_{1}$ equal $B$ and $C$ in some order, in which case $B C=B_{1} C_{1}$. This would imply that triangles $A B C$ and $A_{1} B_{1} C_{1}$ are congruent.

The remaining situation occurs when none of $A_{1}, B_{1}, C_{1}$ are in $R_{A} \cup R_{B} \cup R_{C}$, in which case they coincide with $A, B, C$ in some order. Again we conclude that the two triangles are congruent.

We have proved that the distance between any two vertices of the given polygon is the same. Therefore, given a vertex, all other vertices are on a circle centered at that vertex. Two such circles have at most two points in common, showing that the polygon has at most four vertices. If it had four vertices, it would be a rhombus, whose longer diagonal would be longer than the side, a contradiction. Hence the polygon can only be the equilateral triangle, the desired conclusion.

(Romanian Mathematical Olympiad, 2000)

67. Because

$$
a^{2}+b^{2}=\left(\frac{a+b}{\sqrt{2}}\right)^{2}+\left(\frac{a-b}{\sqrt{2}}\right)^{2},
$$

the sum of the squares of the numbers in a triple is invariant under the operation. The sum of squares of the first triple is $\frac{9}{2}$ and that of the second is $6+2 \sqrt{2}$, so the first triple cannot be transformed into the second.

(D. Fomin, S. Genkin, I. Itenberg, Mathematical Circles, AMS, 1996)

68. Assign the value $i$ to each white ball, $-i$ to each red ball, and $-1$ to each green ball. A quick check shows that the given operations preserve the product of the values of the balls in the box. This product is initially $i^{2000}=1$. If three balls were left in the box, none of them green, then the product of their values would be $\pm i$, a contradiction. Hence, if three balls remain, at least one is green, proving the claim in part (a). Furthermore, because no ball has value 1, the box must contain at least two balls at any time. This shows that the answer to the question in part (b) is no.

(Bulgarian Mathematical Olympiad, 2000)

69. Let $I$ be the sum of the number of stones and heaps. An easy check shows that the operation leaves $I$ invariant. The initial value is 1002 . But a configuration with $k$ heaps, each containing 3 stones, has $I=k+3 k=4 k$. This number cannot equal 1002 , since 1002 is not divisible by 4.

(D. Fomin, S. Genkin, I. Itenberg, Mathematical Circles, AMS, 1996)

70. The quantity $I=x v+y u$ does not change under the operation, so it remains equal to $2 m n$ throughout the algorithm. When the first two numbers are both equal to $\operatorname{gcd}(m, n)$, the sum of the latter two is $\frac{2 m n}{\operatorname{gcd}(m, n)}=2 \operatorname{lcm}(m, n)$.

(St. Petersburg City Mathematical Olympiad, 1996)

71. We can assume that $p$ and $q$ are coprime; otherwise, shrink the size of the chessboard by their greatest common divisor. Place the chessboard on the two-dimensional integer lattice such that the initial square is centered at the origin, and the other squares, assumed to have side length 1 , are centered at lattice points. We color the chessboard by the Klein four group $K=\left\{a, b, c, e \mid a^{2}=b^{2}=c^{2}=e, a b=c, a c=b, b c=a\right\}$ as follows: if $(x, y)$ are the coordinates of the center of a square, then the square is colored by $e$ if both $x$ and $y$ are even, by $c$ if both are odd, by $a$ if $x$ is even and $y$ is odd, and by $b$ if $x$ is odd and $y$ is even (see Figure 55). If $p$ and $q$ are both odd, then at each jump the color of the location of the knight is multiplied by $c$. Thus after $n$ jumps the knight is on a square colored by $c^{n}$. The initial square was colored by $e$, and the equality $c^{n}=e$ is possible only if $n$ is even.

If one of $p$ and $q$ is even and the other is odd, then at each jump the color of the square is multiplied by $a$ or $b$. After $n$ jumps the color will be $a^{k} b^{n-k}$. The equality $a^{k} b^{n-k}=e$ implies $a^{k}=b^{n-k}$, so both $k$ and $n-k$ have to be even. Therefore, $n$ itself has to be even. This completes the solution.

(German Mathematical Olympiad)

72. The invariant is the 5-colorability of the knot, i.e., the property of a knot to admit a coloring by the residue classes modulo 5 such that 

\begin{tabular}{|l|l|l|l|l|l|}
\hline$c$ & $b$ & $c$ & $b$ & $c$ & $b$ \\
\hline$a$ & $e$ & $a$ & $e$ & $a$ & $e$ \\
\hline$c$ & $b$ & $c$ & $b$ & $c$ & $b$ \\
\hline$a$ & $e$ & $a$ & $e$ & $a$ & $e$ \\
\hline$c$ & $b$ & $c$ & $b$ & $c$ & $b$ \\
\hline$a$ & $e$ & $a$ & $e$ & $a$ & $e$ \\
\hline
\end{tabular}

Figure 55

(i) at least two residue classes are used;

(ii) at each crossing, $a+c \equiv 2 b(\bmod 5)$, where $b$ is the residue class assigned to the overcrossing, and $a$ and $c$ are the residue classes assigned to the other two arcs.

A coloring of the figure eight knot is given in Figure 56, while the trivial knot does not admit 5-colorings since its simplest diagram does not. This proves that the figure eight knot is knotted.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-364.jpg?height=271&width=348&top_left_y=1089&top_left_x=698)

Figure 56

73. The answer is no. The idea of the proof is to associate to the configuration (a) an encoding defined by a pair of vectors $(v, w) \in \mathbb{Z}_{2}^{2}$ such that the $(i, j)$ square contains a $+$ if the $i$ th coordinate of $v$ is equal to the $j$ th coordinate of $w$, and a $-$ otherwise. A possible encoding for our configuration is $v=w=(1,1,0)$. Any other configuration that can be obtained from it admits such an encoding. Thus we choose as the invariant the possibility of encoding a configuration in such a manner.

It is not hard to see that the configuration in (b) cannot be encoded this way. A slick proof of this fact is that the configuration in which all signs are negative except for the one in the center can be obtained from this by the specified move, and this latter one cannot be encoded. Hence it is impossible to transform the first configuration into the second.

(Russian Mathematical Olympiad 1983-1984, solution by A. Badev)

74. The answer is no. The essential observation is that

$$
99 \ldots 99 \equiv 99 \equiv 3(\bmod 4) .
$$

When we write this number as a product of two factors, one of the factors is congruent to 1 and the other is congruent to 3 modulo 4 . Adding or subtracting a 2 from each factor produces numbers congruent to 3 , respectively, 1 modulo 4 . We deduce that what stays invariant in this process is the parity of the number of numbers on the blackboard that are congruent to 3 modulo 4 . Since initially this number is equal to 1 , there will always be at least one number that is congruent to 3 modulo 4 written on the blackboard. And this is not the case with the sequence of nines. This proves our claim.

(St. Petersburg City Mathematical Olympiad, 1997)

75. Without loss of generality, we may assume that the length of the hypotenuse is 1 and those of the legs are $p$ and $q$. In the process, we obtain homothetic triangles that are in the ratio $p^{m} q^{n}$ to the original ones, for some nonnegative integers $m$ and $n$. Let us focus on the pairs $(m, n)$.

Each time we cut a triangle, we replace the pair $(m, n)$ with the pairs $(m+1, n)$ and $(m, n+1)$. This shows that if to the triangle corresponding to the pair $(m, n)$ we associate the weight $\frac{1}{2^{m+n}}$, then the sum $I$ of all the weights is invariant under cuts. The initial value of $I$ is 4 . If at some stage the triangles were pairwise incongruent, then the value of $I$ would be strictly less than

$$
\sum_{m, n=0}^{\infty} \frac{1}{2^{m+n}}=\sum_{m=0}^{\infty} \frac{1}{2^{m}} \sum_{n=0}^{\infty} \frac{1}{2^{n}}=4,
$$

a contradiction. Hence a configuration with all triangles of distinct sizes cannot be achieved.

(Russian Mathematical Olympiad, 1995)

76. First solution: Here the invariant is given; we just have to prove its invariance. We first examine the simpler case of a cyclic quadrilateral $A B C D$ inscribed in a circle of radius $R$. Recall that for a triangle $X Y Z$ the radii of the incircle and the circumcircle are related by

$$
r=4 R \sin \frac{X}{2} \sin \frac{Y}{2} \sin \frac{Z}{2} .
$$

Let $\angle C A D=\alpha_{1}, \angle B A C=\alpha_{2}, \angle A B D=\beta$. Then $\angle D B C=\alpha_{1}$, and $\angle A C D=\beta$, $\angle B D C=\alpha_{2}$, and $\angle A C B=\angle A D B=180^{\circ}-\alpha_{1}-\alpha_{2}-\beta$. The independence of the sum of the inradii in the two possible dissections translates, after dividing by $4 R$, into the identity

$$
\begin{aligned}
&\sin \frac{\alpha_{1}+\alpha_{2}}{2} \sin \frac{\beta}{2} \sin \left(90^{\circ}-\frac{\alpha_{1}+\alpha_{2}+\beta}{2}\right)+\sin \left(90^{\circ}-\frac{\alpha_{1}+\alpha_{2}}{2}\right) \sin \frac{\alpha_{1}}{2} \sin \frac{\alpha_{2}}{2} \\
&=\sin \frac{\alpha_{1}+\beta_{1}}{2} \sin \frac{\alpha_{2}}{2} \sin \left(90^{\circ}-\frac{\alpha_{1}+\alpha_{2}+\beta}{2}\right)+\sin \left(90^{\circ}-\frac{\alpha_{1}+\beta_{1}}{2}\right) \sin \frac{\alpha_{1}}{2} \sin \frac{\beta}{2} .
\end{aligned}
$$

This is equivalent to

$$
\begin{array}{r}
\cos \frac{\alpha_{1}+\beta_{1}+\alpha_{2}}{2}\left(\sin \frac{\alpha_{1}+\alpha_{2}}{2} \sin \frac{\beta}{2}-\sin \frac{\alpha_{1}+\beta}{2} \sin \frac{\alpha_{2}}{2}\right) \\
=\sin \frac{\alpha_{1}}{2}\left(\sin \frac{\beta}{2} \cos \frac{\alpha_{1}+\beta_{1}}{2}-\sin \frac{\alpha_{2}}{2} \cos \frac{\alpha_{1}+\alpha_{2}}{2}\right)
\end{array}
$$

or

$$
\begin{gathered}
\cos \frac{\alpha_{1}+\alpha_{2}+\beta}{2}\left(\cos \frac{\alpha_{1}+\alpha_{2}-\beta}{2}-\cos \frac{\alpha_{1}-\alpha_{2}+\beta}{2}\right) \\
=\sin \frac{\alpha_{1}}{2}\left(\sin \left(\beta_{1}+\frac{\alpha_{1}}{2}\right)-\sin \left(\alpha_{2}+\frac{\alpha_{1}}{2}\right)\right) .
\end{gathered}
$$

Using product-to-sum formulas, both sides can be transformed into $\cos \left(\alpha_{1}+\alpha_{2}\right)$ $+\cos \beta_{1}-\cos \left(\alpha_{1}+\beta_{1}\right)-\cos \alpha_{2}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-366.jpg?height=180&width=698&top_left_y=992&top_left_x=518)

Figure 57

The case of a general polygon follows from the particular case of the quadrilateral. This is a consequence of the fact that any two dissections can be transformed into one another by a sequence of quadrilateral moves (Figure 57). Indeed, any dissection can be transformed into a dissection in which all diagonals start at a given vertex, by moving the endpoints of diagonals one by one to that vertex. So one can go from any dissection to any other dissection using this particular type as an intermediate step. Since the sum of the inradii is invariant under quadrilateral moves, it is independent of the dissection. Second solution: This time we use the trigonometric identity

$$
1+\frac{r}{R}=\cos X+\cos Y+\cos Z .
$$

We will check therefore that the sum of $1+\frac{r_{i}}{R}$ is invariant, where $r_{i}$ are the inradii of the triangles of the decomposition. Again we prove the property for a cyclic quadrilateral and then obtain the general case using the quadrilateral move. Using the fact that the sum of cosines of supplementary angles is zero and chasing angles in the cyclic quadrilateral $A B C D$, we obtain

$\cos \angle D B A+\cos \angle B D A+\cos \angle D A B+\cos \angle B C D+\cos \angle C B D+\cos \angle C D B$

$=\cos \angle D B A+\cos \angle B D A+\cos \angle C B D+\cos \angle C D B$ 

$$
\begin{aligned}
&=\cos \angle D C A+\cos \angle B C A+\cos \angle C A D+\cos \angle C A B \\
&=\cos \angle D C A+\cos \angle C A D+\cos \angle A D C+\cos \angle B C A+\cos \angle C A B+\cos \angle A B C,
\end{aligned}
$$

and we are done.

Remark. A more general theorem states that two triangulations of a polygonal surface (not necessarily by diagonals) are related by the move from Figure 57 and the move from Figure 58 or its inverse. These are usually called Pachner moves.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-367.jpg?height=196&width=619&top_left_y=661&top_left_x=558)

Figure 58

(Indian Team Selection Test for the International Mathematical Olympiad, 2005, second solution by A. Tripathy)

77. Let $S$ be the sum of the elements of the table. By performing moves on the rows or columns with negative sum, we obtain a strictly increasing sequence $S_{1}<S_{2}<\cdots$. Because $S$ can take at most $2^{n^{2}}$ values (all possible sign choices for the entries of the table), the sequence becomes stationary. At that time no row or column will have negative sum.

78. Skipping the first step, we may assume that the integers are nonnegative. The semiinvariant is $S(a, b, c, d)=\max (a, b, c, d)$. Because for nonnegative numbers $x, y$, we have $|x-y| \leq \max (x, y), S$ does not increase under $T$. If $S$ decreases at every step, then it eventually becomes 0 , in which case the quadruple is $(0,0,0,0)$. Let us see in what situation $S$ is preserved by $T$. If

$$
S(a, b, c, d)=S(T(a, b, c, d))=S(|a-b|,|b-c|,|c-d|,|d-a|),
$$

then next to some maximal entry there must be a zero. Without loss of generality, we may assume $a=S(a, b, c, d)$ and $b=0$. Then

$$
\begin{aligned}
(a, 0, c, d) & \stackrel{T}{\longrightarrow}(a, c,|c-d|,|d-a|) \\
\stackrel{T}{\longrightarrow}(|a-c|,|c-| c-d|,||c-d|-|d-a||,| a-|d-a| \mid) .
\end{aligned}
$$

Can $S$ stay invariant in both these steps? If $|a-c|=a$, then $c=0$. If $|c-| c-d||=a$, then since $a$ is the largest of the four numbers, either $c=d=a$ or else $c=0, d=a$. The equality $\|c-d|-| d-a\|=a$ can hold only if $c=0, d=a$, or $d=0, c=a$. Finally, $|a-| d-a||=a$ if $d=a$. So $S$ remains invariant in two consecutive steps only for quadruples of the form 

$$
(a, 0,0, d),(a, 0,0, a),(a, 0, a, 0),(a, 0, c, a)
$$

and their cyclic permutations.

At the third step these quadruples become

$$
(a, 0, d,|d-a|),(a, 0, a, 0),(a, a, a, a),(a, c,|c-a|, 0) \text {. }
$$

The second and the third quadruples become $(0,0,0,0)$ in one and two steps, respectively. Now let us look at the first and the last. By our discussion, unless they are of the form $(a, 0, a, 0)$ or $(a, a, 0,0)$, respectively, the semi-invariant will decrease at the next step. So unless it is equal to zero, $S$ can stay unchanged for at most five consecutive steps. If initially $S=m$, after $5 m$ steps it will be equal to zero and the quadruple will then be $(0,0,0,0)$

79. If $a, b$ are erased and $c<d$ are written instead, we have $c \leq \min (a, b)$ and $d \geq$ $\max (a, b)$. Moreover, $a b=c d$. Using derivatives we can show that the function $f(c)=c+\frac{a b}{c}$ is strictly decreasing on $\left(0, \frac{a+b}{2}\right)$, which implies $a+b \leq c+d$. Thus the sum of the numbers is nondecreasing. It is obviously bounded, for example by $n$ times the product of the numbers, where $n$ is the number of numbers on the board. Hence the sum of the numbers eventually stops changing. At that moment the newly introduced $c$ and $d$ should satisfy $c+d=a+b$ and $c d=a b$, which means that they should equal $a$ and $b$. Hence the numbers themselves stop changing.

(St. Petersburg City Mathematical Olympiad, 1996)

80. To a configuration of pebbles we associate the number

$$
S=\sum \frac{1}{2^{|i|+|j|}},
$$

where the sum is taken over the coordinates of all nodes that contain pebbles. At one move of the game, a node $(i, j)$ loses its pebble, while two nodes $\left(i_{1}, j_{1}\right)$ and $\left(i_{2}, j_{2}\right)$ gain pebbles. Since either the first coordinate or the second changes by one unit, $\left|i_{k}\right|+\left|j_{k}\right| \leq$ $|i|+|j|+1, k=1,2$. Hence

$$
\frac{1}{2^{|i|+|j|}}=\frac{1}{2^{|i|+|j|+1}}+\frac{1}{2^{|i|+|j|+1}} \leq \frac{1}{2^{\left|i_{1}\right|+\left|j_{1}\right|}}+\frac{1}{2^{\left|i_{2}\right|+\left|j_{2}\right|}},
$$

which shows that $S$ is a nondecreasing semi-invariant. We will now show that at least one pebble is inside or on the boundary of the square $R$ determined by the lines $x \pm y=\pm 5$. Otherwise, the total value of $S$ would be less than

$$
\begin{aligned}
&\sum_{|i|+|j|>5} \frac{1}{2^{|i|+|j|}} \\
&\quad=1+4 \sum_{i=1}^{\infty} \sum_{j=0}^{\infty} \frac{1}{2^{i+j}}-\sum_{|i|+|j| \leq 5} \frac{1}{2^{|i|+|j|}}
\end{aligned}
$$



$$
\begin{aligned}
&=1+4 \sum_{i=1}^{\infty} \frac{1}{2^{i}} \sum_{j=0}^{\infty} \frac{1}{2^{j}}-1-4\left(1 \cdot \frac{1}{2}+2 \cdot \frac{1}{4}+3 \cdot \frac{1}{8}+4 \cdot \frac{1}{16}+5 \cdot \frac{1}{32}\right) \\
&=9-\frac{65}{8}=\frac{7}{8}<1
\end{aligned}
$$

This is impossible, since the original value of $S$ was 1 . Consequently, there will always be a pebble inside $R$, and this pebble will be at distance at most 5 from the origin. 

\section{Algebra}

81. Assume that both numbers are perfect cubes. Then so is their product

$$
(n+3)\left(n^{2}+3 n+3\right)=n^{3}+6 n^{2}+12 n+9 .
$$

However, this number differs from the perfect cube $(n+2)^{3}=n^{3}+6 n^{2}+12 n+8$ by one unit. And this is impossible because no perfect cubes can be consecutive integers (unless one of them is zero). This proves the claim.

82. Let $m=p q$. We use the identity

$$
x^{m}-y^{m}=(x-y)\left(x^{m-1}+x^{m-2} y+\cdots+y^{m-1}\right),
$$

which can be applied to the matrices $A$ and $-B$ since they commute. We have

$$
\begin{array}{r}
(A-(-B))\left(A^{m-1}+A^{m-2}(-B)+\cdots+(-B)^{m-1}\right) \\
=A^{m}-(-B)^{m}=\left(A^{p}\right)^{q}-(-1)^{p q}\left(B^{q}\right)^{p}=\mathcal{I}_{n} .
\end{array}
$$

Hence the inverse of $A+B=A-(-B)$ is $A^{m-1}+A^{m-2}(-B)+\cdots+(-B)^{m-1}$.

83. First solution: Let $F(x)$ be the polynomial in question. If $F(x)$ is the square of a polynomial, then write $F(x)=G(x)^{2}+0^{2}$. In general, $F(x)$ is nonnegative for all real numbers $x$ if and only if it has even degree and is of the form

$$
F(x)=R(x)^{2}\left(x^{2}+a_{1} x+b_{1}\right)\left(x^{2}+a_{2} x+b_{2}\right) \cdots\left(x^{2}+a_{n} x+b_{n}\right),
$$

where the discriminant of each quadratic factor is negative. Completing the square

$$
x^{2}+a_{k} x+b_{k}=\left(x+\frac{a_{k}}{2}\right)^{2}+\Delta^{2}, \quad \text { with } \Delta=\sqrt{b_{k}-\frac{a_{k}^{2}}{4}},
$$

we can write 

$$
F(x)=\left(P_{1}(x)^{2}+Q_{1}(x)^{2}\right)\left(P_{2}(x)^{2}+Q_{2}(x)^{2}\right) \cdots\left(P_{n}(x)^{2}+Q_{n}(x)^{2}\right),
$$

where the factor $R(x)^{2}$ is incorporated in $P_{1}(x)^{2}$ and $Q_{1}(x)^{2}$. Using the Lagrange identity

$$
\left(a^{2}+b^{2}\right)\left(c^{2}+d^{2}\right)=(a c+b d)^{2}+(a d-b c)^{2},
$$

we can transform this product in several steps into $P(x)^{2}+Q(x)^{2}$, where $P(x)$ and $Q(x)$ are polynomials.

Second solution: Likewise, with the first solution write the polynomial as

$$
F(x)=R(x)^{2}\left(x^{2}+a_{1} x+b_{1}\right)\left(x^{2}+a_{2} x+b_{2}\right) \cdots\left(x^{2}+a_{n} x+b_{n}\right) .
$$

Factor the quadratics as $\left(x+\alpha_{k}+i \beta_{k}\right)\left(x+\alpha_{k}-i \beta_{k}\right)$. Group the factors with $+i \beta_{k}$ into a polynomial $P(x)+i Q(x)$ and the factors with $-i \beta_{k}$ into the polynomial $P(x)-i Q(x)$. Then

$$
F(x)=(R(x) P(x))^{2}+(R(x) Q(x))^{2},
$$

which proves the conclusion.

Remark. D. Hilbert discovered that not every positive two-variable polynomial can be written as a sum of squares of polynomials. The appropriate generalization to the case of rational functions makes the object of his 16th problem. While Hilbert's proof is nonconstructive, the first examples of such polynomials were discovered surprisingly late, and were quite complicated. Here is a simple example found by T. Motzkin: $f(x, y)=$ $1+x^{2} y^{2}\left(x^{2}+y^{2}-3\right)$

84. Simply substitute $x=5^{5^{n}}$ in the factorization

$$
x^{5}+x+1=\left(x^{2}+x+1\right)\left(x^{3}-x^{2}+1\right)
$$

to obtain a factorization of the number from the statement. It is not hard to prove that both factors are greater than 1 .

(T.Andreescu, published in T.Andreescu, D. Andrica, 360 Problems for Mathematical Contests, GIL, 2003)

85. Let

$$
N=5^{n-1}-\left(\begin{array}{l}
n \\
1
\end{array}\right) 5^{n-2}+\left(\begin{array}{l}
n \\
2
\end{array}\right) 5^{n-3}-\cdots+\left(\begin{array}{c}
n \\
n-1
\end{array}\right) .
$$

Then $5 N-1=(5-1)^{n}$. Hence

$$
N=\frac{4^{n}+1}{5}=\frac{4\left(2^{k}\right)^{4}+1}{5}=\frac{\left(2^{2 k+1}+2^{k+1}+1\right)\left(2^{2 k+1}-2^{k+1}+1\right)}{5},
$$

where $k=\frac{n-1}{2}$. Since $n \geq 5$, both factors at the numerator are greater than 5 , which shows that after canceling the denominator, the expression on the right can still be written as a product of two numbers. This proves that $N$ is not prime.

(T.Andreescu, published in T.Andreescu, D. Andrica, 360 Problems for Mathematical Contests, GIL, 2003)

86. We use the identity

$$
a^{5}-1=(a-1)\left(a^{4}+a^{3}+a^{2}+a+1\right)
$$

applied for $a=5^{397}$. The difficult part is to factor $a^{4}+a^{3}+a^{2}+a+1$. Note that

$$
a^{4}+a^{3}+a^{2}+a+1=\left(a^{2}+3 a+1\right)^{2}-5 a(a+1)^{2} .
$$

Hence

$$
\begin{aligned}
a^{4}+a^{3}+a^{2}+a+1 &=\left(a^{2}+3 a+1\right)^{2}-5^{398}(a+1)^{2} \\
&=\left(a^{2}+3 a+1\right)^{2}-\left(5^{199}(a+1)\right)^{2} \\
&=\left(a^{2}+3 a+1+5^{199}(a+1)\right)\left(a^{2}+3 a+1-5^{199}(a+1)\right) .
\end{aligned}
$$

It is obvious that $a-1$ and $a^{2}+3 a+1+5^{199}(a+1)$ are both greater than $5^{100}$. As for the third factor, we have

$$
a^{2}+3 a+1-5^{199}(a+1)=a\left(a-5^{199}\right)+3 a-5^{199}+1 \geq a+0+1 \geq 5^{100} .
$$

Hence the conclusion.

(proposed by Russia for the 26th International Mathematical Olympiad, 1985)

87. The number from the statement is equal to $a^{4}+a^{3}+a^{2}+a+1$, where $a=5^{25}$. As in the case of the previous problem, we rely on the identity

$$
a^{4}+a^{3}+a^{2}+a+1=\left(a^{2}+3 a+1\right)^{2}-5 a(a+1)^{2},
$$

and factor our number as follows:

$$
\begin{aligned}
a^{4}+a^{3}+a^{2}+a+1 &=\left(a^{2}+3 a+1\right)^{2}-\left(5^{13}(a+1)\right)^{2} \\
&=\left(a^{2}+3 a+1+5^{13}(a+1)\right)\left(a^{2}+a+1-5^{13}(a+1)\right) .
\end{aligned}
$$

The first factor is obviously greater than 1 . The second factor is also greater than 1 , since

$$
a^{2}+a+1-5^{13} a-5^{13}=a\left(a-5^{13}\right)+\left(a-5^{13}\right)+1,
$$

and $a>5^{13}$. This proves that the number from the statement of the problem is not prime. (proposed by Korea for the 33rd International Mathematical Olympiad, 1992) 

88. The solution is based on the identity

$$
a^{k}+b^{k}=(a+b)\left(a^{k-1}+b^{k-1}\right)-a b\left(a^{k-2}+b^{k-2}\right) .
$$

This identity arises naturally from the fact that both $a$ and $b$ are solutions to the equation $x^{2}-(a+b) x+a b=0$, hence also to $x^{k}-(a+b) x^{k-1}+a b x^{k-2}=0$.

Assume that the conclusion is false. Then for some $n, a^{2 n}+b^{2 n}$ is divisible by $a+b$. For $k=2 n$, we obtain that the right-hand side of the identity is divisible by $a+b$, hence so is $a b\left(a^{2 n-2}+b^{2 n-2}\right)$. Moreover, $a$ and $b$ are coprime to $a+b$, and therefore $a^{2 n-2}+b^{2 n-2}$ must be divisible by $a+b$. Through a backward induction, we obtain that $a^{0}+b^{0}=2$ is divisible by $a+b$, which is impossible since $a, b>1$. This contradiction proves the claim.

(R. Gelca)

89. Let $n$ be an integer and let $\frac{n^{3}-n}{6}=k$. Because $n^{3}-n$ is the product of three consecutive integers, $n-1, n, n+1$, it is divisible by 6 ; hence $k$ is an integer. Then

$$
n^{3}-n=6 k=(k-1)^{3}+(k+1)^{3}-k^{3}-k^{3} .
$$

It follows that

$$
n=n^{3}-(k-1)^{3}-(k+1)^{3}+k^{3}+k^{3},
$$

and thus

$$
n=n^{3}+\left(1-\frac{n^{3}-n}{6}\right)^{3}+\left(-1-\frac{n^{3}+n}{6}\right)^{3}+\left(\frac{n^{3}-n}{6}\right)^{3}+\left(\frac{n^{3}-n}{6}\right)^{3} .
$$

Remark. Lagrange showed that every positive integer is a sum of at most four perfect squares. Wieferich showed that every positive integer is a sum of at most nine perfect cubes of positive integers. Waring conjectured that in general, for every $n$ there is a number $w(n)$ such that every positive integer is the sum of at most $w(n) n$th powers of positive integers. This conjecture was proved by Hilbert.

90. First solution: Using the indentity

$$
a^{3}+b^{3}+c^{3}-3 a b c=\frac{1}{2}(a+b+c)\left((a-b)^{2}+(b-c)^{2}+(c-a)^{2}\right)
$$

applied to the (distinct) numbers $a=\sqrt[3]{x-1}, b=\sqrt[3]{x}$, and $c=\sqrt[3]{x+1}$, we transform the equation into the equivalent

$$
(x-1)+x+(x+1)-3 \sqrt[3]{(x-1) x(x+1)}=0 .
$$

We further change this into $x=\sqrt[3]{x^{3}-x}$. Raising both sides to the third power, we obtain $x^{3}=x^{3}-x$. We conclude that the equation has the unique solution $x=0$.

Second solution: The function $f: \mathbb{R} \rightarrow \mathbb{R}, f(x)=\sqrt[3]{x-1}+\sqrt[3]{x}+\sqrt[3]{x+1}$ is strictly increasing, so the equation $f(x)=0$ has at most one solution. Since $x=0$ satisfies this equation, it is the unique solution.

91. The key observation is that the left-hand side of the equation can be factored as

$$
(x+y+z)\left(x^{2}+y^{2}+z^{2}-x y-y z-z x\right)=p .
$$

Since $x+y+z>1$ and $p$ is prime, we must have $x+y+z=p$ and $x^{2}+y^{2}+z^{2}-x y-$ $y z-z x=1$. The second equality can be written as $(x-y)^{2}+(y-z)^{2}+(z-x)^{2}=2$. Without loss of generality, we may assume that $x \geq y \geq z$. If $x>y>z$, then $x-y \geq 1$, $y-z \geq 1$, and $x-z \geq 2$, which would imply that $(x-y)^{2}+(y-z)^{2}+(z-x)^{2} \geq 6>2$.

Therefore, either $x=y=z+1$ or $x-1=y=z$. According to whether the prime $p$ is of the form $3 k+1$ or $3 k+2$, the solutions are $\left(\frac{p-1}{3}, \frac{p-1}{3}, \frac{p+2}{3}\right)$ and the corresponding permutations, or $\left(\frac{p-2}{3}, \frac{p+1}{3}, \frac{p+1}{3}\right)$ and the corresponding permutations.

(T. Andreescu, D. Andrica, An Introduction to Diophantine Equations, GIL 2002)

92. The inequality to be proved is equivalent to

$$
a^{3}+b^{3}+c^{3}-3 a b c \geq 9 k .
$$

The left-hand side can be factored, and the inequality becomes

$$
(a+b+c)\left(a^{2}+b^{2}+c^{2}-a b-b c-c a\right) \geq 9 k .
$$

Without loss of generality, we may assume that $a \geq b \geq c$. It follows that $a-b \geq 1$, $b-c \geq 1, a-c \geq 2$; hence $(a-b)^{2}+(b-c)^{2}+(c-a)^{2} \geq 1+1+4=6$. Dividing by 2 , we obtain

$$
a^{2}+b^{2}+c^{2}-a b-b c-c a \geq 3 .
$$

The solution will be complete if we show that $a+b+c \geq 3 k$. The computation

$$
\begin{aligned}
(a+b+c)^{2} &=a^{2}+b^{2}+c^{2}-a b-b c-c a+3(a b+b c+c a) \\
& \geq 3+3\left(3 k^{2}-1\right)=9 k^{2}
\end{aligned}
$$

completes the proof.

(T. Andreescu)

93. This is a difficult exercise in completing squares. We have

$$
m n p=1+\frac{x^{2}}{z^{2}}+\frac{z^{2}}{y^{2}}+\frac{x^{2}}{y^{2}}+\frac{y^{2}}{x^{2}}+\frac{y^{2}}{z^{2}}+\frac{z^{2}}{x^{2}}+1
$$



$$
=\left(\frac{x}{y}+\frac{y}{x}\right)^{2}+\left(\frac{y}{z}+\frac{z}{y}\right)^{2}+\left(\frac{z}{x}+\frac{x}{z}\right)^{2}-4 .
$$

Hence

$$
m^{2}+n^{2}+p^{2}=m n p+4 .
$$

Adding $2(m n+n p+p m)$ to both sides yields

$$
(m+n+p)^{2}=m n p+2(m n+n p+p m)+4 .
$$

Adding now $4(m+n+p)+4$ to both sides gives

$$
(m+n+p+2)^{2}=(m+2)(n+2)(p+2) .
$$

It follows that

$$
(m+2)(n+2)(p+2)=2004^{2} .
$$

But $2004=2^{2} \times 3 \times 167$, and a simple case analysis shows that the only possibilities are $(m+2, n+2, p+2)=(4,1002,1002),(1002,4,1002),(1002,1002,4)$. The desired triples are $(2,1000,1000),(1000,2,1000),(1000,1000,2)$.

(proposed by T. Andreescu for the 43rd International Mathematical Olympiad, 2002)

94. Let $M(a, b)=\max \left(a^{2}+b, b^{2}+a\right)$. Then $M(a, b) \geq a^{2}+b$ and $M(a, b) \geq b^{2}+a$, so $2 M(a, b) \geq a^{2}+b+b^{2}+a$. It follows that

$$
2 M(a, b)+\frac{1}{2} \geq\left(a+\frac{1}{2}\right)^{2}+\left(b+\frac{1}{2}\right)^{2} \geq 0,
$$

hence $M(a, b) \geq-\frac{1}{4}$. We deduce that

$$
\min _{a, b \in \mathbb{R}} M(a, b)=-\frac{1}{4},
$$

which, in fact, is attained when $a=b=-\frac{1}{2}$.

(T. Andreescu)

95. Let $a=2^{x}$ and $b=3^{x}$. We need to show that

$$
a+b-a^{2}+a b-b^{2} \leq 1 .
$$

But this is equivalent to

$$
0 \leq \frac{1}{2}\left[(a-b)^{2}+(a-1)^{2}+(b-1)^{2}\right] .
$$

The equality holds if and only if $a=b=1$, i.e., $x=0$.

(T. Andreescu, Z. Feng, 101 Problems in Algebra, Birkhäuser, 2001)

96. Clearly, 0 is not a solution. Solving for $n$ yields $\frac{-4 x-3}{x^{4}} \geq 1$, which reduces to $x^{4}+4 x+3 \leq 0$. The last inequality can be written in its equivalent form,

$$
\left(x^{2}-1\right)^{2}+2(x+1)^{2} \leq 0,
$$

whose only real solution is $x=-1$.

Hence $n=1$ is the unique solution, corresponding to $x=-1$.

(T. Andreescu)

97. If $x=0$, then $y=0$ and $z=0$, yielding the triple $(x, y, z)=(0,0,0)$. If $x \neq 0$, then $y \neq 0$ and $z \neq 0$, so we can rewrite the equations of the system in the form

$$
\begin{aligned}
&1+\frac{1}{4 x^{2}}=\frac{1}{y}, \\
&1+\frac{1}{4 y^{2}}=\frac{1}{z}, \\
&1+\frac{1}{4 z^{2}}=\frac{1}{x} .
\end{aligned}
$$

Summing up the three equations leads to

$$
\left(1-\frac{1}{x}+\frac{1}{4 x^{2}}\right)+\left(1-\frac{1}{y}+\frac{1}{4 y^{2}}\right)+\left(1-\frac{1}{z}+\frac{1}{4 z^{2}}\right)=0 .
$$

This is equivalent to

$$
\left(1-\frac{1}{2 x}\right)^{2}+\left(1-\frac{1}{2 y}\right)^{2}+\left(1-\frac{1}{2 z}\right)^{2}=0 .
$$

It follows that $\frac{1}{2 x}=\frac{1}{2 y}=\frac{1}{2 z}=1$, yielding the triple $(x, y, z)=\left(\frac{1}{2}, \frac{1}{2}, \frac{1}{2}\right)$. Both triples satisfy the equations of the system.

(Canadian Mathematical Olympiad, 1996)

98. First, note that $\left(x-\frac{1}{2}\right)^{2} \geq 0$ implies $x-\frac{1}{4} \leq x^{2}$, for all real numbers $x$. Applying this and using the fact that the $x_{i}$ 's are less than 1 , we find that

$$
\log _{x_{k}}\left(x_{k+1}-\frac{1}{4}\right) \geq \log _{x_{k}}\left(x_{k+1}^{2}\right)=2 \log _{x_{k}} x_{k+1} .
$$

Therefore,

$$
\sum_{k=1}^{n} \log _{x_{k}}\left(x_{k+1}-\frac{1}{4}\right) \geq 2 \sum_{k=1}^{n} \log _{x_{k}} x_{k+1} \geq 2 n \sqrt[n]{\frac{\ln x_{2}}{\ln x_{1}} \cdot \frac{\ln x_{3}}{\ln x_{2}} \cdots \frac{\ln x_{n}}{\ln x_{1}}}=2 n .
$$

So a good candidate for the minimum is $2 n$, which is actually attained for $x_{1}=x_{2}=$ $\cdots=x_{n}=\frac{1}{2}$.

(Romanian Mathematical Olympiad, 1984, proposed by T. Andreescu)

99. Assume the contrary, namely that $7 a+5 b+12 a b>9$. Then

$$
9 a^{2}+8 a b+7 b^{2}-(7 a+5 b+12 a b)<6-9 .
$$

Hence

$$
2 a^{2}-4 a b+2 b^{2}+7\left(a^{2}-a+\frac{1}{4}\right)+5\left(b^{2}-b+\frac{1}{4}\right)<0,
$$

or

$$
2(a-b)^{2}+7\left(a-\frac{1}{2}\right)^{2}+5\left(b-\frac{1}{2}\right)^{2}<0,
$$

a contradiction. The conclusion follows.

(T. Andreescu)

100. We rewrite the inequalities to be proved as $-1 \leq a_{k}-n \leq 1$. In this respect, we have

$$
\sum_{k=1}^{n}\left(a_{k}-n\right)^{2}=\sum_{k=1}^{n} a_{k}^{2}-2 n \sum_{k=1}^{n} a_{k}+n \cdot n^{2} \leq n^{3}+1-2 n \cdot n^{2}+n^{3}=1,
$$

and the conclusion follows.

(Math Horizons, proposed by T. Andreescu)

101. Adding up the two equations yields

$$
\left(x^{4}+2 x^{3}-x+\frac{1}{4}\right)+\left(y^{4}+2 y^{3}-y+\frac{1}{4}\right)=0 .
$$

Here we recognize two perfect squares, and write this as

$$
\left(x^{2}+x-\frac{1}{2}\right)^{2}+\left(y^{2}+y-\frac{1}{2}\right)^{2}=0 .
$$

Equality can hold only if $x^{2}+x-\frac{1}{2}=y^{2}+y-\frac{1}{2}=0$, which then gives $\{x, y\} \subset$ $\left\{-\frac{1}{2}-\frac{\sqrt{3}}{2},-\frac{1}{2}+\frac{\sqrt{3}}{2}\right\}$. Moreover, since $x \neq y,\{x, y\}=\left\{-\frac{1}{2}-\frac{\sqrt{3}}{2},-\frac{1}{2}+\frac{\sqrt{3}}{2}\right\}$. A simple verification leads to $(x, y)=\left(-\frac{1}{2}+\frac{\sqrt{3}}{2},-\frac{1}{2}-\frac{\sqrt{3}}{2}\right)$.

(Mathematical Reflections, proposed by T. Andreescu)

102. Let $n=2 k$. It suffices to prove that 

$$
\frac{1}{2} \pm x+x^{2} \pm x^{3}+x^{4} \pm \cdots \pm x^{2 k-1}+x^{2 k}>0,
$$

for all $2^{k}$ choices of the signs $+$ and $-$. This reduces to

$$
\begin{aligned}
\left(\frac{1}{2} \pm x+\frac{1}{2} x^{2}\right) &+\left(\frac{1}{2} x^{2} \pm x^{3}+\frac{1}{2} x^{4}\right) \\
&+\cdots+\left(\frac{1}{2} x^{2 k-2} \pm x^{2 k-1}+\frac{1}{2} x^{2 k}\right)+\frac{1}{2} x^{2 k}>0,
\end{aligned}
$$

which is true because $\frac{1}{2} x^{2 k-2} \pm x^{2 k-1}+\frac{1}{2} x^{2 k}=\frac{1}{2}\left(x^{k-1} \pm x^{k}\right)^{2} \geq 0$ and $\frac{1}{2} x^{2 k} \geq 0$, and the equality cases cannot hold simultaneously.

103. This is the Cauchy-Schwarz inequality applied to the numbers $a_{1}=a \sqrt{b}, a_{2}=$ $b \sqrt{c}, a_{3}=c \sqrt{a}$ and $b_{1}=c \sqrt{b}, b_{2}=a \sqrt{c}, b_{3}=b \sqrt{a}$. Indeed,

$$
\begin{aligned}
9 a^{2} b^{2} c^{2} &=(a b c+a b c+a b c)^{2}=\left(a_{1} b_{1}+a_{2} b_{2}+a_{3} b_{3}\right)^{2} \\
& \leq\left(a_{1}^{2}+a_{2}^{2}+a_{3}^{2}\right)\left(b_{1}^{2}+b_{2}^{2}+b_{3}^{2}\right)=\left(a^{2} b+b^{2} c+c^{2} a\right)\left(c^{2} b+a^{2} c+b^{2} a\right) .
\end{aligned}
$$

104. By the Cauchy-Schwarz inequality,

$$
\left(a_{1}+a_{2}+\cdots+a_{n}\right)^{2} \leq(1+1+\cdots+1)\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right) .
$$

Hence $a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2} \geq n$. Repeating, we obtain

$$
\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right)^{2} \leq(1+1+\cdots+1)\left(a_{1}^{4}+a_{2}^{4}+\cdots+a_{n}^{4}\right),
$$

which shows that $a_{1}^{4}+a_{2}^{4}+\cdots+a_{n}^{4} \geq n$, as desired.

105. Apply Cauchy-Schwarz:

$$
\begin{aligned}
\left(a_{1} a_{\sigma(a)}+a_{2} a_{\sigma(2)}+\cdots+a_{n} a_{\sigma(n)}\right)^{2} & \leq\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right)\left(a_{\sigma(1)}+a_{\sigma(2)}+\cdots+a_{\sigma(n)}^{2}\right) \\
&=\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right)^{2} .
\end{aligned}
$$

The maximum is $a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}$. The only permutation realizing it is the identity permutation.

106. Applying the Cauchy-Schwarz inequality to the numbers $\sqrt{f_{1}} x_{1}, \sqrt{f_{2}} x_{2}, \ldots$, $\sqrt{f_{n}} x_{n}$ and $\sqrt{f_{1}}, \sqrt{f_{2}}, \ldots, \sqrt{f_{n}}$, we obtain

$$
\left(f_{1} x_{1}^{2}+f_{2} x_{2}^{2}+\cdots+f_{n} x_{n}^{2}\right)\left(f_{1}+f_{2}+\cdots+f_{n}\right) \geq\left(f_{1} x_{1}+f_{2} x_{2}+\cdots+f_{n} x_{n}\right)^{2},
$$

hence the inequality from the statement. Remark. In statistics the numbers $f_{i}$ are integers that record the frequency of occurrence of the sampled random variable $x_{i}, i=1,2, \ldots, n$. If $f_{1}+f_{2}+\cdots+f_{n}=N$, then

$$
s^{2}=\frac{f_{1} x_{1}^{2}+f_{2} x_{2}^{2}+\cdots+f_{n} x_{n}^{2}-\frac{\left(f_{1} x_{1}+f_{2} x_{2}+\cdots+f_{n} x_{n}\right)^{2}}{N}}{N-1}
$$

is called the sample variance. We have just proved that the sample variance is nonnegative.

107. By the Cauchy-Schwarz inequality,

$$
\left(k_{1}+\cdots+k_{n}\right)\left(\frac{1}{k_{1}}+\cdots+\frac{1}{k_{n}}\right) \geq n^{2} .
$$

We must thus have $5 n-4 \geq n^{2}$, so $n \leq 4$. Without loss of generality, we may suppose that $k_{1} \leq \cdots \leq k_{n}$.

If $n=1$, we must have $k_{1}=1$, which is a solution. Note that hereinafter we cannot have $k_{1}=1$

If $n=2$, we have $\left(k_{1}, k_{2}\right) \in\{(2,4),(3,3)\}$, neither of which satisfies the relation from the statement.

If $n=3$, we have $k_{1}+k_{2}+k_{3}=11$, so $2 \leq k_{1} \leq 3$. Hence $\left(k_{1}, k_{2}, k_{3}\right) \in$ $\{(2,2,7),(2,3,6),(2,4,5),(3,3,5),(3,4,4)\}$, and only $(2,3,6)$ works.

If $n=4$, we must have equality in the Cauchy-Schwarz inequality, and this can happen only if $k_{1}=k_{2}=k_{3}=k_{4}=4$.

Hence the solutions are $n=1$ and $k_{1}=1, n=3$, and $\left(k_{1}, k_{2}, k_{3}\right)$ is a permutation of $(2,3,6)$, and $n=4$ and $\left(k_{1}, k_{2}, k_{3}, k_{4}\right)=(4,4,4,4)$.

(66th W.L. Putnam Mathematical Competition, 2005, proposed by T. Andreescu)

108. One can check that geometric progressions satisfy the identity. A slick proof of the converse is to recognize that we have the equality case in the Cauchy-Schwarz inequality. It holds only if $\frac{a_{0}}{a_{1}}=\frac{a_{1}}{a_{2}}=\cdots=a_{n-1} / a_{n}$, i.e., only if $a_{0}, a_{1}, \ldots, a_{n}$ is a geometric progression.

109. Let $P(x)=c_{0} x^{n}+c_{1} x^{n-1}+\cdots+c_{n}$. Then

$$
\begin{aligned}
P(a) P(b) &=\left(c_{0} a^{n}+c_{1} a^{n-1}+\cdots+c_{n}\right)\left(c_{0} b^{n}+c_{1} b^{n-1}+\cdots+c_{n}\right) \\
& \geq\left(c_{0}(\sqrt{a b})^{n}+c_{1}(\sqrt{a b})^{n-1}+\cdots+c_{n}\right)^{2}=(P(\sqrt{a b}))^{2},
\end{aligned}
$$

by the Cauchy-Schwarz inequality, and the conclusion follows.

110. First solution: If $a_{1}, a_{2}, \ldots, a_{n}$ are positive integers, the Cauchy-Schwarz inequality implies

$$
\left(a_{1}+a_{2}+\cdots+a_{n}\right)\left(\frac{1}{a_{1}}+\frac{1}{a_{2}}+\cdots+\frac{1}{a_{n}}\right) \geq n^{2} .
$$

For $a_{1}=x_{0}-x_{1}, a_{2}=x_{1}-x_{2}, \ldots, a_{n}=x_{n-1}-x_{n}$ this gives

$$
\begin{aligned}
\frac{1}{x_{0}-x_{1}}+\frac{1}{x_{1}-x_{2}}+\cdots+\frac{1}{x_{n-1}-x_{n}} & \geq \frac{n^{2}}{x_{0}-x_{1}+x_{1}-x_{2}+\cdots+x_{n-1}-x_{n}} \\
&=\frac{n^{2}}{x_{0}-x_{n}} .
\end{aligned}
$$

The inequality from the statement now follows from

$$
x_{0}+x_{n}+\frac{n^{2}}{x_{0}-x_{n}} \geq 2 n
$$

which is rather easy, because it is equivalent to

$$
\left(\sqrt{x_{0}-x_{n}}-\frac{n}{\sqrt{x_{0}-x_{n}}}\right)^{2} \geq 0
$$

Equality in Cauchy-Schwarz holds if and only if $x_{0}-x_{1}, x_{1}-x_{2}, \ldots, x_{n-1}-x_{n}$ are proportional to $\frac{1}{x_{0}-x_{1}}, \frac{1}{x_{1}-x_{2}}, \ldots, \frac{1}{x_{n-1}-x_{n}}$. This happens when $x_{0}-x_{1}=x_{1}-x_{2}=\cdots=$ $x_{n-1}-x_{n}$. Also, $\sqrt{x_{0}-x_{n}}-n / \sqrt{x_{0}-x_{n}}=0$ only if $x_{0}-x_{n}=n$. This means that the inequality from the statement becomes an equality if and only if $x_{0}, x_{1}, \ldots, x_{n}$ is an arithmetic sequence with common difference 1 .

Second solution: As before, let $a_{i}=x_{i}-x_{i+1}$. The inequality can be written as

$$
\sum_{i=1}^{n-1}\left(a_{i}+\frac{1}{a_{i}}\right) \geq 2 n .
$$

This follows immediately from $x+x^{-1} \geq 2$.

(St. Petersburg City Mathematical Olympiad, 1999, second solution by R. Stong)

111. Because

$$
\frac{1}{\sec (a-b)}=\cos (a-b)=\sin a \sin b+\cos a \cos b
$$

it suffices to show that

$$
\left(\frac{\sin ^{3} a}{\sin b}+\frac{\cos ^{3} a}{\cos b}\right)(\sin a \sin b+\cos a \cos b) \geq 1
$$

This is true because by the Cauchy-Schwarz inequality,

$$
\left(\frac{\sin ^{3} a}{\sin b}+\frac{\cos ^{3} a}{\cos b}\right)(\sin a \sin b+\cos a \cos b) \geq\left(\sin ^{2} a+\cos ^{2} a\right)^{2}=1 \text {. }
$$

112. Bring the denominator to the left:

$$
(a+b)(b+c)(c+a)\left(\frac{1}{a+b}+\frac{1}{b+c}+\frac{1}{c+a}+\frac{1}{2 \sqrt[3]{a b c}}\right) \geq(a+b+c+\sqrt[3]{a b c})^{2} .
$$

The identity

$$
(a+b)(b+c)(c+a)=c^{2}(a+b)+b^{2}(c+a)+a^{2}(b+c)+2 a b c
$$

enables us to transform this into

$$
\begin{gathered}
\left(c^{2}(a+b)+b^{2}(c+a)+a^{2}(b+c)+2 a b c\right)\left(\frac{1}{a+b}+\frac{1}{b+c}+\frac{1}{c+a}+\frac{1}{2 \sqrt[3]{a b c}}\right) \\
\geq(c+b+a+\sqrt[3]{a b c})^{2}
\end{gathered}
$$

And now we recognize the Cauchy-Schwarz inequality. Equality holds only if $a=b=c$. (Mathematical Olympiad Summer Program, T. Andreescu)

113. Let $c$ be the largest side. By the triangle inequality, $c^{n}<a^{n}+b^{n}$ for all $n \geq 1$. This is equivalent to

$$
1<\left(\frac{a}{c}\right)^{n}+\left(\frac{b}{c}\right)^{n}, \quad n \geq 1 .
$$

If $a<c$ and $b<c$, then by letting $n \rightarrow \infty$, we obtain $1<0$, impossible. Hence one of the other two sides equals $c$, and the triangle is isosceles.

114. Define $\vec{d}=-\vec{a}-\vec{b}-\vec{c}$. The inequality becomes

$$
\|\vec{a}\|+\|\vec{b}\|+\|\vec{c}\|+\|\vec{d}\| \geq\|\vec{a}+\vec{d}\|+\|\vec{b}+\vec{d}\|+\|\vec{c}+\vec{d}\| .
$$

If the angles formed by $\vec{a}$ with $\vec{b}, \vec{c}$, and $\vec{d}$ come in increasing order, then the closed polygonal line $\vec{a}, \vec{b}, \vec{c}, \vec{d}$ is a convex quadrilateral. Figure 59 shows how this quadrilateral can be transformed into one that is skew by choosing one angle such that one of the pairs of adjacent angles containing it totals at most $180^{\circ}$ and the other at least $180^{\circ}$ and then folding that angle in.

The triangle inequality implies $\|\vec{b}\|+\|\vec{c}\| \geq\|\vec{b}+\vec{d}\|+\|\vec{c}+\vec{d}\|$. To be more convincing, let us explain that the left-hand side is the sum of the lengths of the dotted segments, while the right-hand side can be decomposed into the lengths of some four segments, which together with the dotted segments form two triangles. The triangle inequality also gives $\|\vec{a}\|+\|\vec{d}\| \geq\|\vec{a}+\vec{d}\|$. Adding the two yields the inequality from the statement.

$($ Kvant $($ Quantum $))$

115. Let $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ be the roots of the polynomial, $D_{1}=\{z,|z-c| \leq R\}$ the disk covering them, and $D_{2}=\{z,|z-c| \leq R+|k|\}$. We will show that the roots of $n P(z)-k P^{\prime}(z)$ lie inside $D_{2}$. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-382.jpg?height=315&width=1125&top_left_y=258&top_left_x=305)

Figure 59

For $u \notin D_{2}$, the triangle inequality gives

$$
\left|u-\lambda_{i}\right| \geq|u-c|-\left|c-\lambda_{i}\right|>R+|k|-R=|k| .
$$

Hence $\frac{|k|}{\left|u-\lambda_{i}\right|}<1$, for $i=1,2, \ldots, n$. For such a $u$ we then have

$$
\begin{aligned}
\left|n P(u)-k P^{\prime}(u)\right| &=\left|n P(u)-k P(u) \sum_{i=1}^{n} \frac{1}{u-\lambda_{i}}\right|=|P(u)|\left|n-k \sum_{i=1}^{n} \frac{1}{u-\lambda_{i}}\right| \\
& \geq|P(u)|\left|n-\sum_{i=1}^{n} \frac{|k|}{\left|u-\lambda_{i}\right|}\right|
\end{aligned}
$$

where the last inequality follows from the triangle inequality.

But we have seen that

$$
n-\sum_{i=1}^{n} \frac{|k|}{\left|u-\lambda_{i}\right|}=\sum_{i=1}^{n}\left(1-\frac{|k|}{\left|u-\lambda_{i}\right|}\right)>0,
$$

and since $P(u) \neq 0$, it follows that $u$ cannot be a root of $n P(u)-k P^{\prime}(u)$. Thus all roots of this polynomial lie in $D_{2}$.

(17th W.L. Putnam Mathematical Competition, 1956)

116. The inequality in the statement is equivalent to

$$
\left(a^{2}+b^{2}+c^{2}\right)^{2}<4\left(a^{2} b^{2}+b^{2} c^{2}+c^{2} a^{2}\right) .
$$

The latter can be written as

$$
0<(2 b c)^{2}-\left(a^{2}-b^{2}-c^{2}\right)^{2},
$$

or

$$
\left(2 b c+b^{2}+c^{2}-a^{2}\right)\left(2 b c-b^{2}-c^{2}+a^{2}\right) .
$$

This is equivalent to

$$
0<(a+b+c)(-a+b+c)(a-b+c)(a-b-c) .
$$

It follows that $-a+b+c, a-b+c, a-b-c$ are all positive, because $a+b+c>0$, and no two of the factors could be negative, for in that case the sum of the three numbers would also be negative. Done.

117. The first idea is to simplify the problem and prove separately the inequalities $\mid A B-$ $C D|\geq| A C-B D \mid$ and $|A D-B C| \geq|A C-B D|$. Because of symmetry it suffices to prove the first.

Let $M$ be the intersection of the diagonals $A C$ and $B D$. For simplicity, let $A M=x$, $B M=y, A B=z$. By the similarity of triangles $M A B$ and $M D C$ there exists a positive number $k$ such that $D M=k x, C M=k y$, and $C D=k z$ (Figure 60). Then

$$
|A B-C D|=|k-1| z
$$

and

$$
|A C-B D|=|(k x+y)-(k y+x)|=|k-1| \cdot|x-y| .
$$

By the triangle inequality, $|x-y| \leq z$, which implies $|A B-C D| \geq|A C-B D|$, completing the proof.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-383.jpg?height=423&width=420&top_left_y=1338&top_left_x=664)

Figure 60

(USA Mathematical Olympiad, 1999, proposed by T. Andreescu, solution by P.R. Loh)

118. We induct on $m$. When $m=1$ there is nothing to prove. Now assume that the inequality holds for $m-1$ isometries and let us prove that it holds for $m$ isometries. Define $V=\prod_{i=1}^{m-1} V_{i}$ and $W=\prod_{i=1}^{m-1} W_{i}$. Both $V$ and $W$ are isometries. For a vector $x$ with $\|x\| \leq 1$, 

$$
\begin{aligned}
\left\|\left(\prod_{i=1}^{m} V_{i}\right) x-\left(\prod_{i=1}^{m} W_{i}\right) x\right\| &=\left\|V V_{m} x-W W_{m} x\right\| \\
&=\left\|V\left(V_{m}-W_{m}\right) x+(V-W) W_{m} x\right\|
\end{aligned}
$$

Now we use the triangle inequality to increase the value of this expression to

$$
\left\|V\left(V_{m}-W_{m}\right) x\right\|+\left\|(V-W) W_{m} x\right\| .
$$

From the fact that $V$ is an isometry it follows that

$$
\left\|V\left(V_{m}-W_{m}\right) x\right\|=\left\|\left(V_{m}-W_{m}\right) x\right\| \leq 1 .
$$

From the fact that $W_{m}$ is an isometry, it follows that $\left\|W_{m} x\right\| \leq 1$, and so $\left\|(V-W) W_{m} x\right\| \leq$ $m-1$ by the induction hypothesis. Putting together the two inequalities completes the induction, and the inequality is proved.

Remark. In quantum mechanics the vector spaces are complex (not real) and the word isometry is replaced by unitary. Unitary linear transformations model evolution, and the above property shows that (measurement) errors accumulate linearly.

119. Place triangle $A B C$ in the complex plane such that the coordinates of the vertices $A$, $B$, and $C$ are, respectively, the third roots of unity $1, \epsilon, \epsilon^{2}$. Call $z$ the complex coordinate of $P$. Start with the obvious identity

$$
(z-1)+\epsilon(z-\epsilon)+\epsilon^{2}\left(z-\epsilon^{2}\right)=0 .
$$

Move one term to the other side:

$$
-\epsilon^{2}\left(z-\epsilon^{2}\right)=(z-1)+\epsilon(z-\epsilon) .
$$

Now take the absolute value and use the triangle inequality:

$$
\left|z-\epsilon^{2}\right|=|(z-1)+\epsilon(z-\epsilon)| \leq|z-1|+\mid\left(\epsilon(z-\epsilon)|=| z-1|+| z-\epsilon^{2} \mid\right.
$$

Geometrically, this is $P C \leq P A+P B$

Equality corresponds to the equality case in the triangle inequality for complex numbers, which holds if the complex numbers have positive ratio. Specifically, $(z-1)=$ $a \epsilon(z-\epsilon)$ for some positive real number $a$, which is equivalent to

$$
\frac{z-1}{z-\epsilon}=a \epsilon \text {. }
$$

In geometric terms this means that $P A$ and $P B$ form an angle of $120^{\circ}$, so that $P$ is on the $\operatorname{arc} \stackrel{A B}{A}$. The other two inequalities are obtained by permuting the letters.

(D. Pompeiu) 

120. We start with the algebraic identity

$$
x^{3}(y-z)+y^{3}(z-x)+z^{3}(x-y)=(x+y+z)(x-y)(y-z)(z-x),
$$

where $x, y, z$ are complex numbers. Applying to it the triangle inequality, we obtain

$$
|x|^{3}|y-z|+|y|^{3}|z-x|+|z|^{3}|x-y| \geq|x+y+z||x-y||x-z||y-z| .
$$

So let us see how this can be applied to our problem. Place the triangle in the complex plane so that $M$ is the origin, and let $a, b$, and $c$, respectively, be the complex coordinates of $A, B, C$. The coordinate of $G$ is $\frac{(a+b+c)}{3}$, and if we set $x=a, y=b$, and $z=c$ in the inequality we just derived, we obtain the geometric inequality from the statement.

(M. Dincă, M. Chiriţă, Numere Complexe în Matematica de Liceu (Complex Numbers in High School Mathematics), ALL Educational, Bucharest, 1996)

121. Because $P(x)$ has odd degree, it has a real zero $r$. If $r>0$, then by the AM-GM inequality

$$
P(r)=r^{5}+1+1+1+2^{5}-5 \cdot 2 \cdot r \geq 0 .
$$

And the inequality is strict since $1 \neq 2$. Hence $r<0$, as desired.

122. We can rewrite the inequality as

$$
\frac{n^{n}-1}{n-1} \geq n^{\frac{n+1}{2}},
$$

or

$$
n^{n-1}+n^{n-2}+\cdots+1 \geq n^{\frac{n+1}{2}} .
$$

This form suggests the use of the AM-GM inequality, and indeed, we have

$$
1+n+n^{2}+\cdots+n^{n-1} \geq n \sqrt[n]{1 \cdot n \cdot n^{2} \cdots n^{n-1}}=n \sqrt[n]{n^{\frac{n(n-1)}{2}}}=n^{\frac{n+1}{2}},
$$

which proves the inequality.

(Gh. Călugăriţa, V. Mangu, Probleme de Matematică pentru Treapta I şi a II-a de Liceu (Mathematics Problems for High School), Editura Albatros, Bucharest, 1977)

123. The inequality is homogeneous in the sense that if we multiply some $a_{k}$ and $b_{k}$ simultaneously by a positive number, the inequality does not change. Hence we can assume that $a_{k}+b_{k}=1, k=1,2, \ldots, n$. In this case, applying the AM-GM inequality, we obtain

$$
\begin{aligned}
\left(a_{1} a_{2} \cdots a_{n}\right)^{1 / n}+\left(b_{1} b_{2} \cdots b_{n}\right)^{1 / n} & \leq \frac{a_{1}+a_{2}+\cdots+a_{n}}{n}+\frac{b_{1}+b_{2}+\cdots+b_{n}}{n} \\
&=\frac{a_{1}+b_{1}+a_{2}+b_{2}+\cdots+a_{n}+b_{n}}{n}=\frac{n}{n}=1,
\end{aligned}
$$

and the inequality is proved.

(64th W.L. Putnam Mathematical Competition, 2003)

124. The inequality from the statement is equivalent to

$$
0<1-(a+b+c)+a b+b c+c a-a b c<\frac{1}{27},
$$

that is,

$$
0<(1-a)(1-b)(1-c) \leq \frac{1}{27} .
$$

From the triangle inequalities $a+b>c, b+c>a, a+c>b$ and the condition $a+b+c=2$ it follows that $0<a, b, c<1$. The inequality on the left is now evident, and the one on the right follows from the AM-GM inequality

$$
\sqrt[3]{x y z} \leq \frac{x+y+z}{3}
$$

applied to $x=1-a, y=1-b, z=1-c$.

125. It is natural to try to simplify the product, and for this we make use of the AM-GM inequality:

$$
\prod_{n=1}^{25}\left(1-\frac{n}{365}\right) \leq\left[\frac{1}{25} \sum_{n=1}^{25}\left(1-\frac{n}{365}\right)\right]^{25}=\left(\frac{352}{365}\right)^{25}=\left(1-\frac{13}{365}\right)^{25} .
$$

We now use Newton's binomial formula to estimate this power. First, note that

$$
\left(\begin{array}{c}
25 \\
k
\end{array}\right)\left(\frac{13}{365}\right)^{k} \geq\left(\begin{array}{c}
25 \\
k+1
\end{array}\right)\left(\frac{13}{365}\right)^{k+1},
$$

since this reduces to

$$
\frac{13}{365} \leq \frac{k+1}{25-k},
$$

and the latter is always true for $1 \leq k \leq 24$. For this reason if we ignore the part of the binomial expansion beginning with the fourth term, we increase the value of the expression. In other words,

$$
\left(1-\frac{13}{365}\right)^{25} \leq 1-\left(\begin{array}{c}
25 \\
1
\end{array}\right) \frac{13}{365}+\left(\begin{array}{c}
25 \\
2
\end{array}\right) \frac{13^{2}}{365^{2}}=1-\frac{65}{73}+\frac{169 \cdot 12}{63^{2}}<\frac{1}{2} .
$$

We conclude that the second number is larger.

(Soviet Union University Student Mathematical Olympiad, 1975) 

126. The solution is based on the Lagrange identity, which in our case states that if $M$ is a point in space and $G$ is the centroid of the tetrahedron $A B C D$, then

$$
\begin{aligned}
& A B^{2}+A C^{2}+C D^{2}+A D^{2}+B C^{2}+B D^{2} \\
& =4\left(M A^{2}+M B^{2}+M C^{2}+M D^{2}\right)-16 M G^{2} \text {. }
\end{aligned}
$$

For $M=O$ the center of the circumscribed sphere, this reads

$$
A B^{2}+A C^{2}+C D^{2}+A D^{2}+B C^{2}+B D^{2}=16-16 O G^{2} .
$$

Applying the AM-GM inequality, we obtain

$$
6 \sqrt[3]{A B \cdot A C \cdot C D \cdot A D \cdot B C \cdot B D} \leq 16-16 O G^{2} .
$$

This combined with the hypothesis yields $16 \leq 16-O G^{2}$. So on the one hand we have equality in the AM-GM inequality, and on the other hand $O=G$. Therefore, $A B=A C=A D=B C=B D=C D$, so the tetrahedron is regular.

127. Adding 1 to all fractions transforms the inequality into

$$
\frac{x^{2}+y^{2}+1}{2 x^{2}+1}+\frac{y^{2}+z^{2}+1}{2 y^{2}+1}+\frac{z^{2}+x^{2}+1}{2 z^{2}+1} \geq 3 .
$$

Applying the AM-GM inequality to the left-hand side gives

$$
\begin{aligned}
&\frac{x^{2}+y^{2}+1}{2 x^{2}+1}+\frac{y^{2}+z^{2}+1}{2 y^{2}+1}+\frac{z^{2}+x^{2}+1}{2 z^{2}+1} \\
&\geq 3 \sqrt[3]{\frac{x^{2}+y^{2}+1}{2 x^{2}+1} \cdot \frac{y^{2}+z^{2}+1}{2 y^{2}+1} \cdot \frac{z^{2}+x^{2}+1}{2 z^{2}+1}} .
\end{aligned}
$$

We are left with the simpler but sharper inequality

$$
\frac{x^{2}+y^{2}+1}{2 x^{2}+1} \cdot \frac{y^{2}+z^{2}+1}{2 y^{2}+1} \cdot \frac{z^{2}+x^{2}+1}{2 z^{2}+1} \geq 1 .
$$

This can be proved by multiplying together

$$
\begin{gathered}
x^{2}+y^{2}+1=x^{2}+\frac{1}{2}+y^{2}+\frac{1}{2} \geq 2 \sqrt{\left(x^{2}+\frac{1}{2}\right)\left(y^{2}+\frac{1}{2}\right)}, \\
y^{2}+z^{2}+1=y^{2}+\frac{1}{2}+z^{2}+\frac{1}{2} \geq 2 \sqrt{\left(y^{2}+\frac{1}{2}\right)\left(z^{2}+\frac{1}{2}\right)}, \\
z^{2}+x^{2}+1=z^{2}+\frac{1}{2}+x^{2}+\frac{1}{2} \geq 2 \sqrt{\left(z^{2}+\frac{1}{2}\right)\left(y^{2}+\frac{1}{2}\right)},
\end{gathered}
$$

and each of these is just the AM-GM inequality.

(Greek Team Selection Test for the Junior Balkan Mathematical Olympiad, 2005)

128. Denote the positive number $1-\left(a_{1}+a_{2}+\cdots+a_{n}\right)$ by $a_{n+1}$. The inequality from the statement becomes the more symmetric

$$
\frac{a_{1} a_{2} \cdots a_{n} a_{n+1}}{\left(1-a_{1}\right)\left(1-a_{2}\right) \cdots\left(1-a_{n}\right)\left(1-a_{n+1}\right)} \leq \frac{1}{n^{n+1}} .
$$

But from the AM-GM inequality,

$$
\begin{aligned}
1-a_{1}=a_{2}+a_{3}+\cdots+a_{n+1} & \geq n \sqrt[n]{a_{2} a_{3} \cdots a_{n+1}}, \\
1-a_{2} &=a_{1}+a_{3}+\cdots+a_{n+1} \geq n \sqrt[n]{a_{1} a_{3} \cdots a_{n+1}}, \\
& \cdots \\
1-a_{n+1} &=a_{1}+a_{2}+\cdots+a_{n} \geq n \sqrt[n]{a_{1} a_{2} \cdots a_{n}} .
\end{aligned}
$$

Multiplying these $n+1$ inequalities yields

$$
\left(1-a_{1}\right)\left(1-a_{2}\right) \cdots\left(1-a_{n+1}\right) \geq n^{n+1} a_{1} a_{2} \cdots a_{n},
$$

and the conclusion follows.

(short list of the 43rd International Mathematical Olympiad, 2002)

129. Trick number 1: Use the fact that

$$
1=\frac{n-1+x_{j}}{n-1+x_{j}}=(n-1) \frac{1}{n-1+x_{j}}+\frac{x_{j}}{n-1+x_{j}}, \quad j=1,2, \ldots, n,
$$

to transform the inequality into

$$
\frac{x_{1}}{n-1+x_{1}}+\frac{x_{2}}{n-1+x_{2}}+\cdots+\frac{x_{n}}{n-1+x_{n}} \geq 1 .
$$

Trick number 2: Break this into the $n$ inequalities

$$
\frac{x_{j}}{n-1+x_{j}} \geq \frac{x_{j}^{1-\frac{1}{n}}}{x_{1}^{1-\frac{1}{n}}+x_{2}^{1-\frac{1}{n}}+\cdots+x_{n}^{1-\frac{1}{n}}}, \quad j=1,2, \ldots, n .
$$

We are left with $n$ somewhat simpler inequalities, which can be rewritten as

$$
x_{1}^{1-\frac{1}{n}}+x_{2}^{1-\frac{1}{n}}+x_{j-1}^{1-\frac{1}{n}}+x_{j+1}^{1-\frac{1}{n}}+\cdots+x_{n}^{1-\frac{1}{n}} \geq(n-1) x_{j}^{-\frac{1}{n}} .
$$

Trick number 3: Use the AM-GM inequality 

$$
\begin{aligned}
\frac{x_{1}^{1-\frac{1}{n}}+x_{2}^{1-\frac{1}{n}}+x_{j-1}^{1-\frac{1}{n}}+x_{j+1}^{1-\frac{1}{n}}+\cdots+x_{n}^{1-\frac{1}{n}}}{n-1} & \geq\left(\left(x_{1} x_{2} \cdots x_{j-1} x_{j+1} \cdots x_{n}\right)^{\frac{n-1}{n}}\right)^{\frac{1}{n-1}} \\
&=\left(x_{1} x_{2} \cdots x_{j-1} x_{j+1} \cdots x_{n}\right)^{\frac{1}{n}}=x_{j}^{-\frac{1}{n}} .
\end{aligned}
$$

This completes the proof.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1999, proposed by V. Cârtoaje and Gh. Eckstein)

130. First solution: Note that the triple $(a, b, c)$ ranges in the closed and bounded set $D=\left\{(x, y, z) \in \mathbb{R}^{3} \mid 0 \leq x, y, z \leq 1, x+y+z=1\right\}$. The function $f(x, y, z)=$ $4(x y+y z+x z)-9 x y z-1$ is continuous; hence it has a maximum on $D$. Let $(a, b, c)$ be a point in $D$ at which $f$ attains this maximum. By symmetry we may assume that $a \geq b \geq c$. This immediately implies $c \leq \frac{1}{3}$.

Let us apply Sturm's method. Suppose that $b<a$, and let $0<x<a-b$. We show that $f(a-x, b+x, c)>f(a, b, c)$. The inequality is equivalent to

$$
4(a-x)(b+x)-9(a-x)(b+x) c>4 a b-9 a b c
$$

or

$$
(4-9 c)\left((a-b) x-x^{2}\right)>0
$$

and this is obviously true. But this contradicts the fact that $(a, b, c)$ was a maximum. Hence $a=b$. Then $c=1-2 a$, and it suffices to show that $f(a, a, 1-2 a) \leq 0$. Specifically, this means

$$
4 a^{2}-8 a(1-2 a)-9 a^{2}(1-2 a)-1 \leq 0
$$

The left-hand side factors as $-(1-2 a)(3 a-1)^{2}=-c(3 a-1)^{2}$, which is negative or zero. The inequality is now proved. Moreover, we have showed that the only situations in which equality is attained occur when two of the numbers are equal to $\frac{1}{2}$ and the third is 0 , or when all three numbers are equal to $\frac{1}{3}$.

Second solution: A solution is possible using the Viète relations. Here it is. Consider the polynomial

$$
P(x)=(x-a)(x-b)(x-c)=x^{3}-x^{2}+(a b+b c+c a) x-a b c
$$

the monic polynomial of degree 3 whose roots are $a, b, c$. Because $a+b+c=1$, at most one of the numbers $a, b, c$ can be equal to or exceed $\frac{1}{2}$. If any of these numbers is greater than $\frac{1}{2}$, then

$$
P\left(\frac{1}{2}\right)=\left(\frac{1}{2}-a\right)\left(\frac{1}{2}-b\right)\left(\frac{1}{2}-c\right)<0
$$

This implies

$$
\frac{1}{8}-\frac{1}{4}+\frac{1}{2}(a b+b c+c a)-a b c<0,
$$

and so $4(a b+b c+c a)-8 a b c \leq 1$, and the desired inequality holds.

If $\frac{1}{2}-a \geq 0, \frac{1}{2}-b \geq 0, \frac{1}{2}-c \geq 0$, then

$$
2 \sqrt{\left(\frac{1}{2}-a\right)\left(\frac{1}{2}-b\right)} \leq\left(\frac{1}{2}-a\right)+\left(\frac{1}{2}-b\right)=1-a-b=c .
$$

Similarly,

$$
2 \sqrt{\left(\frac{1}{2}-b\right)\left(\frac{1}{2}-c\right)} \leq a \text { and } 2 \sqrt{\left(\frac{1}{2}-c\right)\left(\frac{1}{2}-a\right)} \leq b .
$$

It follows that

$$
8\left(\frac{1}{2}-a\right)\left(\frac{1}{2}-b\right)\left(\frac{1}{2}-c\right) \leq a b c,
$$

and the desired inequality follows.

(Mathematical Reflections, proposed by T. Andreescu)

131. If $x_{i}<x_{j}$ for some $i$ and $j$, increase $x_{i}$ and decrease $x_{j}$ by some number $a$, $0<a \leq x_{j}-x_{i}$. We need to show that

$$
\left(1+\frac{1}{x_{i}+a}\right)\left(1+\frac{1}{x_{j}-a}\right)<\left(1+\frac{1}{x_{i}}\right)\left(1+\frac{1}{x_{j}}\right),
$$

or

$$
\frac{\left(x_{i}+a+1\right)\left(x_{j}-a+1\right)}{\left(x_{i}+a\right)\left(x_{j}-a\right)}<\frac{\left(x_{i}+1\right)\left(x_{j}+1\right)}{x_{i} x_{j}} .
$$

All denominators are positive, so after multiplying out and canceling terms, we obtain the equivalent inequality

$$
-a x_{i}^{2}+a x_{j}^{2}-a^{2} x_{i}-a^{2} x_{j}-a x_{i}+a x_{j}-a^{2}>0 .
$$

This can be rewritten as

$$
a\left(x_{j}-x_{i}\right)\left(x_{j}+x_{i}+1\right)>a^{2}\left(x_{j}+x_{i}+1\right),
$$

which is true, since $a<x_{j}-x_{i}$. Starting with the smallest and the largest of the numbers, we apply the trick and make one of the numbers equal to $\frac{1}{n}$ by decreasing the value of the expression. Repeating, we can decrease the expression to one in which all numbers are equal to $\frac{1}{n}$. The value of the latter expression is $(n+1)^{n}$. This concludes the proof.

132. Project orthogonally the ellipse onto a plane to make it a circle. Because all areas are multiplied by the same constant, namely the cosine of the angle made by the plane of the ellipse and that of the projection, the problem translates to finding the largest area triangles inscribed in a given circle. We apply Sturm's principle, after we guess that all these triangles have to be equilateral.

Starting with a triangle that is not equilateral, two cases can be distinguished. Either the triangle is obtuse, in which case it lies inside a semidisk. Then its area is less than half the area of the disk, and consequently smaller than the area of the inscribed equilateral triangle. Or otherwise the triangle is acute. This is the case to which we apply the principle.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-391.jpg?height=362&width=366&top_left_y=874&top_left_x=684)

Figure 61

One of the sides of the triangle is larger than the side of the equilateral triangle and one is smaller (since some side must subtend an arc greater than $\frac{2 \pi}{3}$ and another an arc smaller than $\frac{2 \pi}{3}$ ). Moving the vertex on the circle in the direction of the longer side increases the area, as seen in Figure 61. We stop when one of the two sides becomes equal to the side of the equilateral triangle. Repeating the procedure for the other two sides, we eventually reach an equilateral triangle. In the process we kept increasing the area. Therefore, the inscribed triangles that maximize the area are the equilateral triangles (this method also proves that the maximum exists). These triangles are exactly those whose centroid coincides with the center of the circle. Returning to the ellipse, since the orthogonal projection preserves centroids, we conclude that the maximal-area triangles inscribed an ellipse are those with the centroid at the center of the ellipse.

Remark. This last argument can be applied mutatis mutandis to show that of all $n$-gons inscribed in a certain circle, the regular one has the largest area.

(12th W.L. Putnam Mathematical Competition, 1952)

133. The first inequality follows easily from $a b \geq a b c$ and $b c \geq a b c$. For the second, define $E(a, b, c)=a b+b c+a c-2 a b c$. Assume that $a \leq b \leq c, a<c$, and let $\alpha=\min \left(\frac{1}{3}-a, c-\frac{1}{3}\right)$, which is a positive number. We compute 

$$
E(a+\alpha, b, c-\alpha)=E(a, b, c)+\alpha(1-2 b)[(c-a)-\alpha] .
$$

Since $b \leq c$ and $a+b+c=1$, we have $b \leq \frac{1}{2}$. This means that $E(a+\alpha, b, c-\alpha) \geq$ $E(a, b, c)$. So we were able to make one of $a$ and $c$ equal to $\frac{1}{3}$ by increasing the value of the expression. Repeating the argument for the remaining two numbers, we are able to increase $E(a, b, c)$ to $E\left(\frac{1}{3}, \frac{1}{3}, \frac{1}{3}\right)=\frac{7}{27}$. This proves the inequality. (communicated by V. Grover)

134. The inequality from the statement can be rewritten as

$$
\frac{\prod_{j=1}^{n} x_{j}}{\prod_{j=1}^{n}\left(1-x_{j}\right)} \leq \frac{\left(\sum_{j=1}^{n} x_{j}\right)^{n}}{\left(\sum_{j=1}^{n}\left(1-x_{j}\right)\right)^{n}} .
$$

If we fix the sum $S=x_{1}+x_{2}+\cdots+x_{n}$, then the right-hand side is constant, being equal to $\left(\frac{S}{n-S}\right)^{n}$. We apply Sturm's principle to the left-hand side. If the $x_{j}$ 's are not all equal, then there exist two of them, $x_{k}$ and $x_{l}$, with $x_{k}<\frac{s}{n}<x_{l}$. We would like to show that by adding a small positive number $\alpha$ to $x_{k}$ and subtracting the same number from $x_{l}$ the expression grows. This reduces to

$$
\frac{\left(x_{k}+\alpha\right)\left(x_{l}-\alpha\right)}{\left(1-x_{k}-\alpha\right)\left(1-x_{l}+\alpha\right)}<\frac{x_{k} x_{l}}{\left(1-x_{k}\right)\left(1-x_{l}\right)} .
$$

Some computations transform this into

$$
\alpha\left(1-x_{k}-x_{l}\right)\left(x_{l}-x_{k}-\alpha\right)>0,
$$

which is true if $\alpha<x_{l}-x_{k}$. Choosing $\alpha=x_{l}-\frac{s}{n}$ allows us to transform $x_{l}$ into $\frac{s}{n}$ by this procedure. One by one we make the numbers equal to $\frac{S}{n}$, increasing the value of the expression on the left each time. The fact that in this case we achieve equality proves the inequality in the general case.

(Indian Team Selection Test for the International Mathematical Olympiad, 2004)

135. We apply the same kind of reasoning, varying the parameters until we reach the maximum. To find the maximum of $\sqrt{a}+\sqrt{b}+\sqrt{c}+\sqrt{d}$, we increase the sum $a+b+c+d$ until it reaches the upper limit 30. Because $a+b+c \leq 14$ it follows that $d \geq 16$. Now we fix $a, b$ and vary $c, d$ to maximize $\sqrt{c}+\sqrt{d}$. This latter expression is maximal if $c$ and $d$ are closest to $\frac{c+d}{2}$. But since $c+d \leq 30, \frac{c+d}{2} \leq 15$. So in order to maximize $\sqrt{c}+\sqrt{d}$, we must choose $d=16$.

Now we have $a+b+c=14, a+b \leq 5$, and $a \leq 1$. The same argument carries over to show that in order to maximize $\sqrt{a}+\sqrt{b}+\sqrt{c}$ we have to choose $c=9$. And the reasoning continues to show that $a$ has to be chosen 1 and $b$ has to be 4 .

We conclude that under the constraints $a \leq 1, a+b \leq 5, a+b+c \leq 14$, and $a+b+c+d \leq 30$, the sum $\sqrt{a}+\sqrt{b}+\sqrt{c}+\sqrt{d}$ is maximal when $a=1, b=4$, $c=9, d=16$, in which case the sum of the square roots is equal to 10 . The inequality is proved.

\section{(V. Cârtoaje)}

136. There exist finitely many $n$-tuples of positive integers with the sum equal to $m$, so the expression from the statement has indeed a maximal value.

We show that the maximum is not attained if two of the $x_{i}$ 's differ by 2 or more. Without loss of generality, we may assume that $x_{1} \leq x_{2}-2$. Increasing $x_{1}$ by 1 and decreasing $x_{2}$ by 1 yields

$$
\begin{array}{r}
\sum_{2<i<j} x_{i} x_{j}+\left(x_{1}+1\right) \sum_{2<i} x_{i}+\left(x_{2}-1\right) \sum_{2<i} x_{i}+\left(x_{1}+1\right)\left(x_{2}-1\right) \\
=\sum_{2<i<j} x_{i} x_{j}+x_{1} \sum_{2<i} x_{i}+x_{2} \sum_{2<i} x_{i}+x_{1} x_{2}-x_{1}+x_{2}+1 .
\end{array}
$$

The sum increased by $x_{2}-x_{1}-1 \geq 1$, and hence the original sum was not maximal.

This shows that the expression attains its maximum for a configuration in which the $x_{i}$ 's differ from each other by at most 1 . If $\frac{m}{n}=r n+s$, with $0 \leq s<n$, then for this to happen $n-s$ of the $x_{i}$ 's must be equal to $r+1$ and the remaining must be equal to $r$. This gives that the maximal value of the expression must be equal to

$$
\frac{1}{2}(n-s)(n-s-1) r^{2}+s(n-s) r(r+1)+\frac{1}{2} s(s-1)(r+1)^{2} .
$$

(Mathematical Olympiad Summer Program 2002, communicated by Z. Sunik)

137. There are finitely many such products, so a smallest product does exist. Examining the $2 \times 2,3 \times 3$, and $4 \times 4$ arrays, we conjecture that the smallest product is attained on the main diagonal and is $1 \cdot 3 \cdots 5 \cdots(2 n-1)$. To prove this, we show that if the permutation $\sigma$ of $\{1,2, \ldots, n\}$ has an inversion, then $a_{1 \sigma(1)} a_{2 \sigma(2)} \cdots a_{n \sigma(n)}$ is not minimal.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-393.jpg?height=258&width=443&top_left_y=1592&top_left_x=646)

Figure 62

So assume that the inversion gives rise to the factors $i+(j+k)-1$ and $(i+m)+j-1$ in the product. Let us replace them with $i+j-1$ and $(i+m)+(j+k)-1$, as shown in Figure 62. The product of the first pair is

$$
i^{2}+i k+i(j-1)+m i+m k+m(j-1)+(j-1) i+(j-1) k+(j-1)^{2},
$$

while the product of the second pair is

$$
i^{2}+i m+i k+i(j-1)+(j-1) m+(j-1) k+(j-1)^{2} .
$$

We can see that the first of these expressions exceeds the second by $m k$. This proves that if the permutation has an inversion, then the product is not minimal. The only permutation without inversions is the identity permutation. By Sturm's principle, it is the permutation for which the minimum is attained. This minimum is $1 \cdot 3 \cdots 5 \cdots(2 n-1)$, as claimed.

138. Order the numbers $x_{1}<x_{2}<\cdots<x_{n}$ and call the expression from the statement $E\left(x_{1}, x_{2}, \ldots, x_{n}\right)$. Note that $E\left(x_{1}, x_{2}, \ldots, x_{n}\right)>\frac{x_{n}^{2}}{n}$, which shows that as the variables tend to infinity, so does the expression. This means that the minimum exists. Assume that the minimum is attained at the point $\left(y_{1}, y_{2}, \ldots, y_{n}\right)$. If $y_{n}-y_{1}>n$ then there exist indices $i$ and $j, i<j$, such that $y_{1}, \ldots, y_{i}+1, \ldots, y_{j}-1, \ldots, y_{n}$ are still distinct integers. When substituting these numbers into $E$ the denominator stays constant while the numerator changes by $3\left(y_{j}+y_{i}\right)\left(y_{j}-y_{i}-1\right)$, a negative number, decreasing the value of the expression. This contradicts the minimality. We now look at the case with no gaps: $y_{n}-y_{1}=n-1$. Then there exists $a$ such that $y_{1}=a+1, y_{2}=a+2, \ldots, y_{n}=a+n$. We have

$$
\begin{aligned}
E\left(y_{1}, \ldots, y_{n}\right) &=\frac{n a^{3}+3 \frac{n(n+1)}{2} a^{2}+\frac{n(n+1)(2 n+1)}{2} a+\frac{n^{2}(n+1)^{2}}{4}}{n a+\frac{n(n+1)}{2}} \\
&=\frac{a^{3}+\frac{3(n+1)}{2} a^{2}+\frac{(n+1)(2 n+1)}{2} a+\frac{n(n+1)^{2}}{4}}{a+\frac{n+1}{2}} .
\end{aligned}
$$

When $a=0$ this is just $\frac{n(n+1)}{2}$. Subtracting this value from the above, we obtain

$$
\frac{a^{3}+\frac{3(n+1)}{2} a^{2}+\left[\frac{(n+1)(2 n+1)}{2}-\frac{n(n+1)}{2}\right] a}{a+\frac{n+1}{2}}>0 .
$$

We deduce that $\frac{n(n+1)}{2}$ is a good candidate for the minimum.

If $y_{n}-y_{1}=n$, then there exist $a$ and $k$ such that $y_{1}=a, \ldots, y_{k}=a+k-1, y_{k+1}=$ $a+k+1, \ldots, y_{n}=a+n$. Then

$$
\begin{aligned}
E\left(y_{1}, \ldots, y_{n}\right) &=\frac{a^{3}+\cdots+(a+k-1)^{3}+(a+k+1)^{3}+\cdots+(a+n)^{3}}{a+\cdots+(a+k-1)+(a+k+1)+\cdots+(a+n)} \\
&=\frac{\sum_{j=0}^{n}(a+j)^{3}-(a+k)^{3}}{\sum_{j=0}^{n}(a+j)-(a+k)} \\
&=\frac{n a^{3}+3\left[\frac{n(n+1)}{2}-k\right] a^{2}+3\left[\frac{n(n+1)(2 n+1)}{6}-k^{2}\right] a+\left[\frac{n^{2}(n+1)^{2}}{4}-k^{3}\right]}{n a+\frac{n(n+1)}{2}-k} .
\end{aligned}
$$

Subtracting $\frac{n(n+1)}{2}$ from this expression, we obtain

$$
\frac{n a^{3}+3\left[\frac{n(n+1)}{2}-k\right] a^{2}+\left[\frac{n(n+1)(2 n+1)}{2}-3 k^{2}-\frac{n^{2}(n+1)}{2}\right] a-k^{3}+\frac{n(n+1)}{2} k}{n a+\frac{n(n+1)}{2}-k} .
$$

The numerator is the smallest when $k=n$ and $a=1$, in which case it is equal to 0 . Otherwise, it is strictly positive, proving that the minimum is not attained in that case. Therefore, the desired minimum is $\frac{n(n+1)}{2}$, attained only if $x_{k}=k, k=1,2, \ldots, n$.

(American Mathematical Monthly, proposed by C. Popescu)

139. First, note that the inequality is obvious if either $x$ or $y$ is at least 1 . For the case $x, y \in(0,1)$, we rely on the inequality

$$
a^{b} \geq \frac{a}{a+b-a b},
$$

which holds for $a, b \in(0,1)$. To prove this new inequality, write it as

$$
a^{1-b} \leq a+b-a b,
$$

and then use the Bernoulli inequality to write

$$
a^{1-b}=(1+a-1)^{1-b} \leq 1+(a-1)(1-b)=a+b-a b .
$$

Using this, we have

$$
x^{y}+y^{x} \geq \frac{x}{x+y-x y}+\frac{y}{x+y-x y}>\frac{x}{x+y}+\frac{y}{x+y}=1,
$$

completing the solution to the problem,

(French Mathematical Olympiad, 1996)

140. We have

$$
x^{5}-x^{2}+3 \geq x^{3}+2,
$$

for all $x \geq 0$, because this is equivalent to $\left(x^{3}-1\right)\left(x^{2}-1\right) \geq 0$. Thus

$$
\left(a^{5}-a^{2}+3\right)\left(b^{5}-b^{2}+3\right)\left(c^{5}-c^{2}+3\right) \geq\left(a^{3}+1+1\right)\left(1+b^{3}+1\right)\left(1+1+c^{3}\right) .
$$

Let us recall Hölder's inequality, which in its most general form states that for $r_{1}, r_{2}, \ldots$, $r_{k}>0$, with $\frac{1}{r_{1}}+\frac{1}{r_{2}}+\cdots+\frac{1}{r_{k}}=1$ and for positive real numbers $a_{i j}, i=1,2, \ldots, k$, $j=1,2, \ldots, n$,

$$
\sum_{i=1}^{n} a_{1 i} a_{2 i} \cdots a_{k i} \leq\left(\sum_{i=1}^{n} a_{1 i}^{r_{1}}\right)^{\frac{1}{r_{1}}}\left(\sum_{i=1}^{n} a_{2 i}^{r_{2}}\right)^{\frac{1}{r_{2}}} \ldots\left(\sum_{i=1}^{n} a_{k i}^{r_{k}}\right)^{\frac{1}{r_{k}}} .
$$

Applying it for $k=n=3, r_{1}=r_{2}=r_{3}=3$, and the numbers $a_{11}=a, a_{12}=1, a_{13}=1$, $a_{21}=1, a_{22}=b, a_{23}=1, a_{31}=1, a_{32}=1, a_{33}=c$, we obtain

$$
(a+b+c) \leq\left(a^{3}+1+1\right)^{\frac{1}{3}}\left(1+b^{3}+1\right)^{\frac{1}{3}}(1+1+c)^{\frac{1}{3}} .
$$

We thus have

$$
\left(a^{3}+1+1\right)\left(1+b^{3}+1\right)\left(1+1+c^{3}\right) \geq(a+b+c)^{3},
$$

and the inequality is proved.

(USA Mathematical Olympiad, 2004, proposed by T. Andreescu)

141. Let $x_{i}, i=1,2, \ldots, n, x_{i}>0$, be the roots of the polynomial. Using the relations between the roots and the coefficients, we obtain

$$
\sum x_{1} x_{2} \cdots x_{m}=\left(\begin{array}{c}
n \\
m
\end{array}\right) \text { and } \sum x_{1} x_{2} \cdots x_{p}=\left(\begin{array}{c}
n \\
p
\end{array}\right) .
$$

The generalized Maclaurin inequality

$$
\sqrt[m]{\frac{\sum x_{1} x_{2} \cdots x_{m}}{\left(\begin{array}{l}
n \\
m
\end{array}\right)}} \geq \sqrt[p]{\frac{\sum x_{1} x_{2} \cdots x_{p}}{\left(\begin{array}{l}
n \\
p
\end{array}\right)}}
$$

thus becomes equality. This is possible only if $x_{1}=x_{2}=\cdots=x_{n}$. Since $\sum x_{1} x_{2} \cdots x_{m}=\left(\begin{array}{c}n \\ m\end{array}\right)$, it follows that $x_{i}=1, i=1,2, \ldots, n$, and hence $P(x)=(x-1)^{n}$.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

142. The idea of the solution is to reduce the inequality to a particular case of the Huygens inequality,

$$
\prod_{i=1}^{n}\left(a_{i}+b_{i}\right)^{p_{i}} \geq \prod_{i=1}^{n} a_{i}^{p_{i}}+\prod_{i=1}^{n} b_{i}^{p_{i}},
$$

which holds for positive real numbers $p_{1}, p_{2}, \ldots, p_{n}, a_{1}, a_{2}, \ldots, a_{n}, b_{1}, b_{2}, \ldots, b_{n}$ with $p_{1}+p_{2}+\cdots+p_{n}=1$.

To this end, start with

$$
\frac{n-x_{i}}{1-x_{i}}=1+\frac{n-1}{x_{1}+\cdots+x_{i-1}+x_{i+1}+\cdots+x_{n}}
$$

and apply the AM-GM inequality to get

$$
\frac{n-x_{i}}{1-x_{i}} \leq 1+\frac{1}{\sqrt[n-1]{x_{1} \cdots x_{i-1} x_{i+1} \cdots x_{n}}} .
$$

Multiplying all $n$ inequalities gives

$$
\prod_{i=1}^{n}\left(\frac{n-x_{i}}{1-x_{i}}\right) \leq \prod_{i=1}^{n}\left(1+\frac{1}{\sqrt[n-1]{x_{1} \cdots x_{i-1} x_{i+1} \cdots x_{n}}}\right) .
$$

Thus we are left to prove

$$
\prod_{i=1}^{n}\left(1+\frac{1}{x_{i}}\right) \geq \prod_{i=1}^{n}\left(1+\frac{1}{\sqrt[n-1]{x_{1} \cdots x_{i-1} x_{i+1} \cdots x_{n}}}\right) .
$$

This inequality is a product of the individual inequalities

$$
\prod_{j \neq i}\left(1+\frac{1}{x_{j}}\right) \geq\left(1+\sqrt[n-1]{\prod_{j \neq i} \frac{1}{x_{i}}}\right)^{n-1}, \quad j=1,2, \ldots, n .
$$

Each of these is Huygens' inequality applied to the numbers $1,1, \ldots, 1$ and $\frac{1}{x_{1}}, \ldots, \frac{1}{x_{i-1}}$, $\frac{1}{x_{i+1}}, \ldots, x_{n}$, with $p_{1}=p_{2}=\cdots=p_{n}=\frac{1}{n-1}$.

(Crux Mathematicorum, proposed by W. Janous)

143. We will use the following inequality of Aczèl: If $x_{1}, x_{2}, \ldots, x_{m}, y_{1}, y_{2}, \ldots, y_{m}$ are real numbers such that $x_{1}^{2}>x_{2}^{2}+\cdots+x_{m}^{2}$, then

$$
\left(x_{1} y_{1}-x_{2} y_{2}-\cdots-x_{m} y_{m}\right)^{2} \geq\left(x_{1}^{2}-x_{2}^{2}-\cdots-x_{m}^{2}\right)\left(y_{1}^{2}-y_{2}^{2}-\cdots-y_{m}^{2}\right) .
$$

This is proved in the following way. Consider

$$
f(t)=\left(x_{1} t+y_{1}\right)^{2}-\sum_{i=2}^{m}\left(x_{i} t+y_{i}\right)^{2}
$$

and note that $f\left(-\frac{y_{1}}{x_{1}}\right) \leq 0$. It follows that the discriminant of the quadratic function $f(t)$ is nonnegative. This condition that the discriminant is nonnegative is basically Aczèl's inequality.

Let us return to the problem. It is clear that $a_{1}^{2}+a_{2}+\cdots+a_{n}^{2}-1$ and $b_{1}^{2}+b_{2}^{2}+\cdots+b_{n}^{2}-1$ have the same sign. If

$$
1>a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2} \text { or } 1>b_{1}^{2}+b_{2}^{2}+\cdots+b_{n}^{2},
$$

then by Aczèl's inequality,

$$
\left(1-a_{1} b_{1}-\cdots-a_{n} b_{n}\right)^{2} \geq\left(1-a_{1}^{2}-a_{2}^{2}-\cdots-a_{n}^{2}\right)\left(1-b_{1}^{2}-b_{2}^{2}-\cdots-b_{n}^{2}\right),
$$

which contradicts the hypothesis. The conclusion now follows.

(USA Team Selection Test for the International Mathematical Olympiad, proposed by T. Andreescu and D. Andrica)

144. The solution is based on the Muirhead inequality. Theorem. If $a_{1}, a_{2}, a_{3}, b_{1}, b_{2}, b_{3}$ are real numbers such that

$$
\begin{array}{cc}
a_{1} \geq a_{2} \geq a_{3} \geq 0, & b_{1} \geq b_{2} \geq b_{3} \geq 0, \quad a_{1} \geq b_{1}, \quad a_{1}+a_{2} \geq b_{1}+b_{2}, \\
& a_{1}+a_{2}+a_{3}=b_{1}+b_{2}+b_{3},
\end{array}
$$

then for any positive real numbers $x, y, z$, one has

$$
\sum_{\text {sym }} x^{a_{1}} y^{a_{2}} z^{a_{3}} \geq \sum_{\text {sym }} x^{b_{1}} y^{b_{2}} z^{b_{3}}
$$

where the index sym signifies that the summation is over all permutations of $x, y, z$.

Using the fact that $a b c=1$, we rewrite the inequality as

$$
\frac{1}{a^{3}(b+c)}+\frac{1}{b^{3}(c+a)}+\frac{1}{c^{3}(a+b)} \geq \frac{3}{2(a b c)^{4 / 3}} \text {. }
$$

Set $a=x^{3}, b=y^{3}, c=z^{3}$, with $x, y, z>0$. The inequality becomes

$$
\sum_{\text {cyclic }} \frac{1}{x^{9}\left(y^{3}+z^{3}\right)} \geq \frac{3}{2 x^{4} y^{4} z^{4}}
$$

Clearing denominators, this becomes

$$
\sum_{\text {sym }} x^{12} y^{12}+2 \sum_{\text {sym }} x^{12} y^{9} z^{3}+\sum_{\text {sym }} x^{9} y^{9} z^{6} \geq 3 \sum_{\text {sym }} x^{11} y^{8} z^{5}+6 x^{8} y^{8} z^{8}
$$

or

$$
\begin{aligned}
& \left(\sum_{\text {sym }} x^{12} y^{12}-\sum_{\text {sym }} x^{11} y^{8} z^{5}\right)+2\left(\sum_{\text {sym }} x^{12} y^{9} z^{3}-\sum_{\text {sym }} x^{11} y^{8} z^{5}\right) \\
& +\left(\sum_{\text {sym }} x^{9} y^{9} z^{6}-\sum_{\text {sym }} x^{8} y^{8} z^{8}\right) \geq 0 .
\end{aligned}
$$

And every term on the left-hand side is nonnegative by the Muirhead inequality.

(36th International Mathematical Olympiad, 1995)

145. View $Q$ as a polynomial in $x$. It is easy to see that $y$ is a zero of this polynomial; hence $Q$ is divisible by $x-y$. By symmetry, it is also divisible by $y-z$ and $z-x$.

146. The relation $(x+1) P(x)=(x-10) P(x+1)$ shows that $P(x)$ is divisible by $(x-10)$. Shifting the variable, we obtain the equivalent relation $x P(x-1)=(x-11) P(x)$, which shows that $P(x)$ is also divisible by $x$. Hence $P(x)=x(x-10) P_{1}(x)$ for some polynomial $P_{1}(x)$. Substituting in the original equation and canceling common factors, we find that $P_{1}(x)$ satisfies 

$$
x P_{1}(x)=(x-9) P_{1}(x+1) .
$$

Arguing as before, we find that $P_{1}(x)=(x-1)(x-9) P_{2}(x)$. Repeating the argument, we eventually find that $P(x)=x(x-1)(x-2) \cdots(x-10) Q(x)$, where $Q(x)$ satisfies $Q(x)=Q(x+1)$. It follows that $Q(x)$ is constant, and the solution to the problem is

$$
P(x)=\operatorname{ax}(x-1)(x-2) \cdots(x-10),
$$

where $a$ is an arbitrary constant.

147. Having odd degree, $P(x)$ is surjective. Hence for every root $r_{i}$ of $P(x)=0$ there exists a solution $a_{i}$ to the equation $P\left(a_{i}\right)=r_{i}$, and trivially $a_{i} \neq a_{j}$ if $r_{i} \neq r_{j}$. Then $P\left(P\left(a_{i}\right)\right)=0$, and the conclusion follows.

(Russian Mathematical Olympiad, 2002)

148. First solution: Let $m$ be the degree of $P(x)$, and write

$$
P(x)=a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{0} .
$$

Using the binomial formula for $\left(x \pm \frac{1}{n}\right)^{m}$ and $\left(x \pm \frac{1}{n}\right)^{m-1}$ we transform the identity from the statement into

$$
\begin{array}{r}
2 a_{m} x^{m}+2 a_{m-1} x^{m-1}+2 a_{m-2} x^{m-2}+a_{m} \frac{m(m-1)}{n^{2}} x^{m-2}+Q(x) \\
=2 a_{m} x^{m}+2 a_{m-1} x^{m-1}+2 a_{m-2} x^{m-2}+R(x),
\end{array}
$$

where $Q$ and $R$ are polynomials of degree at most $m-3$. If we identify the coefficients of the corresponding powers of $x$, we find that $a_{m} \frac{m(m-1)}{n^{2}}=0$. But $a_{m} \neq 0$, being the leading coefficient of the polynomial; hence $m(m-1)=0$. So either $m=0$ or $m=1$. One can check in an instant that all polynomials of degree 0 or 1 satisfy the required condition.

Second solution: Fix a point $x_{0}$. The graph of $P(x)$ has infinitely many points in common with the line that has slope

$$
m=n\left(P\left(x_{0}+\frac{1}{n}\right)-P\left(x_{0}\right)\right)
$$

and passes through the point $\left(x_{0}, P\left(x_{0}\right)\right)$. Therefore, the graph of $P(x)$ is a line, so the polynomial has degree 0 or 1 .

Third solution: If there is such a polynomial of degree $m \geq 2$, differentiating the given relation $m-2$ times we find that there is a quadratic polynomial that satisfies the given relation. But then any point on its graph would be the vertex of the parabola, which of course is impossible. Hence only linear and constant polynomials satisfy the given relation.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1979, proposed by D. Buşneag)

149. Let $x=\sqrt{2}+\sqrt[3]{3}$. Then $\sqrt[3]{3}=x-\sqrt{2}$, which raised to the third power yields $3=x^{3}-3 \sqrt{2} x^{2}+6 x-2 \sqrt{2}$, or

$$
x^{3}+6 x-3=\left(3 x^{2}+2\right) \sqrt{2} .
$$

By squaring this equality we deduce that $x$ satisfies the polynomial equation

$$
x^{6}-6 x^{4}-6 x^{3}+12 x^{2}-36 x+1=0 .
$$

(Belgian Mathematical Olympiad, 1978, from a note by P. Radovici-Mărculescu)

150. Note that $r$ and $s$ are zeros of both $P(x)$ and $Q(x)$. So on the one hand, $Q(x)=$ $(x-r)(x-s)$, and on the other, $r$ and $s$ are roots of $P(x)-Q(x)$. The assumption that this polynomial is nonnegative implies that the two roots are double; hence

$$
P(x)-Q(x)=(x-r)^{2}(x-s)^{2}=Q(x)^{2} .
$$

We find that $P(x)=Q(x)(Q(x)+1)$. Because the signs of $P(x)$ and $Q(x)$ agree, the quadratic polynomial $Q(x)+1$ is nonnegative. This cannot happen because its discriminant is $(r-s)^{2}-4>0$. The contradiction proves that our assumption was false; hence for some $x_{0}, P\left(x_{0}\right)<Q\left(x_{0}\right)$.

(Russian Mathematical Olympiad, 2001)

151. Because $P(0)=0$, there exists a polynomial $Q(x)$ such that $P(x)=x Q(x)$. Then

$$
Q(k)=\frac{1}{k+1}, \quad k=1,2, \ldots, n .
$$

Let $H(x)=(x+1) Q(x)-1$. The degree of $H(x)$ is $n$ and $H(k)=0$ for $k=1,2, \ldots, n$. Hence

$$
H(x)=(x+1) Q(x)-1=a_{0}(x-1)(x-2) \cdots(x-n) .
$$

In this equality $H(-1)=-1$ yields $a_{0}=\frac{(-1)^{n+1}}{(n+1) !}$. For $x=m, m>n$, which gives

$$
Q(m)=\frac{(-1)^{n+1}(m-1)(m-2) \cdots(m-n)+1}{(n+1) !(m+1)}+\frac{1}{m+1},
$$

and so 

$$
P(m)=\frac{(-1)^{m+1} m(m-1) \cdots(m-n)}{(n+1) !(m+1)}+\frac{m}{m+1} .
$$

(D. Andrica, published in T. Andreescu, D. Andrica, 360 Problems for Mathematical Contests, GIL, 2003)

152. Adding and subtracting the conditions from the statement, we find that $a_{1}+a_{2}+$ $\cdots+a_{n}$ and $a_{1}-a_{2}+\cdots+(-1)^{n} a_{n}$ are both real numbers, meaning that $P(1)$ and $P(-1)$ are real numbers. It follows that $P(1)=\overline{P(1)}$ and $P(-1)=\overline{P(-1)}$. Writing $P(x)=\left(x-x_{1}\right)\left(x-x_{2}\right) \cdots\left(x-x_{n}\right)$, we deduce

$$
\begin{aligned}
&\left(1-x_{1}\right)\left(1-x_{2}\right) \cdots\left(1-x_{n}\right)=\left(1-\bar{x}_{1}\right)\left(1-\bar{x}_{2}\right) \cdots\left(1-\bar{x}_{n}\right) \\
&\left(1+x_{1}\right)\left(1+x_{2}\right) \cdots\left(1+x_{n}\right)=\left(1+\bar{x}_{1}\right)\left(1+\bar{x}_{2}\right) \cdots\left(1+\bar{x}_{n}\right)
\end{aligned}
$$

Multiplying, we obtain

$$
\left(1-x_{1}^{2}\right)\left(1-x_{2}^{2}\right) \cdots\left(1-x_{n}^{2}\right)=\left(1-\bar{x}_{1}^{2}\right)\left(1-\bar{x}_{2}^{2}\right) \cdots\left(1-\bar{x}_{n}^{2}\right) .
$$

This means that $Q(1)=\overline{Q(1)}$, and hence $b_{1}+b_{2}+\cdots+b_{n}$ is a real number, as desired. (Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

153. If such a $Q(x)$ exists, it is clear that $P(x)$ is even. Conversely, assume that $P(x)$ is an even function. Writing $P(x)=P(-x)$ and identifying coefficients, we conclude that no odd powers appear in $P(x)$. Hence

$$
P(x)=a_{2 n} x^{2 n}+a_{2 n-2} x^{2 n-2}+\cdots+a_{2} x^{2}+a_{0}=P_{1}\left(x^{2}\right) .
$$

Factoring

$$
P_{1}(y)=a\left(y-y_{1}\right)\left(y-y_{2}\right) \cdots\left(y-y_{n}\right),
$$

we have

$$
P(x)=a\left(x^{2}-y_{1}\right)\left(x^{2}-y_{2}\right) \cdots\left(x^{2}-y_{n}\right) .
$$

Now choose complex numbers $b, x_{1}, x_{2}, \ldots, x_{n}$ such that $b^{2}=(-1)^{n} a$ and $x_{j}^{2}=y_{j}$, $j=1,2, \ldots, n$. We have the factorization

$$
\begin{aligned}
P(x) &=b^{2}\left(x_{1}^{2}-x^{2}\right)\left(x_{2}^{2}-x^{2}\right) \cdots\left(x_{n}^{2}-x^{2}\right) \\
&=b^{2}\left(x_{1}-x\right)\left(x_{1}+x\right)\left(x_{2}-x\right)\left(x_{2}+x\right) \cdots\left(x_{n}-x\right)\left(x_{n}+x\right) \\
&=\left[b\left(x_{1}-x\right)\left(x_{2}-x\right) \cdots\left(x_{n}-x\right)\right]\left[b\left(x_{1}+x\right)\left(x_{2}+x\right) \cdots\left(x_{n}+x\right)\right] \\
&=Q(x) Q(-x),
\end{aligned}
$$

where $Q(x)=b\left(x_{1}-x\right)\left(x_{2}-x\right) \cdots\left(x_{n}-x\right)$. This completes the proof.

(Romanian Mathematical Olympiad, 1979, proposed by M. Tुena)

154. Denote the zeros of $P(x)$ by $x_{1}, x_{2}, x_{3}, x_{4}$, such that $x_{1}+x_{2}=4$. The first Viète relation gives $x_{1}+x_{2}+x_{3}+x_{4}=6$; hence $x_{3}+x_{4}=2$. The second Viète relation can be written as

$$
x_{1} x_{2}+x_{3} x_{4}+\left(x_{1}+x_{2}\right)\left(x_{3}+x_{4}\right)=18,
$$

from which we deduce that $x_{1} x_{2}+x_{3} x_{4}=18-2 \cdot 4=10$. This, combined with the fourth Viète relation $x_{1} x_{2} x_{3} x_{4}=25$, shows that the products $x_{1} x_{2}$ and $x_{3} x_{4}$ are roots of the quadratic equation $u^{2}-10 u+25=0$. Hence $x_{1} x_{2}=x_{3} x_{4}=5$, and therefore $x_{1}$ and $x_{2}$ satisfy the quadratic equation $x^{2}-4 x+5=0$, while $x_{3}$ and $x_{4}$ satisfy the quadratic equation $x^{2}-2 x+5=0$. We conclude that the zeros of $P(x)$ are $2+i, 2-i, 1+2 i, 1-2 i$. 

155. If $a \geq 0, b \geq 0, c \geq 0$, then obviously $a+b+c>0, a b+b c+c a \geq 0$, and $a b c \geq 0$. For the converse, let $u=a+b+c, v=a b+b c+c a$, and $w=a b c$, which are assumed to be positive. Then $a, b, c$ are the three zeros of the polynomial

$$
P(x)=x^{3}-u x^{2}+v x-w .
$$

Note that if $t<0$, that is, if $t=-s$ with $s>0$, then $P(t)=s^{3}+u s^{2}+v s+w>0$; hence $t$ is not a zero of $P(x)$. It follows that the three zeros of $P(x)$ are nonnegative, and we are done.

156. Taking the conjugate of the first equation, we obtain

$$
\bar{x}+\bar{y}+\bar{z}=1,
$$

and hence

$$
\frac{1}{x}+\frac{1}{y}+\frac{1}{z}=1 .
$$

Combining this with $x y z=1$, we obtain

$$
x y+y z+x z=1 .
$$

Therefore, $x, y, z$ are the roots of the polynomial equation

$$
t^{3}-t^{2}+t-1=0,
$$

which are $1, i,-i$. Any permutation of these three complex numbers is a solution to the original system of equations.

157. Dividing by the nonzero $x y z$ yields $\frac{x}{z}+\frac{y}{x}+\frac{z}{y}=\frac{y}{z}+\frac{z}{x}+\frac{x}{y}=r$. Let $a=\frac{x}{y}, b=\frac{y}{z}$, $c=\frac{z}{x}$. Then $a b c=1, \frac{1}{a}+\frac{1}{b}+\frac{1}{c}=r, a+b+c=r$. Hence 

$$
\begin{aligned}
a+b+c &=r, \\
a b+b c+c a &=r, \\
a b c &=1 .
\end{aligned}
$$

We deduce that $a, b, c$ are the solutions of the polynomial equation $t^{3}-r t^{2}+r t-1=0$. This equation can be written as

$$
(t-1)\left[t^{2}-(r-1) t+1\right]=0 .
$$

Since it has three real solutions, the discriminant of the quadratic must be positive. This means that $(r-1)^{2}-4 \geq 0$, leading to $r \in(-\infty,-1] \cup[3, \infty)$. Conversely, all such $r$ work.

158. Consider the polynomial $P(t)=t^{5}+q t^{4}+r t^{3}+s t^{2}+u t+v$ with roots $a, b, c, d, e$. The condition from the statement implies that $q$ is divisible by $n$. Moreover, since

$$
\sum a b=\frac{1}{2}\left(\sum a\right)^{2}-\frac{1}{2}\left(\sum a^{2}\right),
$$

it follows that $r$ is also divisible by $n$. Adding the equalities $P(a)=0, P(b)=0$, $P(c)=0, P(d)=0, P(e)=0$, we deduce that

$$
a^{5}+b^{5}+c^{5}+d^{5}+e^{5}+s\left(a^{2}+b^{2}+c^{2}+d^{2}+e^{2}\right)+u(a+b+c+d+e)+5 v
$$

is divisible by $n$. But since $v=-a b c d e$, it follows that

$$
a^{5}+b^{5}+c^{5}+d^{5}+e^{5}-5 a b c d e
$$

is divisible by $n$, and we are done.

$$
\text { (Kvant (Quantum)) }
$$

159. Let $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$. Denote its zeros by $x_{1}, x_{2}, \ldots, x_{n}$. The first two of Viète's relations give

$$
\begin{aligned}
x_{1}+x_{2}+\cdots+x_{n} &=-\frac{a_{n-1}}{a_{n}}, \\
x_{1} x_{2}+x_{1} x_{3}+\cdots+x_{n-1} x_{n} &=\frac{a_{n-2}}{a_{n}}
\end{aligned}
$$

Combining them, we obtain

$$
x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}=\left(\frac{a_{n-1}}{a_{n}}\right)^{2}-2\left(\frac{a_{n-2}}{a_{n}}\right) .
$$

The only possibility is $x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}=3$. Given that $x_{1}^{2} x_{2}^{2} \cdots x_{n}^{2}=1$, the AM-GM inequality yields 

$$
3=x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2} \geq n \sqrt[n]{x_{1}^{2} x_{2}^{2} \cdots x_{n}^{2}}=n .
$$

Therefore, $n \leq 3$. Eliminating case by case, we find among linear polynomials $x+1$ and $x-1$, and among quadratic polynomials $x^{2}+x-1$ and $x^{2}-x-1$. As for the cubic polynomials, we should have equality in the AM-GM inequality. So all zeros should have the same absolute values. The polynomial should share a zero with its derivative. This is the case only for $x^{3}+x^{2}-x-1$ and $x^{3}-x^{2}-x+1$, which both satisfy the required property. Together with their negatives, these are all desired polynomials.

(Indian Olympiad Training Program, 2005)

160. The first Viète relation gives

$$
r_{1}+r_{2}+r_{3}+r_{4}=-\frac{b}{a},
$$

so $r_{3}+r_{4}$ is rational. Also,

$$
r_{1} r_{2}+r_{1} r_{3}+r_{1} r_{4}+r_{2} r_{3}+r_{2} r_{4}+r_{3} r_{4}=\frac{c}{a} .
$$

Therefore,

$$
r_{1} r_{2}+r_{3} r_{4}=\frac{c}{a}-\left(r_{1}+r_{2}\right)\left(r_{3}+r_{4}\right) .
$$

Finally,

$$
r_{1} r_{2} r_{3}+r_{1} r_{2} r_{4}+r_{1} r_{3} r_{4}+r_{2} r_{3} r_{4}=-\frac{d}{a},
$$

which is equivalent to

$$
\left(r_{1}+r_{2}\right) r_{3} r_{4}+\left(r_{3}+r_{4}\right) r_{1} r_{2}=-\frac{d}{a} .
$$

We observe that the products $r_{1} r_{2}$ and $r_{3} r_{4}$ satisfy the linear system of equations

$$
\begin{aligned}
&\alpha x+\beta y=u, \\
&\gamma x+\delta y=v,
\end{aligned}
$$

where $\alpha=1, \beta=1, \gamma=r_{3}+r_{4}, \delta=r_{1}+r_{2}, u=\frac{c}{a}-\left(r_{1}+r_{2}\right)\left(r_{3}+r_{4}\right), v=-\frac{d}{a}$. Because $r_{1}+r_{2} \neq r_{3}+r_{4}$, this system has a unique solution; this solution is rational. Hence both $r_{1} r_{2}$ and $r_{3} r_{4}$ are rational, and the problem is solved.

(64th W.L. Putnam Mathematical Competition, 2003)

161. First solution: Let $\alpha=\arctan u, \beta=\arctan v$, and $\arctan w$. We are required to determine the sum $\alpha+\beta+\gamma$. The addition formula for the tangent of three angles, 

$$
\tan (\alpha+\beta+\gamma)=\frac{\tan \alpha+\tan \beta+\tan \gamma-\tan \alpha \tan \beta \tan \gamma}{1-(\tan \alpha \tan \beta+\tan \beta \tan \gamma+\tan \alpha \tan \gamma)},
$$

implies

$$
\tan (\alpha+\beta+\gamma)=\frac{u+v+w-u v w}{1-(u v+v w+u v)} .
$$

Using Viète's relations,

$$
u+v+w=0, \quad u v+v w+u w=-10, \quad u v w=-11,
$$

we further transform this into $\tan (\alpha+\beta+\gamma)=\frac{11}{1+10}=1$. Therefore, $\alpha+\beta+\gamma=\frac{\pi}{4}+k \pi$, where $k$ is an integer that remains to be determined.

From Viète's relations we can see the product of the zeros of the polynomial is negative, so the number of negative zeros is odd. And since the sum of the zeros is 0 , two of them are positive and one is negative. Therefore, one of $\alpha, \beta, \gamma$ lies in the interval $\left(-\frac{\pi}{2}, 0\right)$ and two of them lie in $\left(0, \frac{\pi}{2}\right)$. Hence $k$ must be equal to 0 , and $\arctan u+$ $\arctan v+\arctan w=\frac{\pi}{4}$.

Second solution: Because

$$
\operatorname{Im} \ln (1+i x)=\arctan x,
$$

we see that

$$
\begin{aligned}
\arctan u+\arctan v+\arctan w &=\operatorname{Im} \ln (i P(i))=\operatorname{Im} \ln (11+11 i) \\
&=\arctan 1=\frac{\pi}{4} .
\end{aligned}
$$

(Kózépiskolai Matematikai Lapok (Mathematics Magazine for High Schools, Budapest), proposed by K. Bérczi).

162. Expanding the binomial $(\cos \alpha+i \sin \alpha)^{m}$, and using the de Moivre formula,

$$
(\cos \alpha+i \sin \alpha)^{m}=\cos m \alpha+i \sin m \alpha,
$$

we obtain

$$
\sin m \alpha=\left(\begin{array}{c}
m \\
1
\end{array}\right) \cos ^{m-1} \alpha \sin \alpha-\left(\begin{array}{c}
m \\
3
\end{array}\right) \cos ^{m-3} \alpha \sin ^{3} \alpha+\left(\begin{array}{c}
m \\
5
\end{array}\right) \cos ^{m-5} \alpha \sin ^{5} \alpha+\cdots .
$$

For $m=2 n+1$, if $\alpha=\frac{\pi}{2 n+1}, \frac{2 \pi}{2 n+1}, \ldots, \frac{n \pi}{2 n+1}$ then $\sin (2 n+1) \alpha=0$, and $\sin \alpha$ and $\cos \alpha$ are both different from zero. Dividing the above relation by $\sin ^{2 n} \alpha$, we find that

$$
\left(\begin{array}{c}
2 n+1 \\
1
\end{array}\right) \cot ^{2 n} \alpha-\left(\begin{array}{c}
2 n+1 \\
3
\end{array}\right) \cot ^{2 n-2} \alpha+\cdots+(-1)^{n}\left(\begin{array}{c}
2 n+1 \\
2 n+1
\end{array}\right)=0
$$

holds true for $\alpha=\frac{\pi}{2 n+1}, \frac{2 \pi}{2 n+1}, \ldots, \frac{n \pi}{2 n+1}$. Hence the equation

$$
\left(\begin{array}{c}
2 n+1 \\
1
\end{array}\right) x^{n}-\left(\begin{array}{c}
2 n+1 \\
3
\end{array}\right) x^{n-1}+\cdots+(-1)^{n}\left(\begin{array}{c}
2 n+1 \\
2 n+1
\end{array}\right)=0
$$

has the roots

$$
x_{k}=\cot ^{2} \frac{k \pi}{2 n+1}, \quad k=1,2, \ldots, n .
$$

The product of the roots is

$$
x_{1} x_{2} \cdots x_{n}=\frac{\left(\begin{array}{c}
2 n+1 \\
2 n+1
\end{array}\right)}{\left(\begin{array}{c}
2 n+1 \\
1
\end{array}\right)}=\frac{1}{2 n+1}
$$

So

$$
\cot ^{2} \frac{\pi}{2 n+1} \cot ^{2} \frac{2 \pi}{2 n+1} \cdot \cdot \cot ^{2} \frac{n \pi}{2 n+1}=\frac{1}{2 n+1} .
$$

Because $0<\frac{k \pi}{2 n+1}<\frac{\pi}{2}, k=1,2, \ldots, n$, it follows that all these cotangents are positive. Taking the square root and inverting the fractions, we obtain the identity from the statement.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1970)

163. A good guess is that $P(x)=(x-1)^{n}$, and we want to show that this is the case. To this end, let $x_{1}, x_{2}, \ldots, x_{n}$ be the zeros of $P(x)$. Using Viète's relations, we can write

$$
\begin{aligned}
\sum_{i}\left(x_{i}-1\right)^{2} &=\left(\sum_{i} x_{i}\right)^{2}-2 \sum_{i<j} x_{i} x_{j}-2 \sum_{i} x_{i}+n \\
&=n^{2}-2 \frac{n(n-1)}{2}-2 n+n=0 .
\end{aligned}
$$

This implies that all squares on the left are zero. So $x_{1}=x_{2}=\cdots=x_{n}=1$, and $P(x)=(x-1)^{n}$, as expected.

\section{(Gazeta Matematic $\breve{a}$ (Mathematics Gazette, Bucharest))}

164. Let $\alpha, \beta, \gamma$ be the zeros of $P(x)$. Without loss of generality, we may assume that $0 \leq \alpha \leq \beta \leq \gamma$. Then

$$
x-a=x+\alpha+\beta+\gamma \geq 0 \quad \text { and } \quad P(x)=(x-\alpha)(x-\beta)(x-\gamma) .
$$

If $0 \leq x \leq \alpha$, using the AM-GM inequality, we obtain

$$
-P(x)=(\alpha-x)(\beta-x)(\gamma-x) \leq \frac{1}{27}(\alpha+\beta+\gamma-3 x)^{3}
$$



$$
\leq \frac{1}{27}(x+\alpha+\beta+\gamma)^{3}=\frac{1}{27}(x-a)^{3},
$$

so that $P(x) \geq-\frac{1}{27}(x-a)^{3}$. Equality holds exactly when $\alpha-x=\beta-x=\gamma-x$ in the first inequality and $\alpha+\beta+\gamma-3 x=x+\alpha+\beta+\gamma$ in the second, that is, when $x=0$ and $\alpha=\beta=\gamma$.

If $\beta \leq x \leq \gamma$, then using again the AM-GM inequality, we obtain

$$
\begin{aligned}
-P(x) &=(x-\alpha)(x-\beta)(\gamma-x) \leq \frac{1}{27}(x+\gamma-\alpha-\beta)^{3} \\
& \leq \frac{1}{27}(x+\alpha+\beta+\gamma)^{3}=\frac{1}{27}(x-a)^{3},
\end{aligned}
$$

so that again $P(x) \geq-\frac{1}{27}(x-a)^{3}$. Equality holds exactly when there is equality in both inequalities, that is, when $\alpha=\beta=0$ and $\gamma=2 x$.

Finally, when $\alpha<x<\beta$ or $x>\gamma$, then

$$
P(x)>0 \geq-\frac{1}{27}(x-a)^{3} .
$$

Thus the desired constant is $\lambda=-\frac{1}{27}$, and the equality occurs when $\alpha=\beta=\gamma$ and $x=0$, or when $\alpha=\beta=0, \gamma$ is any nonnegative real, and $x=\frac{\gamma}{2}$.

(Chinese Mathematical Olympiad, 1999)

165. The key idea is to view $a^{n+1}-(a+1)^{n}-2001$ as a polynomial in $a$. Its free term is 2002 , so any integer zero divides this number.

From here the argument shifts to number theory and becomes standard. First, note that $2002=2 \times 7 \times 11 \times 13$. Since 2001 is divisible by 3 , we must have $a \equiv 1(\bmod 3)$; otherwise, one of $a^{n+1}$ and $(a+1)^{n}$ would be a multiple of 3 and the other not, and their difference would not be divisible by 3 . We deduce that $a \geq 7$. Moreover, $a^{n+1} \equiv 1$ $(\bmod 3)$, so we must have $(a+1)^{n} \equiv 1(\bmod 3)$, which forces $n$ to be even, and in particular at least 2.

If $a$ is even, then $a^{n+1}-(a+1)^{n} \equiv-(a+1)^{n}(\bmod 4)$. Because $n$ is even, $-(a+1)^{n} \equiv-1(\bmod 4)$. But on the right-hand side, $2001 \equiv 1(\bmod 4)$, and the equality is impossible. Therefore, $a$ must odd, so it divides $1001=7 \times 11 \times 13$. Moreover, $a^{n+1}-(a+1)^{n} \equiv a(\bmod 4)$, so $a \equiv 1(\bmod 4)$.

Of the divisors of $7 \times 11 \times 13$, those congruent to 1 modulo 3 are precisely those not divisible by 11 (since 7 and 13 are both congruent to 1 modulo 3). Thus $a$ divides $7 \times 13$. Now $a \equiv 1(\bmod 4)$ is possible only if $a$ divides 13.

We cannot have $a=1$, since $1-2^{n} \neq 2001$ for any $n$. Hence the only possibility is $a=13$. One easily checks that $a=13, n=2$ is a solution; all that remains to check is that no other $n$ works. In fact, if $n>2$, then $13^{n+1} \equiv 2001 \equiv 1(\bmod 8)$. But $13^{n+1} \equiv 13(\bmod 8)$ since $n$ is even, a contradiction. We conclude that $a=13, n=2$ is the unique solution.

(62nd W.L. Putnam Mathematical Competition, 2001)

166. Let us first consider the case $n \geq 2$. Let $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$, $a_{n} \neq 0$. Then

$$
P^{\prime}(x)=n a_{n} x^{n-1}+(n-1) a_{n-1} x^{n-2}+\cdots+a_{1} .
$$

Identifying the coefficients of $x^{n(n-1)}$ in the equality $P\left(P^{\prime}(x)\right)=P^{\prime}(P(x))$, we obtain

$$
a_{n}^{n+1} \cdot n^{n}=a_{n}^{n} \cdot n .
$$

This implies $a_{n} n^{n-1}=1$, and so

$$
a_{n}=\frac{1}{n^{n-1}} .
$$

Since $a_{n}$ is an integer, $n$ must be equal to 1 , a contradiction. If $n=1$, say $P(x)=a x+b$, then we should have $a^{2}+b=a$, hence $b=a-a^{2}$. Thus the answer to the problem is the polynomials of the form $P(x)=a x^{2}+a-a^{2}$.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

167. Let $m$ be the degree of $P(x)$, so $P(x)=a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{0}$. If $P(x)=$ $x^{k} Q(x)$, then

$$
x^{k n} Q^{n}(x)=x^{k n} Q\left(x^{n}\right),
$$

so

$$
Q^{n}(x)=Q\left(x^{n}\right),
$$

which means that $Q(x)$ satisfies the same relation.

Thus we can assume that $P(0) \neq 0$. Substituting $x=0$, we obtain $a_{0}^{n}=a_{0}$, and since $a_{0}$ is a nonzero real number, it must be equal to 1 if $n$ is even, and to $\pm 1$ if $n$ is odd.

Differentiating the relation from the statement, we obtain

$$
n P^{n-1}(x) P^{\prime}(x)=n P^{\prime}\left(x^{n}\right) x^{n-1} .
$$

For $x=0$ we have $P^{\prime}(0)=0$; hence $a_{1}=0$. Differentiating the relation again and reasoning similarly, we obtain $a_{2}=0$, and then successively $a_{3}=a_{4}=\cdots=a_{m}=0$. It follows that $P(x)=1$ if $n$ is even and $P(x)=\pm 1$ if $n$ is odd.

In general, the only solutions are $P(x)=x^{m}$ if $n$ is even, and $P(x)=\pm x^{m}$ if $n$ is odd, $m$ being some nonnegative integer.

(T. Andreescu) 

168. Assume without loss of generality that $\operatorname{deg}(P(z))=n \geq \operatorname{deg}(Q(z))$. Consider the polynomial $R(z)=(P(z)-Q(z)) P^{\prime}(z)$. Clearly, $\operatorname{deg}(R(z)) \leq 2 n-1$. If $\omega$ is a zero of $P(z)$ of multiplicity $k$, then $\omega$ is a zero of $P^{\prime}(z)$ of multiplicity $k-1$. Hence $\omega$ is also a zero of $R(z)$, and its multiplicity is at least $k$. So the $n$ zeros of $P(z)$ produce at least $n$ zeros of $R(z)$, when multiplicities are counted.

Analogously, let $\omega$ be a zero of $P(z)-1$ of multiplicity $k$. Then $\omega$ is a zero of $Q(z)-1$, and hence of $P(z)-Q(z)$. It is also a zero of $(P(z)-1)^{\prime}=P^{\prime}(z)$ of multiplicity $k-1$. It follows that $\omega$ is a zero of $R(z)$ of multiplicity at least $k$. This gives rise to at least $n$ more zeros for $R(z)$.

It follows that $R(z)$, which is a polynomial of degree less than or equal to $2 n-1$, has at least $2 n$ zeros. This can happen only if $R(z)$ is identically zero, hence if $P(z) \equiv Q(z)$.

(Soviet Union University Student Mathematical Olympiad, 1976)

169. Let $Q(x)=x P(x)$. The conditions from the statement imply that the zeros of $Q(x)$ are all real and distinct. From Rolle's theorem, it follows that the zeros of $Q^{\prime}(x)$ are real and distinct.

Let $H(x)=x Q^{\prime}(x)$. Reasoning similarly we deduce that the polynomial $H^{\prime}(x)$ has all zeros real and distinct. Note that the equation $H^{\prime}(x)=0$ is equivalent to the equation

$$
x^{2} P^{\prime \prime}(x)+3 x P^{\prime}(x)+P(x)=0 ;
$$

the problem is solved.

(D. Andrica, published in T. Andreescu, D. Andrica, 360 Problems for Mathematical Contests, GIL, 2003)

170. Differentiating the product, we obtain

$$
P^{\prime}(x)=\sum_{k=1}^{n} k x^{k-1}\left(x^{n}-1\right) \cdots\left(x^{k+1}-1\right)\left(x^{k-1}-1\right) \cdots(x-1) .
$$

We will prove that each of the terms is divisible by $P_{\lfloor n / 2\rfloor}(x)$. This is clearly true if $k>\left\lfloor\frac{n}{2}\right\rfloor$.

If $k \leq\left\lfloor\frac{n}{2}\right\rfloor$, the corresponding term contains the factor

$$
\left(x^{n}-1\right) \cdots\left(x^{\lfloor n / 2\rfloor+2}-1\right)\left(x^{\lfloor n / 2\rfloor+1}-1\right) .
$$

That this is divisible by $P_{\lfloor n / 2\rfloor}(x)$ follows from a more general fact, namely that for any positive integers $k$ and $m$, the polynomial

$$
\left(x^{k+m}-1\right)\left(x^{k+m-1}-1\right) \cdots\left(x^{k+1}-1\right)
$$

is divisible by

$$
\left(x^{m}-1\right)\left(x^{m-1}-1\right) \cdots(x-1)
$$

in the ring of polynomials with integer coefficients. Since the two polynomials are monic and have integer coefficients, it suffices to prove that the zeros of the second are also zeros of the first, with at least the same multiplicity.

Note that if $\zeta$ is a primitive $r$ th root of unity, then $\zeta$ is a zero of $x^{j}-1$ precisely when $j$ is divisible by $r$. So the multiplicity of $\zeta$ as a zero of the polynomial $\left(x^{m}-1\right)\left(x^{m-1}-\right.$ 1) $\cdots(x-1)$ is $\left\lfloor\frac{m}{r}\right\rfloor$, while its multiplicity as a zero of $\left(x^{k+m}-1\right)\left(x^{k+m-1}-1\right) \cdots\left(x^{k+1}-1\right)$ is $\left\lfloor\frac{m+k}{r}\right\rfloor-\left\lfloor\frac{k}{r}\right\rfloor$. The claim now follows from the inequality

$$
\left\lfloor\frac{m+k}{r}\right\rfloor-\left\lfloor\frac{k}{r}\right\rfloor \geq\left\lfloor\frac{m}{r}\right\rfloor .
$$

This completes the solution.

(communicated by T.T. Le)

171. The equation $Q(x)=0$ is equivalent to

$$
n \frac{P(x) P^{\prime \prime}(x)-\left(P^{\prime}(x)\right)^{2}}{P(x)^{2}}+\left[\frac{P^{\prime}(x)}{P(x)}\right]^{2}=0 .
$$

We recognize the first term on the left to be the derivative of $\frac{P^{\prime}(x)}{P(x)}$. Denoting the roots of $P(x)$ by $x_{1}, x_{2}, \ldots, x_{n}$, the equation can be rewritten as

$$
-n \sum_{k=1}^{n} \frac{1}{\left(x-x_{k}\right)^{2}}+\left(\sum_{k=1}^{n} \frac{1}{x-x_{k}}\right)^{2}=0,
$$

or

$$
n \sum_{k=1}^{n} \frac{1}{\left(x-x_{k}\right)^{2}}=\left(\sum_{k=1}^{n} \frac{1}{x-x_{k}}\right)^{2} .
$$

If this were true for some real number $x$, then we would have the equality case in the Cauchy-Schwarz inequality applied to the numbers $a_{k}=1, b_{k}=\frac{1}{x-x_{k}}, k=1,2, \ldots, n$. This would then further imply that all the $x_{i}$ 's are equal, which contradicts the hypothesis that the zeros of $P(x)$ are distinct. So the equality cannot hold for a real number, meaning that none of the zeros of $Q(x)$ is real.

(D.M. Bătineţu, I.V. Maftei, I.M. Stancu-Minasian, Exerciţii şi Probleme de Analiză Matematică (Exercises and Problems in Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1981)

172. We start with the identity

$$
\frac{P^{\prime}(x)}{P(x)}=\frac{1}{x-x_{1}}+\frac{1}{x-x_{2}}+\cdots+\frac{1}{x-x_{n}}, \text { for } x \neq x_{j}, \quad j=1,2, \ldots, n .
$$

If $P^{\prime}\left(\frac{x_{1}+x_{2}}{2}\right)=0$, then this identity gives

$$
0=\frac{1}{\frac{x_{1}+x_{2}}{2}-x_{3}}+\frac{1}{\frac{x_{1}+x_{2}}{2}-x_{4}}+\cdots+\frac{1}{\frac{x_{1}+x_{2}}{2}-x_{n}}<0+0+\cdots+0=0,
$$

a contradiction. Similarly, if $P^{\prime}\left(\frac{x_{n-1}+x_{n}}{2}\right)=0$, then

$$
0=\frac{1}{\frac{x_{n-1}+x_{n}}{2}-x_{1}}+\frac{1}{\frac{x_{n-1}+x_{n}}{2}-x_{2}}+\cdots+\frac{1}{\frac{x_{n-1}+x_{n}}{2}-x_{n-2}}>0+0+\cdots+0=0,
$$

another contradiction. The conclusion follows.

\section{(T. Andreescu)}

173. The equation $P(x)=0$ is equivalent to the equation $f(x)=1$, where $f(x)=$ $\frac{a_{1}}{x}+\frac{a_{2}}{x^{2}}+\cdots+\frac{a_{n}}{x^{n}}$. Since $f$ is strictly decreasing on $(0, \infty), \lim _{x \rightarrow 0^{+}} f(x)=\infty$ and $\lim _{x \rightarrow \infty} f(x)=0$, the equation has a unique solution.

Remark. A more general principle is true, namely that if the terms of the polynomial are written in decreasing order of their powers, then the number of sign changes of the coefficients is the maximum possible number of positive zeros; the actual number of positive zeros may differ from this by an even number.

174. Assume to the contrary that there is $z$ with $|z| \geq 2$ such that $P(z)=0$. Then by the triangle inequality,

$$
\begin{aligned}
0 &=\left|\frac{P(z)}{z^{7}}\right|=\left|1+\frac{7}{z^{3}}+\frac{4}{z^{6}}+\frac{1}{z^{7}}\right| \geq 1-\frac{7}{|z|^{3}}-\frac{4}{|z|^{6}}-\frac{1}{|z|^{7}} \\
& \geq 1-\frac{7}{8}-\frac{4}{64}-\frac{1}{128}=\frac{7}{128}>0,
\end{aligned}
$$

a contradiction. Hence our initial assumption was false, and therefore all the zeros of $P(z)$ lie inside the disk of radius 2 centered at the origin.

175. Let $z=r(\cos t+i \sin t), \sin t \neq 0$. Using the de Moivre formula, the equality $z^{n}+a z+1=0$ translates to

$$
\begin{aligned}
r^{n} \cos n t+a r \cos t+1 &=0, \\
r^{n} \sin n t+a r \sin t &=0 .
\end{aligned}
$$

View this as a system in the unknowns $r^{n}$ and $a r$. Solving the system gives

$$
r^{n}=\frac{\left|\begin{array}{r}
-1 \cos t \\
0 \sin t
\end{array}\right|}{\left|\begin{array}{c}
\cos n t \cos t \\
\sin n t \sin t
\end{array}\right|}=\frac{\sin t}{\sin (n-1) t} .
$$

An exercise in the section on induction shows that for any positive integer $k,|\sin k t| \leq$ $k|\sin t|$. Then

$$
r^{n}=\frac{\sin t}{\sin (n-1) t} \geq \frac{1}{n-1} .
$$

This implies the desired inequality $|z|=r \geq \sqrt[n]{\frac{1}{n-1}}$.

(Romanian Mathematical Olympiad, proposed by I. Chiţescu)

176. By the theorem of Lucas, if the zeros of a polynomial lie in a closed convex domain, then the zeros of the derivative lie in the same domain. In our problem, change the variable to $z=\frac{1}{x}$ to obtain the polynomial $Q(z)=z^{n}+z^{n-1}+a$. If all the zeros of $a x^{n}+x+1$ were outside of the circle of radius 2 centered at the origin, then the zeros of $Q(z)$ would lie in the interior of the circle of radius $\frac{1}{2}$. Applying the theorem of Lucas to the convex hull of these zeros, we deduce that the same would be true for the zeros of the derivative. But $Q^{\prime}(z)=n z^{n-1}+(n-1) z^{n-2}$ has $z=\frac{n-1}{n} \geq \frac{1}{2}$ as one of its zeros, which is a contradiction. This implies that the initial polynomial has a root of absolute value less than or equal to 2 .

177. The problem amounts to showing that the zeros of $Q(z)=z P^{\prime}(z)-\frac{n}{2} P(z)$ lie on the unit circle. Let the zeros of $P(z)$ be $z_{1}, z_{2}, \ldots, z_{n}$, and let $z$ be a zero of $Q(z)$. The relation $Q(z)=0$ translates into

$$
\frac{z}{z-z_{1}}+\frac{z}{z-z_{2}}+\cdots+\frac{z}{z-z_{n}}=\frac{n}{2},
$$

or

$$
\left(\frac{2 z}{z-z_{1}}-1\right)+\left(\frac{2 z}{z-z_{2}}-1\right)+\cdots+\left(\frac{2 z}{z-z_{n}}-1\right)=0,
$$

and finally

$$
\frac{z+z_{1}}{z-z_{1}}+\frac{z+z_{2}}{z-z_{2}}+\cdots+\frac{z+z_{n}}{z-z_{n}}=0 .
$$

The terms of this sum should remind us of a fundamental transformation of the complex plane. This transformation is defined as follows: for $a$ a complex number of absolute value 1 , we let $\phi_{a}(z)=(z+a) /(z-a)$. The map $\phi_{a}$ has the important property that it maps the unit circle to the imaginary axis, the interior of the unit disk to the half-plane $\operatorname{Re} z<0$, and the exterior of the unit disk to the half-plane $\operatorname{Re} z>0$. Indeed, since the unit disk is invariant under rotation by the argument of $a$, it suffices to check this for $a=1$. Then $\phi\left(e^{i \theta}\right)=-i \cot \frac{\theta}{2}$, which proves that the unit circle maps to the entire imaginary axis. The map is one-to-one, so the interior of the unit disk is mapped to that half-plane where the origin goes, namely to $\operatorname{Re} z<0$, and the exterior is mapped to the other half-plane. If $z$ has absolute value less than one, then all terms of the sum 

$$
\frac{z+z_{1}}{z-z_{1}}+\frac{z+z_{2}}{z-z_{2}}+\cdots+\frac{z+z_{n}}{z-z_{n}}
$$

have negative real part, while if $z$ has absolute value greater than 1 , all terms in this sum have positive real part. In order for this sum to be equal to zero, $z$ must have absolute value 1 . This completes the proof.

An alternative approach to this last step was suggested by R. Stong. Taking the real part of

$$
\frac{z+z_{1}}{z-z_{1}}+\frac{z+z_{2}}{z-z_{2}}+\cdots+\frac{z+z_{n}}{z-z_{n}}=0,
$$

we obtain

$$
\sum_{j=1}^{n} \operatorname{Re}\left(\frac{z+z_{j}}{z-z_{j}}\right)=\sum_{j=1}^{n} \frac{1}{\left|z-z_{j}\right|^{2}} \operatorname{Re}\left(\left(z+z_{j}\right)\left(\bar{z}-\bar{z}_{j}\right)\right)=\frac{|z|^{2}-\left|z_{j}\right|^{2}}{\left|z-z_{j}\right|^{2}} .
$$

Since $\left|z_{j}\right|=1$ for all $j$, we conclude that $|z|=1$.

Remark. When $a=-i, \phi_{a}$ is called the Cayley transform.

178. Let the zeros of the polynomial be $p, q, r, s$. We have $p+q+r+s=0, p q+p r+$ $r s+q r+q s+r s=-2$, and hence $p^{2}+q^{2}+r^{2}+s^{2}=0^{2}-2(-2)=4$. By the CauchySchwarz inequality, $(1+1+1)\left(q^{2}+r^{2}+s^{2}\right) \geq(q+r+s)^{2}$. Furthermore, because $q, r, s$ must be distinct, the inequality is strict. Thus $4=p^{2}+q^{2}+r^{2}+s^{2}>p^{2}+\frac{(-p)^{2}}{3}=\frac{4 p^{2}}{3}$, or $|p|<\sqrt{3}$. The same argument holds for the other zeros.

(Hungarian Mathematical Olympiad, 1999)

179. We argue by induction on $k$. For $k=1$ the property is obviously true.

Assume that the property is true for polynomials of degree $k-1$ and let us prove it for the polynomials $P_{n}(z), n \geq 1$, and $P(z)$ of degree $k$. Subtracting a constant from all polynomials, we may assume that $P(0)=0$. Order the zeros of $P_{n}(z)$ such that $\left|z_{1}(n)\right| \leq\left|z_{2}(n)\right| \leq \cdots \leq\left|z_{k}(n)\right|$. The product $z_{1}(n) z_{2}(n) \cdots z_{k}(n)$, being the free term of $P_{n}(z)$, converges to 0 . This can happen only if $z_{1}(n) \rightarrow 0$. So we have proved the property for one of the zeros.

In general, the polynomial obtained by dividing a monic polynomial $Q(z)$ by $z-$ $a$ depends continuously on $a$ and on the coefficients of $Q(z)$. This means that the coefficients of $P_{n}(z) /\left(z-z_{1}(n)\right)$ converge to the coefficients of $P(z) / z$, so we can apply the induction hypothesis to these polynomials. The conclusion follows.

Remark. A stronger result is true, namely that if the coefficients of a monic polynomial are continuous functions of a parameter $t$, then the zeros are also continuous functions of $t$. 

180. The hypothesis of the problem concerns the coefficients $a_{m}$ and $a_{0}$, and the conclusion is about a zero of the polynomial. It is natural to write the Viète relations for the two coefficients,

$$
\begin{aligned}
&\frac{a_{m}}{a_{n}}=(-1)^{m} \sum x_{1} x_{2} \cdots x_{m}, \\
&\frac{a_{0}}{a_{n}}=(-1)^{n} x_{1} x_{2} \cdots x_{n} .
\end{aligned}
$$

Dividing, we obtain

$$
\left|\sum \frac{1}{x_{1} x_{2} \cdots x_{m}}\right|=\left|\frac{a_{m}}{a_{0}}\right|>\left(\begin{array}{c}
n \\
m
\end{array}\right) .
$$

An application of the triangle inequality yields

$$
\sum \frac{1}{\left|x_{1}\right|\left|x_{2}\right| \cdots\left|x_{m}\right|}>\left(\begin{array}{c}
n \\
m
\end{array}\right) .
$$

Of the absolute values of the zeros, let $\alpha$ be the smallest. If we substitute all absolute values in the above inequality by $\alpha$, we obtain an even bigger left-hand side. Therefore,

$$
\left(\begin{array}{l}
n \\
m
\end{array}\right) \frac{1}{\alpha^{n-m}}>\left(\begin{array}{l}
n \\
m
\end{array}\right) .
$$

It follows that $\alpha<1$, and hence the corresponding zero has absolute value less than 1 , as desired.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

181. Let

$$
f(x)=\frac{P^{\prime}(x)}{P(x)}=\frac{1}{x-x_{1}}+\frac{1}{x-x_{2}}+\cdots+\frac{1}{x-x_{n}} .
$$

First, note that from Rolle's theorem applied to $P(x)=e^{-k x} f(x)$ it follows that all roots of the polynomial $P^{\prime}(x)-k P(x)$ are real. We need the following lemma.

Lemma. Iffor some $j, y_{0}$ and $y_{1}$ satisfy $y_{0}<x_{j}<y_{1} \leq y_{0}+\delta(P)$, then $y_{0}$ and $y_{1}$ are not zeros of $f$ and $f\left(y_{0}\right)<f\left(y_{1}\right)$.

Proof. Let $d=\delta(P)$. The hypothesis implies that for all $i, y_{1}-y_{0} \leq d \leq x_{i+1}-x_{i}$. Hence for $1 \leq i \leq j-1$ we have $y_{0}-x_{i} \geq y_{1}-x_{i+1}>0$, and so $1 /\left(y_{0}-x_{i}\right) \leq$ $1 /\left(y_{1}-x_{i+1}\right)$; similarly, for $j \leq i \leq n-1$ we have $y_{1}-x_{i+1} \leq y_{0}-x_{i}<0$ and again $1 /\left(y_{0}-x_{i}\right) \leq 1 /\left(y_{1}-x_{i+1}\right)$.

Finally, $y_{0}-x_{n}<0<y_{1}-x_{1}$, so $1 /\left(y_{0}-x_{n}\right)<0<1 /\left(y_{1}-x_{1}\right)$, and the result follows by addition of these inequalities. Returning to the problem, we see that if $y_{0}$ and $y_{1}$ are zeros of $P^{\prime}(x)-k P(x)$ with $y_{0}<y_{1}$, then they are separated by a zero of $P$ and satisfy $f\left(y_{0}\right)=f\left(y_{1}\right)=k$. From the lemma it follows that we cannot have $y_{1} \leq y_{0}+\delta(P(x))$, so $y_{1}-y_{0}>d$, and we are done.

(American Mathematical Monthly, published in a note by P. Walker, solution by R. Gelca)

182. The number 101 is prime, yet we cannot apply Eisenstein's criterion because of the 102. The trick is to observe that the irreducibility of $P(x)$ is equivalent to the irreducibility of $P(x-1)$. Because the binomial coefficients $\left(\begin{array}{c}101 \\ k\end{array}\right), 1 \leq k \leq 100$, are all divisible by 101, the polynomial $P(x-1)$ has all coefficients but the first divisible by 101 , while the last coefficient is $(-1)^{101}+101(-1)^{101}+102=202$, which is divisible by 101 but not by $101^{2}$. Eisenstein's criterion proves that $P(x-1)$ is irreducible; hence $P(x)$ is irreducible as well.

183. Note that $P(x)=\left(x^{p}-1\right) /(x-1)$. If $P(x)$ were reducible, then so would be $P(x+1)$. But

$$
P(x+1)=\frac{(x+1)^{p}-1}{x}=x^{p-1}+\left(\begin{array}{c}
p \\
1
\end{array}\right) x^{p-1}+\cdots+\left(\begin{array}{c}
p \\
p-1
\end{array}\right) .
$$

The coefficient $\left(\begin{array}{l}p \\ k\end{array}\right)$ is divisible by $p$ for all $1 \leq k \leq p-1$, and $\left(\begin{array}{c}p \\ p-1\end{array}\right)=p$ is not divisible by $p^{2}$; thus Eisenstein's criterion applies to show that $P(x+1)$ is irreducible. It follows that $P(x)$ itself is irreducible, and the problem is solved.

184. Same idea as in the previous problem. We look at the polynomial

$$
\begin{aligned}
P(x+1) &=(x+1)^{2^{n}}+1 \\
&=x^{2^{n}}+\left(\begin{array}{c}
2^{n} \\
1
\end{array}\right) x^{2^{n}-1}+\left(\begin{array}{c}
2^{n} \\
2
\end{array}\right) x^{2^{n-1}-2}+\cdots+\left(\begin{array}{c}
2^{n} \\
2^{n}-1
\end{array}\right) x+2 .
\end{aligned}
$$

For $1 \leq k \leq 2^{n}$, the binomial coefficient $\left(\begin{array}{c}2^{n} \\ k\end{array}\right)$ is divisible by 2 . This follows from the equality

$$
\left(\begin{array}{c}
2^{n} \\
k
\end{array}\right)=\frac{2^{n}}{k}\left(\begin{array}{c}
2^{n}-1 \\
k-1
\end{array}\right),
$$

since the binomial coefficient on the right is an integer, and 2 appears to a larger power in the numerator than in the denominator. The application of Eisenstein's irreducibility criterion is now straightforward.

185. Arguing by contradiction, assume that $P(x)$ can be factored, and let $P(x)=$ $Q(x) R(x)$. Because $P\left(a_{i}\right)=-1, i=1,2, \ldots, n$, and $Q\left(a_{i}\right)$ and $R\left(a_{i}\right)$ are integers, either $Q\left(a_{i}\right)=1$ and $R\left(a_{i}\right)=-1$, or $Q\left(a_{i}\right)=-1$ and $R\left(a_{i}\right)=1$. In both situations $(Q+R)\left(a_{i}\right)=0, i=1,2, \ldots, n$. Since the $a_{i}$ 's are all distinct and the degree of $Q(x)+R(x)$ is at most $n-1$, it follows that $Q(x)+R(x) \equiv 0$. Hence $R(x)=-Q(x)$, and $P(x)=-Q^{2}(x)$. But this contradicts the fact that the coefficient of the term of maximal degree in $P(x)$ is 1 . The contradiction proves that $P(x)$ is irreducible.

\section{(I. Schur)}

186. Assume that the polynomial $P(x)$ is reducible, and write it as a product $Q(x) R(x)$ of monic polynomials with integer coefficients of degree $i$, respectively, $2 n-i$. Both $Q(x)$ and $R(x)$ are positive for any real number $x$ (being monic and with no real zeros), and from $Q\left(a_{k}\right) R\left(a_{k}\right)=1, k=1,2, \ldots, n$, we find that $Q\left(a_{k}\right)=R\left(a_{k}\right)=1, k=1,2, \ldots, n$. If, say, $i<n$, then the equation $Q(x)=1$ has $n$ solutions, which, taking into account the fact that $Q(x)$ has degree less than $n$, means that $Q(x)$ is identically equal to 1 . This contradicts our original assumption. Also, if $i=n$, the polynomial $Q(x)-R(x)$ has $n$ zeros, and has degree less than $n$, so it is identically equal to 0 . Therefore, $Q(x)=R(x)$, which means that

$$
\left(x-a_{1}\right)^{2}\left(x-a_{2}\right)^{2} \cdots\left(x-a_{n}\right)^{2}+1=Q(x)^{2} .
$$

Substituting integer numbers for $x$, we obtain infinitely many equalities of the form $p^{2}+1=q^{2}$, with $p$ and $q$ integers. But this equality can hold only if $p=0$ and $q=1$, and we reach another contradiction. Therefore, the polynomial is irreducible.

\section{(I. Schur)}

187. Let $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{0}$, and assume to the contrary that $P(x)=$ $Q(x) R(x)$, where $Q(x)$ and $R(x)$ are polynomials with integer coefficients of degree at least 1 (the degree zero is ruled out because any factor that divides all coefficients of $P(x)$ divides the original prime $)$.

Because the coefficients of $P(x)$ are nonnegative integers between 0 and 9 , and the leading coefficient is positive, it follows that the zeros of $P(x)$ are in the union of the left half-plane $\operatorname{Im} z \leq 0$ and the disk $|z|<4$. Otherwise, if $\operatorname{Im} z>0$ and $|z| \geq 4$, then

$$
\begin{aligned}
1 & \leq a_{n} \leq \operatorname{Re}\left(a_{n}+a_{n-1} z^{-1}\right)=\operatorname{Re}\left(-a_{2} z^{-2}-\cdots-a_{n} z^{-n}\right) \\
&<\frac{9|z|^{-2}}{1-|z|^{-1}} \leq \frac{3}{4},
\end{aligned}
$$

a contradiction.

On the other hand, by hypothesis $P(10)$ is prime; hence either $Q(10)$ or $R(10)$ is 1 (or $-1$ but then just multiply both polynomials by $-1$ ). Assume $Q(10)=1$, and let $Q(x)=c\left(x-x_{1}\right)\left(x-x_{2}\right) \cdots\left(x-x_{k}\right)$. Then $x_{i}, i=1,2, \ldots, k$, are also zeros of $P(x)$, and we have seen that these lie either in the left half-plane or in the disk of radius 4 centered at the origin. It follows that

$$
1=Q(10)=|Q(10)|=|c| \cdot\left|10-x_{1}\right| \cdot\left|10-x_{2}\right| \cdots\left|10-x_{k}\right| \geq|c| \cdot 6^{k},
$$

a contradiction. We conclude that $P(x)$ is irreducible.

188. Assume the contrary, and let

$$
\left(x^{2}+1\right)^{n}+p=Q(x) R(x),
$$

with $Q(x)$ and $R(x)$ of degree at least 1 . Denote by $\hat{Q}(x), \hat{R}(x)$ the reduction of these polynomials modulo $p$, viewed as polynomials in $\mathbb{Z}_{p}[x]$. Then $\hat{Q}(x) \hat{R}(x)=\left(x^{2}+1\right)^{n}$. The polynomial $x^{2}+1$ is irreducible in $\mathbb{Z}_{p}[x]$, since $-1$ is not a quadratic residue in $\mathbb{Z}_{p}$. This implies $\hat{Q}(x)=\left(x^{2}+1\right)^{k}$ and $\hat{R}(x)=\left(x^{2}+1\right)^{n-k}$, with $1 \leq k \leq n-1$ (the polynomials are monic and their degree is at least 1 ). It follows that there exist polynomials $Q_{1}(x)$ and $R_{1}(x)$ with integer coefficients such that

$$
Q(x)=\left(x^{2}+1\right)^{k}+p Q_{1}(x) \quad \text { and } \quad R(x)=\left(x^{2}+1\right)^{n-k}+p R_{1}(x) .
$$

Multiplying the two, we obtain

$$
\left(x^{2}+1\right)^{n}+p=\left(x^{2}+1\right)^{n}+p\left(\left(x^{2}+1\right)^{n-k} Q_{1}(x)+\left(x^{2}+1\right)^{k} R_{1}(x)\right)+p^{2} Q_{1}(x) R_{1}(x) .
$$

Therefore,

$$
\left(x^{2}+1\right)^{n-k} Q_{1}(x)+\left(x^{2}+1\right)^{k} R_{1}(x)+p Q_{1}(x) R_{1}(x)=1 .
$$

Reducing modulo $p$ we see that $x^{2}+1$ divides 1 in $\mathbb{Z}_{p}[x]$, which is absurd. The contradiction proves that the polynomial from the statement is irreducible.

189. We will show that all the zeros of $P(x)$ have absolute value greater than 1 . Let $y$ be a complex zero of $P(x)$. Then

$$
0=(y-1) P(y)=y^{p}+y^{p-1}+y^{p-2}+\cdots+y-p .
$$

Assuming $|y| \leq 1$, we obtain

$$
p=\left|y^{p}+y^{p-1}+y^{p-2}+\cdots+y\right| \leq \sum_{i=1}^{p}|y|^{i} \leq \sum_{i=1}^{p} 1=p .
$$

This can happen only if the two inequalities are, in fact, equalities, in which case $y=1$. But $P(1)>0$, a contradiction that proves our claim.

Next, let us assume that $P(x)=Q(x) R(x)$ with $Q(x)$ and $R(x)$ polynomials with integer coefficients of degree at least 1 . Then $p=P(0)=Q(0) R(0)$. Since both $Q(0)$ and $R(0)$ are integers, either $Q(0)=\pm 1$ or $R(0)=\pm 1$. Without loss of generality, we may assume $Q(0)=\pm 1$. This, however, is impossible, since all zeros of $Q(x)$, which are also zeros of $P(x)$, have absolute value greater than 1 . We conclude that $P(x)$ is irreducible.

(proposed by M. Manea for Mathematics Magazine) 

190. Let $n$ be the degree of $P(x)$. Suppose that we can find polynomials with integer coefficients $R_{1}(x)$ and $R_{2}(x)$ of degree at most $2 n-1$ such that $Q(x)=P\left(x^{2}\right)=$ $R_{1}(x) R_{2}(x)$. Then we also have $Q(x)=Q(-x)=R_{1}(-x) R_{2}(-x)$. Let $F(x)$ be the greatest common divisor of $R_{1}(x)$ and $R_{1}(-x)$. Since $F(x)=F(-x)$, we can write $F(x)=G\left(x^{2}\right)$ with the degree of $G(x)$ at most $n-1$. Since $G\left(x^{2}\right)$ divides $Q(x)=P\left(x^{2}\right)$, we see that $G(x)$ divides $P(x)$ and has lower degree; hence by the irreducibility of $P(x), G(x)$ is constant. Similarly, the greatest common divisor of $R_{2}(x)$ and $R_{2}(-x)$ is constant. Hence $R_{1}(-x)$ divides $R_{2}(x)$, while $R_{2}(x)$ divides $R_{1}(-x)$. Hence $R_{1}(x)$ and $R_{2}(x)$ both have degree $n, R_{2}(x)=c R_{1}(-x)$, and $Q(x)=c R_{1}(x) R_{1}(-x)$. Because $P(x)$ is monic, we compute $c=(-1)^{n}$ and $P(0)=(-1)^{n} R_{1}(0)^{2}$. Hence $|P(0)|$ is a square, contradicting the hypothesis.

(Romanian Team Selection Test for the International Mathematical Olympiad, 2003, proposed by M. Piticari)

191. These are just direct consequences of the trigonometric identities

$$
\cos (n+1) \theta=\cos \theta \cos n \theta-\sin \theta \sin n \theta
$$

and

$$
\frac{\sin (n+1) \theta}{\sin \theta}=\cos \theta \frac{\sin n \theta}{\sin \theta}+\cos n \theta .
$$

192. Denote the second determinant by $D_{n}$. Expanding by the first row, we obtain

$$
D_{n}=2 x D_{n-1}-\left|\begin{array}{ccccc}
1 & 1 & 0 & \cdots & 0 \\
0 & 2 x & 1 & \cdots & 0 \\
0 & 1 & 2 x & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 2 x
\end{array}\right|=2 x D_{n-1}-D_{n-2} .
$$

Since $D_{1}=2 x$ and $D_{2}=4 x^{2}-1$, we obtain inductively $D_{n}=U_{n}(x), n \geq 1$. The same idea works for the first determinant, except that we expand it by the last row. With the same recurrence relation and with the values $x$ for $n=1$ and $2 x^{2}-1$ for $n=2$, the determinant is equal to $T_{n}(x)$ for all $n$.

193. Let $P(x)=x^{4}+a x^{3}+b x^{2}+c x+d$ and denote by $M$ the maximum of $|P(x)|$ on $[-1,1]$. From $-M \leq P(x) \leq M$, we obtain the necessary condition $-M \leq \frac{1}{2}(P(x)+$ $P(-x)) \leq M$ for $x \in[-1,1]$. With the substitution $y=x^{2}$, this translates into

$$
-M \leq y^{2}+b y+d \leq M, \quad \text { for } y \in[0,1] .
$$

For a monic quadratic function to have the smallest variation away from 0 on $[0,1]$, it needs to have the vertex (minimum) at $\frac{1}{2}$. The variation is minimized by $\left(y-\frac{1}{2}\right)^{2}-\frac{1}{8}$, and so we obtain $M \geq \frac{1}{8}$. Equality is attained for $\frac{1}{8} T_{4}(x)$. Now let us assume that $P(x)$ is a polynomial for which $M=\frac{1}{8}$. Then $b=-1$, $d=\frac{1}{8}$. Writing the double inequality $-\frac{1}{8} \leq P(x) \leq \frac{1}{8}$ for $x=1$ and $-1$, we obtain $-\frac{1}{8} \leq \frac{1}{8}+a+c \leq \frac{1}{8}$ and $-\frac{1}{8} \leq \frac{1}{8}-a-c \leq \frac{1}{8}$. So on the one hand, $a+c \geq 0$, and on the other hand, $a+c \leq 0$. It follows that $a=-c$. But then for $x=\frac{1}{\sqrt{2}}$, $0 \leq a\left(\frac{1}{2 \sqrt{2}}-\frac{1}{\sqrt{2}}\right) \leq \frac{1}{4}$, and for $x=-\frac{1}{\sqrt{2}}, 0 \leq-a\left(\frac{1}{2 \sqrt{2}}-\frac{1}{\sqrt{2}}\right) \leq \frac{1}{4}$. This can happen only if $a=0$. Therefore, $P(x)=x^{4}-x^{2}+\frac{1}{8}=\frac{1}{8} T_{4}(x)$.

194. From the identity

$$
x^{3}+\frac{1}{x^{3}}=\left(x+\frac{1}{x}\right)^{3}-3\left(x+\frac{1}{x}\right),
$$

it follows that

$$
\sqrt{r}+\frac{1}{\sqrt{r}}=6^{3}-3 \times 6=198 .
$$

Hence

$$
\left(\sqrt[4]{r}-\frac{1}{\sqrt[4]{r}}\right)^{2}=198-2,
$$

and the maximum value of $\sqrt[4]{r}-\frac{1}{\sqrt[4]{r}}$ is 14 .

(University of Wisconsin at Whitewater Math Meet, 2003, proposed by T. Andreescu)

195. Let $x_{1}=2 \cos \alpha, x_{2}=2 \cos 2 \alpha, \ldots, x_{n}=2 \cos n \alpha$. We are to show that the determinant

$$
\left|\begin{array}{cccc}
T_{0}\left(x_{1}\right) & T_{0}\left(x_{2}\right) & \cdots & T_{0}\left(x_{n}\right) \\
T_{1}\left(x_{1}\right) & T_{1}\left(x_{2}\right) & \cdots & T_{1}\left(x_{n}\right) \\
\vdots & \vdots & \ddots & \vdots \\
T_{n-1}\left(x_{1}\right) & T_{n-1}\left(x_{2}\right) & \cdots & T_{n-1}\left(x_{n}\right)
\end{array}\right|
$$

is nonzero. Substituting $T_{0}\left(x_{i}\right)=1, T_{1}\left(x_{i}\right)=x, i=1,2, \ldots, n$, and performing row operations to eliminate powers of $x_{i}$, we can transform the determinant into

$$
2 \cdot 4 \cdots 2^{n-1}\left|\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
x_{1} & x_{2} & \cdots & x_{n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-1} & x_{2}^{n-1} & \cdots & x_{n}^{n-1}
\end{array}\right| .
$$

This is a Vandermonde determinant, and the latter is not zero since $x_{i} \neq x_{j}$, for $1 \leq i<$ $j \leq n$, whence the original matrix is invertible. Its determinant is equal to 

$$
2^{(n-1)(n-2) / 2} \prod_{1 \leq i<j \leq n}(\cos j \alpha-\cos i \alpha) \neq 0
$$

196. Because the five numbers lie in the interval $[-2,2]$, we can find corresponding angles $t_{1}, t_{2}, t_{3}, t_{4}, t_{5} \in[0, \pi]$ such that $x=2 \cos t_{1}, y=2 \cos t_{2}, z=2 \cos t_{3}, v=$ $2 \cos t_{4}$, and $w=2 \cos t_{5}$. We would like to translate the third and fifth powers into trigonometric functions of multiples of the angles. For that we use the polynomials $\mathcal{T}_{n}(a)$. For example, $\mathcal{T}_{5}(a)=a^{5}-5 a^{3}+5 a$. This translates into the trigonometric identity $2 \cos 5 \theta=(2 \cos \theta)^{5}-5(2 \cos \theta)^{3}+5(2 \cos \theta)$.

Add to the third equation of the system the first multiplied by 5 and the second multiplied by $-5$, then use the above-mentioned trigonometric identity to obtain

$$
2 \cos 5 t_{1}+2 \cos 5 t_{2}+2 \cos 5 t_{3}+2 \cos 5 t_{4}+2 \cos 5 t_{5}=-10 .
$$

This can happen only if $\cos 5 t_{1}=\cos 5 t_{2}=\cos 5 t_{3}=\cos 5 t_{5}=\cos 5 t_{5}=-1$. Hence

$$
t_{1}, t_{2}, t_{3}, t_{4}, t_{5} \in\left\{\frac{\pi}{5}, \frac{3 \pi}{5}, \frac{5 \pi}{5}\right\} .
$$

Using the fact that the roots of $x^{5}=1$, respectively, $x^{10}=1$, add up to zero, we deduce that

$$
\sum_{k=0}^{4} \cos \frac{2 k \pi}{5}=0 \quad \text { and } \quad \sum_{k=0}^{9} \cos \frac{k \pi}{5}=0 .
$$

It follows that

$$
\cos \frac{\pi}{5}+\cos \frac{3 \pi}{5}+\cos \frac{5 \pi}{5}+\cos \frac{7 \pi}{5}+\cos \frac{9 \pi}{5}=0 .
$$

Since $\cos \frac{\pi}{5}=\cos \frac{9 \pi}{5}$ and $\cos \frac{3 \pi}{5}=\cos \frac{7 \pi}{5}$, we find that $\cos \frac{\pi}{5}+\cos \frac{3 \pi}{5}=\frac{1}{2}$. Also, it is not hard to see that the equation $\mathcal{T}_{5}(a)=-2$ has no rational solutions, which implies that $\cos \frac{\pi}{5}$ is irrational.

The first equation of the system yields $\sum_{i=1}^{5} t_{i}=0$, and the above considerations show that this can happen only when two of the $t_{i}$ are equal to $\frac{\pi}{5}$, two are equal to $\frac{3 \pi}{5}$, and one is equal to $\pi$. Let us show that in this situation the second equation is also satisfied. Using $\mathcal{T}_{3}(a)=a^{3}-3 a$, we see that the first two equations are jointly equivalent to $\sum_{k=1}^{5} \cos t_{i}=0$ and $\sum_{k=1}^{5} \cos 3 t_{i}=0$. Thus we are left to check that this last equality is satisfied. We have

$$
2 \cos \frac{3 \pi}{5}+2 \cos \frac{9 \pi}{5}+\cos 3 \pi=2 \cos \frac{3 \pi}{5}+2 \cos \frac{\pi}{5}+\cos \pi=0,
$$

as desired. We conclude that up to permutations, the solution to the system is 

$$
\left(2 \cos \frac{\pi}{5}, 2 \cos \frac{\pi}{5}, 2 \cos \frac{3 \pi}{5}, 2 \cos \frac{3 \pi}{5}, 2 \cos \pi\right) \text {. }
$$

(Romanian Mathematical Olympiad, 2002, proposed by T. Andreescu)

197. The Lagrange interpolation formula applied to the Chebyshev polynomial $T_{n-1}(x)$ and to the points $x_{1}, x_{2}, \ldots, x_{n}$ gives

$$
T_{n-1}(x)=\sum_{k=1}^{n} T_{n-1}\left(x_{k}\right) \frac{\left(x-x_{1}\right) \cdots\left(x-x_{k-1}\right)\left(x-x_{k+1}\right) \cdots\left(x-x_{n}\right)}{\left(x_{k}-x_{1}\right) \cdots\left(x_{k}-x_{k-1}\right)\left(x_{k}-x_{k+1}\right) \cdots\left(x_{k}-x_{n}\right)} .
$$

Equating the leading coefficients on both sides, we obtain

$$
2^{n-2}=\sum_{k=1}^{n} \frac{T_{n-1}\left(x_{k}\right)}{\left(x_{k}-x_{1}\right) \cdots\left(x_{k}-x_{k-1}\right)\left(x_{k}-x_{k+1}\right) \cdots\left(x_{k}-x_{n}\right)} \text {. }
$$

We know that the maximal variation away from 0 of $T_{n-1}(x)$ is 1 ; in particular, $\left|T_{n-1}\left(x_{k}\right)\right| \leq 1, k=1,2, \ldots, n$. Applying the triangle inequality, we obtain

$$
2^{n-2} \leq \sum_{k=1}^{n} \frac{\left|T_{n-1}\left(x_{k}\right)\right|}{\left|x_{k}-x_{1}\right| \cdots\left|x_{k}-x_{k-1}\right|\left|x_{k}-x_{k+1}\right| \cdots\left|x_{k}-x_{n}\right|} \leq \sum_{k=1}^{n} \frac{1}{t_{k}} .
$$

The inequality is proved.

(T. Andreescu, Z. Feng, 103 Trigonometry Problems, Birkhäuser, 2004)

198. Let us try to prove the first identity. Viewing both sides of the identity as sequences in $n$, we will show that they satisfy the same recurrence relation and the same initial condition. For the left-hand side the recurrence relation is, of course,

$$
\frac{T_{n+1}(x)}{\sqrt{1-x^{2}}}=2 x \frac{T_{n}(x)}{\sqrt{1-x^{2}}}-\frac{T_{n+1}(x)}{\sqrt{1-x^{2}}},
$$

and the initial condition is $T_{1}(x) / \sqrt{1-x^{2}}=x / \sqrt{1-x^{2}}$. It is an exercise to check that the right-hand side satisfies the same initial condition. As for the recurrence relation, we compute

$$
\begin{aligned}
\frac{d^{n+1}}{d x^{n+1}}\left(1-x^{2}\right)^{n+1-\frac{1}{2}} &=\frac{d^{n}}{d x^{n}} \frac{d}{d x}\left(1-x^{2}\right)^{n+1-\frac{1}{2}} \\
&=\frac{d^{n}}{d x^{n}}\left(n+1-\frac{1}{2}\right)\left(1-x^{2}\right)^{n-\frac{1}{2}}(-2 x) \\
&=-(2 n+1) x \frac{d^{n}}{d x^{n}}\left(1-x^{2}\right)^{n-\frac{1}{2}}-n(2 n+1) \frac{d^{n-1}}{d x^{n-1}}\left(1-x^{2}\right)^{n-\frac{1}{2}} .
\end{aligned}
$$

Here we apply the Leibniz rule for the differentiation of a product to obtain 

$$
\begin{array}{r}
-(2 n+1) x \frac{d^{n}}{d x^{n}}\left(1-x^{2}\right)^{n-\frac{1}{2}}-(2 n+1)\left(\begin{array}{c}
n \\
1
\end{array}\right) \frac{d}{d x} x \frac{d^{n-1}}{d x^{n-1}}\left(1-x^{2}\right)^{n-\frac{1}{2}} \\
=-(2 n+1) x \frac{d^{n}}{d x^{n}}\left(1-x^{2}\right)^{n-\frac{1}{2}}-n(2 n+1) \frac{d^{n-1}}{d x^{n-1}}\left(1-x^{2}\right)^{n-\frac{1}{2}} .
\end{array}
$$

So if $t_{n}(x)$ denotes the right-hand side, then

$$
t_{n+1}(x)=x t_{n}(x)-\frac{(-1)^{n-1} n}{1 \cdot 3 \cdots(2 n-1)} \frac{d^{n-1}}{d x^{n-1}}\left(1-x^{2}\right)^{n-1+\frac{1}{2}} .
$$

Look at the second identity from the statement! If it were true, then the last term would be equal to $\sqrt{1-x^{2}} U_{n-1}(x)$. This suggests a simultaneous proof by induction. Call the right-hand side of the second identity $u_{n}(x)$.

We will prove by induction on $n$ that $t_{n}(x)=T_{n}(x) / \sqrt{1-x^{2}}$ and $u_{n-1}(x)=$ $\sqrt{1-x^{2}} U_{n-1}(2 x)$. Let us assume that this holds true for all $k<n$. Using the induction hypothesis, we have

$$
t_{n}(x)=x \frac{T_{n-1}(x)}{\sqrt{1-x^{2}}}-\sqrt{1-x^{2}} U_{n-2}(x) .
$$

Using the first of the two identities proved in the first problem of this section, we obtain $t_{n}(x)=T_{n}(x) / \sqrt{1-x^{2}}$.

For the second half of the problem we show that $\sqrt{1-x^{2}} U_{n-1}(x)$ and $u_{n-1}(x)$ are equal by verifying that their derivatives are equal, and that they are equal at $x=1$. The latter is easy to check: when $x=1$ both are equal to 0 . The derivative of the first is

$$
\frac{-x}{\sqrt{1-x^{2}}} U_{n-1}(x)+2 \sqrt{1-x^{2}} U_{n-1}^{\prime}(x) .
$$

Using the inductive hypothesis, we obtain $u_{n-1}^{\prime}(x)=-n T_{n}(x) / \sqrt{1-x^{2}}$. Thus we are left to prove that

$$
-x U_{n-1}(x)+2\left(1-x^{2}\right) U_{n-1}^{\prime}(x)=-n T_{n}(x),
$$

which translates to

$$
-\cos x \frac{\sin n x}{\sin x}+2 \sin ^{2} x \frac{n \cos n x \sin x-\cos x \sin n x}{\sin ^{2} x} \cdot \frac{1}{\sin x}=n \cos n x .
$$

This is straightforward, and the induction is complete.

Remark. These are called the formulas of Rodrigues.

199. If $M=A+i B$, then $\overline{M^{t}}=\overline{A^{t}}-i \overline{B^{t}}=A-i B$. So we should take

$$
A=\frac{1}{2}\left(M+\overline{M^{t}}\right) \quad \text { and } \quad B=\frac{1}{2 i}\left(M-\overline{M^{t}}\right) \text {, }
$$

which are of course both Hermitian. Remark. This decomposition plays a special role, especially for linear operators on infinite-dimensional spaces. If $A$ and $B$ commute, then $M$ is called normal.

200. The answer is negative. The trace of $A B-B A$ is zero, while the trace of $\mathcal{I}_{n}$ is $n$; the matrices cannot be equal.

Remark. The equality cannot hold even for continuous linear transformations on an infinite-dimensional vector space. If $P$ and $Q$ are the linear maps that describe the momentum and the position in Heisenberg's matrix model of quantum mechanics, and if $\hbar$ is Planck's constant, then the equality $P Q-Q P=\hbar \mathcal{I}$ is the mathematical expression of Heisenberg's uncertainty principle. We now see that the position and the momentum cannot be modeled using finite-dimensional matrices (not even infinite-dimensional continuous linear transformations). Note on the other hand that the matrices whose entries are residue classes in $\mathbb{Z}_{4}$,

$$
A=\left(\begin{array}{llll}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0
\end{array}\right) \text { and } B=\left(\begin{array}{llll}
0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 \\
0 & 2 & 0 & 0 \\
0 & 0 & 3 & 0
\end{array}\right) \text {, }
$$

satisfy $A B-B A=\mathcal{I}_{4}$.

201. To simplify our work, we note that in general, for any two square matrices $A$ and $B$ of arbitrary dimension, the trace of $A B-B A$ is zero. We can therefore write

$$
A B-B A=\left(\begin{array}{rr}
a & b \\
c & -a
\end{array}\right) \text {. }
$$

But then $(A B-B A)^{2}=k \mathcal{I}_{2}$, where $k=a^{2}+b c$. This immediately shows that an odd power of $A B-B A$ is equal to a multiple of this matrix. The odd power cannot equal $\mathcal{I}_{2}$ since it has trace zero. Therefore, $n$ is even.

The condition from the statement implies that $k$ is a root of unity. But there are only two real roots of unity and these are 1 and $-1$. The squares of both are equal to 1 . It follows that $(A B-B A)^{4}=k^{2} \mathcal{I}_{2}=\mathcal{I}_{2}$, and the problem is solved.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

202. Assume that $p \neq q$. The second relation yields $A^{2} B^{2}=B^{2} A^{2}=r A^{4}$ and $r B^{2} A=$ $r A B^{2}=A^{3}$. Multiplying the relation $p A B+q B A=\mathcal{I}_{n}$ on the right and then on the left by $B$, we obtain

$$
p B A B-q B^{2} A=B \text { and } p A B^{2}+q B A B=B .
$$

From these two identities and the fact that $B^{2} A=A B^{2}$ and $p \neq q$ we deduce $B A B=$ $A B^{2}=B^{2} A$. Therefore, $(p+q) A B^{2}=(p+q) B^{2} A=B$. This implies right away that $(p+q) A^{2} B^{2}=A B$ and $(p+q) B^{2} A^{2}=B A$. We have seen that $A^{2}$ and $B^{2}$ commute, and so we find that $A$ and $B$ commute as well, which contradicts the hypothesis. Therefore, $p=q$

\section{(V. Vornicu)}

203. For any number $t$,

$$
\left(\begin{array}{ll}
1 & t \\
0 & 1
\end{array}\right)\left(\begin{array}{cc}
1 & -t \\
0 & 1
\end{array}\right)=\left(\begin{array}{cc}
1 & -t \\
0 & 1
\end{array}\right)\left(\begin{array}{ll}
1 & t \\
0 & 1
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right) .
$$

The equality from the statement can be rewritten

$$
\left(\begin{array}{ll}
1 & u \\
0 & 1
\end{array}\right)\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)\left(\begin{array}{ll}
1 & v \\
0 & 1
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
c & 1
\end{array}\right) .
$$

This translates to

$$
\left(\begin{array}{cc}
a+u c & v(a+u c)+b+u d \\
c & c v+d
\end{array}\right)=\left(\begin{array}{ll}
1 & 0 \\
c & 1
\end{array}\right) .
$$

Because $c \neq 0$ we can choose $u$ such that $a+u c=1$. Then choose $v=-(b+u d)$. The resulting matrix has 1 in the upper left corner and 0 in the upper right corner. In the lower right corner it has

$$
\begin{aligned}
c v+d &=-c(b+u d)+d=-b c-c u d+d=1-a d-u c d+d \\
&=1-(a+u c) d+d=1 .
\end{aligned}
$$

This also follows from the fact that the determinant of the matrix is 1 . The numbers $u$ and $v$ that we have constructed satisfy the required identity.

Remark. This factorization appears in Gaussian optics. The matrices

$$
\left(\begin{array}{cc}
1 & \pm u \\
0 & 1
\end{array}\right) \text { and }\left(\begin{array}{cc}
1 & \pm v \\
0 & 1
\end{array}\right)
$$

model a ray of light that travels on a straight line through a homogeneous medium, while the matrix

$$
\left(\begin{array}{ll}
1 & 0 \\
c & 1
\end{array}\right)
$$

models refraction between two regions of different refracting indices. The result we have just proved shows that any $\operatorname{SL}(2, \mathbb{R})$ matrix with nonzero lower left corner is an optical matrix. 


204. First solution: Computed by hand, the second, third, and fourth powers of $J_{4}(\lambda)$ are

$$
\left(\begin{array}{cccc}
\lambda^{2} & 2 \lambda & 1 & 0 \\
0 & \lambda^{2} & 2 \lambda & 1 \\
0 & 0 & \lambda^{2} & 2 \lambda \\
0 & 0 & 0 & \lambda^{2}
\end{array}\right), \quad\left(\begin{array}{cccc}
\lambda^{3} & 3 \lambda^{2} & 3 \lambda & 1 \\
0 & \lambda^{3} & 3 \lambda^{2} & 3 \lambda \\
0 & 0 & \lambda^{3} & 3 \lambda^{2} \\
0 & 0 & 0 & \lambda^{3}
\end{array}\right), \quad\left(\begin{array}{cccc}
\lambda^{4} & 4 \lambda^{3} & 6 \lambda^{2} & 4 \lambda \\
0 & \lambda^{4} & 4 \lambda^{3} & 6 \lambda^{2} \\
0 & 0 & \lambda^{4} & 4 \lambda^{3} \\
0 & 0 & 0 & \lambda^{4}
\end{array}\right) \text {. }
$$

This suggest that in general, the $i j$ th entry of $J_{m}(\lambda)^{n}$ is $\left(J_{m}(\lambda)^{n}\right)_{i j}=\left(\begin{array}{c}i \\ j-i\end{array}\right) \lambda^{n+i-j}$, with the convention $\left(\begin{array}{l}k \\ l\end{array}\right)=0$ if $l<0$. The proof by induction is based on the recursive formula for binomial coefficients. Indeed, from $J_{m}(\lambda)^{n+1}=J_{m}(\lambda)^{n} J_{m}(\lambda)$, we obtain

$$
\begin{aligned}
\left(J_{m}(\lambda)^{n+1}\right)_{i j} &=\lambda\left(J_{m}(\lambda)^{n}\right)_{i j}+\left(J_{m}(\lambda)^{n}\right)_{i, j-1} \\
&=\lambda\left(\begin{array}{c}
n \\
j-i
\end{array}\right) \lambda^{n+i-j}+\left(\begin{array}{c}
n \\
j-1-i
\end{array}\right) \lambda^{n+i-j+1}=\left(\begin{array}{c}
n+1 \\
j-i
\end{array}\right) \lambda^{n+1+i-j},
\end{aligned}
$$

which proves the claim.

Second solution: Define $S$ to be the $n \times n$ matrix with ones just above the diagonal and zeros elsewhere (usually called a shift matrix), and note that $S^{k}$ has ones above the diagonal at distance $k$ from it, and in particular $S^{n}=\mathcal{O}_{n}$. Hence

$$
J_{m}(\lambda)^{n}=\left(\lambda \mathcal{I}_{n}+S\right)^{n}=\sum_{k=0}^{n-1}\left(\begin{array}{l}
n \\
k
\end{array}\right) \lambda^{n-k} S^{k} .
$$

The conclusion follows.

Remark. The matrix $J_{m}(\lambda)$ is called a Jordan block. It is part of the Jordan canonical form of a matrix. Specifically, given a square matrix $A$ there exists an invertible matrix $S$ such that $S^{-1} A S$ is a block diagonal matrix whose blocks are matrices of the form $J_{m_{i}}\left(\lambda_{i}\right)$. The numbers $\lambda_{i}$ are the eigenvalues of $A$. As a consequence of this problem, we obtain a standard method for raising a matrix to the $n$th power. The idea is to write the matrix in the Jordan canonical form and then raise the blocks to the power.

205. There is one property of the trace that we need. For an $n \times n$ matrix $X$ with real entries, $\operatorname{tr}\left(X X^{t}\right)$ is the sum of the squares of the entries of $X$. This number is nonnegative and is equal to 0 if and only if $X$ is the zero matrix. It is noteworthy to mention that $\|X\|=\sqrt{\operatorname{tr}\left(C C^{t}\right)}$ is a norm known as the Hilbert-Schmidt norm.

We would like to apply the above-mentioned property to the matrix $A-B^{t}$ in order to show that this matrix is zero. Writing

$$
\begin{aligned}
\operatorname{tr}\left[\left(A-B^{t}\right)\left(A-B^{t}\right)^{t}\right] &=\operatorname{tr}\left[\left(A-B^{t}\right)\left(A^{t}-B\right)\right]=\operatorname{tr}\left(A A^{t}+B^{t} B-A B-B^{t} A^{t}\right) \\
&=\operatorname{tr}\left(A A^{t}+B^{t} B\right)-\operatorname{tr}\left(A B+B^{t} A^{t}\right)
\end{aligned}
$$

we see that we could almost use the equality from the statement, but the factors in two terms come in the wrong order. Another property of the trace comes to the rescue, namely, $\operatorname{tr}(X Y)=\operatorname{tr}(Y X)$. We thus have

$$
\begin{aligned}
\operatorname{tr}\left(A A^{t}+B^{t} B\right)-\operatorname{tr}\left(A B+B^{t} A^{t}\right) &=\operatorname{tr}\left(A A^{t}\right)+\operatorname{tr}\left(B^{t} B\right)-\operatorname{tr}(A B)-\operatorname{tr}\left(B^{t} A^{t}\right) \\
&=\operatorname{tr}\left(A A^{t}\right)+\operatorname{tr}\left(B B^{t}\right)-\operatorname{tr}(A B)-\operatorname{tr}\left(A^{t} B^{t}\right)=0 .
\end{aligned}
$$

It follows that $\operatorname{tr}\left[\left(A-B^{t}\right)\left(A-B^{t}\right)^{t}\right]=0$, which implies $A-B^{t}=\mathcal{O}_{n}$, as desired.

Remark. The Hilbert-Schmidt norm plays an important role in the study of linear transformations of infinite-dimensional spaces. It was first considered by E. Schmidt in his study of integral equations of the form

$$
f(x)-\int_{a}^{b} K(x, y) f(y) d y=g(x) .
$$

Here the linear transformation (which is a kind of infinite-dimensional matrix) is

$$
f(x) \rightarrow \int_{a}^{b} K(x, y) f(y) d y,
$$

and its Hilbert-Schmidt norm is

$$
\left(\int_{a}^{b} \int_{a}^{b}|K(x, y)|^{2} d x d y\right)^{1 / 2} .
$$

For a (finite- or infinite-dimensional) diagonal matrix $D$, whose diagonal elements are $d_{1}, d_{2}, \cdots \in \mathbb{C}$, the Hilbert-Schmidt norm is

$$
\sqrt{\operatorname{tr} D \overline{D^{t}}}=\left(\left|d_{1}\right|^{2}+\left|d_{2}\right|^{2}+\cdots\right)^{1 / 2} .
$$

206. The elegant solution is based on the equality of matrices

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-426.jpg?height=168&width=1004&top_left_y=1621&top_left_x=372)

Passing to determinants and factoring a 2, we obtain a product of two Vandermonde determinants, hence the formula from the statement.

(C. Coşniţă, F. Turtoiu, Probleme de Algebră (Problems in Algebra), Editura Tehnic $\breve{a}$, Bucharest, 1972)

207. Consider the matrix

$$
M=\left(\begin{array}{ll}
1 & 1 \\
1 & 0
\end{array}\right),
$$

which has the property that

$$
M^{n}=\left(\begin{array}{ll}
F_{n+1} & F_{n} \\
F_{n} & F_{n-1}
\end{array}\right), \quad \text { for } n \geq 1 .
$$

Taking determinants, we have

$$
F_{n+1} F_{n-1}-F_{n}^{2}=\operatorname{det} M^{n}=(\operatorname{det} M)^{n}=(-1)^{n},
$$

as desired.

\section{(J.D. Cassini)}

208. Subtract the $p$ th row from the $(p+1)$ st, then the $(p-1)$ st from the $p$ th, and so on. Using the identity $\left(\begin{array}{c}n \\ k\end{array}\right)-\left(\begin{array}{c}n-1 \\ k\end{array}\right)=\left(\begin{array}{c}n-1 \\ k-1\end{array}\right)$, the determinant becomes

$$
\left|\begin{array}{cccc}
1 & \left(\begin{array}{c}
m \\
1
\end{array}\right) & \cdots & \left(\begin{array}{c}
m \\
p
\end{array}\right) \\
0 & \left(\begin{array}{c}
m \\
0
\end{array}\right) & \cdots & \left(\begin{array}{c}
m \\
p-1
\end{array}\right) \\
\vdots & \vdots & \ddots & \vdots \\
0 & \left(\begin{array}{c}
m-1+p \\
0
\end{array}\right) & \cdots & \left(\begin{array}{c}
m-1+p \\
p-1
\end{array}\right)
\end{array}\right| .
$$

Expanding by the first row, we obtain a determinant of the same form but with $m$ replaced by $m-1$ and $p$ replaced by $p-1$. For $p=0$ the determinant is obviously equal to 1 , and an induction on $p$ proves that this is also true in the general case.

(C. Năstăsescu, C. Niţă, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogică, Bucharest, 1983)

209. The determinant

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-427.jpg?height=238&width=364&top_left_y=1469&top_left_x=690)

is an integer. On the other hand, for some positive integer $m$ and $k$, the binomial coefficient $\left(\begin{array}{c}m \\ k\end{array}\right)$ is a linear combination of $m^{k},\left(\begin{array}{c}m \\ k-1\end{array}\right), \ldots,\left(\begin{array}{c}m \\ 0\end{array}\right)$ whose coefficients do not depend on $m$. In this linear combination the coefficient of $m^{k}$ is $1 / k !$. Hence by performing row operations in the above determinant we can transform it into

$$
\left|\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
x_{1} & x_{2} & \cdots & x_{n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{1}^{n-1} & x_{2}^{n-1} & \cdots & x_{n}^{n-1}
\end{array}\right| .
$$

The Vandermonde determinant has the value $\prod_{i>j}\left(x_{i}-x_{j}\right)$.

It follows that our determinant is equal to $\prod_{i>j}\left(x_{i}-x_{j}\right) /(1 ! 2 ! \cdots(n-1) !)$, which therefore must be an integer. Hence the conclusion.

(Mathematical Mayhem, 1995)

210. The determinant is an $n$ th-degree polynomial in each of the $x_{i}$ 's. (If you have a problem working with multinomials, think of $x_{1}$ as the variable and of the others as parameters!) Adding all other columns to the first, we obtain that the determinant is equal to zero when $x_{1}+x_{2}+\cdots+x_{n}=0$, so $x_{1}+x_{2}+\cdots+x_{n}$ is a factor of the polynomial. This factor corresponds to $j=0$ on the right-hand side of the identity from the statement. For some other $j$, multiply the first column by $\zeta^{j}$, the second by $\zeta^{2 j}$, and so forth; then add all columns to the first. As before, we see that the determinant is zero when $\sum_{k=1}^{n} \zeta^{j k} x_{k}=0$, so $\sum_{k=1}^{n} \zeta^{j k} x_{k}$ is a factor of the determinant. No two of these polynomials are a constant multiple of the other, so the determinant is a multiple of

$$
\prod_{j=1}^{n-1}\left(\sum_{k=1}^{n} \zeta^{j k} x_{k}\right)
$$

The quotient of the two is a scalar $C$, independent of $x_{1}, x_{2}, \ldots, x_{n}$. For $x_{1}=1, x_{2}=$ $x_{3}=\cdots=x_{n}=0$, we obtain

$$
\begin{aligned}
x_{1}^{n} &=C \prod_{j=1}^{n-1}\left(\zeta^{j} x_{1}\right)=C \zeta^{1+2+\cdots+(n-1)} x_{1}=C \zeta^{n(n-1) / 2} x_{1}^{n} \\
&=C e^{(n-1) \pi i} x_{1}^{n}=C(-1)^{n-1} x_{1} .
\end{aligned}
$$

Hence $C=(-1)^{n-1}$, which gives rise to the formula from the statement.

211. By adding the second row to the first, the third row to the second, .., the $n$th row to the $(n-1)$ st, the determinant does not change. Hence

$$
\operatorname{det}(A)=\left|\begin{array}{rrrrrr}
2 & -1 & +1 & \cdots & \pm 1 & \mp 1 \\
-1 & 2 & -1 & \cdots & \mp 1 & \pm 1 \\
+1 & -1 & 2 & \cdots & \pm 1 \mp 1 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
\mp 1 \pm 1 & \mp 1 & \cdots & 2 & -1 \\
\pm 1 & \mp 1 \pm 1 & \cdots & -1 & 2
\end{array}\right|=\left|\begin{array}{ccccccc}
1 & 1 & 0 & 0 & \cdots & 0 & 0 \\
0 & 1 & 1 & 0 & \cdots & 0 & 0 \\
0 & 0 & 1 & 1 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \cdots & 1 & 1 \\
\pm 1 \mp 1 \pm 1 & \mp 1 & \ldots & -1 & 2
\end{array}\right| .
$$

Now subtract the first column from the second, then subtract the resulting column from the third, and so on. This way we obtain 

$$
\operatorname{det}(A)=\left|\begin{array}{cccccc}
1 & 0 & 0 & \cdots & 0 & 0 \\
0 & 1 & 0 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & 1 & 0 \\
\pm 1 & \mp 2 & \pm 3 & \cdots & -n+1 & n+1
\end{array}\right|=n+1 .
$$

(9th International Mathematics Competition for University Students, 2002)

212. View the determinant as a polynomial in the independent variables $x_{1}, x_{2}, \ldots, x_{n}$. Because whenever $x_{i}=x_{j}$ the determinant vanishes, it follows that the determinant is divisible by $x_{i}-x_{j}$, and therefore by the product $\prod_{1 \leq i<j \leq n}\left(x_{j}-x_{i}\right)$. Because the $k_{i}$ 's are positive, the determinant is also divisible by $x_{1} x_{2} \cdots x_{n}$. To solve the problem, it suffices to show that for any positive integers $x_{1}, x_{2}, \ldots, x_{n}$, the product

$$
x_{1} x_{2} \cdots x_{n} \prod_{1 \leq i<j \leq n}\left(x_{j}-x_{i}\right)
$$

is divisible by $n !$. This can be proved by induction on $n$. A parity check proves the case $n=2$. Assume that the property is true for any $n-1$ integers and let us prove it for $n$. Either one of the numbers $x_{1}, x_{2}, \ldots, x_{n}$ is divisible by $n$, or, by the pigeonhole principle, the difference of two of them is divisible by $n$. In the first case we may assume that $x_{n}$ is divisible by $n$, in the latter that $x_{n}-x_{1}$ is divisible by $n$. In either case,

$$
x_{1} x_{2} \cdots x_{n-1} \prod_{1 \leq i<j \leq n-1}\left(x_{j}-x_{i}\right)
$$

is divisible by $(n-1)$ !, by the induction hypothesis. It follows that the whole product is divisible by $n \times(n-1) !=n !$ as desired. We are done.

(proposed for the Romanian Mathematical Olympiad by N. Chichirim)

213. Expand the determinant as

$$
\operatorname{det}(x A+y B)=a_{0}(x) y^{3}+a_{1}(x) y^{2}+a_{2}(x) y+a_{3}(x),
$$

where $a_{i}(x)$ are polynomials of degree at most $i, i=0,1,2,3$. For $y=0$ this gives $\operatorname{det}(x A)=x^{3} \operatorname{det} A=0$, and hence $a_{3}(x)=0$ for all $x$. Similarly, setting $y=x$ we obtain $\operatorname{det}(x A+x B)=x^{3} \operatorname{det}(A+B)=0$, and thus $a_{0}(x) x^{3}+a_{1}(x) x^{2}+a_{2}(x) x=0$. Also, for $y=-x$ we obtain $\operatorname{det}(x A-x B)=x^{3} \operatorname{det}(A-B)=0$; thus $-a_{0}(x) x^{3}+$ $a_{1}(x) x^{2}-a_{x}(x) x=0$. Adding these two relations gives $a_{1}(x)=0$ for all $x$. For $x=0$ we find that $\operatorname{det}(y B)=y^{3} \operatorname{det} B=0$, and hence $a_{0}(0) y^{3}+a_{x}(0) y=0$ for all $y$. Therefore, $a_{0}(0)=0$. But $a_{0}(x)$ is a constant, so $a_{0}(x)=0$. This implies that $a_{2}(x) x=0$ for all $x$, and so $a_{2}(x)=0$ for all $x$. We conclude that $\operatorname{det}(x A+y B)$ is identically equal to zero, and the problem is solved.

(Romanian mathematics competition, 1979, M. Martin) 


214. We reduce the problem to a computation with $4 \times 4$ determinants. Expanding according to the rule of Laplace, we see that

$$
x^{2}=\left|\begin{array}{llll}
a & 0 & b & 0 \\
c & 0 & d & 0 \\
0 & b & 0 & a \\
0 & d & 0 & c
\end{array}\right| \quad \text { and } \quad x^{\prime 2}=\left|\begin{array}{cccc}
b^{\prime} & a^{\prime} & 0 & 0 \\
d^{\prime} & c^{\prime} & 0 & 0 \\
0 & 0 & b^{\prime} & a^{\prime} \\
0 & 0 & d^{\prime} & c^{\prime}
\end{array}\right| .
$$

Multiplying these determinants, we obtain $\left(x x^{\prime}\right)^{2}$.

(C. Coşniţă, F. Turtoiu, Probleme de Algebră (Problems in Algebra), Editura Tehnică, Bucharest, 1972)

215. First, suppose that $A$ is invertible. Then we can write

$$
\left(\begin{array}{ll}
A & B \\
C & D
\end{array}\right)=\left(\begin{array}{cc}
A & 0 \\
C & \mathcal{I}_{n}
\end{array}\right)\left(\begin{array}{cc}
\mathcal{I}_{n} & A^{-1} B \\
0 & D-C A^{-1} B
\end{array}\right) .
$$

The matrices on the right-hand side are of block-triangular type, so their determinants are the products of the determinants of the blocks on the diagonal (as can be seen on expanding the determinants using the rule of Laplace). Therefore,

$$
\operatorname{det}\left(\begin{array}{ll}
A & B \\
C & D
\end{array}\right)=(\operatorname{det} A)\left(\operatorname{det}\left(D-C A^{-1} B\right)\right)=\operatorname{det}\left(A D-A C A^{-1} B\right) .
$$

The equality from the statement now follows form that fact that $A$ and $C$ commute.

If $A$ is not invertible, then since the polynomial $\operatorname{det}\left(A+\epsilon \mathcal{I}_{n}\right)$ has finitely many zeros, $A+\epsilon \mathcal{I}_{n}$ is invertible for any sufficiently small $\epsilon>0$. This matrix still commutes with $C$, so we can apply the above argument to $A$ replaced by $A+\epsilon \mathcal{I}_{n}$. The identity from the statement follows by letting $\epsilon \rightarrow 0$.

216. Applying the previous problem, we can write

$$
\begin{aligned}
\operatorname{det}\left(\mathcal{I}_{n}-X Y\right) &=\operatorname{det}\left(\begin{array}{cc}
\mathcal{I}_{n} & X \\
Y & \mathcal{I}_{n}
\end{array}\right)=(-1)^{n} \operatorname{det}\left(\begin{array}{cc}
Y & \mathcal{I}_{n} \\
\mathcal{I}_{n} & X
\end{array}\right) \\
&=(-1)^{2 n} \operatorname{det}\left(\begin{array}{cc}
\mathcal{I}_{n} & Y \\
X & \mathcal{I}_{n}
\end{array}\right)=\operatorname{det}\left(\mathcal{I}_{n}-Y X\right) .
\end{aligned}
$$

Note that we performed some row and column permutations in the process, while keeping track of the sign of the determinant.

217. For $k$ even, that is, $k=2 m$, the inequality holds even without the assumption from the statement. Indeed, there exists $\epsilon$ arbitrarily small such that the matrix $B_{0}=B+\epsilon \mathcal{I}_{n}$ is invertible. Then

$$
\operatorname{det}\left(A^{2 m}+B_{0}^{2 m}\right)=\operatorname{det} B_{0}^{2 m} \operatorname{det}\left(\left(A^{m} B_{0}^{-m}\right)^{2}+\mathcal{I}_{n}\right),
$$

and the latter is nonnegative, as seen in the introduction. Taking the limit with $\epsilon$ approaching zero, we obtain $\operatorname{det}\left(A^{2 m}+B^{2 m}\right) \geq 0$.

For $k$ odd, $k=2 m+1$, let $x_{0}=-1, x_{1}, x_{2}, \ldots, x_{2 m}$ be the zeros of the polynomial $x^{2 m+1}+1$, with $x_{j+m}=\bar{x}_{j}, j=1,2, \ldots, m$. Because $A$ and $B$ commute, we have

$$
A^{2 m+1}+B^{2 m+1}=(A+B) \prod_{j=1}^{m}\left(A-x_{j} B\right)\left(A-\bar{x}_{j} B\right) .
$$

Since $A$ and $B$ have real entries, by taking determinants we obtain

$$
\begin{aligned}
\operatorname{det}\left(A-x_{j} B\right)\left(A-\bar{x}_{j} B\right) &=\operatorname{det}\left(A-x_{j} B\right) \operatorname{det}\left(A-\bar{x}_{j} B\right) \\
&=\operatorname{det}\left(A-x_{j} B\right) \operatorname{det} \overline{\left(A-x_{j} B\right)} \\
&=\operatorname{det}\left(A-x_{j} B\right) \overline{\operatorname{det}\left(A-x_{j} B\right)} \geq 0,
\end{aligned}
$$

for $j=1,2, \ldots, m$. This shows that the sign of $\operatorname{det}\left(A^{2 m+1}+B^{2 m+1}\right)$ is the same as the sign of $\operatorname{det}(A+B)$ and we are done.

(Romanian Mathematical Olympiad, 1986)

218. The case $\lambda \geq 0$ was discussed before. If $\lambda<0$, let $\omega=\sqrt{-\lambda}$. We have

$$
\begin{aligned}
\operatorname{det}\left(\mathcal{I}_{n}+\lambda A^{2}\right) &=\operatorname{det}\left(\mathcal{I}_{n}-\omega^{2} A^{2}\right)=\operatorname{det}\left(\mathcal{I}_{n}-\omega A\right)\left(\mathcal{I}_{n}+\omega A\right) \\
&=\operatorname{det}\left(\mathcal{I}_{n}-\omega A\right) \operatorname{det}\left(\mathcal{I}_{n}+\omega A\right) .
\end{aligned}
$$

Because $-A=A^{t}$, it follows that

$$
\mathcal{I}_{n}-\omega A=\mathcal{I}_{n}+\omega A^{t}={ }^{t}\left(\mathcal{I}_{n}+\omega A\right) .
$$

Therefore,

$$
\operatorname{det}\left(\mathcal{I}_{n}+\lambda A^{2}\right)=\operatorname{det}\left(\mathcal{I}_{n}+\omega A\right) \operatorname{det}^{t}\left(\mathcal{I}_{n}+\omega A\right)=\left(\operatorname{det}\left(\mathcal{I}_{n}+\omega A\right)\right)^{2} \geq 0,
$$

and the inequality is proved.

(Romanian mathematics competition, proposed by S. Rădulescu)

219. First solution: We can assume that the leading coefficient of $P(t)$ is 1 . Let $\alpha$ be a real number such that $P(t)+\alpha$ is strictly positive and let $Y$ be a matrix with negative determinant. Assume that $f$ is onto. Then there exists a matrix $X$ such that $P(X)=Y-\alpha \mathcal{I}_{n}$.

Because the polynomial $Q(t)=P(t)+\alpha$ has no real zeros, it factors as

$$
Q(t)=\prod_{k=1}^{m}\left[\left(t+a_{k}\right)^{2}+b_{k}^{2}\right]
$$

with $a_{k}, b_{k} \in \mathbb{R}$. It follows that

$$
\operatorname{det} Q(X)=\prod_{k=1}^{m} \operatorname{det}\left[\left(X+a_{k}\right)^{2}+b_{k}^{2} \mathcal{I}_{n}\right] \geq 0,
$$

and the latter is positive, since for all $k$,

$$
\operatorname{det}\left[\left(X+a_{k}\right)^{2}+b_{k}^{2} \mathcal{I}_{n}\right]=b_{k}^{2 n} \operatorname{det}\left[\left(\frac{1}{b_{k}} X+\frac{a_{k}}{b_{k}}\right)^{2}+\mathcal{I}_{n}\right] \geq 0 .
$$

In particular, $Q(X) \neq Y$ and thus the function $f$ is not onto.

Second solution: Because the polynomial $P(t)$ is of even degree, the function it defines on $\mathbb{R}$ is not onto. Let $\mu$ be a number that is not of the form $P(t), t \in \mathbb{R}$. Then the matrix $\mu \mathcal{I}_{n}$ is not in the image of $f$. Indeed, if $X$ is an $n \times n$ matrix, then by the spectral mapping theorem the eigenvalues of $P(X)$ are of the form $p(\lambda)$, where $\lambda$ is an eigenvalue of $X$. Since $\mu$ is not of this form, it cannot be an eigenvalue of a matrix in the image of $f$. But $\mu$ is the eigenvalue of $\mu \mathcal{I}_{n}$, which shows that the latter is not in the image of $f$, and the claim is proved.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by D. Andrica) 

220. If $A^{2}=\mathcal{O}_{n}$, then

$$
\operatorname{det}\left(A+\mathcal{I}_{n}\right)=\operatorname{det}\left(\frac{1}{4} A^{2}+A+\mathcal{I}_{n}\right)=\operatorname{det}\left(\frac{1}{2} A+\mathcal{I}_{n}\right)^{2}=\left(\operatorname{det}\left(\frac{1}{2} A+\mathcal{I}_{n}\right)\right)^{2} \geq 0
$$

Similarly,

$$
\begin{aligned}
\operatorname{det}\left(A-\mathcal{I}_{n}\right) &=\operatorname{det}\left(-\left(\mathcal{I}_{n}-A\right)\right)=(-1)^{n} \operatorname{det}\left(\mathcal{I}_{n}-A\right)=(-1)^{n} \operatorname{det}\left(\mathcal{I}_{n}-A+\frac{1}{4} A^{2}\right) \\
&=(-1)^{n} \operatorname{det}\left(\mathcal{I}_{n}-\frac{1}{2} A\right)^{2}=(-1)^{n}\left(\operatorname{det}\left(\mathcal{I}_{n}-\frac{1}{2} A\right)\right)^{2} \leq 0,
\end{aligned}
$$

since $n$ is odd. Hence $\operatorname{det}\left(A+\mathcal{I}_{n}\right) \geq 0 \geq \operatorname{det}\left(A-\mathcal{I}_{n}\right)$.

If $A^{2}=\mathcal{I}_{n}$, then

$$
\begin{aligned}
0 & \leq\left(\operatorname{det}\left(A+\mathcal{I}_{n}\right)^{2}\right)=\operatorname{det}\left(A+\mathcal{I}_{n}\right)^{2}=\operatorname{det}\left(A^{2}+2 A+\mathcal{I}_{n}\right) \\
&=\operatorname{det}\left(2 A+2 \mathcal{I}_{n}\right)=2^{n} \operatorname{det}\left(A+\mathcal{I}_{n}\right) .
\end{aligned}
$$

Also,

$$
\operatorname{det}\left(A-\mathcal{I}_{n}\right)=(-1)^{n} \operatorname{det}\left(\mathcal{I}_{n}-A\right)=(-1)^{n} \operatorname{det}\left(\frac{1}{2}\left(2 \mathcal{I}_{n}-2 A\right)\right)
$$



$$
\begin{aligned}
&=\left(-\frac{1}{2}\right)^{n} \operatorname{det}\left(\mathcal{I}_{n}-2 A+\mathcal{I}_{n}\right)=\left(-\frac{1}{2}\right)^{n} \operatorname{det}\left(A^{2}-2 A+\mathcal{I}_{n}\right) \\
&=\left(-\frac{1}{2}\right)^{n} \operatorname{det}\left(A-\mathcal{I}_{n}\right)^{2} \leq 0
\end{aligned}
$$

and the inequality is proved in this case, too.

(Romanian mathematics competition, 1987)

221. All the information about the inverse of $A$ is contained in its determinant. If we compute the determinant of $A$ by expanding along the $k$ th column, we obtain a polynomial in $x_{k}$, and the coefficient of $x_{k}^{m-1}$ is exactly the minor used for computing the entry $b_{k m}$ of the adjoint matrix multiplied by $(-1)^{k+m}$. Viewing the product $\prod_{i>j}\left(x_{i}-x_{j}\right)$ as a polynomial in $x_{k}$, we have

$$
\begin{aligned}
\prod_{i>j}\left(x_{i}-x_{j}\right)=& \Delta\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) \times\left(x_{k}-x_{1}\right) \cdots\left(x_{k}-x_{k-1}\right) \\
& \times\left(x_{k+1}-x_{k}\right) \ldots\left(x_{n}-x_{k}\right) \\
=&(-1)^{n-k} \Delta\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) \times \prod_{j \neq k}\left(x_{k}-x_{j}\right) .
\end{aligned}
$$

In the product $\prod_{j \neq k}\left(x_{k}-x_{j}\right)$ the coefficient of $x_{k}^{m-1}$ is

$$
(-1)^{n-m} S_{n-m}\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) .
$$

Combining all these facts, we obtain

$$
\begin{aligned}
b_{k m}=&(-1)^{k+m} \Delta\left(x_{1}, x_{2}, \ldots, x_{n}\right)^{-1}(-1)^{k+m}(-1)^{n-k}(-1)^{n-m} \\
& \times \Delta\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) S_{m}\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) \\
=&(-1)^{k+m} \Delta\left(x_{1}, x_{2}, \ldots, x_{n}\right)^{-1} \Delta\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right) \\
& \times S_{m}\left(x_{1}, \ldots, x_{k-1}, x_{k+1}, \ldots, x_{n}\right)
\end{aligned}
$$

as desired.

222. The inverse of a $2 \times 2$ matrix $C=\left(c_{i j}\right)_{i, j}$ with integer entries is a matrix with integer entries if and only if det $C=\pm 1$ (one direction of this double implication follows from the formula for the inverse, and the other from $\operatorname{det} C^{-1}=1 / \operatorname{det} C$ ).

With this in mind, let us consider the polynomial $P(x) \in \mathbb{Z}[x], P(x)=\operatorname{det}(A+x B)$. The hypothesis of the problem implies that $P(0), P(1), P(2), P(3), P(4) \in\{-1,1\}$. By the pigeonhole principle, three of these numbers are equal, and because $P(x)$ has degree at most 2 , it must be constant. Therefore, $\operatorname{det}(A+x B)=\pm 1$ for all $x$, and in particular for $x=5$ the matrix $A+5 B$ is invertible and has determinant equal to $\pm 1$. Consequently, the inverse of this matrix has integer entries.

(55th W.L. Putnam Mathematical Competition, 1994) 

223. We know that $A A^{*}=A^{*} A=(\operatorname{det} A) \mathcal{I}_{3}$, so if $A$ is invertible then so is $A^{*}$, and $A=\operatorname{det} A\left(A^{*}\right)^{-1}$. Also, $\operatorname{det} A \operatorname{det} A^{*}=(\operatorname{det} A)^{3}$; hence $\operatorname{det} A^{*}=(\operatorname{det} A)^{2}$. Therefore, $A=\pm \sqrt{\operatorname{det} A^{*}}\left(A^{*}\right)^{-1}$.

Because

$$
A^{*}=(1-m)\left(\begin{array}{ccc}
-m-1 & 1 & 1 \\
1 & -m-1 & 1 \\
1 & 1 & -m-1
\end{array}\right)
$$

we have

$$
\operatorname{det} A^{*}=(1-m)^{3}\left[-(m+1)^{3}+2+3(m+1)\right]=(1-m)^{4}(m+2)^{2} .
$$

Using the formula with minors, we compute the inverse of the matrix

$$
\left(\begin{array}{ccc}
-m-1 & 1 & 1 \\
1 & -m-1 & 1 \\
1 & 1 & -m-1
\end{array}\right)
$$

to be

$$
\frac{1}{(1-m)(m+2)^{2}}\left(\begin{array}{ccc}
-m^{2}-m-2 & m+2 & m+2 \\
m+2 & -m^{2}-m-2 & m+2 \\
m+2 & m+2 & -m^{2}-m-2
\end{array}\right) .
$$

Then $\left(A^{*}\right)^{-1}$ is equal to this matrix divided by $(1-m)^{3}$. Consequently, the matrix we are looking for is

$$
\begin{aligned}
A &=\pm \sqrt{\operatorname{det} A^{*}}\left(A^{*}\right)^{-1} \\
&=\pm \frac{1}{(1-m)^{2}(m+2)}\left(\begin{array}{ccc}
-m^{2}-m-2 & m+2 & m+2 \\
m+2 & -m^{2}-m-2 & m+2 \\
m+2 & m+2 & -m^{2}-m-2
\end{array}\right) .
\end{aligned}
$$

(Romanian mathematics competition)

224. The series expansion

$$
\frac{1}{1-x}=1+x+x^{2}+x^{3}+\cdots
$$

suggests that

$$
\left(\mathcal{I}_{n}-A\right)^{-1}=\mathcal{I}_{n}+A+A^{2}+A^{3}+\cdots .
$$

But does the series on the right converge? Let

$$
\alpha=\max _{i}\left(\sum_{j=1}^{n}\left|a_{i j}\right|\right)<1 .
$$

Then

$$
\sum_{k}\left|\sum_{j} a_{i j} a_{j k}\right| \leq \sum_{j, k}\left|a_{i j} a_{j k}\right|=\sum_{j}\left(\left|a_{i j}\right| \sum_{k}\left|a_{j k}\right|\right) \leq \alpha \sum_{j}\left|a_{i j}\right| \leq \alpha^{2} .
$$

Inductively we obtain that the entries $a_{i j}(n)$ of $A^{n}$ satisfy $\sum_{j}\left|a_{i j}(n)\right|<\alpha^{n}$ for all $i$. Because the geometric series $1+\alpha+\alpha^{2}+\alpha^{3}+\cdots$ converges, so does $\mathcal{I}_{n}+A+A^{2}+$ $A^{3}+\cdots$. And the sum of this series is the inverse of $\mathcal{I}_{n}-A$.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

225. The trick is to compute $A^{2}$. The elements on the diagonal are

$$
\sum_{k=1}^{n} \sin ^{2} k m \alpha, \quad m=1,2, \ldots, n,
$$

which are all nonzero. Off the diagonal, the $(m, j)$ th entry is equal to

$$
\sum_{k=1}^{n} \sin k m \alpha \sin k j \alpha=\frac{1}{2}\left[\sum_{k=1}^{n} \cos k(m-j) \alpha-\sum_{k=1}^{n} k(m+j) \alpha\right] .
$$

We are led to the computation of two sums of the form $\sum_{k=1}^{n} \cos k x$. This is done as follows:

$$
\sum_{k=1}^{n} \cos k x=\frac{1}{2 \sin \frac{x}{2}} \sum_{k=1}^{n} \sin \frac{x}{2} \cos k x=\frac{1}{2 \sin \frac{x}{2}} \sum_{k=1}^{n}\left[\sin \left(k+\frac{1}{2}\right) x-\sin \left(k-\frac{1}{2} x\right)\right] .
$$

The sum telescopes, and we obtain

$$
\sum_{k=1}^{n} \cos k x=\frac{\sin \left(n+\frac{1}{2}\right) x}{2 \sin \frac{x}{2}}-\frac{1}{2} .
$$

Note that for $x=(m \pm j) \alpha=\frac{(m \pm j) \pi}{n+1}$,

$$
\sin \left(n+\frac{1}{2}\right) x=\sin \left((m \pm j) \pi-\frac{x}{2}\right)=(-1)^{m+j+1} \sin \frac{x}{2} .
$$

Hence 

$$
\sum_{k=1}^{n} \cos (m \pm j) k \alpha=\frac{(-1)^{m+j+1}}{2}-\frac{1}{2} .
$$

It follows that for $m \neq j$, the $(m, j)$ entry of the matrix $A^{2}$ is zero. Hence $A^{2}$ is a diagonal matrix with nonzero diagonal entries. This shows that $A^{2}$ is invertible, and so is $A$.

Remark. This matrix appears in topological quantum field theory. A matrix of this type is used in the discrete Fourier transform, which has found applications to the JPEG encoding of digital photography.

226. If $A+i B$ is invertible, then so is $A^{\dagger}-i B^{\dagger}$. Let us multiply these two matrices:

$$
\left(A^{\dagger}-i B^{\dagger}\right)(A+i B)=A^{\dagger} A+B^{\dagger} B+i\left(A^{\dagger} B-B^{\dagger} A\right) .
$$

We have

$$
\begin{aligned}
&\left\langle\left(A^{\dagger} A+B^{\dagger} B+i\left(A^{\dagger} B-B^{\dagger} A\right)\right) v, v\right\rangle \\
&=\left\langle A^{\dagger} A v, v\right\rangle+\left\langle B^{\dagger} B v, v\right\rangle+\left\langle i\left(A^{\dagger} B-B^{\dagger} A\right) v, v\right\rangle \\
&=\|A v\|^{2}+\|B v\|^{2}+\left\langle i\left(A^{\dagger} B-B^{\dagger} A\right) v, v\right\rangle,
\end{aligned}
$$

which is strictly greater than zero for any vector $v \neq 0$. This shows that the product $\left(A^{\dagger}-i B^{\dagger}\right)(A+i B)$ is a positive definite matrix (i.e., $\left\langle\left(A^{\dagger}-i B^{\dagger}\right)(A+i B) v, v\right\rangle>0$ for all $v \neq 0$ ). The linear transformation that it defines is therefore injective, hence an isomorphism. This implies that $\left(A^{\dagger}-i B^{\dagger}\right)(A+i B)$ is invertible, and so $(A+i B)$ itself is invertible.

227. First solution: The fact that $A-\mathcal{I}_{n}$ is invertible follows from the spectral mapping theorem. To find its inverse, we recall the identity

$$
1+x+x^{2}+\cdots+x^{k}=\frac{x^{k+1}-1}{x-1},
$$

which by differentiation gives

$$
1+2 x+\cdots+k x^{k-1}=\frac{k x^{k+1}-(k+1) x^{k}+1}{(x-1)^{2}} .
$$

Substituting $A$ for $x$, we obtain

$$
\left(A-\mathcal{I}_{n}\right)^{2}\left(\mathcal{I}_{n}+2 A+\cdots+k A^{k-1}\right)=k A^{k+1}-(k+1) A^{k}+\mathcal{I}_{n}=\mathcal{I}_{n} .
$$

Hence

$$
\left(A-\mathcal{I}_{n}\right)^{-1}=\left(A-\mathcal{I}_{n}\right)\left(\mathcal{I}_{n}+2 A+\cdots+k A^{k-1}\right) .
$$

Second solution: Simply write

$$
\mathcal{I}_{n}=k A^{k+1}-(k+1) A^{k}+\mathcal{I}_{n}=\left(A-\mathcal{I}_{n}\right)\left(k A^{k}-A^{k-1}-\cdots-A-\mathcal{I}_{n}\right),
$$

which gives the inverse written in a different form.

(Mathematical Reflections, proposed by T. Andreescu)

228. If $\alpha \neq-1$ then

$$
\begin{aligned}
\left(A^{-1}-\frac{1}{\alpha+1} A^{-1} B A^{-1}\right)(A+B)=& \mathcal{I}_{n}+A^{-1} B-\frac{1}{\alpha+1} A^{-1} B A^{-1} B \\
&-\frac{1}{\alpha+1} A^{-1} B .
\end{aligned}
$$

But $\left(A^{-1} B\right)^{2}=A^{-1} X\left(Y A^{-1} X\right) Y=\alpha A^{-1} X Y=\alpha A^{-1} B$. Hence in the above equality, the right-hand side is equal to the identity matrix. This proves the claim.

If $\alpha=-1$, then $\left(A^{-1} B\right)^{2}+A^{-1} B=0$, that is, $\left(\mathcal{I}_{n}+A^{-1} B\right) A^{-1} B=0$. This implies that $\mathcal{I}_{n}+A^{-1} B$ is a zero divisor. Multiplying by $A$ on the right we find that $A+B$ is a zero divisor itself. Hence in this case $A+B$ is not invertible.

(C. Năstăsescu, C. Niţ̆̆, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogică, Bucharest, 1983)

229. The computation

$$
\left(A-b \mathcal{I}_{n}\right)\left(B-a \mathcal{I}_{n}\right)=a b \mathcal{I}_{n}
$$

shows that $A-b \mathcal{I}_{n}$ is invertible, and its inverse is $\frac{1}{a b}\left(B-a \mathcal{I}_{n}\right)$. Then

$$
\left(B-a \mathcal{I}_{n}\right)\left(A-b \mathcal{I}_{n}\right)=a b \mathcal{I}_{n},
$$

which translates into $B A-a A-b B=\mathcal{O}_{n}$. Consequently, $B A=a A+b B=A B$, proving that the matrices commute.

230. We have

$$
\left(A+i B^{2}\right)\left(B+i A^{2}\right)=A B-B^{2} A^{2}+i\left(A^{3}+B^{3}\right)=\mathcal{I}_{n} .
$$

This implies that $A+i B^{2}$ is invertible, and its inverse is $B+i A^{2}$. Then

$$
\mathcal{I}_{n}=\left(B+i A^{2}\right)\left(A+i B^{2}\right)=B A-A^{2} B^{2}+i\left(A^{3}+B^{3}\right)=B A-A^{2} B^{2},
$$

as desired.

(Romanian Mathematical Olympiad, 1982, proposed by I.V. Maftei)

231. Of course, one can prove that the coefficient matrix is nonsingular. But there is a slick solution. Add the equations and group the terms as 

$$
3\left(x_{1}+x_{2}+x_{3}\right)+3\left(x_{4}+x_{5}+x_{6}\right)+\cdots+3\left(x_{97}+x_{98}+x_{99}\right)+3 x_{100}=0 .
$$

The terms in the parentheses are all zero; hence $x_{100}=0$. Taking cyclic permutations yields $x_{1}=x_{2}=\cdots=x_{100}=0$.

232. If $y$ is not an eigenvalue of the matrix

$$
\left(\begin{array}{lllll}
0 & 1 & 0 & 0 & 1 \\
1 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 1 \\
1 & 0 & 0 & 1 & 0
\end{array}\right),
$$

then the system has the unique solution $x_{1}=x_{2}=x_{3}=x_{4}=x_{5}=0$. Otherwise, the eigenvectors give rise to nontrivial solutions. Thus, we have to compute the determinant

$$
\left|\begin{array}{ccccc}
-y & 1 & 0 & 0 & 1 \\
1 & -y & 1 & 0 & 0 \\
0 & 1 & -y & 1 & 0 \\
0 & 0 & 1 & -y & 1 \\
1 & 0 & 0 & 1 & -y
\end{array}\right| .
$$

Adding all rows to the first and factoring $2-y$, we obtain

$$
(2-y)\left|\begin{array}{ccccc}
1 & 1 & 1 & 1 & 1 \\
1 & -y & 1 & 0 & 0 \\
0 & 1 & -y & 1 & 0 \\
0 & 0 & 1 & -y & 1 \\
1 & 0 & 0 & 1 & -y
\end{array}\right| .
$$

The determinant from this expression is computed using row-column operations as follows:

$$
\begin{aligned}
& \left|\begin{array}{ccccc}1 & 1 & 1 & 1 & 1 \\1 & -y & 1 & 0 & 0 \\0 & 1 & -y & 1 & 0 \\0 & 0 & 1 & -y & 1 \\1 & 0 & 0 & 1 & -y\end{array}\right|=\left|\begin{array}{ccccc}1 & 0 & 0 & 0 & 0 \\1 & -y-1 & 0 & -1 & -1 \\0 & 1 & -y & 1 & 0 \\0 & 0 & 1 & -y & 1 \\1 & -1 & -1 & 0 & -y-1\end{array}\right|
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-438.jpg?height=212&width=848&top_left_y=1981&top_left_x=597)



$$
=\left|\begin{array}{cccc}
-y-1 & 0 & 0 & -1 \\
0 & -y & 1 & -1 \\
-1 & 1 & -y-1-1 \\
-1 & 0 & 0 & -y
\end{array}\right|,
$$

which, after expanding with the rule of Laplace, becomes

$$
-\left|\begin{array}{cc}
-y & -1 \\
1 & -y-1
\end{array}\right| \cdot\left|\begin{array}{cc}
-y-1 & -1 \\
-1 & -y
\end{array}\right|=-\left(y^{2}+y-1\right)^{2} .
$$

Hence the original determinant is equal to $(y-2)\left(y^{2}+y-1\right)^{2}$. If $y=2$, the space of solutions is therefore one-dimensional, and it is easy to guess the solution $x_{1}=x_{2}=$ $x_{3}=x_{4}=x_{5}=\lambda, \lambda \in \mathbb{R}$.

If $y=\frac{-1+\sqrt{5}}{2}$ or if $y=\frac{-1-\sqrt{5}}{2}$, the space of solutions is two-dimensional. In both cases, the minor

$$
\left|\begin{array}{ccc}
-y & 1 & 0 \\
1 & -y & 1 \\
0 & 1 & -y
\end{array}\right|
$$

is nonzero, hence $x_{3}, x_{4}$, and $x_{5}$ can be computed in terms of $x_{1}$ and $x_{2}$. In this case the general solution is

$$
(\lambda, \mu,-\lambda+y \mu,-y(\lambda+\mu), y \lambda-\mu), \quad \lambda, \mu \in \mathbb{R} .
$$

Remark. The determinant of the system can also be computed using the formula for the determinant of a circulant matrix.

(5th International Mathematical Olympiad, 1963, proposed by the Soviet Union)

233. Taking the logarithms of the four relations from the statement, we obtain the following linear system of equations in the unknowns $\ln a, \ln b, \ln c, \ln d$ :

$$
\begin{aligned}
-x \ln a+\ln b+\ln c+\ln d &=0, \\
\ln a-y \ln b+\ln c+\ln d &=0, \\
\ln a+\ln b-z \ln c+\ln d &=0, \\
\ln a+\ln b+\ln c-t \ln d &=0 .
\end{aligned}
$$

We are given that this system has a nontrivial solution. Hence the determinant of the coefficient matrix is zero, which is what had to be proved.

(Romanian mathematics competition, 2004)

234. First solution: Suppose there is a nontrivial solution $\left(x_{1}, x_{2}, x_{3}\right)$. Without loss of generality, we may assume $x_{1} \leq x_{2} \leq x_{3}$. Let $x_{2}=x_{1}+m, x_{3}=x_{1}+m+n, m, n \geq 0$. The first and the last equations of the system become 

$$
\begin{aligned}
&\left(a_{11}+a_{12}+a_{13}\right) x_{1}+\left(a_{12}+a_{13}\right) m+a_{13} n=0, \\
&\left(a_{31}+a_{32}+a_{33}\right) x_{1}+\left(a_{32}+a_{33}\right) m+a_{33} n=0 .
\end{aligned}
$$

The hypotheses $a_{31}+a_{32}+a_{33}>0$ and $a_{31}<0$ imply $a_{32}+a_{33} \geq 0$, and therefore $\left(a_{32}+a_{33}\right) m \geq 0$ and $a_{33} n \geq 0$. We deduce that $x_{1} \leq 0$, which combined with $a_{12}<0$, $a_{13}<0, a_{11}+a_{12}+a_{13}>0$ gives

$$
\left(a_{11}+a_{12}+a_{13}\right) x_{1} \leq 0, \quad\left(a_{12}+a_{13}\right) m \leq 0, \quad a_{13} n \leq 0 .
$$

The sum of these three nonpositive terms can be zero only when they are all zero. Hence $x_{1}=0, m=0, n=0$, which contradicts our assumption. We conclude that the system has the unique solution $x_{1}=x_{2}=x_{3}=0$.

Second solution: Suppose there is a nontrival solution $\left(x_{1}, x_{2}, x_{3}\right)$. Without loss of generality, we may assume that $\left|x_{3}\right| \geq\left|x_{2}\right| \geq\left|x_{1}\right|$. We have $a_{31}, a_{32}<0$ and $0<$ $-a_{31}-a_{32}<a_{33}$, so

$$
\left|a_{33} x_{3}\right|=\left|-a_{31} x_{1}-a_{32} x_{2}\right| \leq\left(-a_{31}-a_{32}\right)\left|x_{2}\right| \leq\left(-a_{31}-a_{32}\right)\left|x_{3}\right|<a_{33}\left|x_{3}\right| .
$$

This is a contradiction, which proves that the system has no nontrivial solution.

(7th International Mathematical Olympiad, 1965, proposed by Poland)

235. First solution: The zeros of $P(x)$ are $\epsilon, \epsilon^{2}, \ldots, \epsilon^{n}$, where $\epsilon$ is a primitive $(n+1)$ st root of unity. As such, the zeros of $P(x)$ are distinct. Let

$$
P\left(x^{n+1}\right)=Q(x) \cdot P(x)+R(x),
$$

where $R(x)=a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}$ is the remainder. Replacing $x$ successively by $\epsilon, \epsilon^{2}, \ldots, \epsilon^{n}$, we obtain

$$
\begin{aligned}
a_{n} \epsilon^{n-1}+\cdots+a_{1} \epsilon+a_{0} &=n+1, \\
a_{n}\left(\epsilon^{2}\right)^{n-1}+\cdots+a_{1} \epsilon^{2}+a_{0} &=n+1, \\
& \cdots \\
a_{n}\left(\epsilon^{n}\right)^{n-1}+\cdots+a_{1} \epsilon^{n}+a_{0} &=n+1,
\end{aligned}
$$

or

$$
\begin{aligned}
{\left[a_{0}-(n+1)\right]+a_{1} \epsilon+\cdots+a_{n-1} \epsilon^{n-1} } &=0, \\
{\left[a_{0}-(n+1)\right]+a_{1}\left(\epsilon^{2}\right)+\cdots+a_{n-1}\left(\epsilon^{2}\right)^{n-1} } &=0, \\
& \cdots \\
{\left[a_{0}-(n+1)\right]+a_{1}\left(\epsilon^{n}\right)+\cdots+a_{n-1}\left(\epsilon^{n}\right)^{n-1} } &=0 .
\end{aligned}
$$

This can be interpreted as a homogeneous system in the unknowns $a_{0}-(n+1)$, $a_{1}, a_{2}, \ldots, a_{n-1}$. The determinant of the coefficient matrix is Vandermonde, thus nonzero, and so the system has the unique solution $a_{0}-(n+1)=a_{1}=\cdots=a_{n-1}=0$. We obtain $R(x)=n+1$.

Second solution: Note that

$$
x^{n+1}=(x-1) P(x)+1 ;
$$

hence

$$
x^{k(n+1)}=(x-1)\left(x^{(k-1)(n+1)}+x^{(k-2)(n+1)}+\cdots+1\right) P(x)+1 .
$$

Thus the remainder of any polynomial $F\left(x^{n+1}\right)$ modulo $P(x)$ is $F(1)$. In our situation this is $n+1$, as seen above.

(Gazeta Matematic ă (Mathematics Gazette, Bucharest), proposed by M. Diaconescu) 

236. The function $\phi(t)=\frac{t-3}{t+1}$ has the property that $\phi \circ \phi \circ \phi$ equals the identity function. And $\phi(\phi(t))=\frac{3+t}{1-t}$. Replace $x$ in the original equation by $\phi(x)$ and $\phi(\phi(x))$ to obtain two more equations. The three equations form a linear system

$$
\begin{aligned}
f\left(\frac{x-3}{x+1}\right)+f\left(\frac{3+x}{1-x}\right) &=x, \\
f\left(\frac{3+x}{1-x}\right)+f(x) &=\frac{x-3}{x+1}, \\
f(x)+f\left(\frac{x-3}{x+1}\right) &=\frac{3+x}{1-x},
\end{aligned}
$$

in the unknowns

$$
f(x), \quad f\left(\frac{x-3}{x+1}\right), \quad f\left(\frac{3+x}{1-x}\right) .
$$

Solving, we find that

$$
f(t)=\frac{4 t}{1-t^{2}}-\frac{t}{2},
$$

which is the unique solution to the functional equation.

(Kvant (Quantum), also appeared at the Korean Mathematical Olympiad, 1999)

237. It is obvious that $\operatorname{gcd}(x, x+y)=\operatorname{gcd}(x, x+z)=1$. So in the equality from the statement, $x$ divides $y+z$. Similarly, $y$ divides $z+x$ and $z$ divides $x+y$. It follows that there exist integers $a, b, c$ with $a b c=t$ and

$$
\begin{aligned}
&x+y=c z, \\
&y+z=a x,
\end{aligned}
$$



$$
z+x=b y .
$$

View this as a homogeneous system in the variables $x, y, z$. Because we assume that the system admits nonzero solutions, the determinant of the coefficient matrix is zero. Writing down this fact, we obtain a new Diophantine equation in the unknowns $a, b, c$ :

$$
a b c-a-b-c-2=0 .
$$

This can be solved by examining the following cases:

1. $a=b=c$. Then $a=2$ and it follows that $x=y=z$, because these numbers are pairwise coprime. This means that $x=y=z=1$ and $t=8$. We have obtained the solution $(1,1,1,8)$.

2. $a=b, a \neq c$. The equation becomes $a^{2} c-2=2 a+c$, which is equivalent to $c\left(a^{2}-1\right)=2(a+1)$, that is, $c(a-1)=2$. We either recover case 1 , or find the new solution $c=1, a=b=3$. This yields the solution to the original equation $(1,1,2,9)$

3. $a>b>c$. In this case $a b c-2=a+b+c<3 a$. Therefore, $a(b c-3)<2$. It follows that $b c-3<2$, that is, $b c<5$. We have the following situations:

(i) $b=2, c=1$, so $a=5$ and we obtain the solution $(1,2,3,10)$.

(ii) $b=3, c=1$, so $a=3$ and we return to case 2 .

(iii) $b=4, c=1$, so $3 a=7$, which is impossible.

In conclusion, we have obtained the solutions $(1,1,1,8),(1,1,2,9),(1,2,3,10)$, and those obtained by permutations of $x, y, z$.

(Romanian Mathematical Olympiad, 1995)

238. Note that $m$ comparisons give rise to a homogeneous linear system of $m$ equations with $n$ unknowns, namely the masses, whose coefficients are $-1,0$, and 1 . Determining whether all coins have equal mass is the same as being able to decide whether the solution belongs to the one-dimensional subspace of $\mathbb{R}^{n}$ spanned by the vector $(1,1, \ldots, 1)$. Since the space of solutions has dimension at least $n-m$, in order to force the solution to lie in a one-dimensional space one needs at least $n-1$ equations. This means that we need to perform at least $n-1$ comparisions.

(Mathematical Olympiad Summer Program, 2006)

239. We are given that $a_{0}=a_{n+1}=0$ and $a_{k-1}-2 a_{k}+a_{k+1}=b_{k}$, with $b_{k} \in[-1,1]$, $k=1,2, \ldots, n$. Consider the linear system of equations

$$
\begin{aligned}
&a_{0}-2 a_{1}+a_{2}=b_{1}, \\
&a_{1}-2 a_{2}+a_{3}=b_{2},
\end{aligned}
$$



$$
a_{n-1}-2 a_{n}+a_{n+1}=b_{n}
$$

in the unknowns $a_{1}, a_{2}, \ldots, a_{n}$. To determine $a_{k}$ for some $k$, we multiply the first equation by 1 , the second by 2 , the third by 3 , and so on up to the $(k-1)$ st, which we multiply by $k-1$, then add them up to obtain

$$
-k a_{k-1}+(k-1) a_{k}=\sum_{j<k} j b_{j} .
$$

Working backward, we multiply the last equation by by 1 , the next-to-last by 2 , and so on up to the $(k+1)$ st, which we multiply by $n-k$, then add these equations to obtain

$$
-(n-k+1) a_{k+1}+(n-k) a_{k}=\sum_{j>k}(n-j+1) b_{j} .
$$

We now have a system of three equations,

$$
\begin{aligned}
-k a_{k-1}+(k-1) a_{k} &=\sum_{j<k} j b_{j}, \\
a_{k-1}-2 a_{k}+a_{k+1} &=b_{k}, \\
-(n-k+1) a_{k+1}+(n-k) a_{k} &=\sum_{j>k}(n-j+1) b_{j}
\end{aligned}
$$

in the unknowns $a_{k-1}, a_{k}, a_{k+1}$. Eliminating $a_{k-1}$ and $a_{k+1}$, we obtain

$$
\left(\frac{k-1}{k}-2+\frac{n-k}{n-k+1}\right) a_{k}=b_{k}+\frac{1}{k} \sum_{j<k} j b_{j}+\frac{1}{n-k+1} \sum_{j>k}(n-j+1) b_{j} .
$$

Taking absolute values and using the triangle inequality and the fact that $\left|b_{j}\right| \leq 1$, for all $j$, we obtain

$$
\begin{aligned}
\left|\frac{-n-1}{k(n-k+1)}\right|\left|a_{k}\right| & \leq 1+\frac{1}{k} \sum_{j<k} j+\frac{1}{n-k+1} \sum_{j>k}(n-j+1) \\
&=1+\frac{k-1}{2}+\frac{n-k}{2}=\frac{n+1}{2} .
\end{aligned}
$$

Therefore, $\left|a_{k}\right| \leq k(n-k+1) / 2$, and the problem is solved.

240. The fact that the matrix is invertible is equivalent to the fact that the system of linear equations

$$
\frac{x_{1}}{1}+\frac{x_{2}}{2}+\cdots+\frac{x_{n}}{n}=0,
$$



$$
\begin{array}{r}
\frac{x_{1}}{2}+\frac{x_{2}}{3}+\cdots+\frac{x_{n}}{n+1}=0 \\
\cdots \\
\frac{x_{1}}{n}+\frac{x_{2}}{n+1}+\cdots+\frac{x_{n}}{2 n-1}=0
\end{array}
$$

has only the trivial solution. For a solution $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ consider the polynomial

$$
\begin{aligned}
P(x)=& x_{1}(x+1)(x+2) \cdots(x+n-1)+x_{2} x(x+2) \cdots(x+n-1)+\cdots \\
&+x_{n} x(x+1) \cdots(x+n-2)
\end{aligned}
$$

Bringing to the common denominator each equation, we can rewrite the system in short form as $P(1)=P(2)=\cdots=P(n)=0$. The polynomial $P(x)$ has degree $n-1$; the only way it can have $n$ zeros is if it is identically zero. Taking successively $x=$ $0,-1,-2, \ldots,-n$, we deduce that $x_{i}=0$ for all $i$. Hence the system has only the trivial solution, and the matrix is invertible.

For the second part, note that the sum of the entries of a matrix $A$ is equal to the sum of the coordinates of the vector $A \overline{1}$, where $\overline{1}$ is the vector $(1,1, \ldots, 1)$. Hence the sum of the entries of the inverse matrix is equal to $x_{1}+x_{2}+\cdots+x_{n}$, where $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ is the unique solution to the system of linear equations

$$
\begin{aligned}
\frac{x_{1}}{1}+\frac{x_{2}}{2}+\cdots+\frac{x_{n}}{n} &=1 \\
\frac{x_{1}}{2}+\frac{x_{2}}{3}+\cdots+\frac{x_{n}}{n+1} &=1 \\
\frac{x_{1}}{n}+\frac{x_{2}}{n+1}+\cdots+\frac{x_{n}}{2 n-1} &=1
\end{aligned}
$$

This time, for a solution to this system, we consider the polynomial

$$
\begin{aligned}
Q(x)=& x_{1}(x+1)(x+2) \cdots(x+n-1)+\cdots+x_{n} x(x+1) \cdots(x+n-2) \\
&-x(x+1) \cdots(x+n-1)
\end{aligned}
$$

Again we observe that $Q(1)=Q(2)=\cdots=Q(n)=0$. Because $Q(x)$ has degree $n$ and dominating coefficient $-1$, it follows that $Q(x)=-(x-1)(x-2) \cdots(x-n)$. So

$$
\begin{gathered}
x_{1} \frac{(x+1)(x+2) \cdots(x+n-1)}{x^{n-1}}+\cdots+x_{n} \frac{x(x+1) \cdots(x+n-2)}{x^{n-1}} \\
=\frac{x(x+1) \cdots(x+n-1)-(x-1)(x-2) \cdots(x-n)}{x^{n-1}}
\end{gathered}
$$

The reason for writing this complicated relation is that as $x \rightarrow \infty$, the left-hand side becomes $x_{1}+x_{2}+\cdots+x_{n}$, while the right-hand side becomes the coefficient of $x^{n-1}$ in the numerator. And this coefficient is 

$$
1+2+\cdots+(n-1)+1+2+\cdots+n=\frac{n(n-1)}{2}+\frac{n(n+1)}{2}=n^{2} .
$$

The problem is solved.

Remark. It is interesting to note that the same method allows the computation of the inverse as $\left(b_{k, m}\right)_{k m}$, giving

$$
b_{k, m}=\frac{(-1)^{k+m}(n+k-1) !(n+m-1) !}{(k+m-1)[(k-1) !(m-1) !]^{2}(n-m) !(n-k) !} .
$$

241. First, note that the polynomials $\left(\begin{array}{c}x \\ 1\end{array}\right),\left(\begin{array}{c}x+1 \\ 3\end{array}\right),\left(\begin{array}{c}x+2 \\ 5\end{array}\right), \ldots$ are odd and have degrees $1,3,5, \ldots$, and so they form a basis of the vector space of the odd polynomial functions with real coefficients.

The scalars $c_{1}, c_{2}, \ldots, c_{m}$ are computed successively from

$$
\begin{aligned}
&P(1)=c_{1}, \\
&P(2)=c_{1}\left(\begin{array}{l}
2 \\
1
\end{array}\right)+c_{2}, \\
&P(3)=c_{1}\left(\begin{array}{l}
3 \\
1
\end{array}\right)+c_{2}\left(\begin{array}{l}
4 \\
3
\end{array}\right)+c_{3} .
\end{aligned}
$$

The conclusion follows.

(G. Pólya, G. Szegó, Aufgaben und Lehrsätze aus der Analysis, Springer-Verlag, 1964)

242. Inspired by the previous problem we consider the integer-valued polynomials $\left(\begin{array}{l}x \\ m\end{array}\right)=$ $x(x-1) \cdots(x-m+1) / m !, m=0,1,2, \ldots$. They form a basis of the vector space of polynomials with real coefficients. The system of equations

$$
P(k)=b_{0}\left(\begin{array}{l}
x \\
n
\end{array}\right)+b_{1}\left(\begin{array}{c}
x \\
n-1
\end{array}\right)+\cdots+b_{n-1}\left(\begin{array}{c}
x \\
1
\end{array}\right)+b_{n}, \quad k=0,1, \ldots, n,
$$

can be solved by Gaussian elimination, producing an integer solution $b_{0}, b_{1}, \ldots, b_{n}$. Yes, we do obtain an integer solution because the coefficient matrix is triangular and has ones on the diagonal! Finally, when multiplying $\left(\begin{array}{c}x \\ m\end{array}\right), m=0,1, \ldots, n$, by $n$ !, we obtain polynomials with integer coefficients. We find that $n ! P(x)$ has integer coefficients, as desired.

(G. Pólya, G. Szegó, Aufgaben und Lehrsätze aus der Analysis, Springer-Verlag, 1964)

243. For $n=1$ the rank is 1 . Let us consider the case $n \geq 2$. Observe that the rank does not change under row/column operations. For $i=n, n-1, \ldots, 2$, subtract the $(i-1)$ st row from the $i$ th. Then subtract the second row from all others. Explicitly, we obtain 

$$
\begin{aligned}
& \operatorname{rank}\left(\begin{array}{cccc}2 & 3 & \cdots & n+1 \\3 & 4 & \cdots & n+2 \\\vdots & \vdots & \ddots & \vdots \\n+1 & n+2 & \cdots & 2 n\end{array}\right)=\operatorname{rank}\left(\begin{array}{cccc}2 & 3 & \cdots & n+1 \\1 & 1 & \cdots & 1 \\\vdots & \ddots & \ddots & \vdots \\1 & 1 & \cdots & 1\end{array}\right) \\
& =\operatorname{rank}\left(\begin{array}{cccc}1 & 2 & \cdots & n \\1 & 1 & \cdots & 1 \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0\end{array}\right)=2 \text {. }
\end{aligned}
$$

(12th International Competition in Mathematics for University Students, 2005)

244. The polynomials $P_{j}(x)=(x+j)^{k}, j=0,1, \ldots, n-1$, lie in the $(k+1)$-dimensional real vector space of polynomials of degree at most $k$. Because $k+1<n$, they are linearly dependent. The columns consist of the evaluations of these polynomials at $1,2, \ldots, n$, so the columns are linearly dependent. It follows that the determinant is zero.

245. We prove this property by induction on $n$. For $n=1$, if $f_{1}$ is identically equal to zero, then so is $f$. Otherwise, pick a vector $e \notin f_{1}^{-1}(0)$. Note that any other vector $v \in V$ is of the form $\alpha e+w$ with $\alpha \in \mathbb{R}$ and $w \in f_{1}^{-1}(0)$. It follows that $f=\frac{f(e)}{f_{1}(e)} f_{1}$, and the base case is proved.

We now assume that the statement is true for $n=k-1$ and prove it for $n=k$. By passing to a subset, we may assume that $f_{1}, f_{2}, \ldots, f_{k}$ are linearly independent. Because $f_{k}$ is linearly independent of $f_{1}, f_{2}, \ldots, f_{k-1}$, by the induction hypothesis there exists a vector $e_{k}$ such that $f_{1}\left(e_{k}\right)=f_{2}\left(e_{k}\right)=\cdots=f_{k-1}\left(e_{k}\right)=0$, and $f_{k}\left(e_{k}\right) \neq 0$. Multiplying $e_{k}$ by a constant, we may assume that $f_{k}\left(e_{k}\right)=1$. The vectors $e_{1}, e_{2}, \ldots, e_{k-1}$ are defined similarly, so that $f_{j}\left(e_{i}\right)=1$ if $i=j$ and 0 otherwise.

For an arbitrary vector $v \in V$ and for $i=1,2, \ldots, k$, we have

$$
f_{i}\left(v-\sum_{j=1}^{k} f_{j}(v) e_{j}\right)=f_{i}(v)-\sum_{j=1}^{k} f_{j}(v) f_{i}\left(e_{j}\right)=f_{i}(v)-f_{i}(v) f_{i}\left(e_{i}\right)=0 .
$$

By hypothesis $f\left(v-\sum_{j=1}^{k} f_{j}(v) e_{j}\right)=0$. Since $f$ is linear, this implies

$$
f(v)=f\left(e_{1}\right) f_{1}(v)+f\left(e_{2}\right) f_{2}(v)+\cdots+f\left(e_{k}\right) f_{k}(v), \quad \text { for all } v \in V .
$$

This expresses $f$ as a linear combination of $f_{1}, f_{2}, \ldots, f_{k}$, and we are done.

(5th International Competition in Mathematics for University Students, 1998)

246. First solution: We will prove this property by induction on $n$. For $n=1$ it is obviously true. Assume that it is true for $n-1$, and let us prove it for $n$. Using the induction hypothesis, we can find $x_{1}, x_{2}, \ldots, x_{n-1} \in S$ such that $a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n-1} x_{n-1}$ is irrational for any nonnegative rational numbers $a_{1}, a_{2}, \ldots, a_{n}$ not all equal to zero. Denote the other elements of $S$ by $x_{n}, x_{n+1}, \ldots, x_{2 n-1}$ and assume that the property does not hold for $n$. Then for each $k=0,1, \ldots, n-1$ we can find rational numbers $r_{k}$ such that

$$
\left(\sum_{i=1}^{n-1} b_{i k} x_{i}\right)+c_{k} x_{n+k}=r_{k}
$$

with $b_{i k}, c_{k}$ some nonnegative integers, not all equal to zero. Because linear combinations of the $x_{i}$ 's, $i=1,2, \ldots, n-1$, with nonnegative coefficients are irrational, it follows that $c_{k}$ cannot be equal to zero. Dividing by the appropriate numbers if necessary, we may assume that for all $k, c_{k}=1$. We can write $x_{n+k}=r_{k}-\sum_{i=1}^{n-1} b_{i k} x_{i}$. Note that the irrationality of $x_{n+k}$ implies in addition that for a fixed $k$, not all the $b_{i k}$ 's are zero.

Also, for the $n$ numbers $x_{n}, x_{n+1}, \ldots, x_{2 n-1}$, we can find nonnegative rationals $d_{1}, d_{2}, \ldots, d_{n}$, not all equal to zero, such that

$$
\sum_{k=0}^{n-1} d_{k} x_{n+k}=r,
$$

for some rational number $r$. Replacing each $x_{n+k}$ by the formula found above, we obtain

$$
\sum_{k=0}^{n-1} d_{k}\left(-\sum_{i=1}^{n-1} b_{i k} x_{i}+r_{k}\right)=r .
$$

It follows that

$$
\sum_{i=1}^{n-1}\left(\sum_{k=0}^{n-1} d_{k} b_{i k}\right) x_{i}
$$

is rational. Note that there exists a nonzero $d_{k}$, and for that particular $k$ also a nonzero $b_{i k}$. We found a linear combination of $x_{1}, x_{2}, \ldots, x_{n-1}$ with coefficients that are positive, rational, and not all equal to zero, which is a rational number. This is a contradiction. The conclusion follows.

Second solution: Let $V$ be the span of $1, x_{1}, x_{2}, \ldots, x_{2 n-1}$ over $\mathbb{Q}$. Then $V$ is a finitedimensional $\mathbb{Q}$-vector space inside $\mathbb{R}$. Choose a $\mathbb{Q}$-linear function $f: V \rightarrow \mathbb{Q}$ such that $f(1)=0$ and $f\left(x_{i}\right) \neq 0$. Such an $f$ exists since the space of linear functions with $f(1)=0$ has dimension $\operatorname{dim} V-1$ and the space of functions that vanish on 1 and $x_{i}$ has dimension $\operatorname{dim} V-2$, and because $\mathbb{Q}$ is infinite, you cannot cover an $m$-dimensional vector space with finitely many $(m-1)$-dimensional subspaces. By the pigeonhole principle there are $n$ of the $x_{i}$ for which $f\left(x_{i}\right)$ has the same sign. Since $f(r)=0$ for all rational $r$, no linear combination of these $n$ with positive coefficients can be rational.

(second solution by R. Stong) 

247. First solution: Assume first that all numbers are integers. Whenever we choose a number, the sum of the remaining ones is even; hence the parity of each number is the same as the parity of the sum of all. And so all numbers have the same parity.

By subtracting one of the numbers from all we can assume that one of them is zero. Hence the numbers have the same parity as zero. After dividing by 2 , we obtain $2 n+1$ numbers with the same property. So we can keep dividing by 2 forever, which is possible only if all numbers are zero. It follows that initially all numbers were equal.

The case of rational numbers is resolved by multiplying by the least common multiple of the denominators. Now let us assume that the numbers are real. The reals form an infinite-dimensional vector space over the rationals. Using the axiom of choice we can find a basis of this vector space (sometimes called a Hammel basis). The coordinates of the $2 n+1$ numbers are rational, and must also satisfy the property from the statement (this follows from the fact that the elements of the basis are linearly independent over the rationals). So for each basis element, the corresponding coordinates of the $2 n+1$ numbers are the same. We conclude that the numbers are all equal, and the problem is solved.

However, this solution works only if we assume the axiom of choice to be true. The axiom states that given a family of sets, one can choose an element from each. Obvious as this statement looks, it cannot be deduced from the other axioms of set theory and has to be taken as a fundamental truth. A corollary of the axiom is Zorn's lemma, which is the actual result used for constructing the Hammel basis. Zorn's lemma states that if every totally ordered subset of a partially ordered set has an upper bound, then the set has a maximal element. In our situation this lemma is applied to families of linearly independent vectors with the ordering given by the inclusion to yield a basis.

Second solution: The above solution can be improved to avoid the use of the axiom of choice. As before, we prove the result for rational numbers. Arguing by contradiction we assume that there exist $2 n+1$ real numbers, not all equal, such that whenever one is removed the others can be separated into two sets with $n$ elements having the sum of their elements equal. If in each of these equalities we move all numbers to one side, we obtain a homogeneous system of $2 n+1$ equations with $2 n+1$ unknowns. In each row of the coefficient matrix, 1 and $-1$ each occur $n$ times, and 0 appears once. The solution to the system obviously contains the one-dimensional vector space $V$ spanned by the vector $(1,1, \ldots, 1)$. By hypothesis, it contains another vector that does not lie in $V$. Solving the system using Gaussian elimination, we conclude that there must also exist a vector with rational coordinates outside of $V$. But we already know that this is impossible. The contradiction proves that the numbers must be all equal.

248. Let $\lambda_{1}, \lambda_{2}$ be the eigenvalues of $A$. Then $-\lambda_{1} \mathcal{I}_{2}$ and $-\lambda_{2} \mathcal{I}_{2}$ both belong to $C(A)$, so

$$
0=\left|\operatorname{det}\left(A-\lambda_{i} \mathcal{I}_{2}\right)\right| \geq\left|\lambda_{i}\right|^{2}, \quad \text { for } i=1,2 .
$$

It follows that $\lambda_{1}=\lambda_{2}=0$. Change the basis to $v, w$ with $v$ an eigenvector of $A$ (which does exist because $A v=0$ has nontrivial solutions). This transforms the matrix into one of the form

$$
\left(\begin{array}{ll}
0 & a \\
0 & 0
\end{array}\right) .
$$

One easily checks that the square of this matrix is zero.

Conversely, assume that $A^{2}=\mathcal{O}_{2}$. By the spectral mapping theorem both eigenvalues of $A$ are zero, so by appropriately choosing the basis we can make $A$ look like

$$
\left(\begin{array}{ll}
0 & a \\
0 & 0
\end{array}\right) .
$$

If $a=0$, we are done. If not, then

$$
C(A)=\left\{\left(\begin{array}{cc}
\alpha & \beta \\
0 & \alpha
\end{array}\right) \mid \alpha, \beta \in \mathbb{R}\right\} .
$$

One verifies immediately that for every $B \in C(A)$, $\operatorname{det}(A+B)=\operatorname{det} B$. So the inequality from the statement is satisfied with equality. This completes the solution.

(Romanian Mathematical Olympiad, 1999, proposed by D. Miheţ)

249. Since $\operatorname{det} B=1, B$ is invertible and $B^{-1}$ has integer entries. From

$$
A^{3}+B^{3}=\left(\left(A B^{-1}\right)^{3}+\mathcal{I}_{2}\right) B^{3},
$$

it follows that $\operatorname{det}\left(\left(A B^{-1}\right)^{3}+\mathcal{I}_{2}\right)=1$. We will show that $\left(A B^{-1}\right)^{2}=\mathcal{O}_{2}$. Set $A B^{-1}=C$.

We know that $\operatorname{det}\left(C^{3}+\mathcal{I}_{2}\right)=1$. We have the factorization

$$
C^{3}+\mathcal{I}_{2}=\left(C+\mathcal{I}_{2}\right)\left(C+\epsilon \mathcal{I}_{2}\right)\left(C+\epsilon^{2} \mathcal{I}_{2}\right),
$$

where $\epsilon$ is a primitive cubic root. Taking determinants, we obtain

$$
P(-1) P(-\epsilon) P\left(-\epsilon^{2}\right)=1,
$$

where $P$ is the characteristic polynomial of $C$.

Let $P(x)=x^{2}-m x+n$; clearly $m, n$ are integers. Because $P\left(-\epsilon^{2}\right)=P(-\bar{\epsilon})=$ $\overline{P(\epsilon)}$, it follows that $P(-\epsilon) P\left(-\epsilon^{2}\right)$ is a positive integer. So $P(-1)=P(-\epsilon) P\left(-\epsilon^{2}\right)=$ 1. We obtain $1+m+n=1$ and $\left(\epsilon^{2}+m \epsilon+n\right)\left(\epsilon+m \epsilon^{2}+1\right)=1$, which, after some algebra, give $m=n=0$. So $C$ has just the eigenvalue 0 , and being a $2 \times 2$ matrix, its square is zero.

Finally, from the fact that $A B=B A$ and $\left(A B^{-1}\right)^{2}=\mathcal{O}_{2}$, we obtain $A^{2} B^{-2}=\mathcal{O}_{2}$, and multiplying on the right by $B^{2}$ we have $A^{2}=\mathcal{O}_{2}$, as desired.

(Romanian Mathematics Competition, 2004, proposed by M. Becheanu) 

250. First solution: The eigenvalues are the zeros of the polynomial $\operatorname{det}\left(\lambda \mathcal{I}_{n}-a A-b A^{t}\right)$. The matrix $\lambda \mathcal{I}_{n}-a A-b A^{t}$ is a circulant matrix, and the determinant of a circulant matrix was the subject of problem 211 in Section 2.3.2. According to that formula,

$$
\operatorname{det}\left(\lambda \mathcal{I}_{n}-a A-b A^{t}\right)=(-1)^{n-1} \prod_{j=0}^{n-1}\left(\lambda \zeta^{j}-a \zeta^{2 j}-b\right),
$$

where $\zeta=e^{2 \pi i / n}$ is a primitive $n$th root of unity. We find that the eigenvalues of $a A+b A^{t}$ are $a \zeta^{j}+b \zeta^{-j}, j=0,1, \ldots, n-1$.

Second solution: Simply note that for $\zeta=e^{2 \pi i / n}$ and $j=0,1, \ldots, n-1,\left(1, \zeta^{j}, \zeta^{2 j}\right.$, $\ldots, \zeta^{(n-1) j}$ ) is an eigenvector with eigenvalue $a \zeta^{j}+b \zeta^{-j}$.

251. Let $\phi$ be the linear transformation of the space $\mathbb{R}^{n}$ whose matrix in a certain basis $e_{1}, e_{2}, \ldots, e_{n}$ is $A$. Consider the orthogonal decompositions of the space $\mathbb{R}^{n}=\operatorname{ker} \phi \oplus T$, $\mathbb{R}^{n}=\operatorname{Im} \phi \oplus S$. Set $\phi^{\prime}=\left.\phi\right|_{T}$. Then $\phi^{\prime}: T \rightarrow \operatorname{Im} \phi$ is an isomorphism. Let $\gamma^{\prime}$ be its inverse, which we extend to a linear transformation $\gamma$ of the whole of $\mathbb{R}^{n}$ by setting $\left.\gamma\right|_{S}=0$. Then $\phi \gamma \phi=\phi^{\prime} \gamma^{\prime} \phi^{\prime}=\phi^{\prime}$ on $T$ and $\phi \gamma \phi=0$ on $T^{\perp}=\operatorname{ker} \phi$. Hence $\phi \gamma \phi=\phi$, and we can choose $B$ to be the matrix of $\gamma$ in the basis $e_{1}, e_{2}, \ldots, e_{n}$.

(Soviet Union University Student Mathematical Olympiad, 1976)

252. The map that associates to the angle the measure of its projection onto a plane is linear in the angle. The process of taking the average is also linear. Therefore, it suffices to check the statement for a particular angle. We do this for the angle of measure $\pi$, where it trivially works.

Remark. This lemma allows another proof of Fenchel's theorem, which is the subject of problem 644 in Section 4.1.4. If we defined the total curvature of a polygonal line to be the sum of the "exterior" angles, then the projection of any closed polygonal line in threedimensional space onto a one-dimensional line has total curvature at least $\pi+\pi=2 \pi$ (two complete turns). Hence the total curvature of the curve itself is at least $2 \pi$.

(communicated by J. Sullivan)

253. The first involution $A$ that comes to mind is the symmetry with respect to a hyperplane. For that particular involution, the operator $B=\frac{1}{2}(A+\mathcal{I})$ is the projection onto the hyperplane. Let us show that in general for any involution $A$, the operator $B$ defined as such is a projection. We have

$$
B^{2}=\frac{1}{4}(A+\mathcal{I})^{2}=\frac{1}{4}\left(A^{2}+2 A \mathcal{I}+\mathcal{I}^{2}\right)=\frac{1}{4}(\mathcal{I}+2 A+\mathcal{I})=B .
$$

There exists a basis of $V$ consisting of eigenvectors of $B$. Just consider the decomposition of $V$ into the direct sum of the image of $B$ and the kernel of $B$. The eigenvectors that form the basis are either in the image of $B$, in which case their eigenvalue is 1 , or in the kernel, in which case their eigenvalue is 0 . Because $A=2 B-\mathcal{I}$, it has the same eigenvectors as $B$, with eigenvalues $\pm 1$. This proves (a).

Part (b) is based on the fact that any family of commuting diagonalizable operators on $V$ can be diagonalized simultaneously. Let us prove this property by induction on the dimension of $V$. If all operators are multiples of the identity, there is nothing to prove. If one of them, say $S$, is not a multiple of the identity, then consider the eigenspace $V_{\lambda}$ of a certain eigenvalue $\lambda$. If $T$ is another operator in the family, then since $S T v=$ $T S v=\lambda T v$, it follows that $T v \in V_{\lambda}$; hence $V_{\lambda}$ is an invariant subspace for all operators in the family. This is true for all eigenspaces of $A$, and so all operators in the family are diagonal blocks on the direct decomposition of $V$ into eigenvectors of $A$. By the induction hypothesis, the family can be simultaneously diagonalized on each of these subspaces, and so it can be diagonalized on the entire space $V$.

Returning to the problem, diagonalize the pairwise commuting involutions. Their diagonal entries may equal $+1$ or $-1$ only, showing that there are at most $2^{n}$ such involutions. The number can be attained by considering all choices of sign on the diagonal.

(3rd International Competition in Mathematics for University Students, 1996)

254. From the orthogonality of $A u$ and $u$, we obtain

$$
\langle A u, u\rangle=\left\langle u, A^{t} u\right\rangle=\left\langle A^{t} u, u\right\rangle=0 .
$$

Adding, we obtain that $\left\langle\left(A+A^{t}\right) u, u\right\rangle=0$ for every vector $u$. But $A+A^{t}$ is symmetric, hence diagonalizable. For an eigenvector $v$ of eigenvalue $\lambda$, we have

$$
\left\langle\left(A+A^{t}\right) v, v\right\rangle=\langle\lambda v, v\rangle=\lambda\langle v, v\rangle=0 .
$$

This shows that all eigenvalues are zero, so $A+A^{t}=0$, which proves (a).

As a corollary of this, we obtain that $A$ is of the form

$$
A=\left(\begin{array}{ccc}
0 & a_{12} & a_{13} \\
-a_{12} & 0 & a_{23} \\
-a_{13} & -a_{23} & 0
\end{array}\right) .
$$

So $A$ depends on only three parameters, which shows that the matrix can be identified with a three-dimensional vector. To choose this vector, we compute

$$
A u=\left(\begin{array}{ccc}
0 & a_{12} & a_{13} \\
-a_{12} & 0 & a_{23} \\
-a_{13} & -a_{23} & 0
\end{array}\right)\left(\begin{array}{l}
u_{1} \\
u_{2} \\
u_{3}
\end{array}\right)=\left(\begin{array}{c}
a_{12} u_{1}+a_{13} u_{2} \\
-a_{12} u_{1}+a_{23} u_{3} \\
-a_{13} u_{1}-a_{23} u_{2}
\end{array}\right) .
$$

It is easy to see now that if we set $v=\left(-a_{23}, a_{13},-a_{12}\right)$, then $A u=v \times u$.

Remark. The set of such matrices is the Lie algebra so(3), and the problem describes two of its well-known properties. 

255. There is a more general property, of which the problem is a particular case.

Riesz lemma. If $V$ is a finite-dimensional vector space with inner product $\langle\cdot, \cdot\rangle$, then any linear functional $f: V \rightarrow \mathbb{R}$ is of the form $f(x)=\langle x, z\rangle$ for some unique $z \in V$.

This result can be generalized to any (complex) Hilbert space, and it is there where it carries the name of $\mathrm{F}$. Riesz.

We prove it as follows. If $f$ is identically zero, then $f(x)=\langle x, 0\rangle$. Otherwise, let $W$ be the kernel of $f$, which has codimension 1 in $V$. There exists a nonzero vector $y$ orthogonal to $W$ such that $f(y)=1$. Set $\mu=\langle y, y\rangle$ and define $z=\mu^{-1} y$. Then $\langle z, z\rangle=\mu^{-1}$. Any vector $x \in V$ is of the form $x^{\prime}+\lambda z$, with $x^{\prime} \in W$. We compute

$$
f(x)=f\left(x^{\prime}\right)+\lambda f(z)=\lambda \mu^{-1}=\lambda\langle z, z\rangle=\left\langle x^{\prime}, z\right\rangle+\lambda\langle z, z\rangle=\langle x, z\rangle .
$$

Note that $z$ is unique, because if $\langle x, z\rangle=\left\langle x, z^{\prime}\right\rangle$ for all $x$, then $z-z^{\prime}$ is orthogonal to all vectors, hence is the zero vector. There exists a simpler proof, but the one we gave here can be generalized to infinite-dimensional Hilbert spaces!

For our particular case, $V=M_{n}(\mathbb{R})$ and the inner product is the famous HilbertSchmidt inner product $\langle A, B\rangle=\operatorname{tr}\left(A B^{t}\right)$.

For the second part of the problem, the condition from the statement translates to $\operatorname{tr}((A B-B A) C)=0$ for all matrices $A$ and $B$. First, let us show that all off-diagonal entries of $C$ are zero. If $c_{i j}$ is an entry of $C$ with $i \neq j$, let $A$ be the matrix whose entry $a_{i k}$ is 1 and all others are 0 , and $B$ the matrix whose entry $b_{k j}$ is 1 and all others are 0 , for some number $k$. Then $\operatorname{tr}((A B-B A) C)=c_{i j}=0$. So $C$ is diagonal. Moreover, choose $a_{i j}=b_{i j}=1$, with $i \neq j$. Then $A B-B A$ has two nonzero entries, the $(i, i)$ entry, which is 1 , and the $(j, j)$ entry, which is $-1$. Therefore, $\operatorname{tr}((A B-B A) C)=c_{i i}-c_{j j}=0$. We deduce that all diagonal entries of $C$ are equal to some number $\lambda$, and hence

$$
f(A)=\operatorname{tr}(A C)=\operatorname{tr}(\lambda A)=\lambda \operatorname{tr}(A),
$$

as desired.

Remark. The condition $f(A B)=f(B A)$ gives

$$
\operatorname{tr}(A C)=f(A)=f\left(A B B^{-1}\right)=f\left(B^{-1} A B\right)=\operatorname{tr}\left(B^{-1} A B C\right)=\operatorname{tr}\left(A B C B^{-1}\right)
$$

hence by uniqueness of $C$, we have shown that $C=B C B^{-1}$ for all $B$, or $B C=C B$. The solution of the problem is essentially a proof that if $C$ commutes with all invertible matrices $B$, then $C=\lambda \mathcal{I}_{n}$ for some scalar $\lambda$.

256. Fix $x \in \mathbb{R}^{n}$ with $\|x\|=1$, and let $y=U^{-1} V^{-1} x$. Because $U$ and $V$ are isometric transformations, $\|y\|=1$. Then

$$
\left\|U V U^{-1} V^{-1} x-x\right\|=\|U V y-V U y\|
$$



$$
\begin{aligned}
&=\left\|\left(U-\mathcal{I}_{n}\right)\left(V-\mathcal{I}_{n}\right) y-\left(V-\mathcal{I}_{n}\right)\left(U-\mathcal{I}_{n}\right) y\right\| \\
&\leq\left\|\left(U-\mathcal{I}_{n}\right)\left(V-\mathcal{I}_{n}\right) y\right\|+\left\|\left(V-\mathcal{I}_{n}\right)\left(U-\mathcal{I}_{n}\right) y\right\| .
\end{aligned}
$$

The claim follows if we prove that $\left\|\left(U-\mathcal{I}_{n}\right)\left(V-\mathcal{I}_{n}\right) y\right\|$ and $\left\|\left(V-\mathcal{I}_{n}\right)\left(U-\mathcal{I}_{n}\right) y\right\|$ are both less than $\frac{1}{4}$, and because of symmetry, it suffices to check this for just one of them. If $\left(V-\mathcal{I}_{n}\right) y=0$, then $\left\|\left(U-\mathcal{I}_{n}\right)\left(V-\mathcal{I}_{n}\right) y\right\|=0<\frac{1}{4}$. Otherwise, using the properties of vector length, we proceed as follows:

$$
\begin{aligned}
\left\|\left(U-\mathcal{I}_{n}\right)\left(V-\mathcal{I}_{n}\right) y\right\| &=\left\|\left(U-\mathcal{I}_{n}\right)\right\|\left(V-\mathcal{I}_{n}\right) y\left\|\frac{\left(V-\mathcal{I}_{n}\right) y}{\left\|\left(V-\mathcal{I}_{n}\right) y\right\|}\right\| \\
&=\left\|\left(V-\mathcal{I}_{n}\right) y\right\| \times\left\|\left(U-\mathcal{I}_{n}\right) z\right\|,
\end{aligned}
$$

where $z$ is the length one vector $\frac{1}{\left\|\left(V-\mathcal{I}_{n}\right) y\right\|}\left(V-\mathcal{I}_{n}\right) y$. By the hypothesis, each factor in the product is less than $\frac{1}{2}$. This proves the claim and completes the solution.

257. The equality for general $k$ follows from the case $k=n$, when it is the well-known $\operatorname{det}(A B)=\operatorname{det}(B A)$. Apply this to

$$
\left(\begin{array}{ll}
\mathcal{I}_{n} & A \\
\mathcal{O}_{n} & \mathcal{I}_{n}
\end{array}\right)\left(\begin{array}{cc}
\lambda \mathcal{I}_{n}-A B & \mathcal{O}_{n} \\
B & \mathcal{I}_{n}
\end{array}\right)=\left(\begin{array}{cc}
\lambda \mathcal{I}_{n} & A \\
B & \mathcal{I}_{n}
\end{array}\right)=\left(\begin{array}{cc}
\mathcal{I}_{n} & \mathcal{O}_{n} \\
B & \mathcal{I}_{n}
\end{array}\right)\left(\begin{array}{lc}
\mathcal{I}_{n} & A \\
\mathcal{O}_{n} \lambda \mathcal{I}_{n}-B A
\end{array}\right)
$$

to obtain

$$
\operatorname{det}\left(\lambda \mathcal{I}_{n}-A B\right)=\operatorname{det}\left(\lambda \mathcal{I}_{n}-B A\right) .
$$

The coefficient of $\lambda^{k}$ in the left-hand side is $\phi_{k}(A B)$, while the coefficient of $\lambda^{k}$ in the right-hand side is $\phi_{k}(B A)$, and they must be equal.

Remark. From the many applications of the functions $\phi_{k}(A)$, we mention the construction of Chern classes in differential geometry.

258. From

$$
\mathcal{I}_{2}=\left(u \mathcal{I}_{2}+v A\right)\left(u^{\prime} \mathcal{I}_{2}+v^{\prime} A\right)=u u^{\prime} \mathcal{I}_{2}+\left(u v^{\prime}+v u^{\prime}\right) A+v v^{\prime} A^{2},
$$

using the Cayley-Hamilton Theorem, we obtain

$$
\mathcal{I}_{2}=\left(u u^{\prime}-v v^{\prime} \operatorname{det} A\right) \mathcal{I}_{2}+\left(u v^{\prime}+v u^{\prime}+v v^{\prime} \operatorname{tr} A\right) A .
$$

Thus $u^{\prime}$ and $v^{\prime}$ should satisfy the linear system

$$
\begin{array}{r}
u u^{\prime}-(v \operatorname{det} A) v^{\prime}=1, \\
v u^{\prime}+(u+v \operatorname{tr} A) v^{\prime}=0 .
\end{array}
$$

The determinant of the system is $u^{2}+u v \operatorname{tr} A+v^{2}$ det $A$, and an easy algebraic computation shows that this is equal to $\operatorname{det}\left(u \mathcal{I}_{2}+v A\right)$, which is nonzero by hypothesis. Hence the system can be solved, and its solution determines the desired inverse.

259. Rewriting the matrix equation as

$$
X^{2}\left(X-3 \mathcal{I}_{2}\right)=\left(\begin{array}{ll}
-2 & -2 \\
-2 & -2
\end{array}\right)
$$

and taking determinants, we obtain that either $\operatorname{det} X=0$ or $\operatorname{det}\left(X-3 \mathcal{I}_{2}\right)=0$. In the first case, the Cayley-Hamilton equation implies that $X^{2}=(\operatorname{tr} X) X$, and the equation takes the form

$$
\left[(\operatorname{tr} X)^{2}-3 \operatorname{tr} X\right] X=\left(\begin{array}{ll}
-2 & -2 \\
-2 & -2
\end{array}\right) .
$$

Taking the trace of both sides, we find that the trace of $X$ satisfies the cubic equation $t^{3}-3 t^{2}+4=0$, with real roots $t=2$ and $t=-1$. In the case $\operatorname{tr} X=2$, the matrix equation is

$$
-2 X=\left(\begin{array}{ll}
-2 & -2 \\
-2 & -2
\end{array}\right)
$$

with the solution

$$
X=\left(\begin{array}{ll}
1 & 1 \\
1 & 1
\end{array}\right) .
$$

When $\operatorname{tr} X=-1$, the matrix equation is

$$
4 X=\left(\begin{array}{ll}
-2 & -2 \\
-2 & -2
\end{array}\right)
$$

with the solution

$$
X=\left(\begin{array}{l}
-\frac{1}{2}-\frac{1}{2} \\
-\frac{1}{2}-\frac{1}{2}
\end{array}\right) .
$$

Let us now study the case $\operatorname{det}\left(X-3 \mathcal{I}_{2}\right)=0$. One of the two eigenvalues of $X$ is 3 . To determine the other eigenvalue, add $4 \mathcal{I}_{2}$ to the equation from the statement. We obtain

$$
X^{3}-3 X^{2}+4 \mathcal{I}_{2}=\left(X-2 \mathcal{I}_{2}\right)\left(X+\mathcal{I}_{2}\right)=\left(\begin{array}{l}
-2-2 \\
-2-2
\end{array}\right) .
$$

Taking determinants we find that either $\operatorname{det}\left(X-2 \mathcal{I}_{2}\right)=0$ or $\operatorname{det}\left(X+\mathcal{I}_{2}\right)=0$. So the second eigenvalue of $X$ is either 2 or $-1$. In the first case, the Cayley-Hamilton equation for $X$ is 

$$
X^{2}-5 X+6 \mathcal{I}_{2}=0,
$$

which can be used to transform the original equation into

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-455.jpg?height=116&width=405&top_left_y=416&top_left_x=665)

with the solution

$$
X=\left(\begin{array}{cc}
\frac{5}{2} & -\frac{1}{2} \\
-\frac{1}{2} & \frac{5}{2}
\end{array}\right) .
$$

The case in which the second eigenvalue of $X$ is $-1$ is treated similarly and yields the solution

$$
X=\left(\begin{array}{cc}
1 & -2 \\
-2 & 1
\end{array}\right) .
$$

(Romanian competition, 2004, proposed by A. Buju)

260. Because the trace of $[A, B]$ is zero, the Cayley-Hamilton Theorem for this matrix is $[A, B]^{2}+(\operatorname{det}[A, B]) \mathcal{I}_{2}=0$, which shows that $[A, B]^{2}$ is a multiple of the identity. The same argument applied to the matrices $[C, D]$ and $[A, B]+[C, D]$ shows that their squares are also multiples of the identity.

We have

$$
[A, B] \cdot[C, D]+[C, D] \cdot[A, B]=([A, B]+[C, D])^{2}-[A, B]^{2}-[C, D]^{2} .
$$

Hence $[A, B] \cdot[C, D]+[C, D] \cdot[A, B]$ is also a multiple of the identity, and the problem is solved.

(Romanian Mathematical Olympiad, 1981, proposed by C. Năstăsescu)

261. The Cayley-Hamilton Theorem gives

$$
(A B-B A)^{3}-c_{1}(A B-B A)^{2}+c_{2}(A B-B A)-c_{3} \mathcal{I}_{3}=\mathcal{O}_{3},
$$

where $c_{1}=\operatorname{tr}(A B-B A)=0$, and $c_{3}=\operatorname{det}(A B-B A)$. Taking the trace and using the fact that the trace of $A B-B A$ is zero, we obtain $\operatorname{tr}\left((A B-B A)^{3}\right)-3 \operatorname{det}(A B-B A)=0$, and the equality is proved.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

262. Let $C=A B-B A$. We have

$$
A B^{2}+B A^{2}=(A B-B A) B+B(A B-B A)=C B+B C=2 B C .
$$

Let $P_{B}(\lambda)=\lambda^{2}+r \lambda+s$ be the characteristic polynomial of $B$. By the Cayley-Hamilton Theorem, $P_{B}(B)=0$. We have

$$
\mathcal{O}_{2}=A P_{B}(B)-P_{B}(B) A=A B^{2}-B^{2} A+r(A B-B A)=2 B C+r C .
$$

Using this and the fact that $C$ commutes with $A$ and $B$, we obtain

$$
\mathcal{O}_{2}=A(2 B C+r C)-(2 B C+r C) A=2(A B-B A) C=2 C^{2} .
$$

Therefore, $C^{2}=\mathcal{O}_{2}$. In some basis

$$
C=\left(\begin{array}{cc}
0 & \alpha \\
0 & 0
\end{array}\right) .
$$

Hence $\mathrm{C}$ commutes only with polynomials in $C$. But if $A$ and $B$ are polynomials in $C$, then $C=\mathcal{O}_{2}$, a contradiction. So $C$ must be scalar whose square is equal to zero, whence $C=\mathcal{O}_{2}$ again. This shows that such matrices $A$ and $B$ do not exist.

(American Mathematical Monthly, solution by W. Gustafson)

263. Choose $\lambda \in \mathbb{R}$ sufficiently large such that $\lambda \mathcal{I}_{n}+A$ has positive entries. By the Perron-Frobenius Theorem, the largest eigenvalue $\rho$ of $\lambda \mathcal{I}_{n}+A$ is positive, and all other eigenvalues lie inside the circle of radius $\rho$ centered at the origin. In particular, $\rho$ is real and all other eigenvalues lie strictly to its left. The eigenvalues of $A$ are the horizontal translates by $\lambda$ of the eigenvalues of $\lambda \mathcal{I}_{n}+A$, so they enjoy the same property.

Remark. The result is true even for matrices whose off-diagonal entries are nonnegative, the so-called Metzler matrices, where a more general form of the Perron-Frobenius Theorem needs to be applied.

264. First solution: Define $A=\left(a_{i j}\right)_{i, j=1}^{3}$. Then replace $A$ by $B=\alpha \mathcal{I}_{3}-A$, where $\alpha$ is chosen large enough so that the entries $b_{i j}$ of the matrix $B$ are all positive. By the Perron-Frobenius Theorem, there exist a positive eigenvalue $\lambda$ and an eigenvector $c=\left(c_{1}, c_{2}, c_{3}\right)$ with positive coordinates. The equality $B c=\lambda c$ yields

$$
\begin{aligned}
&a_{11} c_{1}+a_{12} c_{2}+a_{13} c_{3}=(\alpha-\lambda) c_{1}, \\
&a_{21} c_{1}+a_{22} c_{2}+a_{23} c_{3}=(\alpha-\lambda) c_{2}, \\
&a_{31} c_{1}+a_{32} c_{2}+a_{33} c_{3}=(\alpha-\lambda) c_{3} .
\end{aligned}
$$

The three expressions from the statement have the same sign as $\alpha-\lambda$ : they are either all three positive, all three zero, or all three negative.

Second solution: The authors of this problem had a geometric argument in mind. Here it is. Consider the points $P\left(a_{11}, a_{21}, a_{31}\right), Q\left(a_{12}, a_{22}, a_{32}\right), R\left(a_{13}, a_{23}, a_{33}\right)$ in three-dimensional Euclidean space. It is enough to find a point in the interior of the triangle $P Q R$ whose coordinates are all positive, all negative, or all zero.

Let $P^{\prime}, Q^{\prime}, R^{\prime}$ be the projections of $P, Q, R$ onto the $x y$-plane. The hypothesis implies that $P^{\prime}, Q^{\prime}$, and $R^{\prime}$ lie in the fourth, second, and third quadrant, respectively.

Case 1. The origin $O$ is in the exterior or on the boundary of the triangle $P^{\prime} Q^{\prime} R^{\prime}$ (Figure 63).

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-457.jpg?height=429&width=564&top_left_y=696&top_left_x=590)

Figure 63

Denote by $S^{\prime}$ the intersection of the segments $P^{\prime} Q^{\prime}$ and $O R^{\prime}$, and let $S$ be the point on the segment $P Q$ whose projection is $S^{\prime}$. Note that the $z$-coordinate of the point $S$ is negative, since the $z$-coordinates of $P^{\prime}$ and $Q^{\prime}$ are negative. Thus any point in the interior of the segment $S R$ sufficiently close to $S$ has all coordinates negative, and we are done.

Case 2. The origin $O$ is in the interior of the triangle $P^{\prime} Q^{\prime} R^{\prime}$ (Figure 64).

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-457.jpg?height=431&width=564&top_left_y=1560&top_left_x=590)

Figure 64

Let $T$ be the point inside the triangle $P Q R$ whose projection is $O$. If $T=O$, we are done. Otherwise, if the $z$-coordinate of $T$ is negative, choose a point $S$ close to it inside the triangle $P Q R$ whose $x$ - and $y$-coordinates are both negative, and if the $z$-coordinate of $T$ is positive, choose $S$ to have the $x$ - and $y$-coordinates positive. Then the coordinates of $S$ are all negative, or all positive, and again we are done.

(short list of the 44th International Mathematical Olympiad, 2003, proposed by the USA)

265. Let $\lambda$ be the positive eigenvalue and $v=\left(v_{1}, v_{2}, \ldots, v_{n}\right)$ the corresponding eigenvector with positive entries of the transpose of the coefficient matrix. The function $y(t)=v_{1} x_{1}(t)+v_{2} x_{2}(t)+\cdots+v_{n} x_{n}(t)$ satisfies

$$
\frac{d y}{d t}=\sum_{i, j} v_{i} a_{i j} x_{j}=\sum_{j} \lambda v_{j} x_{j}=\lambda y .
$$

Therefore, $y(t)=e^{\lambda t} y_{0}$, for some vector $y_{0}$. Because

$$
\lim _{t \rightarrow \infty} y(t)=\sum_{i} v_{i} \lim _{t \rightarrow \infty} x_{i}(t)=0,
$$

and $\lim _{t \rightarrow \infty} e^{\lambda t}=\infty$, it follows that $y_{0}$ is the zero vector. Hence

$$
y(t)=v_{1} x_{1}(t)+v_{2} x_{2}(t)+\cdots+v_{n} x_{n}(t)=0,
$$

which shows that the functions $x_{1}, x_{2}, \ldots, x_{n}$ are necessarily linearly dependent.

(56th W.L. Putnam Mathematical Competition, 1995)

266. We try some particular cases. For $n=2$, we obtain $c=1$ and the sequence 1 , 1 , or $n=3, c=2$ and the sequence $1,2,1$, and for $n=4, c=3$ and the sequence $1,3,3,1$. We formulate the hypothesis that $c=n-1$ and $x_{k}=\left(\begin{array}{c}n-1 \\ k-1\end{array}\right)$.

The condition $x_{n+1}=0$ makes the recurrence relation from the statement into a linear system in the unknowns $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$. More precisely, the solution is an eigenvector of the matrix $A=\left(a_{i j}\right)_{i j}$ defined by

$$
a_{i j}= \begin{cases}i & \text { if } j=i+1, \\ n-j & \text { if } j=i-1, \\ 0 & \text { otherwise. }\end{cases}
$$

This matrix has nonnegative entries, so the Perron-Frobenius Theorem as stated here does not really apply. But let us first observe that $A$ has an eigenvector with positive coordinates, namely $x_{k}=\left(\begin{array}{c}n-1 \\ k-1\end{array}\right), k=1,2, \ldots, n$, whose eigenvalue is $n-1$. This follows by rewriting the combinatorial identity

$$
\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)=\left(\begin{array}{c}
n-2 \\
k
\end{array}\right)+\left(\begin{array}{l}
n-2 \\
k-1
\end{array}\right)
$$

as

$$
\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)=\frac{k+1}{n-1}\left(\begin{array}{c}
n-1 \\
k+1
\end{array}\right)+\frac{n-k}{n-1}\left(\begin{array}{l}
n-1 \\
k-1
\end{array}\right) .
$$

To be more explicit, this identity implies that for $c=n-1$, the sequence $x_{k}=\left(\begin{array}{l}n-1 \\ k-1\end{array}\right)$ satisfies the recurrence relation from the statement, and $x_{n+1}=0$.

Let us assume that $n-1$ is not the largest value that $c$ can take. For a larger value, consider an eigenvector $v$ of $A$. Then $\left(A+\mathcal{I}_{n}\right) v=(c+1) v$, and $\left(A+\mathcal{I}_{n}\right)^{n} v=(c+1)^{n} v$. The matrix $\left(A+\mathcal{I}_{n}\right)^{n}$ has positive entries, and so by the Perron-Frobenius Theorem has a unique eigenvector with positive coordinates. We already found one such vector, that for which $x_{k}=\left(\begin{array}{c}n-1 \\ k-1\end{array}\right)$. Its eigenvalue has the largest absolute value among all eigenvalues of $\left(A+\mathcal{I}_{n}\right)^{n}$, which means that $n^{n}>(c+1)^{n}$. This implies $n>c+1$, contradicting our assumption. So $n-1$ is the largest value $c$ can take, and the sequence we found is the answer to the problem.

(57th W.L. Putnam Mathematical Competition, 1997, solution by G. Kuperberg and published in K. Kedlaya, B. Poonen, R. Vakil, The William Lowell Putnam Mathematical Competition 1985-2000, MAA, 2002)

267. Let us first show that if the two numbers are equal, then the product can be found in six steps. For $x \neq-1$, we compute (1) $x \rightarrow \frac{1}{x},(2) x \rightarrow x+1,(3) x+1 \rightarrow \frac{1}{x+1}$, (4) $\frac{1}{x}, \frac{1}{x+1} \rightarrow \frac{1}{x}-\frac{1}{x+1}=\frac{1}{x^{2}+x}$, (5) $\frac{1}{x^{2}+x} \rightarrow x^{2}+x$, (6) $x^{2}+x, x \rightarrow x^{2}$. If $x=-1$, replace step (2) by $x \rightarrow x-1$ and make the subsequent modifications thereon.

If the two numbers are distinct, say $x$ and $y$, perform the following sequence of operations, where above each arrow we count the steps:

$$
\begin{gathered}
x, y \stackrel{1}{\longrightarrow} x+y \stackrel{7}{\longrightarrow}(x+y)^{2}, \\
x, y \stackrel{8}{\longrightarrow} x-y \stackrel{14}{\longrightarrow}(x-y)^{2}, \\
(x+y)^{2},(x-y)^{2} \stackrel{15}{\longrightarrow} 4 x y \stackrel{16}{\longrightarrow} \frac{1}{4 x y}, \\
\frac{1}{4 x y}, \frac{1}{4 x y} \stackrel{17}{\longrightarrow} \frac{1}{4 x y}+\frac{1}{4 x y}=\frac{2}{x y}, \\
\frac{2}{4 x y}, \frac{2}{4 x y} \stackrel{18}{\longrightarrow} \frac{2}{4 x y}+\frac{2}{4 x y}=\frac{4}{4 x y}=\frac{1}{x y} \stackrel{19}{\longrightarrow} x y .
\end{gathered}
$$

So we are able to compute the product in just 19 steps.

(Kvant (Quantum))

268. Building on the previous problem, we see that it suffices to produce an operation o, from which the subtraction and reciprocal are derivable. A good choice is $\frac{1}{x-y}$. Indeed, $\frac{1}{x}=\frac{1}{x-0}$, and also $x-y=\frac{1}{(1 /(x-y)-0)}$. Success!

(D.J. Newman, A Problem Seminar, Springer-Verlag) 

269. Fix $a$ and $c$ in $S$ and consider the function $f_{a, c}: S \backslash\{a, c\} \rightarrow S$,

$$
f_{a, c}(b)=a *(b * c) .
$$

Because $a * f_{a, c}(b) * c=(a * a) * b *(c * c)=b$, the function is one-to-one. It follows that there are exactly two elements that are not in the image of $f_{a, c}$. These elements are precisely $a$ and $c$. Indeed, if $a *(b * c)=a$, then $(a * a) *(b * c)=a * a$, so $b * c=a * a$, and then $b *(c * c)=(a * a) * c$, which implies $b=c$. This contradicts the fact that $a, b, c$ are distinct. A similar argument rules out the case $a *(b * c)=c$.

Now choose $a^{\prime}, c^{\prime}$ different from both $a$ and $c$. The union of the ranges of $f_{a, c}$ and $f_{a^{\prime}, c^{\prime}}$, which is contained in the set under discussion, is the entire set $S$. The conclusion follows.

Remark. An example of such a set is the Klein 4-group. (R. Gelca)

270. Consider the set

$$
U=\{h(x, y) \mid h(-x,-y)=-h(x, y)\} .
$$

It is straightforward to check that $U$ is closed under subtraction and taking reciprocals. Because $f(x, y)=x$ and $g(x, y)=y$ are in $U$, the entire set $S$ is in $U$. But $U$ does not contain nonzero constant functions, so neither does $S$.

(American Mathematical Monthly, 1987, proposed by I. Gessel, solution by O.P. Lossers)

271. All three parts of the conclusion follow from appropriate substitutions in the identity from the statement. For example,

$$
\left(e * e^{\prime}\right) \circ\left(e^{\prime} * e\right)=\left(e \circ e^{\prime}\right) *\left(e^{\prime} \circ e\right)
$$

simplifies to $e^{\prime} \circ e^{\prime}=e * e$, which further yields $e^{\prime}=e$, proving (a). Then, from

$$
(x * e) \circ(e * y)=(x \circ e) *(e \circ y),
$$

we deduce $x \circ y=x * y$, for every $x, y \in M$, showing that the two binary operations coincide. This further yields

$$
(e * x) *(y * e)=(e * x) \circ(y * e)=(e \circ y) *(x \circ e)=(e * y) *(x * e),
$$

and so $x * y=y * x$. Thus $*$ is commutative and (c) is proved.

(Romanian high school textbook)

272. Substituting $x=u * v$ and $y=v$, with $u, v \in S$, in the given condition gives $(u * v) *(v *(u * v))=v$. But $v *(u * v)=u$, for all $u, v \in S$. So $(u * v) * u=v$, for all $u, v \in S$. Hence the existence and uniqueness of the solution to the equation $a * x=b$ is equivalent to the existence and uniqueness of the solution to the equation $x * a=b$.

The existence of the solution for the equation $a * x=b$ follows from the fact that $x=b * a$ is a solution. To prove the uniqueness, let $c \in S$ be a solution. By hypothesis we have the equalities $a *(b * a)=b, b *(c * b)=c, c *(a * c)=a$. From $a * c=b$ it follows that $c *(a * c)=c * b=a$. So $a=c * b$, and from $a * c=b$ it follows that $c *(a * c)=c * b=a$. Therefore, $b * a=b *(c * b)=c$, which implies that $b * a=c$. This completes the proof.

273. Substituting $y=e$ in the second relation, and using the first, we obtain $x * z=$ $(x * e) * z=(z * e) * x=z * x$, which proves the commutativity. Using it, the associativity is proved as follows:

$$
(x * y) * z=(z * x) * y=(y * z) * x=x *(y * z) .
$$

\section{(A. Gheorghe)}

274. The answer is yes. Let $\phi$ be any bijection of $F$ with no fixed points. Define $x * y=\phi(x)$. The first property obviously holds. On the other hand, $x *(y * z)=\phi(x)$ and $(x * y) * z=\phi(x * y)=\phi(\phi(x))$. Again since $\phi$ has no fixed points, these two are never equal, so the second property also holds.

(45th W.L. Putnam Mathematical Competition, 1984)

275. From $a *(a * a)=(a * a) * a$ we deduce that $a * a=a$. We claim that

$$
a *(b * a)=a \quad \text { for all } a, b \in S .
$$

Indeed, we have $a *(a *(b * a))=(a * a) *(b * a)=a *(b * a)$ and $(a *(b * a)) * a=$ $(a * b) *(a * a)=(a * b) * a$. Using associativity, we obtain

$$
a *(a *(b * a))=a *(b * a)=(a * b) * a=(a *(b * a)) * a .
$$

The "noncommutativity" condition from the statement implies $a *(b * a)=a$, proving the claim.

We apply this property as follows:

$$
\begin{aligned}
&(a *(b * c)) *(a * c)=(a * b) *(c *(a * c))=(a * b) * c, \\
&(a * c) *(a *(b * c))=(a *(c * a)) *(b * c)=a *(b * c) .
\end{aligned}
$$

Since $(a * b) * c=a *(b * c)$ (by associativity), we obtain

$$
(a *(b * c)) *(a * c)=(a * c) *(a *(b * c)) .
$$

This means that $a *(b * c)$ and $a * c$ commute, so they must be equal, as desired. For an example of such a binary operation consider any set $S$ endowed with the operation $a * b=a$ for any $a, b \in S$.

276. Using the first law we can write

$$
y *(x * y)=(x *(x * y)) *(x * y) .
$$

Now using the second law, we see that this is equal to $x$. Hence $y *(x * y)=x$. Composing with $y$ on the right and using the first law, we obtain

$$
y * x=y *(y *(x * y))=x * y .
$$

This proves commutativity.

For the second part, the set $S$ of all integers endowed with the operation $x * y=-x-y$ provides a counterexample. Indeed,

$$
x *(x * y)=-x-(x * y)=-x-(-x-y)=y
$$

and

$$
(y * x) * x=-(y * x)-x=-(-y-x)-x=y .
$$

Also, $(1 * 2) * 3=0$ and $1 *(2 * 3)=4$, showing that the operation is not associative. (33rd W.L. Putnam Mathematical Competition, 1972)

277. Define $r(x)=0 * x, x \in \mathbb{Q}$. First, note that

$$
x *(x+y)=(0+x) *(y+x)=0 * y+x=r(y)+x .
$$

In particular, for $y=0$ we obtain $x * x=r(0)+x=0 * 0+x=x$.

We will now prove a multiplicative property of $r(x)$, namely that $r\left(\frac{m}{n} x\right)=\frac{m}{n} r(x)$ for any positive integers $m$ and $n$. To this end, let us show by induction that for all $y$ and all positive integers $n, 0 * y * \cdots * n y=n r(y)$. For $n=0$ we have $0=0 \cdot r(y)$, and for $n=1$ this follows from the definition of $r(y)$. Assume that the property is true for $k \leq n$ and let us show that it is true for $n+1$. We have

$$
\begin{aligned}
0 * y * \cdots * n y *(n+1) y &=0 * y * \cdots *(n y * n y) *(n+1) y \\
&=(0 * y * \cdots * n y) *(n y *(n+1) y) \\
&=(n(0 * y)) *((0+n y) *(y+n y)) \\
&=(0 * y+(n-1)(0 * y)) *(0 * y+n y) \\
&=(n-1) r(y) * n y+0 * y .
\end{aligned}
$$

Using the induction hypothesis, $(n-1) r(y) * n y=0 * y * \cdots *(n-1) y * n y=n r(y)$ (this works even when $n=1)$. Hence $0 * y * \cdots *(n+1) y=n r(y)+r(y)=(n+1) r(y)$, which proves the claim. Using this and the associativity and commutativity of $*$, we obtain

$$
\begin{aligned}
2 n r(y) &=0 * y * 2 y * \cdots * 2 n y \\
&=(0 * n y) *(y *(n+1) y) *(2 y *(n+2) y) * \cdots *(n y * 2 n y) \\
&=r(n y) *(y *(y+n y)) *(2 y *(2 y+n y)) * \cdots *(n y *(n y+n y)) .
\end{aligned}
$$

The first formula we have proved implies that this is equal to

$$
(0+r(n y)) *(y+r(n y)) * \cdots *(n y+r(n y)) .
$$

The distributive-like property of $*$ allows us to transform this into

$$
(0 * y * 2 y * \cdots * n y)+r(n y)=n r(y)+r(n y) .
$$

Hence $2 n r(y)=n r(y)+r(n y)$, or $r(n y)=n r(y)$. Replacing $y$ by $\frac{x}{n}$, we obtain $r\left(\frac{x}{n}\right)=\frac{1}{n} r(x)$, and hence $r\left(\frac{m}{n} x\right)=\frac{m}{n} r(x)$, as desired.

Next, note that $r \circ r=r$; hence $r$ is the identity function on its image. Also,

$$
r(z)=0 * z=(-z+z) *(0+z)=(-z) * 0+z=r(-z)+z,
$$

or $r(z)-r(-z)=z$. Hence for $z \neq 0$, one of $r(z)$ and $r(-z)$ is nonzero. Let $y$ be this number. Since $r(y)=y$, we have $y=r(y)-r(-y)=y-r(-y)$, so $r(-y)=0$. Also, if $x=\frac{m}{n} y$, then $r(x)=\frac{m}{n} r(y)=\frac{m}{n} y=x$, and $r(-x)=\frac{m}{n} r(-y)=0$. If $y>0$, then $r(y)=\max (y, 0)$ and consequently $r(x)=x=\max (x, 0)$, for all $x>0$, while $r(x)=0=\max (x, 0)$ for all $x<0$. Similarly, if $y<0$, then $r(y)=\min (y, 0)$, and then $r(x)=\min (x, 0)$ for all $x \in \mathbb{Q}$. The general case follows from $(a-b+b) *(0+b)=$ $(a-b) * 0+b$.

(American Mathematical Monthly, proposed by H. Derksen, solution by J. Dawson) 

278. For $x \in G$ and $x^{\prime}$ its left inverse, let $x^{\prime \prime} \in G$ be the left inverse of $x^{\prime}$, meaning that $x^{\prime \prime} x^{\prime}=e$. Then

$$
x x^{\prime}=e\left(x x^{\prime}\right)=\left(x^{\prime \prime} x^{\prime}\right)\left(x x^{\prime}\right)=x^{\prime \prime}\left(x^{\prime} x\right) x^{\prime}=x^{\prime \prime}\left(e x^{\prime}\right)=x^{\prime \prime} x^{\prime}=e .
$$

So $x^{\prime}$ is also a right inverse for $x$. Moreover,

$$
x e=x\left(x^{\prime} x\right)=\left(x x^{\prime}\right) x=e x=x,
$$

which proves that $e$ is both a left and right identity. It follows that $G$ is a group. 

279. Let $e \in G$ be the identity element. Set $b=e$ in the relation from the statement. Then

$$
a=a * e=(a \perp a) \perp(a \perp e)=(a \perp a) \perp a,
$$

and canceling $a$ we obtain $a \perp a=e$, for all $a \in G$. Using this fact, we obtain

$$
a * b=(a \perp a) \perp(a \perp b)=e \perp(a \perp b)=a \perp b,
$$

which shows that the composition laws coincide. Because $a * a=e$, we see that $a^{-1}=a$, so for $a, b \in G$

$$
a b=(a b)^{-1}=b^{-1} a^{-1}=b a,
$$

which proves the commutativity.

(D. Ştefănescu)

280. The fundamental theorem of arithmetic allows us to find the integers $u$ and $v$ such that $u s+v t=1$. Since $a b=b a$, we have

$$
a b=(a b)^{u s+v t}=(a b)^{u s}\left((a b)^{t}\right)^{v}=(a b)^{u s} e=(a b)^{u s}=a^{u s}\left(b^{s}\right)^{u}=a^{u s} e=a^{u s} .
$$

Therefore,

$$
b^{r}=e b^{r}=a^{r} b^{r}=(a b)^{r}=a^{u s r}=\left(a^{r}\right)^{u s}=e .
$$

Using again the fundamental theorem of arithmetic we can find $x, y$ such that $x r+y s=1$. Then

$$
b=b^{x r+y s}=\left(b^{r}\right)^{x}\left(b^{s}\right)^{y}=e .
$$

Applying the same argument, mutatis mutandis, we find that $a=e$, so the first part of the problem is solved.

A counterexample for the case of a noncommutative group is provided by the cycles of permutations $a=(123)$ and $b=(34567)$ in the permutation group $S_{7}$ of order 7 . Then $a b=(1234567)$ and $a^{3}=b^{5}=(a b)^{7}=e$.

(8th International Competition in Mathematics for University Students, 2001)

281. Set $c=a b a^{-1}$ and observe that $c a=a b$ and that $c^{n}=e$. We have

$$
a=e a=c^{n} a=c^{n-1} c a=c^{n-1} a b=c^{n-2}(c a) b=c^{n-2} a b^{2},
$$

and, inductively,

$$
a=c^{n-k} a b^{k}, \quad 1 \leq k \leq n .
$$

From $a=a b^{n}$, we obtain the desired conclusion $b^{n}=e$.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by D. BătineţuGiurgiu)

282. Applying the identity from the statement to the elements $x$ and $y x^{-1}$, we have 

$$
x y^{2} x^{-1}=x\left(y x^{-1}\right) x\left(y x^{-1}\right)=\left(y x^{-1}\right) x\left(y x^{-1}\right) x=y^{2} .
$$

Thus for any $x, y$, we have $x y^{2}=y^{2} x$. This means that squares commute with everything. Using this fact, we rewrite the identity from the statement as

$$
x y x y x^{-1} y^{-1} x^{-1} y^{-1}=e
$$

and proceed as follows:

$$
\begin{aligned}
e &=x y x y x^{-1} y^{-1} x^{-1} y^{-1}=x y x y x^{-2} x y^{-2} y x^{-2} x y^{-2} y \\
&=x y x y y^{-2} x^{-2} x y x y y^{-2} x^{-2}=\left(x y x y y^{-2} x^{-2}\right)^{2} .
\end{aligned}
$$

Because there are no elements of order 2, it follows that $x y x y y^{-2} x^{-2}=e$ and hence $x y x y=x^{2} y^{2}$. Cancel an $x$ and a $y$ to obtain $y x=x y$. This proves that the group is Abelian, and we are done.

(K.S. Williams, K. Hardy, The Red Book of Mathematical Problems, Dover, Mineola, NY, 1996)

283. The first axiom shows that the squares of all elements in $M$ are the same; denote the common value by $e$. Then $e^{2}=e$, and from (ii), $a e=a$ for all $a \in M$. Also, $a * b=a(e b)$ for all $a, b \in M$. Let us verify the associativity of $*$. Using (iii) in its new form $e(b c)=c b$, we obtain

$$
a *(b * c)=a[e(b(e c))]=a[(e c) b] .
$$

Continue using (iv) as follows:

$$
a[(e c) b]=[a(e b)][((e c) b)(e b)]=[a(e b)][(e c) e]=[a(e b)](e c)=(a * b) * c .
$$

Here we used the fact that $d e=d$, for the case $d=e c$. Thus associativity is proved. The element $e$ is a right identity by the following argument:

$$
a * e=a\left(e^{2} e\right)=a(e e)=a e^{2}=a e=a .
$$

The right inverse of $a$ is $a e$, since

$$
a *(e a)=a[e(e a)]=a(a e)=a^{2}=e .
$$

So there exists a right identity, and every element has a right inverse, which then implies that $(M, *)$ is a group.

(M. Becheanu, C. Vraciu, Probleme de Teoria Grupurilor (Problems in Group Theory), University of Bucharest, 1982)

284. How can we make the sum $M$ interact with the multiplicative structure of $\Gamma$ ? The idea is to square $M$ and use the distributivity of multiplication with respect to the sum of matrices. If $G_{1}, G_{2}, \ldots, G_{k}$ are the elements of $\Gamma$, then 

$$
\begin{aligned}
M^{2} &=\left(G_{1}+G_{2}+\cdots+G_{k}\right)^{2}=\sum_{i=1}^{k} G_{i}\left(\sum_{j=1}^{k} G_{j}\right)=\sum_{i=1}^{k} G_{i}\left(\sum_{G \in \Gamma} G_{i}^{-1} G\right) \\
&=\sum_{G \in \Gamma} \sum_{i=1}^{k} G_{i}\left(G_{i}^{-1} G\right)=k \sum_{G \in \Gamma} G=k M .
\end{aligned}
$$

Taking determinants, we find that $(\operatorname{det} M)^{2}=k^{n} \operatorname{det} M$. Hence either $\operatorname{det} M=0$ or det $M$ is equal to the order of $\Gamma$ raised to the $n$th power.

Remark. In fact, much more is true. The determinant of the sum of the elements of a finite multiplicative group of matrices is nonzero only when the group consists of one element, the identity, in which case it is equal to 1 . This is the corollary of a basic fact in representation theory.

A representation of a group is a homomorphism of the group into a group of matrices. In our situation the group is already represented as a group of matrices. A representation is called irreducible if there does not exist a basis in which it can be decomposed into blocks. Any representation of a finite group is the block sum of irreducible representations. The simplest representation, called the trivial representation, sends all elements of the group to the identity element. A result in representation theory states that for any nontrivial irreducible representation of a finite group, the sum of the matrices of the representation is zero. In an appropriately chosen basis, our group can be written as the block sum of irreducible representations. If the group is nontrivial, then at least one representation is nontrivial. In summing the elements of the group, the diagonal block corresponding to this irreducible representation is the zero matrix. Taking the determinant, we obtain zero.

285. The condition from the statement implies that for all integers $m$ and $n$,

$$
f(m \sqrt{2}+n \sqrt{3})=f(0) .
$$

Because the ratio $\sqrt{2} / \sqrt{3}$ is irrational, the additive group generated by $\sqrt{2}$ and $\sqrt{3}$ is not cyclic. It means that this group is dense in $\mathbb{R}$. So $f$ is constant on a dense subset of $\mathbb{R}$. Being continuous, it must be constant on the real axis.

286. The conclusion follows from the fact that the additive group

$$
S=\{n+2 \pi m ; m, n \text { integers }\}
$$

is dense in the real numbers. Indeed, by the result we just proved, we only need to check that $S$ is not cyclic. This is so because $n$ and $2 m \pi$ cannot both be integer multiples of the same number (they are incommensurable).

287. That $2^{k}$ starts with a 7 is equivalent to the existence of an integer $m$ such $\frac{2^{k}}{10^{m}} \in[7,8)$. Let us show that the set $\left\{\frac{2^{k}}{10^{m}} \mid k, m\right.$ integers $\}$ is dense in the positive real numbers. Canceling the powers of 2 , this amounts to showing that $\left\{\frac{2^{n}}{5^{m}} \mid m, n\right.$ integers $\}$ is dense. We further simplify the problem by applying the function $\log _{2}$ to the fraction. This function is continuous, so it suffices to prove that $\left\{n-m \log _{2} 5 \mid m, n\right.$ integers $\}$ is dense on the real axis. This is an additive group, which is not cyclic since $\log _{2} 5$ is irrational (and so 1 and $\log _{2} 5$ cannot both be integer multiples of the same number). It follows that this group is dense in the real numbers, and the problem is solved.

(V.I. Arnol'd, Mathematical Methods of Classical Mechanics, Springer-Verlag, 1997)

288. If $r$ is the original ratio of the sides, after a number of folds the ratio will be $2^{m} 3^{n} r$, where $m$ and $n$ are integer numbers. It suffices to show that the set $\left\{2^{m} 3^{n} r \mid m, n \in \mathbb{Z}\right\}$ is dense in the positive real axis. This is the same as showing that $\left\{2^{m} 3^{n} \mid m, n \in \mathbb{Z}\right\}$ is dense. Taking the logarithm, we reduce the problem to the fact that the additive group $\left\{m+n \log _{2} 3 \mid m, n \in \mathbb{Z}\right\}$ is dense in the real axis. And this is true since the group is not cyclic.

(German Mathematical Olympiad)

289. Call the regular pentagon $A B C D E$ and the set $\Sigma$. Composing a reflection across $A B$ with a reflection across $B C$, we can obtain a $108^{\circ}$ rotation around $B$. The set $\Sigma$ is invariant under this rotation. There is a similar rotation around $C$, of the same angle and opposite direction, which also preserves $\Sigma$. Their composition is a translation by a vector that makes an angle of $36^{\circ}$ with $B C$ and has length $2 \sin 54^{\circ} B C$. Figure 65 helps us understand why this is so. Indeed, if $P$ rotates to $P^{\prime}$ around $B$, and $P^{\prime}$ to $P^{\prime \prime}$ around $C$, then the triangle $P^{\prime} B C$ transforms to the triangle $P^{\prime} P P^{\prime \prime}$ by a rotation around $P^{\prime}$ of angle $\angle C P^{\prime} P^{\prime \prime}=36^{\circ}$ followed by a dilation of ratio $P^{\prime} P^{\prime \prime} / P^{\prime} C=2 \sin 54^{\circ}$. Note that the translation preserves the set $\Sigma$. Reasoning similarly with vertices $A$ and

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-467.jpg?height=436&width=621&top_left_y=1438&top_left_x=557)

Figure 65

$D$, and taking into account that $A D$ is parallel to $B C$, we find a translation by a vector of length $2 \sin 54^{\circ} A D$ that makes an angle of $36^{\circ}$ with $B C$ and preserves $\Sigma$. Because $A D / B C=2 \sin 54^{\circ}=\frac{\sqrt{5}+1}{2}$, the group $G_{B C}$ generated by the two translations is dense in the group of all translations by vectors that make an angle of $36^{\circ}$ with $B C$. The same is true if $B C$ is replaced by $A B$. It follows that $\Sigma$ is preserved both by the translations in the group $G_{B C}$ and in the analogous group $G_{A B}$. These generate a group that is dense in the group of all translations of the plane. We conclude that $\Sigma$ is a dense set in the plane, as desired.

(communicated by K. Shankar)

290. The symmetry groups are, respectively, $C_{2 v}, D_{2 h}$, and $D_{2 d}$.

291. If $x$ is an idempotent, then $1-x$ is an idempotent as well. Indeed,

$$
(1-x)^{2}=1-2 x+x^{2}=1-2 x+x=1-x .
$$

Thus there is an involution on $M, x \rightarrow 1-x$. This involution has no fixed points, since $x=1-x$ implies $x^{2}=x-x^{2}$ or $x=x-x=0$. But then $0=1-0=1$, impossible. Having no fixed points, the involution pairs the elements of $M$, showing that the cardinality of $M$ is even.

(Gazeta Matematica (Mathematics Gazette, Bucharest), proposed by V. Zidaru)

292. We have $y=y^{6}=(-y)^{6}=-y$, hence $2 y=0$ for any $y \in R$. Now let $x$ be an arbitrary element in $R$. Using the binomial formula, we obtain

$$
\begin{aligned}
x+1 &=(x+1)^{6}=x^{6}+6 x^{5}+15 x^{4}+20 x^{3}+15 x^{2}+6 x+1 \\
&=x^{4}+x^{2}+x+1,
\end{aligned}
$$

where we canceled the terms that had even coefficients. Hence $x^{4}+x^{2}=0$, or $x^{4}=$ $-x^{2}=x^{2}$. We then have

$$
x=x^{6}=x^{2} x^{4}=x^{2} x^{2}=x^{4}=x^{2},
$$

and so $x^{2}=x$, as desired. From the equality $(x+y)^{2}=x+y$ we deduce $x y+y x=0$, so $x y=-y x=y x$ for any $x, y$. This shows that the ring is commutative, as desired.

293. Substituting $x$ by $x+1$ in the relation from the statement, we find that

$$
\begin{aligned}
((x+1) y)^{2}-(x+1)^{2} y^{2} &=(x y)^{2}+x y^{2}+y x y+y^{2}-x^{2} y^{2}-2 x y^{2}-y^{2} \\
&=y x y-x y^{2}=0 .
\end{aligned}
$$

Hence $x y^{2}=y x y$ for all $x, y \in R$. Substituting in this relation $y$ by $y+1$, we find that

$$
x y^{2}+2 x y+x=y x y+y x+x y+x .
$$

Using the fact that $x y^{2}=y x y$, we obtain $x y=y x$, as desired.

294. This problem generalizes the first example from the introduction. The idea of the solution is similar. Now let $v$ be the inverse of $1-(x y)^{n}$. Then $v\left(1-(x y)^{n}\right)=$ $\left(1-(x y)^{n}\right) v=1$; hence $v(x y)^{n}=(x y)^{n} v=v-1$. We claim that the inverse of $1-(y x)^{n}$ is $1+(y x)^{n-1} y v x$. Indeed, we compute

$$
\begin{aligned}
\left(1+(y x)^{n-1} y v x\right)\left(1-(y x)^{n}\right) &=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n-1} y v x(y x)^{n} \\
&=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n-1} y v(x y)^{n} x \\
&=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n-1} y(v-1) x=1 .
\end{aligned}
$$

Similarly,

$$
\begin{aligned}
\left(1-(y x)^{n}\right)\left(1+(y x)^{n-1} y v x\right) &=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n}(y x)^{n-1} y v x \\
&=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n-1} y(x y)^{n} v x \\
&=1-(y x)^{n}+(y x)^{n-1} y v x-(y x)^{n-1} y(v-1) x=1 .
\end{aligned}
$$

It follows that $1-(y x)^{n}$ is invertible and its inverse is $1+(y x)^{n-1} y v x$.

295. (a) Let $x$ and $z$ be as in the statement. We compute

$$
\begin{aligned}
(z x z-x z)^{2} &=(z x z-x z)(z x z-x z) \\
&=(z x z)(z x z)-(z x z)(x z)-(x z)(z x z)+(x z)(x z) \\
&=z x z^{2} x z-z x z x-x z^{2} x z+x z x z \\
&=z x z x z-z x z x-x z x z-x z x z=0 .
\end{aligned}
$$

Therefore, $(z x z-x z)^{2}=0$, and the property from the statement implies that $z x-x z=0$.

(b) We have seen in part (a) that if $z$ is an idempotent, then $x z x-x z=0$. The same argument works, mutatis mutandis, to prove that $z x z=z x$. Hence $x z=z x z=z x$, which shows that $z$ is in the center of $R$, and we are done.

296. We will show that the elements

$$
a c, a^{2} c, a^{3} c, \ldots, a^{n} c, \ldots
$$

are distinct. Let us argue by contradiction assuming that there exist $n>m$ such that $a^{n} c=a^{m} c$. Multiplying by $c$ on the left, we obtain $c a\left(a^{n-1} c\right)=c a\left(a^{m-1} c\right)$, so by (iii), $b a^{n-1} c=b a^{m-1} c$. Cancel $b$ as allowed by hypothesis (ii) to obtain $a^{n-1} c=a^{m-1} c$. An easy induction shows that $a^{k} c=c$, where $k=n-m$. Multiplying on the right by $a$ and using $c a=b$, we also obtain $a^{k} b=b$. The first condition shows that $b$ commutes with $a$, and so $b a^{k}=b$; canceling $b$ yields $a^{k}=1$. Hence $a$ is invertible and $a^{-1}=a^{k-1}$.

The hypothesis $c a=b$ implies

$$
c=b a^{-1}=b a^{k-1}=a^{k-1} b=a^{-1} b,
$$

hence $a c=b$, contradicting (iii). The contradiction proves that the elements listed in the beginning of the solution are all distinct, and the problem is solved.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by C. Guţan) 

\section{Real Analysis}

297. Examining the sequence, we see that the $m$ th term of the sequence is equal to $n$ exactly for those $m$ that satisfy

$$
\frac{n^{2}-n}{2}+1 \leq m \leq \frac{n^{2}+n}{2} .
$$

So the sequence grows about as fast as the square root of twice the index. Let us rewrite the inequality as

$$
n^{2}-n+2 \leq 2 m \leq n^{2}+n,
$$

then try to solve for $n$. We can almost take the square root. And because $m$ and $n$ are integers, the inequality is equivalent to

$$
n^{2}-n+\frac{1}{4}<2 m<n^{2}+n+\frac{1}{4} .
$$

Here it was important that $n^{2}-n$ is even. And now we can take the square root. We obtain

$$
n-\frac{1}{2}<\sqrt{2 m}<n+\frac{1}{2},
$$

or

$$
n<\sqrt{2 m}+\frac{1}{2}<n+1 .
$$

Now this happens if and only if $n=\left\lfloor\sqrt{2 m}+\frac{1}{2}\right\rfloor$, which then gives the formula for the general term of the sequence

$$
a_{m}=\left\lfloor\sqrt{2 m}+\frac{1}{2}\right\rfloor, \quad m \geq 1 .
$$

(R. Graham, D. Knuth, O. Patashnik, Concrete Mathematics: A Foundation for Computer Science, 2nd ed., Addison-Wesley, 1994) 

298. If we were given the recurrence relation $x_{n}=x_{n-1}+n$, for all $n$, the terms of the sequence would be the triangular numbers $T_{n}=\frac{n(n+1)}{2}$. If we were given the recurrence relation $x_{n}=x_{n-1}+n-1$, the terms of the sequence would be $T_{n-1}+1=\frac{n^{2}-n+2}{2}$. In our case,

$$
\frac{n^{2}-n+2}{2} \leq x_{n} \leq \frac{n^{2}+n}{2} .
$$

We expect $x_{n}=P(n) / 2$ for some polynomial $P(n)=n^{2}+a n+b$; in fact, we should have $x_{n}=\lfloor P(n) / 2\rfloor$ because of the jumps. From here one can easily guess that $x_{n}=\left\lfloor\frac{n^{2}+1}{2}\right\rfloor$, and indeed

$$
\left\lfloor\frac{n^{2}+1}{2}\right\rfloor=\left\lfloor\frac{(n-1)^{2}+1}{2}+\frac{2(n-1)+1}{2}\right\rfloor=\left\lfloor\frac{(n-1)^{2}+1}{2}+\frac{1}{2}\right\rfloor+(n-1),
$$

which is equal to $\left\lfloor\frac{(n-1)^{2}+1}{2}\right\rfloor+(n-1)$ if $n$ is even, and to $\left\lfloor\frac{(n-1)^{2}+1}{2}\right\rfloor+n$ if $n$ is odd. 

299. From the hypothesis it follows that $a_{4}=12, a_{5}=25, a_{6}=48$. We observe that

$$
\frac{a_{1}}{1}=\frac{a_{2}}{2}=1, \quad \frac{a_{3}}{3}=2, \quad \frac{a_{4}}{4}=3, \quad \frac{a_{5}}{5}=5, \quad \frac{a_{6}}{6}=8
$$

are the first terms of the Fibonacci sequence. We conjecture that $a_{n}=n F_{n}$, for all $n \geq 1$. This can be proved by induction with the already checked cases as the base case.

The inductive step is

$$
\begin{aligned}
a_{n+4} &=2(n+3) F_{n+3}+(n+2) F_{n+2}-2(n+1) F_{n+1}-n F_{n} \\
&=2(n+3) F_{n+3}+(n+2) F_{n+2}-2(n+1) F_{n+1}-n\left(F_{n+2}-F_{n+1}\right) \\
&=2(n+3) F_{n+3}+2 F_{n+2}-(n+2)\left(F_{n+3}-F_{n+2}\right) \\
&=(n+4)\left(F_{n+3}+F_{n+2}\right)=(n+4) F_{n+4} .
\end{aligned}
$$

This proves our claim.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by D. Andrica)

300. The relations

$$
a_{m}+a_{m}=\frac{1}{2}\left(a_{2 m}+a_{0}\right) \quad \text { and } \quad a_{2 m}+a_{0}=\frac{1}{2}\left(a_{2 m}+a_{2 m}\right)
$$

imply $a_{2 m}=4 a_{m}$, as well as $a_{0}=0$. We compute $a_{2}=4, a_{4}=16$. Also, $a_{1}+a_{3}=$ $\left(a_{2}+a_{4}\right) / 2=10$, so $a_{3}=9$. At this point we guess that $a_{k}=k^{2}$ for all $k \geq 1$.

We prove our guess by induction on $k$. Suppose that $a_{j}=j^{2}$ for all $j<k$. The given equation with $m=k-1$ and $n=1$ gives 

$$
\begin{aligned}
a_{n} &=\frac{1}{2}\left(a_{2 n-2}+a_{2}\right)-a_{n-2}=2 a_{n-1}+2 a_{1}-a_{n-2} \\
&=2\left(n^{2}-2 n+1\right)+2-\left(n^{2}-4 n+4\right)=n^{2} .
\end{aligned}
$$

This completes the proof.

(Russian Mathematical Olympiad, 1995)

301. First solution: If we compute some terms, $a_{0}=0, a_{1}=2$, $a_{3}=8, a_{4}=34$, $a_{5}=144$, we recognize Fibonacci numbers, namely $F_{0}, F_{3}, F_{6}, F_{9}$, and $F_{12}$. So a good working hypothesis is that $a_{n}=F_{3 n}$ and also that $b_{n}=\left(F_{n}\right)^{3}$, for all $n \geq 0$, from which the conclusion would then follow.

We use induction. Everything is fine for $n=0$ and $n=1$. Assuming $a_{k}=F_{3 k}$ for all $k \leq n$, we have

$$
\begin{aligned}
a_{n+1} &=4 F_{3 n}+F_{3 n-3}=3 F_{3 n}+F_{3 n}+F_{3 n-3} \\
&=3 F_{3 n}+F_{3 n-1}+F_{3 n-2}+F_{3 n-3}=3 F_{3 n}+F_{3 n-1}+F_{3 n-1} \\
&=F_{3 n}+2 F_{3 n}+2 F_{3 n-1}=F_{3 n}+2 F_{3 n+1}=F_{3 n}+F_{3 n+1}+F_{3 n+1} \\
&=F_{3 n+2}+F_{3 n+1}=F_{3 n+3}=F_{3(n+1)},
\end{aligned}
$$

which proves the first part of the claim.

For the second part we deduce from the given recurrence relations that

$$
b_{n+1}=3 b_{n}+6 b_{n-1}-3 b_{n-2}-b_{n-3}, n \geq 3 .
$$

We point out that this is done by substituting $a_{n}=b_{n+1}+b_{n}-b_{n-1}$ into the recurrence relation for $\left(a_{n}\right)_{n}$. On the one hand, $b_{n}=\left(F_{n}\right)^{3}$ is true for $n=0,1,2,3$. The assumption $b_{k}=\left(F_{k}\right)^{3}$ for all $k \leq n$ yields

$$
\begin{aligned}
b_{n+1} &=3\left(F_{n}\right)^{3}+6\left(F_{n-1}\right)^{3}-3\left(F_{n-2}\right)^{3}-\left(F_{n-3}\right)^{3} \\
&=3\left(F_{n-1}+F_{n-2}\right)^{3}+6\left(F_{n-1}\right)^{3}-3\left(F_{n-2}\right)^{3}-\left(F_{n-1}-F_{n-2}\right)^{3} \\
&=8\left(F_{n-1}\right)^{3}+12\left(F_{n-1}\right)^{2} F_{n-2}+6 F_{n-1}\left(F_{n-2}\right)^{2}+\left(F_{n-2}\right)^{3} \\
&=\left(2 F_{n-1}+F_{n-2}\right)^{3}=\left(F_{n+1}\right)^{3} .
\end{aligned}
$$

This completes the induction, and with it the solution to the problem.

Second solution: Another way to prove that $b_{n}=\left(F_{n}\right)^{3}$ is to observe that both sequences satisfy the same linear recurrence relation. Let

$$
M=\left(\begin{array}{ll}
1 & 1 \\
1 & 0
\end{array}\right) .
$$

We have seen before that

$$
M^{n}=\left(\begin{array}{cc}
F_{n+1} & F_{n} \\
F_{n} & F_{n-1}
\end{array}\right) .
$$

Now the conclusion follows from the equality $M^{3 n}=\left(M^{n}\right)^{3}$. Remark. A solution based on the Binet formula is possible if we note the factorization

$$
\lambda^{4}-3 \lambda^{3}-6 \lambda^{2}+3 \lambda+1=\left(\lambda^{2}-4 \lambda-1\right)\left(\lambda^{2}+\lambda-1\right) .
$$

Setting the left-hand side equal to 0 gives the characteristic equation for the sequence $\left(b_{n}\right)_{n}$, while setting the first factor on the right equal to 0 gives the characteristic equation for $\left(a_{n}\right)_{n}$.

(proposed by T. Andreescu for a Romanian Team Selection Test for the International Mathematical Olympiad, 2003, remark by R. Gologan)

302. We compute $u_{0}=1+1, u_{1}=2+\frac{1}{2}, u_{2}=2+\frac{1}{2}, u_{3}=8+\frac{1}{8}$. A good guess is $u_{n}=2^{x_{n}}+2^{-x_{n}}$ for some sequence of positive integers $\left(x_{n}\right)_{n}$.

The recurrence gives

$$
2^{x_{n+1}}+2^{-x_{n+1}}=2^{x_{n}+2 x_{n-1}}+2^{-x_{n}-2 x_{n-1}}+2^{x_{n}-2 x_{n-1}}+2^{-x_{n}+2 x_{n-1}}-2^{x_{1}}-2^{-x_{1}} .
$$

In order to satisfy this we hope that $x_{n+1}=x_{n}+2 x_{n-1}$ and that $x_{n}-2 x_{n-1}=\pm x_{1}=\pm 1$. The characteristic equation of the first recurrence is $\lambda^{2}-\lambda-2=0$, with the roots 2 and $-1$, and using the fact that $x_{0}=0$ and $x_{1}=1$ we get the general term of the sequence $x_{n}=\left(2^{n}-(-1)^{n}\right) / 3$. Miraculously this also satisfies $x_{n}-2 x_{n-1}=(-1)^{n+1}$ so the second condition holds as well. We conclude that $\left\lfloor u_{n}\right\rfloor=2^{x_{n}}$, and so $\left\lfloor u_{n}\right\rfloor=2^{\left[2^{n}-(-1)^{n}\right] / 3}$.

(18th International Mathematical Olympiad, 1976, proposed by the UK)

303. We need to determine $m$ such that $b_{m}>a_{n}>b_{m-1}$. It seems that the difficult part is to prove an inequality of the form $a_{n}>b_{m}$, which reduces to $3^{a_{n-1}}>100^{b_{m-1}}$, or $a_{n-1}>\left(\log _{3} 100\right) b_{m-1}$. Iterating, we obtain $3^{a_{n-2}}>\left(\log _{3} 100\right) 100^{b_{m-2}}$, that is,

$$
a_{n-2}>\log _{3}\left(\log _{3} 100\right)+\left(\left(\log _{3} 100\right) b_{m-2} .\right.
$$

Seeing this we might suspect that an inequality of the form $a_{n}>u+v b_{n}$, holding for all $n$ with some fixed $u$ and $v$, might be useful in the solution. From such an inequality we would derive $a_{n+1}=3^{a_{n}}>3^{u}\left(3^{v}\right)^{b_{m}}$. If $3^{v}>100$, then $a_{n+1}>3^{u} b_{m+1}$, and if $3^{u}>u+v$, then we would obtain $a_{n+1}>u+v b_{m+1}$, the same inequality as the one we started with, but with $m+1$ and $n+1$ instead of $m$ and $n$.

The inequality $3^{v}>100$ holds for $v=5$, and $3^{u}>u+5$ holds for $u=2$. Thus $a_{n}>2+5 b_{m}$ implies $a_{n+1}>2+5 b_{m+1}$. We have $b_{1}=100, a_{1}=3, a_{2}=27, a_{3}=3^{27}$, and $2+5 b_{1}=502<729=3^{6}$, so $a_{3}>2+5 b_{1}$. We find that $a_{n}>2+5 b_{n-2}$ for all $n \geq 3$. In particular, $a_{n} \geq b_{n-2}$.

On the other hand, $a_{n}<b_{m}$ implies $a_{n+1}=3^{a_{n}}<100^{b_{m}}<b_{m+1}$, which combined with $a_{2}<b_{1}$ yields $a_{n}<b_{n-1}$ for all $n \geq 2$. Hence $b_{n-2}<a_{n}<b_{n-1}$, which implies that $m=n-1$, and for $n=100, m=99$.

(short list of the 21st International Mathematical Olympiad, 1979, proposed by Romania, solution by I. Cuculescu) 

304. Assume that we have found such numbers for every $n$. Then $q_{n+1}(x)-x q_{n}(x)$ must be divisible by $p(x)$. But

$$
\begin{aligned}
q_{n+1}(x)-x q_{n}(x) &=x^{n+1}-a_{n+1} x-b_{n+1}-x^{n+1}+a_{n} x^{2}+b_{n} x \\
&=-a_{n+1} x-b_{n+1}+a_{n}\left(x^{2}-3 x+2\right)+3 a_{n} x-2 a_{n}+b_{n} x \\
&=a_{n}\left(x^{2}-3 x+2\right)+\left(3 a_{n}+b_{n}-a_{n+1}\right) x-\left(2 a_{n}+b_{n+1}\right),
\end{aligned}
$$

and this is divisible by $p(x)$ if and only if $3 a_{n}+b_{n}-a_{n+1}$ and $2 a_{n}+b_{n+1}$ are both equal to zero. This means that the sequences $a_{n}$ and $b_{n}$ are uniquely determined by the recurrences $a_{1}=3, b_{1}=-2, a_{n+1}=3 a_{n}+b_{n}, b_{n+1}=-2 a_{n}$. The sequences exist and are uniquely defined by the initial condition.

305. Divide through by the product $(n+1)(n+2)(n+3)$. The recurrence relation becomes

$$
\frac{x_{n}}{n+3}=4 \frac{x_{n-1}}{n+2}+4 \frac{x_{n-2}}{n+1} .
$$

The sequence $y_{n}=x_{n} /(n+3)$ satisfies the recurrence

$$
y_{n}=4 y_{n-1}-4 y_{n-2} .
$$

Its characteristic equation has the double root 2. Knowing that $y_{0}=1$ and $y_{1}=1$, we obtain $y_{n}=2^{n}-n 2^{n-1}$. It follows that the answer to the problem is

$$
x_{n}=(n+3) 2^{n}-n(n+3) 2^{n-1} .
$$

(D. Buşneag, I. Maftei, Teme pentru cercurile şi concursurile de matematic ă (Themes for mathematics circles and contests), Scrisul Românesc, Craiova)

306. Define $c=b / x_{1}$ and consider the matrix

$$
A=\left(\begin{array}{cc}
0 & c \\
x_{1} & a
\end{array}\right) .
$$

It is not hard to see that

$$
A^{n}=\left(\begin{array}{rr}
c x_{n-1} & c x_{n} \\
x_{n} & x_{n+1}
\end{array}\right) .
$$

Using the equality $\operatorname{det} A^{n}=(\operatorname{det} A)^{n}$, we obtain

$$
c\left(x_{n-1} x_{n+1}-x_{n}^{2}\right)=\left(-x_{1} c\right)^{n}=(-b)^{n} .
$$

Hence $x_{n}^{2}-x_{n+1} x_{n-1}=(-b)^{n-1} x_{1}$, which does not depend on $a$. Remark. In the particular case $a=b=1$, we obtain the well-known identity for the Fibonacci sequence $F_{n+1} F_{n-1}-F_{n}^{2}=(-1)^{n+1}$.

307. A standard idea is to eliminate the square root. If we set $b_{n}=\sqrt{1+24 a_{n}}$, then $b_{n}^{2}=1+24 a_{n}$, and so

$$
\begin{aligned}
b_{n+1}^{2} &=1+24 a_{n+1}=1+\frac{3}{2}\left(1+4 a_{n}+\sqrt{1+24 a_{n}}\right) \\
&=1+\frac{3}{2}\left(1+\frac{1}{6}\left(b_{n}^{2}-1\right)+b_{n}\right) \\
&=\frac{1}{4}\left(b_{n}^{2}+6 b_{n}+9\right)=\left(\frac{b_{n}+3}{2}\right)^{2} .
\end{aligned}
$$

Hence $b_{n+1}=\frac{1}{2} b_{n}+\frac{3}{2}$. This is an inhomogeneous first-order linear recursion. We can solve this by analogy with inhomogeneous linear first-order equations. Recall that if $a, b$ are constants, then the equation $f^{\prime}(x)=a f(x)+b$ has the solution

$$
f(x)=e^{a x} \int e^{-a x} b d x+c e^{a x} .
$$

In our problem the general term should be

$$
b_{n}=\frac{1}{2^{n+1}}+3 \sum_{k=1}^{n} \frac{1}{2^{k}}, \quad n \geq 1 .
$$

Summing the geometric series, we obtain $b_{n}=3+\frac{1}{2^{n-2}}$, and the answer to our problem is

$$
a_{n}=\frac{b_{n}^{2}-1}{24}=\frac{1}{3}+\frac{1}{2^{n}}+\frac{1}{3} \cdot \frac{1}{2^{2 n-1}} .
$$

(proposed by Germany for the 22nd International Mathematical Olympiad, 1981)

308. Call the expression from the statement $S_{n}$. It is not hard to find a way to write it in closed form. For example, if we let $u=1+i \sqrt{a}$, then $S_{n}=\frac{1}{2}\left(u^{n}+\bar{u}^{n}\right)$.

Notice that $u^{n}$ and $\bar{u}^{n}$ are both roots of the quadratic equation $z^{2}-2 z+a+1=0$, so they satisfy the recurrence relation $x_{n+2}=2 x_{n+1}-(a+1) x_{n}$. The same should be true for $S_{n}$; hence

$$
S_{n+2}=2 S_{n+1}-(a+1) S_{n}, \quad n \geq 1 .
$$

One verifies that $S_{1}=1$ and $S_{2}=1-2 k$ are divisible by 2 . Also, if $S_{n}$ is divisible by $2^{n-1}$ and $S_{n+1}$ is divisible by $2^{n}$, then $(a+1) S_{n}$ and $2 S_{n+1}$ are both divisible by $2^{n+1}$, and hence so must be $S_{n+2}$. The conclusion follows by induction.

(Romanian Mathematical Olympiad, 1984, proposed by D. Miheţ) 

309. Denote the vertices of the octagon by $A_{1}=A, A_{2}, A_{3}, A_{4}, A_{5}=E, A_{6}, A_{7}, A_{8}$ in successive order. Any time the frog jumps back and forth it makes two jumps, so to get from $A_{1}$ to any vertex with odd index, in particular to $A_{5}$, it makes an even number of jumps. This shows that $a_{2 n-1}=0$.

We compute the number of paths with $2 n$ jumps recursively. Consider the case $n>2$. After two jumps, the frog ends at $A_{1}, A_{3}$, or $A_{7}$. It can end at $A_{1}$ via $A_{2}$ or $A_{8}$. Also, the configurations where it ends at $A_{3}$ or $A_{7}$ are symmetric, so they can be treated simultaneously. If we denote by $b_{2 n}$ the number of ways of getting from $A_{3}$ to $A_{5}$ in $2 n$ steps, we obtain the recurrence $a_{2 n}=2 a_{2 n-2}+2 b_{2 n-2}$. On the other hand, if the frog starts at $A_{3}$, then it can either return to $A_{3}$ in two steps (which can happen in two different ways), or end at $A_{1}$ (here it is important that $n>2$ ). Thus we can write $b_{2 n}=a_{2 n-2}+2 b_{2 n-2}$. In vector form the recurrence is

$$
\left(\begin{array}{l}
a_{2 n} \\
b_{2 n}
\end{array}\right)=\left(\begin{array}{ll}
2 & 2 \\
1 & 2
\end{array}\right)\left(\begin{array}{l}
a_{2 n-2} \\
b_{2 n-2}
\end{array}\right)=\left(\begin{array}{ll}
2 & 2 \\
1 & 2
\end{array}\right)^{n-1}\left(\begin{array}{l}
a_{2} \\
b_{2}
\end{array}\right) .
$$

To find the $n$th power of the matrix we diagonalize it. The characteristic equation is $\lambda^{2}-4 \lambda+2=0$, with roots $x=2+\sqrt{2}$ and $y=2-\sqrt{2}$. The $n$th power of the matrix will be of the form

$$
X\left(\begin{array}{cc}
x^{n} & 0 \\
0 & y^{n}
\end{array}\right) X^{-1},
$$

for some matrix $X$. Consequently, there exist constants $\alpha, \beta$, determined by the initial condition, such that $a_{2 n}=\alpha x^{n-1}+\beta y^{n-1}$. To determine $\alpha$ and $\beta$, note that $a_{2}=0$, $b_{2}=1$, and using the recurrence relation, $a_{4}=2$ and $b_{4}=3$. We obtain $\alpha=\frac{1}{\sqrt{2}}$ and $\beta=-\frac{1}{\sqrt{2}}$, whence

$$
a_{2 n}=\frac{1}{\sqrt{2}}\left(x^{n-1}-y^{n-1}\right), \quad \text { for } n \geq 1 .
$$

(21st International Mathematical Olympiad, 1979, proposed by Germany)

310. We first try a function of the form $f(n)=n+a$. The relation from the statement yields $a=667$, and hence $f(n)=n+667$ is a solution. Let us show that this is the only solution.

Fix some positive integer $n$ and define $a_{0}=n$, and $a_{k}=f(f(\cdots(f(n) \cdots))$, where the composition is taken $k$ times, $k \geq 1$. The sequence $\left(a_{k}\right)_{k \geq 0}$ satisfies the inhomogeneous linear recurrence relation

$$
a_{k+3}-3 a_{k+2}+6 a_{k+1}-4 a_{k}=2001 .
$$

A particular solution is $a_{k}=667 \mathrm{k}$. The characteristic equation of the homogeneous recurrence $a_{k+3}-3 a_{k+2}+6 a_{k+1}-4 a_{k}=0$ is 

$$
\lambda^{3}-3 \lambda^{2}+6 \lambda-4=0 .
$$

An easy check shows that $\lambda_{1}=1$ is a solution to this equation. Since $\lambda^{3}-3 \lambda^{2}+$ $6 \lambda-4=(\lambda-1)\left(\lambda^{2}-2 \lambda+4\right)$, the other two solutions are $\lambda_{2,3}=1 \pm i \sqrt{3}$, that is, $\lambda_{2,3}=2\left(\cos \frac{\pi}{3} \pm i \sin \frac{\pi}{3}\right)$. It follows that the formula for the general term of a sequence satisfying the recurrence relation is

$$
a_{k}=c_{1}+c_{2} 2^{k} \cos \frac{k \pi}{3}+c_{3} 2^{k} \sin \frac{k \pi}{3}+667 k, \quad k \geq 0,
$$

with $c_{1}, c_{2}$, and $c_{3}$ some real constants.

If $c_{2}>0$, then $a_{3(2 m+1)}$ will be negative for large $m$, and if $c_{2}<0$, then $a_{6 m}$ will be negative for large $m$. Since $f(n)$ can take only positive values, this implies that $c_{2}=0$. A similar argument shows that $c_{3}=0$. It follows that $a_{k}=c_{1}+667 k$. So the first term of the sequence determines all the others. Since $a_{0}=n$, we have $c_{1}=n$, and hence $a_{k}=n+667 k$, for all $k$. In particular, $a_{1}=f(n)=n+667$, and hence this is the only possible solution.

(Mathematics Magazine, proposed by R. Gelca)

311. We compute $x_{3}=91, x_{4}=436, x_{5}=2089$. And we already suggested by placing the problem in this section that the solution should involve some linear recurrence. Let us hope that the terms of the sequence satisfy a recurrence $x_{n+1}=\alpha x_{n}+\beta x_{n-1}$. Substituting $n=2$ and $n=3$ we obtain $\alpha=5, \beta=-1$, and then the relation is also verified for the next term $2089=5 \cdot 436-91$. Let us prove that this recurrence holds in general.

If $y_{n}$ is the general term of this recurrence, then $y_{n}=a r^{n}+b s^{n}$, where

$$
r=\frac{5+\sqrt{21}}{2}, \quad s=\frac{5-\sqrt{21}}{2}, \quad r s=1, \quad r-s=\sqrt{21}
$$

and

$$
a=\frac{7+\sqrt{21}}{14}, \quad b=\frac{7-\sqrt{21}}{14}, \quad a b=1 .
$$

We then compute

$$
\begin{aligned}
y_{n+1}-\frac{y_{n}^{2}}{y_{n}-1} &=\frac{y_{n+1} y_{n-1}-y_{n}^{2}}{y_{n-1}}=\frac{\left(a r^{n+1}+b s^{n+1}\right)\left(a r^{n-1}+b s^{n-1}\right)-\left(a r^{n}+b x^{n}\right)^{2}}{a r^{n-1}+b s^{n-1}} \\
&=\frac{a b(r s)^{n-1}(r-s)^{2}}{y_{n-1}}=\frac{3}{y_{n}-1} .
\end{aligned}
$$

Of course, $0<\frac{3}{y_{n}-1}<1$ for $n \geq 2$. Because $y_{n+1}$ is an integer, it follows that

$$
y_{n+1}=\left\lceil\frac{y_{n}^{2}}{y_{n-1}}\right\rceil \text {. }
$$

Hence $x_{n}$ and $y_{n}$ satisfy the same recurrence. This implies that $x_{n}=y_{n}$ for all $n$. The conclusion now follows by induction if we rewrite the recurrence as $\left(x_{n+1}-1\right)=$ $5\left(x_{n}-1\right)-\left(x_{n-1}-1\right)+3$.

(proposed for the USA Mathematical Olympiad by G. Heuer)

312. From the recurrence relation for $\left(a_{n}\right)_{n}$, we obtain

$$
2 a_{n+1}-3 a_{n}=\sqrt{5 a_{n}^{2}-4},
$$

and hence

$$
4 a_{n+1}^{2}-12 a_{n+1} a_{n}+9 a_{n}^{2}=5 a_{n}^{2}-4 .
$$

After canceling similar terms and dividing by 4 , we obtain

$$
a_{n+1}^{2}-3 a_{n+1} a_{n}+a_{n}^{2}=-1 .
$$

Subtracting this from the analogous relation for $n-1$ instead of $n$ yields

$$
a_{n+1}^{2}-3 a_{n+1} a_{n}+3 a_{n} a_{n-1}-a_{n-1}^{2}=0 .
$$

This is the same as

$$
\left(a_{n+1}-a_{n-1}\right)\left(a_{n+1}-3 a_{n}+a_{n-1}\right)=0,
$$

which holds for $n \geq 1$. Looking at the recurrence relation we see immediately that the sequence $\left(a_{n}\right)_{n}$ is strictly increasing, so in the above product the first factor is different from 0 . Hence the second factor is equal to 0 , i.e.,

$$
a_{n+1}=3 a_{n}-a_{n-1}, \quad n \geq 2 .
$$

This is a linear recurrence that can, of course, be solved by the usual algorithm. But this is a famous recurrence relation, satisfied by the Fibonacci numbers of odd index. A less experienced reader can simply look at the first few terms, and then prove by induction that $a_{n}=F_{2 n+1}, n \geq 1$.

The sequence $\left(b_{n}\right)_{n}$ also satisfies a recurrence relation that can be found by substituting $a_{n}=b_{n+1}-b_{n}$ in the recurrence relation for $\left(a_{n}\right)_{n}$. After computations, we obtain

$$
b_{n+1}=2 b_{n}+2 b_{n-1}-b_{n-2}, \quad n \geq 3 .
$$

But now we are told that $b_{n}$ should be equal to $\left(F_{n}\right)^{2}, n \geq 1$. Here is a proof by induction on $n$. It is straightforward to check the equality for $n=1,2,3$. Assuming that $b_{k}=\left(F_{k}\right)^{2}$ for all $k \leq n$, it follows that

$$
b_{n+1}=2\left(F_{n}\right)^{2}+2\left(F_{n-1}\right)^{2}-\left(F_{n-2}\right)^{2}
$$



$$
\begin{aligned}
&=\left(F_{n}+F_{n-1}\right)^{2}+\left(F_{n}-F_{n-1}\right)^{2}-\left(F_{n-2}\right)^{2} \\
&=\left(F_{n+1}\right)^{2}+\left(F_{n-2}\right)^{2}-\left(F_{n-2}\right)^{2}=\left(F_{n+1}\right)^{2} .
\end{aligned}
$$

With this the problem is solved.

(Mathematical Reflections, proposed by T. Andreescu)

313. The function $|\sin x|$ is periodic with period $\pi$. Hence

$$
\lim _{n \rightarrow \infty}\left|\sin \pi \sqrt{n^{2}+n+1}\right|=\lim _{n \rightarrow \infty}\left|\sin \pi\left(\sqrt{n^{2}+n+1}-n\right)\right| .
$$

But

$$
\lim _{n \rightarrow \infty}\left(\sqrt{n^{2}+n+1}-n\right)=\lim _{n \rightarrow \infty} \frac{n^{2}+n+1-n^{2}}{\sqrt{n^{2}+n+1}+n}=\frac{1}{2} .
$$

It follows that the limit we are computing is equal to $\left|\sin \frac{\pi}{2}\right|$, which is 1 .

314. The limit is computed as follows:

$$
\begin{aligned}
\lim _{n \rightarrow \infty} &\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(\frac{\mu}{n}\right)^{k}\left(1-\frac{\mu}{n}\right)^{n-k} \\
&=\lim _{n \rightarrow \infty} \frac{n !}{k !(n-k) !}\left(\frac{\frac{\mu}{n}}{1-\frac{\mu}{n}}\right)^{k}\left(1-\frac{\mu}{n}\right)^{n} \\
&=\frac{1}{k !} \lim _{n \rightarrow \infty} \frac{n(n-1) \cdots(n-k+1)}{\left(\frac{n}{\mu}-1\right)^{k}} \cdot \lim _{n \rightarrow \infty}\left(1-\frac{\mu}{n}\right)^{\frac{n}{\mu} \cdot \mu} \\
&=\frac{e^{\mu}}{k !} \lim _{n \rightarrow \infty} \frac{n^{k}-(1+\cdots+(k-1)) n^{k-1}+\cdots+(-1)^{k-1}(k-1) !}{\frac{1}{\mu^{k}} n^{k}-\left(\begin{array}{c}
k \\
1
\end{array}\right) \frac{1}{\mu^{k-1}} n^{k-1}+\cdots+(-1)^{k}} \\
=& \frac{1}{e^{\mu} \cdot k !} \cdot \frac{1}{\frac{1}{\mu^{k}}}=\frac{\mu^{k}}{e^{\mu} \cdot k !} .
\end{aligned}
$$

Remark. This limit is applied in probability theory in the following context. Consider a large population $n$ in which an event occurs with very low probability $p$. The probability that the event occurs exactly $k$ times in that population is given by the binomial formula

$$
P(k)=\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k} .
$$

But for $n$ large, the number $(1-p)^{n-k}$ is impossible to compute. In that situation we set $\mu=n p$ (the mean occurrence in that population), and approximate the probability by the Poisson distribution 

$$
P(k) \approx \frac{\mu^{k}}{e^{k} \cdot k !} .
$$

The exercise we just solved shows that this approximation is good.

315. Let us assume that the answer is negative. Then the sequence has a bounded subsequence $\left(x_{n_{k}}\right)_{k}$. The set $\left\{x_{x_{n_{k}}} \mid k \in \mathbb{Z}\right\}$ is finite, since the indices $x_{n_{k}}$ belong to a finite set. But $x_{x_{n_{k}}}=n_{k}^{4}$, and this takes infinitely many values for $k \geq 1$. We reached a contradiction that shows that our assumption was false. So the answer to the question is yes.

(Romanian Mathematical Olympiad, 1978, proposed by S. Rădulescu)

316. Define the sequence $\left(b_{n}\right)_{n}$ by

$$
b_{n}=\max \left\{\left|a_{k}\right|, 2^{n-1} \leq k<2^{n}\right\} .
$$

From the hypothesis it follows that $b_{n} \leq \frac{b_{n-1}}{2}$. Hence $0 \leq b_{n} \leq \frac{b_{1}}{2^{n-1}}$, which implies that $\left(b_{n}\right)_{n}$ converges to 0 . We also have that $\left|a_{n}\right| \leq b_{n}$, for $n \geq 1$, so by applying the squeezing principle, we obtain that $\left(a_{n}\right)_{n}$ converges to zero, as desired.

(Romanian Mathematical Olympiad, 1975, proposed by R. Gologan)

317. First solution: Using the fact that $\lim _{n \rightarrow \infty} \sqrt[n]{a}=1$, we pass to the limit in the relation from the statement to obtain

$$
\underbrace{1+1+\cdots+1}_{k \text { times }}=\underbrace{1+1+\cdots+1}_{m \text { times }} .
$$

Hence $k=m$. Using L'Hôpital's theorem, one can prove that $\lim _{x \rightarrow 0} x\left(a^{x}-1\right)=\ln a$, and hence $\lim _{n \rightarrow \infty} n(\sqrt[n]{a}-1)=\ln a$. Transform the relation from the hypothesis into

$$
n\left(\sqrt[n]{a_{1}}-1\right)+\cdots+n\left(\sqrt[n]{a_{k}}-1\right)=n\left(\sqrt[n]{b_{1}}-1\right)+\cdots+n\left(\sqrt[n]{b_{k}}-1\right) .
$$

Passing to the limit with $n \rightarrow \infty$, we obtain

$$
\ln a_{1}+\ln a_{2}+\cdots+\ln a_{k}=\ln b_{1}+\ln b_{2}+\cdots+\ln b_{k} .
$$

This implies that $a_{1} a_{2} \cdots a_{k}=b_{1} b_{2} \cdots b_{k}$, and we are done.

Second solution: Fix $N>k$; then taking $n=\frac{(N !)}{m}$ for $1 \leq m \leq k$, we see that the powersum symmetric polynomials in $a_{i}^{1 / N !}$ agree with the power-sum symmetric polynomials in $b_{i}^{1 / N !}$. Hence the elementary symmetric polynomials in these variables also agree and hence there is a permutation $\pi$ such that $b_{i}=a_{\pi(i)}$.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by D. Andrica, second solution by R. Stong) 

318. It is known that

$$
\lim _{x \rightarrow 0^{+}} x^{x}=1 .
$$

Here is a short proof using L'Hôpital's theorem:

$$
\lim _{x \rightarrow 0^{+}} x^{x}=\lim _{x \rightarrow 0^{+}} e^{x \ln x}=e^{\lim _{x \rightarrow 0^{+}} x \ln x}=e^{\lim _{x \rightarrow 0^{+}} \frac{\ln x}{\frac{1}{x}}}=e^{\lim _{x \rightarrow 0^{+}}(-x)}=1 .
$$

Returning to the problem, fix $\epsilon>0$, and choose $\delta>0$ such that for $0<x<\delta$,

$$
\left|x^{x}-1\right|<\epsilon .
$$

Then for $n \geq \frac{1}{\delta}$ we have

$$
\begin{aligned}
\left|n^{2} \int_{0}^{\frac{1}{n}}\left(x^{x+1}-x\right) d x\right| & \leq n^{2} \int_{0}^{\frac{1}{n}}\left|x^{x+1}-x\right| d x, \\
&=n^{2} \int_{0}^{\frac{1}{n}} x\left|x^{x}-1\right| d x<\epsilon n^{2} \int_{0}^{\frac{1}{n}} x d x=\frac{\epsilon}{2} .
\end{aligned}
$$

It follows that

$$
\lim _{n \rightarrow \infty} \int_{0}^{\frac{1}{n}}\left(x^{x+1}-x\right) d x=0,
$$

and so

$$
\lim _{n \rightarrow \infty} n^{2} \int_{0}^{\frac{1}{n}} x^{x+1} d x=\lim _{n \rightarrow \infty} n^{2} \int_{0}^{\frac{1}{n}} x d x=\frac{1}{2} .
$$

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by D. Andrica)

319. We will prove by induction on $n \geq 1$ that

$$
x_{n+1}>\sum_{k=1}^{n} k x_{k}>a \cdot n !,
$$

from which it will follow that the limit is $\infty$.

For $n=1$, we have $x_{2} \geq 3 x_{1}>x_{1}=a$. Now suppose that the claim holds for all values up through $n$. Then

$$
x_{n+2} \geq(n+3) x_{n+1}-\sum_{k=1}^{n} k x_{k}=(n+1) x_{n+1}+2 x_{n+1}-\sum_{k=1}^{n} k x_{k}
$$



$$
>(n+1) x_{n+1}+2 \sum_{k=1}^{n} k x_{k}-\sum_{k=1}^{n} k x_{k}=\sum_{k=1}^{n+1} k x_{k},
$$

as desired. Furthermore, $x_{1}>0$ by definition and $x_{2}, x_{3}, \ldots, x_{n}$ are also positive by the induction hypothesis. Therefore, $x_{n+2}>(n+1) x_{n+1}>(n+1)(a \cdot n !)=a \cdot(n+1) !$. This completes the induction, proving the claim.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1999) 

320. Denote $\lambda=\inf _{n \geq 1} \frac{x_{n}}{n}$ and for simplicity assume that $\lambda>-\infty$. Fix $\epsilon>0$. Then there exists $n_{0}$ such that $\frac{x_{n_{0}}}{n_{0}} \leq \lambda+\epsilon$. Let $M=\max _{1 \leq i \leq n_{0}} x_{i}$.

An integer $m$ can be written as $n_{0} q+n_{1}$, with $0 \leq n_{1}<q$ and $q=\left\lfloor\frac{m}{n_{0}}\right\rfloor$. From the hypothesis it follows that $x_{m} \leq q x_{n_{0}}+x_{n_{1}}$; hence

$$
\lambda \leq \frac{x_{m}}{m} \leq \frac{q x_{n_{0}}}{m}+\frac{x_{n_{1}}}{m} \leq \frac{q n_{0}}{m}(\lambda+\epsilon)+\frac{M}{m} .
$$

Therefore,

$$
\lambda \leq \frac{x_{m}}{m} \leq \frac{\left[\frac{m}{n_{0}}\right\rfloor}{\frac{m}{n_{0}}}(\lambda+\epsilon)+\frac{M}{m} .
$$

Since

$$
\lim _{m \rightarrow \infty} \frac{\left\lfloor\frac{m}{n_{0}}\right\rfloor}{\frac{m}{n_{0}}}=1 \quad \text { and } \quad \lim _{m \rightarrow \infty} \frac{M}{m}=0,
$$

it follows that for large $m$,

$$
\lambda \leq \frac{x_{m}}{m} \leq \lambda+2 \epsilon .
$$

Since $\epsilon$ was arbitrary, this implies

$$
\lim _{n \rightarrow \infty} \frac{x_{n}}{n}=\lambda=\inf _{n \geq 1} \frac{x_{n}}{n},
$$

as desired.

321. We use the fact that

$$
\lim _{x \rightarrow 0^{+}} x^{x}=1 .
$$

As a consequence, we have

$$
\lim _{x \rightarrow 0^{+}} \frac{x^{x+1}}{x}=1 .
$$

For our problem, let $\epsilon>0$ be a fixed small positive number. There exists $n(\epsilon)$ such that for any integer $n \geq n(\epsilon)$,

$$
1-\epsilon<\frac{\left(\frac{k}{n^{2}}\right)^{\frac{k}{n^{2}}+1}}{\frac{k}{n^{2}}}<1+\epsilon, \quad k=1,2, \ldots, n .
$$

From this, using properties of ratios, we obtain

$$
1-\epsilon<\frac{\sum_{k=1}^{n}\left(\frac{k}{n^{2}}\right)^{\frac{k}{n^{2}}+1}}{\sum_{k=1}^{n} \frac{k}{n^{2}}}<1+\epsilon, \quad \text { for } n \geq n(\epsilon) .
$$

Knowing that $\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$, this implies

$$
(1-\epsilon) \frac{n+1}{2 n}<\sum_{k=1}^{n}\left(\frac{k}{n^{2}}\right)^{\frac{k}{n^{2}}+1}<(1+\epsilon) \frac{n+1}{2 n}, \quad \text { for } n \geq n(\epsilon) .
$$

It follows that

$$
\lim _{n \rightarrow \infty} \sum_{k-1}^{n}\left(\frac{k}{n^{2}}\right)^{\frac{k}{n^{2}}+1}=\frac{1}{2} .
$$

(D. Andrica)

322. Assume that $x_{n}$ is a square for all $n>M$. Consider the integers $y_{n}=\sqrt{x_{n}}$, for $n \geq M$. Because in base $b$,

$$
\frac{b^{2 n}}{b-1}=\underbrace{11 \ldots 1}_{2 n} .111 \ldots,
$$

it follows that

$$
\lim _{n \rightarrow \infty} \frac{\frac{b^{2 n}}{b-1}}{x_{n}}=1 .
$$

Therefore,

$$
\lim _{n \rightarrow \infty} \frac{b^{n}}{y_{n}}=\sqrt{b-1} .
$$

On the other hand,

$$
\left(b y_{n}+y_{n+1}\right)\left(b y_{n}-y_{n+1}\right)=b^{2} x_{n}-x_{n+1}=b^{n+2}+3 b^{2}-2 b-5 .
$$

The last two relations imply

$$
\lim _{n \rightarrow \infty}\left(b y_{n}-y_{n+1}\right)=\lim _{n \rightarrow \infty} \frac{b^{n+2}}{b y_{n}+y_{n+1}}=\frac{b \sqrt{b-1}}{2} .
$$

Here we used the fact that

$$
\lim _{n \rightarrow \infty} \frac{b^{n+2}}{b y_{n}}=\lim _{n \rightarrow \infty} \frac{b^{n+2}}{y_{n+1}}=b \sqrt{b-1} .
$$

Since $b y_{n}-y_{n+1}$ is an integer, if it converges then it eventually becomes constant. Hence there exists $N>M$ such that $b y_{n}-y_{n+1}=\frac{b \sqrt{b-1}}{2}$ for $n>N$. This means that $b-1$ is a perfect square. If $b$ is odd, then $\frac{\sqrt{b-1}}{2}$ is an integer, and so $b$ divides $\frac{b \sqrt{b-1}}{2}$. Since the latter is equal to $b y_{n}-y_{n+1}$ for $n>N$, and this divides $b^{n+2}+3 b^{2}-2 b-5$, it follows that $b$ divides 5 . This is impossible.

If $b$ is even, then by the same argument $\frac{b}{2}$ divides 5 . Hence $b=10$. In this case we have indeed that $x_{n}=\left(\frac{10^{n}+5}{3}\right)^{2}$, and the problem is solved.

(short list of the 44th International Mathematical Olympiad, 2003)

323. Recall the double inequality

$$
\left(1+\frac{1}{n}\right)^{n}<e<\left(1+\frac{1}{n}\right)^{n+1}, \quad n \geq 1 .
$$

Taking the natural logarithm, we obtain

$$
n \ln \left(1+\frac{1}{n}\right)<1<(n+1) \ln \left(1+\frac{1}{n}\right),
$$

which yields the double inequality

$$
\frac{1}{n+1}<\ln (n+1)-\ln n<\frac{1}{n} .
$$

Applying the one on the right, we find that

$$
a_{n}-a_{n-1}=\frac{1}{n}-\ln (n+1)+\ln n>0, \quad \text { for } n \geq 2,
$$

so the sequence is increasing. Adding the inequalities

$$
\begin{aligned}
1 & \leq 1, \\
\frac{1}{2} &<\ln 2-\ln 1, \\
\frac{1}{3} &<\ln 3-\ln 2,
\end{aligned}
$$



$$
\frac{1}{n}<\ln n-\ln (n-1),
$$

we obtain

$$
1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}<1+\ln n<1+\ln (n+1) .
$$

Therefore, $a_{n}<1$, for all $n$. We found that the sequence is increasing and bounded, hence convergent.

324. The sequence is increasing, so all we need to show is that it is bounded. The main trick is to factor a $\sqrt{2}$. The general term of the sequence becomes

$$
\begin{aligned}
a_{n} &=\sqrt{2} \sqrt{\frac{1}{2}+\sqrt{\frac{2}{4}+\sqrt{\frac{3}{8}+\cdots+\sqrt{\frac{n}{2^{n}}}}}} \\
&<\sqrt{2} \sqrt{1+\sqrt{1+\sqrt{1+\cdots+\sqrt{1}}}}
\end{aligned}
$$

Let $b_{n}=\sqrt{1+\sqrt{1+\cdots+\sqrt{1}}}$, where there are $n$ radicals. Then $b_{n+1}=\sqrt{1+b_{n}}$. We see that $b_{1}=1<2$, and if $b_{n}<2$, then $b_{n+1}<\sqrt{1+2}<2$. Inductively we prove that $b_{n}<2$ for all $n$. Therefore, $a_{n}<2 \sqrt{2}$ for all $n$. Being monotonic and bounded, the sequence $\left(a_{n}\right)_{n}$ is convergent.

(Matematika v škole, 1971, solution from R. Honsberger, More Mathematical Morsels, Mathematical Association of America, 1991)

325. We examine first the expression under the square root. Its zeros are $\frac{-1 \pm \sqrt{5}}{2}$. In order for the square root to make sense, $a_{n}$ should be outside the interval $\left(\frac{-1-\sqrt{5}}{2}, \frac{-1+\sqrt{5}}{2}\right)$. Since $a_{n} \geq 0$ for $n \geq 2$, being the square root of an integer, we must have $a_{n} \geq \frac{-1+\sqrt{5}}{2}$ for $n \geq 2$. To simplify the notation, let $r=\frac{-1+\sqrt{5}}{2}$.

Now suppose by contradiction that $a_{1} \in(-2,1)$. Then

$$
a_{2}^{2}=a_{1}^{2}+a_{1}-1=\left(a_{1}+\frac{1}{2}\right)^{2}-\frac{5}{4}<\left(\frac{3}{2}\right)^{2}-\frac{5}{4}=1,
$$

so $a_{2} \in[r, 1)$. Now if $a_{n} \in[r, 1)$, then

$$
a_{n+1}^{2}=a_{n}^{2}+a_{n}-1<a_{n}^{2}<1 .
$$

Inductively we prove that $a_{n} \in[r, 1)$ and $a_{n+1}<a_{n}$. The sequence $\left(a_{n}\right)_{n}$ is bounded and strictly decreasing; hence it has a limit $L$. This limit must lie in the interval $[r, 1)$. Passing to the limit in the recurrence relation, we obtain $L=\sqrt{L^{2}+L-1}$, and therefore $L^{2}=L^{2}+L-1$. But this equation has no solution in the interval $[r, 1)$, a contradiction. Hence $a_{1}$ cannot lie in the interval $(-2,1)$.

(Bulgarian Mathematical Olympiad, 2002)

326. This is the Bolzano-Weierstrass theorem. For the proof, let us call a term of the sequence a giant if all terms following it are smaller. If the sequence has infinitely many giants, they form a bounded decreasing subsequence, which is therefore convergent. If the sequence has only finitely many giants, then after some rank each term is followed by larger term. These terms give rise to a bounded increasing subsequence, which is again convergent.

Remark. The idea can be refined to show that any sequence of $m n+1$ real numbers has either a decreasing subsequence with $m+1$ terms or an increasing subsequence with $n+1$ terms.

327. Consider the truncations

$$
s_{n}=a_{1}-a_{2}+a_{3}-\cdots \pm a_{n}, \quad n \geq 1 .
$$

We are to show that the sequence $\left(s_{n}\right)_{n}$ is convergent. For this we verify that the sequence $\left(s_{n}\right)_{n}$ is Cauchy. Because $\left(a_{n}\right)_{n \geq 1}$ is decreasing, for all $n>m$,

$$
\begin{aligned}
\left|s_{n}-s_{m}\right| &=a_{m}-a_{m+1}+a_{m+2}-\cdots \pm a_{n} \\
&=a_{m}-\left(a_{m+1}-a_{m+2}\right)-\left(a_{m+3}-a_{m+4}\right)-\cdots,
\end{aligned}
$$

where the sum ends either in $a_{n}$ or in $-\left(a_{n-1}-a_{n}\right)$. All terms of this sum, except for the first and maybe the last, are negative. Therefore, $\left|s_{n}-s_{m}\right| \leq a_{m}+a_{n}$, for all $n>m \geq 1$. As $a_{n} \rightarrow 0$, this shows that the sequence $\left(s_{n}\right)_{n}$ is Cauchy, and hence convergent.

(the Leibniz criterion)

328. For a triple of real numbers $(x, y, z)$ define $\Delta(x, y, z)=\max (|x-y|,|x-z|,|y-z|)$. Let $\Delta\left(a_{0}, b_{0}, c_{0}\right)=\delta$. From the recurrence relation we find that

$$
\Delta\left(a_{n+1}, b_{n+1}, c_{n+1}\right)=\frac{1}{2} \Delta\left(a_{n}, b_{n}, c_{n}\right), \quad n \geq 0 .
$$

By induction $\Delta\left(a_{n}, b_{n}, c_{n}\right)=\frac{1}{2^{n}} \delta$. Also, $\max \left(\left|a_{n+1}-a_{n}\right|,\left|b_{n+1}-b_{n}\right|,\left|c_{n+1}-c_{n}\right|\right)=$ $\frac{1}{2} \Delta\left(a_{n}, b_{n}, c_{n}\right)$. We therefore obtain that $\left|a_{n+1}-a_{n}\right|,\left|b_{n+1}-b_{n}\right|,\left|c_{n+1}-c_{n}\right|$ are all less than or equal to $\frac{1}{2^{n}} \delta$. So for $n>m \geq 1$, the absolute values $\left|a_{n}-a_{m}\right|,\left|b_{n}-b_{m}\right|$, and $\left|c_{n}-c_{m}\right|$ are less than

$$
\left(\frac{1}{2^{m}}+\frac{1}{2^{m+1}}+\cdots+\frac{1}{2^{n}}\right) \delta<\frac{\delta}{2^{m}} .
$$

This proves that the sequences are Cauchy, hence convergent. Because as $n$ tends to infinity $\Delta\left(a_{n}, b_{n}, c_{n}\right)$ approaches 0 , the three sequences converge to the same limit $L$. Finally, because for all $n, a_{n}+b_{n}+c_{n}=a_{0}+b_{0}+c_{0}$, we should have $3 L=a_{0}+b_{0}+c_{0}$; hence the common limit is $\frac{\left(a_{0}+b_{0}+c_{0}\right)}{3}$.

329. Because $\sum a_{n}$ converges, Cauchy's criterion implies that

$$
\lim _{n \rightarrow \infty}\left(a_{\lfloor n / 2\rfloor+1}+a_{\lfloor n / 2\rfloor+2}+\cdots+a_{n}\right)=0 .
$$

By monotonicity

$$
a_{\lfloor n / 2\rfloor+1}+a_{\lfloor n / 2\rfloor+2}+\cdots+a_{n} \geq\left\lceil\frac{n}{2}\right\rceil a_{n},
$$

so $\lim _{n \rightarrow \infty}\left\lceil\frac{n}{2}\right\rceil a_{n}=0$. Consequently, $\lim _{n \rightarrow \infty} \frac{n}{2} a_{n}=0$, and hence $\lim _{n \rightarrow \infty} n a_{n}=0$, as desired.

(Abel's lemma)

330. Think of the larger map as a domain $D$ in the plane. The change of scale from one map to the other is a contraction, and since the smaller map is placed inside the larger, the contraction maps $D$ to $D$. Translating into mathematical language, a point such as the one described in the statement is a fixed point for this contraction. And by the fixed point theorem the point exists and is unique.

331. Define the function $f(x)=\epsilon \sin x+t$. Then for any real numbers $x_{1}$ and $x_{2}$,

$$
\begin{aligned}
\left|f\left(x_{1}\right)-f\left(x_{2}\right)\right| &=|\epsilon| \cdot\left|\sin x_{1}-\sin x_{2}\right| \leq 2|\epsilon| \cdot\left|\sin \frac{x_{1}-x_{2}}{2}\right| \cdot\left|\cos \frac{x_{1}+x_{2}}{2}\right| \\
& \leq 2|\epsilon| \cdot\left|\sin \frac{x_{1}-x_{2}}{2}\right| \leq \epsilon\left|x_{1}-x_{2}\right| .
\end{aligned}
$$

Hence $f$ is a contraction, and there exists a unique $x$ such that $f(x)=\epsilon \sin x+t=x$. This $x$ is the unique solution to the equation.

\section{(J. Kepler)}

332. Define $f:(0, \infty) \rightarrow(0, \infty), f(x)=\frac{1}{2}\left(x+\frac{c}{x}\right)$. Then $f^{\prime}(x)=\frac{1}{2}\left(1-\frac{c}{x^{2}}\right)$, which is negative for $x<\sqrt{c}$ and positive for $x>\sqrt{c}$. This shows that $\sqrt{c}$ is a global minimum for $f$ and henceforth $f((0, \infty)) \subset[\sqrt{c}, \infty)$. Shifting indices, we can assume that $x_{0} \geq \sqrt{c}$. Note that $\left|f^{\prime}(x)\right|<\frac{1}{2}$ for $x \in[\sqrt{c}, \infty)$, so $f$ is a contraction on this interval. Because $x_{n}=f\left(f\left(\cdots f\left(x_{0}\right)\right), n \geq 1\right.$, the sequence $\left(x_{n}\right)_{n}$ converges to the unique fixed point $x^{*}$ of $f$. Passing to the limit in the recurrence relation, we obtain $x^{*}=\frac{1}{2}\left(x^{*}+\frac{c}{x^{*}}\right)$, which is equivalent to the quadratic equation $\left(x^{*}\right)^{2}-c=0$. We obtain the desired limit of the sequence $x^{*}=\sqrt{c}$.

(Hero) 

333. Define

$$
x_{n}=\sqrt{1+\sqrt{1+\sqrt{1+\cdots+\sqrt{1}}}}, \quad n \geq 1,
$$

where in this expression there are $n$ square roots. Note that $x_{n+1}$ is obtained from $x_{n}$ by replacing $\sqrt{1}$ by $\sqrt{1+\sqrt{1}}$ at the far end. The square root function being increasing, the sequence $\left(x_{n}\right)_{n}$ is increasing. To prove that the sequence is bounded, we use the recurrence relation $x_{n+1}=\sqrt{1+x_{n}}, n \geq 1$. Then from $x_{n}<2$, we obtain that $x_{n+1}=\sqrt{1+x_{n}}<$ $\sqrt{1+2}<2$, so inductively $x_{n}<2$ for all $n$. Being bounded and monotonic, the sequence $\left(x_{n}\right)_{n}$ is convergent. Let $L$ be its limit (which must be greater than 1). Passing to the limit in the recurrence relation, we obtain $L=\sqrt{1+L}$, or $L^{2}-L-1=0$. The only positive solution is the golden ratio $\frac{\sqrt{5}+1}{2}$, which is therefore the limit of the sequence.

334. If the sequence converges to a certain limit $L$, then $L=\sqrt{a+b L}$, so $L$ is equal to the (unique) positive root $\alpha$ of the equation $x^{2}-b x-a=0$.

The convergence is proved by verifying that the sequence is monotonic and bounded. The condition $x_{n+1} \geq x_{n}$ translates to $x_{n}^{2} \geq a+b x_{n}$, which holds if and only if $x_{n}>\alpha$. On the other hand, if $x_{n} \geq \alpha$, then $x_{n+1}^{2}=a+b x_{n} \geq a+b \alpha=\alpha^{2}$; hence $x_{n+1} \geq \alpha$. Similarly, if $x_{n} \leq \alpha$, then $x_{n+1} \leq \alpha$. There are two situations. Either $x_{1}<\alpha$, and then by induction $x_{n}<\alpha$ for all $n$, and hence $x_{n+1}>x_{n}$ for all $n$. In this case the sequence is increasing and bounded from above by $\alpha$; therefore, it is convergent, its limit being of course $\alpha$. Or $x_{1} \geq \alpha$, in which case the sequence is decreasing and bounded from below by the same $\alpha$, and the limit is again $\alpha$.

335. By the AM-GM inequality, $a_{n}<b_{n}, n \geq 1$. Also,

$$
a_{n+1}-a_{n}=\sqrt{a_{n} b_{n}}-a_{n}=\sqrt{a_{n}}\left(\sqrt{b_{n}}-\sqrt{a_{n}}\right)>0 ;
$$

hence the sequence $\left(a_{n}\right)_{n}$ is increasing. Similarly,

$$
b_{n+1}-b_{n}=\frac{a_{n}+b_{n}}{2}-b_{n}=\frac{a_{n}-b_{n}}{2}<0,
$$

so the sequence $b_{n}$ is decreasing. Moreover,

$$
a_{0}<a_{1}<a_{2}<\cdots<a_{n}<b_{n}<\cdots<b_{1}<b_{0},
$$

for all $n$, which shows that both sequences are bounded. By the Weierstrass theorem, they are convergent. Let $a=\lim _{n \rightarrow \infty} a_{n}$ and $b=\lim _{n \rightarrow \infty} b_{n}$. Passing to the limit in the first recurrence relation, we obtain $a=\sqrt{a b}$, whence $a=b$. Done.

Remark. The common limit, denoted by $M(a, b)$, is called the arithmetic-geometric mean of the numbers $a$ and $b$. It was Gauss who first discovered, as a result of laborious computations, that the arithmetic-geometric mean is related to elliptic integrals. The relation that he discovered is

$$
M(a, b)=\frac{\pi}{4} \cdot \frac{a+b}{K\left(\frac{a-b}{a+b}\right)},
$$

where

$$
K(k)=\int_{0}^{1} \frac{1}{\sqrt{\left(1-t^{2}\right)\left(1-k^{2} t^{2}\right)}} d t
$$

is the elliptic integral of first kind. It is interesting to note that this elliptic integral is used to compute the period of the spherical pendulum. More precisely, for a pendulum described by the differential equation

$$
\frac{d^{2} \theta}{d t^{2}}+\omega^{2} \sin \theta=0,
$$

with maximal angle $\theta_{\max }$, the period is given by the formula

$$
P=\frac{2 \sqrt{2}}{\omega} K\left(\sin \left(\frac{1}{2} \theta_{\max }\right)\right) .
$$

336. The function $f_{n}(x)=x^{n}+x-1$ has positive derivative on $[0,1]$, so it is increasing on this interval. From $f_{n}(0) \cdot f_{n}(1)<0$ it follows that there exists a unique $x_{n} \in(0,1)$ such that $f\left(x_{n}\right)=0$.

Since $0<x_{n}<1$, we have $x_{n}^{n+1}+x_{n}-1<x_{n}^{n}+x_{n}-1=0$. Rephrasing, this means that $f_{n+1}\left(x_{n}\right)<0$, and so $x_{n+1}>x_{n}$. The sequence $\left(x_{n}\right)_{n}$ is increasing and bounded, thus it is convergent. Let $L$ be its limit. There are two possibilities, either $L=1$, or $L<1$. But $L$ cannot be less than 1 , for when passing to the limit in $x_{n}^{n}+x_{n}-1=0$, we obtain $L-1=0$, or $L=1$, a contradiction. Thus $L=1$, and we are done.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by A. Leonte)

337. Let

$$
x_{n}=\sqrt{1+2 \sqrt{1+2 \sqrt{1+\cdots+2 \sqrt{1+2 \sqrt{1969}}}}}
$$

with the expression containing $n$ square root signs. Note that

$$
x_{1}-(1+\sqrt{2})=\sqrt{1969}-(1+\sqrt{2})<50 .
$$

Also, since $\sqrt{1+2(1+\sqrt{2})}=1+\sqrt{2}$, we have 

$$
\begin{aligned}
x_{n+1}-(1+\sqrt{2})=& \sqrt{1+2 x_{n}}-\sqrt{1+2(1+\sqrt{2})}=\frac{2\left(x_{n}-(1-\sqrt{2})\right)}{\sqrt{1+2 x_{n}}+\sqrt{1+2(1+\sqrt{2})}} \\
&<\frac{x_{n}-(1+\sqrt{2})}{1+\sqrt{2}} .
\end{aligned}
$$

From here we deduce that

$$
x_{1969}-(1+\sqrt{2})<\frac{50}{(1+\sqrt{2})^{1968}}<10^{-3},
$$

and the approximation of $x_{1969}$ with two decimal places coincides with that of $1+\sqrt{2}=$ 2.41. This argument proves also that the limit of the sequence is $1+\sqrt{2}$.

(St. Petersburg Mathematical Olympiad, 1969)

338. Write the equation as

$$
\sqrt{x+2 \sqrt{x+\cdots+2 \sqrt{x+2 \sqrt{x+2 x}}}}=x .
$$

We can iterate this equality infinitely many times, always replacing the very last $x$ by its value given by the left-hand side. We conclude that $x$ should satisfy

$$
\sqrt{x+2 \sqrt{x+2 \sqrt{x+2 \cdots}}}=x,
$$

provided that the expression on the left makes sense! Let us check that indeed the recursive sequence given by $x_{0}=x$, and $x_{n+1}=\sqrt{x+2 x_{n}}, n \geq 0$, converges for any solution $x$ to the original equation. Squaring the equation, we find that $x<x^{2}$, hence $x>1$. But then $x_{n+1}<x_{n}$, because it reduces to $x_{n}^{2}-2 x_{n}+x>0$. This is always true, since when viewed as a quadratic function in $x_{n}$, the left-hand side has negative discriminant. Our claim is proved, and we can now transform the equation, the one with infinitely many square roots, into the much simpler

$$
x=\sqrt{x+2 x} .
$$

This has the unique solution $x=3$, which is also the unique solution to the equation from the statement, and this regardless of the number of radicals.

(D.O. Shklyarski, N.N. Chentsov, I.M. Yaglom, Selected Problems and Theorems in Elementary Mathematics, Arithmetic and Algebra, Mir, Moscow)

339. The sequence satisfies the recurrence relation

$$
x_{n+2}=\sqrt{7-\sqrt{7+x_{n}}}, \quad n \geq 1,
$$

with $x_{1}=\sqrt{7}$ and $x_{2}=\sqrt{7-\sqrt{7}}$. Let us first determine the possible values of the limit $L$, assuming that it exists. Passing to the limit in the recurrence relation, we obtain

$$
L=\sqrt{7-\sqrt{7+L}} .
$$

Squaring twice, we obtain the polynomial equation $L^{4}-14 L^{2}-L+42=0$. Two roots are easy to find by investigating the divisors of 42 , and they are $L=2$ and $L=-3$. The other two are $L=\frac{1}{2} \pm \frac{\sqrt{29}}{2}$. Only the positive roots qualify, and of them $\frac{1}{2}+\frac{\sqrt{29}}{2}$ is not a root of the original equation, since

$$
\frac{1}{2}+\frac{\sqrt{29}}{2}>3>\sqrt{7-\sqrt{7+3}}>\sqrt{7-\sqrt{7+\frac{1}{2}+\frac{\sqrt{29}}{2}}} .
$$

So the only possible value of the limit is $L=2$.

Let $x_{n}=2+\alpha_{n}$. Then $\alpha_{1}, \alpha_{2} \in(0,1)$. Also,

$$
\alpha_{n+2}=\frac{3-\sqrt{9+\alpha_{n}}}{\sqrt{7-\sqrt{9+\alpha_{n}}}+4} .
$$

If $\alpha_{n} \in(0,1)$, then

$$
0>\alpha_{n+2}>\frac{3-\sqrt{9+\alpha_{n}}}{4} \geq-\frac{1}{2} \alpha_{n},
$$

where the last inequality follows from $3+2 \alpha_{n} \geq \sqrt{9+\alpha_{n}}$. Similarly, if $\alpha_{n} \in(-1,0)$, then

$$
0<\alpha_{n+2}<\frac{3-\sqrt{9+\alpha_{n}}}{4} \leq \frac{1}{2}\left|\alpha_{n}\right|,
$$

where the last inequality follows from $3<\sqrt{9-\left|\alpha_{n}\right|}+2 \alpha$. Inductively, we obtain that $\alpha_{n} \in\left(-2^{-\lfloor n / 2\rfloor}, 2^{-\lfloor n / 2\rfloor}\right)$, and hence $\alpha_{n} \rightarrow 0$. Consequently, the sequence $\left(x_{n}\right)_{n}$ is convergent, and its limit is 2 .

(13th W.L. Putnam Mathematics Competition, 1953)

340. The solution is a direct application of the Cesàro-Stolz theorem. Indeed, if we let $a_{n}=\ln u_{n}$ and $b_{n}=n$, then

$$
\ln \frac{u_{n+1}}{u_{n}}=\ln u_{n+1}-\ln u_{n}=\frac{a_{n+1}-a_{n}}{b_{n+1}-b_{n}}
$$

and

$$
\ln \sqrt[n]{u_{n}}=\frac{1}{n} \ln u_{n}=\frac{a_{n}}{b_{n}} .
$$

The conclusion follows.

341. In view of the Cesàro-Stolz theorem, it suffices to prove the existence of and to compute the limit

$$
\lim _{n \rightarrow \infty} \frac{(n+1)^{p}}{(n+1)^{p+1}-n^{p+1}} .
$$

We invert the fraction and compute instead

$$
\lim _{n \rightarrow \infty} \frac{(n+1)^{p+1}-n^{p+1}}{(n+1)^{p}} .
$$

Dividing both the numerator and denominator by $(n+1)^{p+1}$, we obtain

$$
\lim _{n \rightarrow \infty} \frac{1-\left(1-\frac{1}{n+1}\right)^{p+1}}{\frac{1}{n+1}},
$$

which, with the notation $h=\frac{1}{n+1}$ and $f(x)=(1-x)^{p+1}$, becomes

$$
-\lim _{h \rightarrow 0} \frac{f(h)-f(0)}{h}=-f^{\prime}(0)=p+1 .
$$

We conclude that the required limit is $\frac{1}{p+1}$.

342. An inductive argument shows that $0<x_{n}<1$ for all $n$. Also, $x_{n+1}=x_{n}-x_{n}^{2}<x_{n}$, so $\left(x_{n}\right)_{n}$ is decreasing. Being bounded and monotonic, the sequence converges; let $x$ be its limit. Passing to the limit in the defining relation, we find that $x=x-x^{2}$, so $x=0$.

We now apply the Cesàro-Stolz theorem. We have

$$
\begin{aligned}
\lim _{n \rightarrow \infty} n x_{n} &=\lim _{n \rightarrow \infty} \frac{n}{\frac{1}{x_{n}}}=\lim _{n \rightarrow \infty} \frac{n+1-n}{\frac{1}{x_{n+1}}-\frac{1}{x_{n}}}=\lim _{n \rightarrow \infty} \frac{1}{\frac{1}{x_{n}-x_{n}^{2}}-\frac{1}{x_{n}}} \\
&=\lim _{n \rightarrow \infty} \frac{x_{n}-x_{n}^{2}}{1-\left(1-x_{n}\right)}=\lim _{n \rightarrow \infty}\left(1-x_{n}\right)=1
\end{aligned}
$$

and we are done.

343. It is not difficult to see that $\lim _{n \rightarrow \infty} x_{n}=0$. Because of this fact,

$$
\lim _{n \rightarrow \infty} \frac{x_{n}}{\sin x_{n}}=1 .
$$

If we are able to find the limit of

$$
\frac{n}{\frac{1}{\sin ^{2} x_{n}}},
$$

then this will equal the square of the limit under discussion. We use the Cesàro-Stolz theorem.

Suppose $0<x_{0} \leq 1$ (the cases $x_{0}<0$ and $x_{0}=0$ being trivial; see above). If $0<x_{n} \leq 1$, then $0<\arcsin \left(\sin ^{2} x_{n}\right)<\arcsin \left(\sin x_{n}\right)=x_{n}$, so $0<x_{n+1}<x_{n}$. It follows by induction on $n$ that $x_{n} \in(0,1]$ for all $n$ and $x_{n}$ decreases to 0 . Rewriting the recurrence as $\sin x_{n+1}=\sin x_{n} \sqrt{1-\sin ^{4} x_{n}}-\sin ^{2} x_{n} \cos x_{n}$ gives

$$
\begin{aligned}
\frac{1}{\sin x_{n+1}}-\frac{1}{\sin x_{n}} &=\frac{\sin x_{n}-\sin x_{n+1}}{\sin x_{n} \sin x_{n+1}} \\
&=\frac{\sin x_{n}-\sin x_{n} \sqrt{1-\sin ^{4} x_{n}}+\sin ^{2} x_{n} \cos x_{n}}{\sin x_{n}\left(\sin x_{n} \sqrt{1-\sin ^{4} x_{n}}-\sin ^{2} x_{n} \cos x_{n}\right)} \\
&=\frac{1-\sqrt{1-\sin ^{4} x_{n}}+\sin x_{n} \cos x_{n}}{\sin x_{n} \sqrt{1-\sin ^{4} x_{n}}-\sin ^{2} x_{n} \cos x_{n}} \\
&=\frac{\frac{\sin ^{4} x_{n}}{1+\sqrt{1-\sin ^{4} x_{n}}}+\sin x_{n} \cos x_{n}}{\sin x_{n} \sqrt{1-\sin ^{4} x_{n}}-\sin ^{2} x_{n} \cos x_{n}} \\
&=\frac{\frac{\sin ^{3} x_{n}}{1+\sqrt{1-\sin ^{4} x_{n}}}+\cos x_{n}}{\sqrt{1-\sin ^{4} x_{n}}-\sin x_{n} \cos x_{n}} .
\end{aligned}
$$

Hence

$$
\lim _{n \rightarrow \infty}\left(\frac{1}{\sin x_{n+1}}-\frac{1}{\sin x_{n}}\right)=1
$$

From the Cesàro-Stolz theorem it follows that $\lim _{n \rightarrow \infty} \frac{1}{n \sin x_{n}}=1$, and so we have $\lim _{n \rightarrow \infty} n x_{n}=1$.

(Gazeta Matematica (Mathematics Gazette, Bucharest), 2002, proposed by T. Andreescu)

344. We compute the square of the reciprocal of the limit, namely $\lim _{n \rightarrow \infty} \frac{1}{n x_{n}^{2}}$. To this end, we apply the Cesàro-Stolz theorem to the sequences $a_{n}=\frac{1}{x_{n}^{2}}$ and $b_{n}=n$. First, note that $\lim _{n \rightarrow \infty} x_{n}=0$. Indeed, in view of the inequality $0<\sin x<x$ on $(0, \pi)$, the sequence is bounded and decreasing, and the limit $L$ satisfies $L=\sin L$, so $L=0$. We then have

$$
\begin{aligned}
\lim _{n \rightarrow \infty}\left(\frac{1}{x_{n+1}^{2}}-\frac{1}{x_{n}^{2}}\right) &=\lim _{n \rightarrow \infty}\left(\frac{1}{\sin ^{2} x_{n}}-\frac{1}{x_{n}^{2}}\right)=\lim _{n \rightarrow \infty} \frac{x_{n}^{2}-\sin ^{2} x_{n}}{x_{n}^{2} \sin ^{2} x_{n}} \\
&=\lim _{x_{n} \rightarrow 0} \frac{x_{n}^{2}-\frac{1}{2}\left(1-\cos 2 x_{n}\right)}{\frac{1}{2} x_{n}^{2}\left(1-\cos 2 x_{n}\right)}=\lim _{x_{n} \rightarrow 0} \frac{2 x_{n}^{2}-\left[\frac{\left(2 x_{n}\right)^{2}}{2 !}-\frac{\left(2 x_{n}\right)^{4}}{4 !}+\cdots\right]}{x_{n}^{2}\left[\frac{\left(2 x_{n}\right)^{2}}{2 !}-\frac{\left(2 x_{n}\right)^{4}}{4 !}+\cdots\right]}
\end{aligned}
$$



$$
=\frac{2^{4} / 4 !}{2^{2} / 2 !}=\frac{1}{3} .
$$

We conclude that the original limit is $\sqrt{3}$.

(J. Dieudonné, Infinitesimal Calculus, Hermann, 1962, solution by Ch. Radoux)

345. Through a change of variable, we obtain

$$
b_{n}=\frac{\int_{0}^{n} f(t) d t}{n}=\frac{x_{n}}{y_{n}},
$$

where $x_{n}=\int_{0}^{n} f(t) d t$ and $y_{n}=n$. We are in the hypothesis of the Cesàro-Stolz theorem, since $\left(y_{n}\right)_{n}$ is increasing and unbounded and

$$
\frac{x_{n+1}-x_{n}}{y_{n+1}-y_{n}}=\frac{\int_{0}^{n+1} f(t) d t-\int_{0}^{n} f(t) d t}{(n+1)-n}=\int_{n}^{n+1} f(t) d t=\int_{0}^{1} f(n+x) d x=a_{n},
$$

which converges. It follows that the sequence $\left(b_{n}\right)_{n}$ converges; moreover, its limit is the same as that of $\left(a_{n}\right)_{n}$.

(proposed by T. Andreescu for the W.L. Putnam Mathematics Competition)

346. The solution is similar to that of problem 342. Because $P(x)>0$, for $x=$ $1,2, \ldots, n$, the geometric mean is well defined. We analyze the two sequences separately. First, let

$$
S_{n, k}=1+2^{k}+3^{k}+\cdots+n^{k} .
$$

Because

$$
\lim _{n \rightarrow \infty} \frac{S_{n+1, k}-S_{n, k}}{(n+1)^{k+1}-n^{k+1}}=\lim _{n \rightarrow \infty} \frac{(n+1)^{k}}{\left(\begin{array}{c}
k+1 \\
1
\end{array}\right) n^{k}+\left(\begin{array}{c}
k+1 \\
2
\end{array}\right) n^{k-1}+\cdots+1}=\frac{1}{k+1},
$$

by the Cesàro-Stolz theorem we have that

$$
\lim _{n \rightarrow \infty} \frac{S_{n, k}}{n^{k+1}}=\frac{1}{k+1} .
$$

Writing

$$
A_{n}=\frac{P(1)+P(2)+\cdots+P(n)}{n}=a_{m} \frac{S_{n, m}}{n}+a_{m-1} \frac{S_{n, m-1}}{n}+\cdots+a_{m},
$$

we obtain

$$
\lim _{n \rightarrow \infty} \frac{A_{n}}{n^{m}}=\frac{a_{m}}{m+1} .
$$

Now we turn to the geometric mean. Applying the Cesàro-Stolz theorem to the sequences

$$
u_{n}=\ln \frac{P(1)}{1^{m}}+\ln \frac{P(2)}{2^{m}}+\cdots+\ln \frac{P(n)}{n^{m}}
$$

and $v_{n}=n, n \geq 1$, we obtain

$$
\lim _{n \rightarrow \infty} \frac{u_{n}}{v_{n}}=\lim _{n \rightarrow \infty} \ln \frac{G_{n}}{(n !)^{m / n}}=\lim _{n \rightarrow \infty} \ln \frac{P(n)}{n^{m}}=\ln a_{m} .
$$

We therefore have

$$
\lim _{n \rightarrow \infty} \frac{A_{n}}{G_{n}} \cdot\left(\frac{\sqrt[n]{n !}}{n}\right)^{m}=\frac{1}{m+1} .
$$

Now we can simply invoke Stirling's formula

$$
n ! \approx n^{n} e^{-n} \sqrt{2 \pi n},
$$

or we can argue as follows. If we let $u_{n}=\frac{n !}{n^{n}}$, then the Cesàro-Stolz theorem applied to $\ln u_{n}$ and $v_{n}=n$ shows that if $\frac{u_{n+1}}{u_{n}}$ converges, then so does $\sqrt[n]{u_{n}}$, and to the same limit. Because

$$
\lim _{n \rightarrow \infty} \frac{u_{n+1}}{u_{n}}=\lim _{n \rightarrow \infty}\left(\frac{n}{n+1}\right)^{n}=\frac{1}{e},
$$

we have

$$
\lim _{n \rightarrow \infty} \frac{\sqrt[n]{n !}}{n}=\frac{1}{e}
$$

Therefore,

$$
\lim _{n \rightarrow \infty} \frac{A_{n}}{G_{n}}=\frac{e^{m}}{m+1} .
$$

(Gazeta Matematică (Mathematics Gazette, Bucharest), 1937, proposed by T. Popoviciu)

347. Clearly, $\left(a_{n}\right)_{n \geq 0}$ is an increasing sequence. Assume that $a_{n}$ is bounded. Then it must have a limit $L$. Taking the limit of both sides of the equation, we have

$$
\lim _{n \rightarrow \infty} a_{n+1}=\lim _{n \rightarrow \infty} a_{n}+\lim _{n \rightarrow \infty} \frac{1}{\sqrt[k]{a_{n}}},
$$

or $L=L+\frac{1}{\sqrt[k]{L}}$, contradiction. Thus $\lim _{n \rightarrow \infty} a_{n}=+\infty$ and dividing the equation by $a_{n}$, we get $\lim _{n \rightarrow \infty} \frac{a_{n+1}}{a_{n}}=1$. Let us write

$$
\lim _{n \rightarrow \infty} \frac{a_{n}^{k+1}}{n^{k}}=\left(\lim _{n \rightarrow \infty} \frac{a_{n}^{\frac{k+1}{k}}}{n}\right)^{k} .
$$

Using the Cesàro-Stolz theorem, we have

$$
\begin{aligned}
\lim _{n \rightarrow \infty} \frac{a_{n}^{\frac{k+1}{k}}}{n} &=\lim _{n \rightarrow \infty} \frac{a_{n+1}^{\frac{k+1}{k}}-a_{n}^{\frac{k+1}{k}}}{n+1-n}=\lim _{n \rightarrow \infty} \sqrt[k]{a_{n+1}^{k+1}}-\sqrt[k]{a_{n}^{k+1}} \\
&=\lim _{n \rightarrow \infty} \frac{a_{n+1}^{k+1}-a_{n}^{k+1}}{\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-1}+\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-2} \sqrt[k]{a_{n}^{k+1}}+\cdots+\left(\sqrt[k]{a_{n}^{k+1}}\right)^{k-1}} \\
&=\lim _{n \rightarrow \infty} \frac{\left(a_{n+1}-a_{n}\right)\left(a_{n+1}^{k}+a_{n+1}^{k-1} a_{n}+\cdots+a_{n}^{k}\right)}{\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-1}+\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-2} \sqrt[k]{a_{n}^{k+1}}+\cdots+\left(\sqrt[k]{a_{n}^{k+1}}\right)^{k-1}} \\
&=\lim _{n \rightarrow \infty} \frac{a_{n+1}^{k}+a_{n+1}^{k-1} a_{n}+\cdots+a_{n}^{k}}{\sqrt[k]{a_{n}}\left(\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-1}+\left(\sqrt[k]{a_{n+1}^{k+1}}\right)^{k-2} \sqrt[k]{a_{n}^{k+1}}+\cdots+\left(\sqrt[k]{a_{n}^{k+1}}\right)^{k-1}\right)} .
\end{aligned}
$$

Dividing both sides by $a_{n}^{k}$, we obtain

$$
\lim _{n \rightarrow \infty} \frac{a_{n}^{\frac{k+1}{k}}}{n}=\lim _{n \rightarrow \infty} \frac{\left(\frac{a_{n+1}}{a_{n}}\right)^{k}+\left(\frac{a_{n+1}}{a_{n}}\right)^{k-1}+\cdots+1}{\left(\frac{a_{n+1}}{a_{n}}\right)^{\frac{(k+1)(k-1)}{k}}+\left(\frac{a_{n+1}}{a_{n}}\right)^{\frac{(k+1)(k-2)}{k}}+\cdots+1} .
$$

Since $\lim _{n \rightarrow \infty} \frac{a_{n+1}}{a_{n}}=1$, we obtain

$$
\lim _{n \rightarrow \infty} \frac{a_{n}^{\frac{k+1}{k}}}{n}=\frac{k+1}{k} .
$$

Hence

$$
\lim _{n \rightarrow \infty} \frac{a_{n}^{k+1}}{n^{k}}=\left(1+\frac{1}{k}\right)^{k} .
$$

(67th W.L. Putnam Mathematical Competition, proposed by T. Andreescu; the special case $k=2$ was the object of the second part of a problem given at the regional round of the Romanian Mathematical Olympiad in 2004)

348. Assume no such $\xi$ exists. Then $f(a)>a$ and $f(b)<b$. Construct recursively the sequences $\left(a_{n}\right)_{n \geq 1}$ and $\left(b_{n}\right)_{n \geq 1}$ with $a_{1}=a, b_{1}=b$, and 

$$
a_{n+1}=a_{n} \quad \text { and } \quad b_{n+1}=\frac{a_{n}+b_{n}}{2} \quad \text { if } f\left(\frac{a_{n}+b_{n}}{2}\right)<\frac{a_{n}+b_{n}}{2},
$$

or

$$
a_{n+1}=\frac{a_{n}+b_{n}}{2} \quad \text { and } \quad b_{n+1}=b_{n} \quad \text { if } f\left(\frac{a_{n}+b_{n}}{2}\right)>\frac{a_{n}+b_{n}}{2} .
$$

Because $b_{n}-a_{n}=\frac{b-a}{2^{n}} \rightarrow 0$, the intersection of the nested sequence of intervals

$$
\left[a_{1}, b_{1}\right] \supset\left[a_{2}, b_{2}\right] \supset\left[a_{3}, b_{3}\right] \supset \cdots \supset\left[a_{n}, b_{n}\right] \supset \cdots
$$

consists of one point; call it $\xi$. Note that

$$
\xi=\lim _{n \rightarrow \infty} a_{n}=\lim _{n \rightarrow \infty} b_{n} .
$$

We have constructed the two sequences such that $a_{n}<f\left(a_{n}\right)<f\left(b_{n}\right)<b_{n}$ for all $n$, and the squeezing principle implies that $\left(f\left(a_{n}\right)\right)_{n}$ and $\left(f\left(b_{n}\right)\right)_{n}$ are convergent, and

$$
\lim _{n \rightarrow \infty} f\left(a_{n}\right)=\lim _{n \rightarrow \infty} f\left(b_{n}\right)=\xi .
$$

Now the monotonicity of $f$ comes into play. From $a_{n} \leq \xi \leq b_{n}$, we obtain $f\left(a_{n}\right) \leq$ $f(\xi) \leq f\left(b_{n}\right)$. Again, by the squeezing principle,

$$
f(\xi)=\lim _{n \rightarrow \infty} f\left(a_{n}\right)=\lim _{n \rightarrow \infty} f\left(b_{n}\right)=\xi .
$$

This contradicts our initial assumption, proving the existence of a point $\xi$ with the desired property.

Remark. This result is known as Knaster's theorem. Its most general form is the KnasterTarski theorem: Let $L$ be a complete lattice and let $f: L \rightarrow L$ be an order-preserving function. Then the set of fixed points of $f$ in $L$ is also a complete lattice, and in particular this set is nonempty.

349. Let $P_{1}(x)=x$ and $P_{n+1}(x)=P_{n}(x)\left(P_{n}(x)+\frac{1}{n}\right)$, for $n \geq 1$. Then $P_{n}(x)$ is a polynomial of degree $2^{n-1}$ with positive coefficients and $x_{n}=P_{n}\left(x_{1}\right)$. Because the inequality $x_{n+1}>x_{n}$ is equivalent to $x_{n}>1-\frac{1}{n}$, it suffices to show that there exists a unique positive real number $t$ such that $1-\frac{1}{n}<P_{n}(t)<1$ for all $n$. The polynomial function $P_{n}(x)$ is strictly increasing for $x \geq 0$, and $P_{n}(0)=0$, so there exist unique numbers $a_{n}$ and $b_{n}$ such that $P_{n}\left(a_{n}\right)=1-\frac{1}{n}$ and $P_{n}\left(b_{n}\right)=1$, respectively. We have that $a_{n}<a_{n+1}$, since $P_{n+1}\left(a_{n}\right)=1-\frac{1}{n}$ and $P_{n+1}^{n}\left(a_{n+1}\right)=1-\frac{1}{n+1}$. Similarly, $b_{n+1}<b_{n}$, since $P_{n+1}\left(b_{n+1}\right)=1$ and $P_{n+1}\left(b_{n}\right)=1+\frac{1}{n}$.

It follows by induction on $n$ that the polynomial function $P_{n}(x)$ is convex for $x \geq 0$, since 

$$
P_{n+1}^{\prime \prime}(x)=P_{n}^{\prime \prime}(x)\left(2 P_{n}(x)+\frac{1}{n}\right)+\left(P_{n}^{\prime}(x)\right)^{2}
$$

and $P_{n}(x) \geq 0$, for $x \geq 0$. Convexity implies

$$
P_{n}(x) \leq \frac{P_{n}\left(b_{n}\right)-P(0)}{b_{n}-0} x=\frac{x}{b_{n}}, \quad \text { for } 0 \leq x \leq b_{n}
$$

In particular, $1-\frac{1}{n}=P_{n}\left(a_{n}\right) \leq \frac{a_{n}}{b_{n}}$. Together with the fact that $b_{n} \leq 1$, this means that $b_{n}-a_{n} \leq \frac{1}{n}$. By Cantor's nested intervals theorem there exists a unique number $t$ such that $a_{n}<t<b_{n}$ for every $n$. This is the unique number satisfying $1-\frac{1}{n}<P_{n}(t)<1$ for all $n$. We conclude that $t$ is the unique number for which the sequence $x_{n}=P_{n}(t)$ satisfies $0<x_{n}<x_{n+1}<1$ for every $n$.

(26th International Mathematical Olympiad, 1985)

350. The answer to the question is yes. We claim that for any sequence of positive integers $n_{k}$, there exists a number $\gamma>1$ such that $\left(\left\lfloor\gamma^{k}\right\rfloor\right)_{k}$ and $\left(n_{k}\right)_{k}$ have infinitely many terms in common. We need the following lemma.

Lemma. For any $\alpha, \beta, 1<\alpha<\beta$, the set $\cup_{k=1}^{\infty}\left[\alpha^{k}, \beta^{k}-1\right]$ contains some interval of the form $(a, \infty)$

Proof. Observe that $(\beta / \alpha)^{k} \rightarrow \infty$ as $k \rightarrow \infty$. Hence for large $k, \alpha^{k+1}<\beta^{k}-1$, and the lemma follows.

Let us return to the problem and prove the claim. Fix the numbers $\alpha_{1}$ and $\beta_{1}$, $1<\alpha_{1}<\beta_{1}$. Using the lemma we can find some $k_{1}$ such that the interval $\left[\alpha_{1}^{k_{1}}, \beta_{1}^{k_{1}}-1\right]$ contains some terms of the sequence $\left(n_{k}\right)_{k}$. Choose one of these terms and call it $t_{1}$. Define

$$
\alpha_{2}=t_{1}^{1 / k_{1}}, \quad \beta_{2}=\left(t_{1}+\frac{1}{2}\right)^{1 / k_{1}}
$$

Then $\left[\alpha_{2}, \beta_{2}\right] \subset\left[\alpha_{1}, \beta_{1}\right]$, and for any $x \in\left[\alpha_{2}, \beta_{2}\right],\left\lfloor x^{k_{1}}\right\rfloor=t_{1}$. Again by the lemma, there exists $k_{2}$ such that $\left[\alpha_{2}^{k_{2}}, \beta_{2}^{k_{2}}-1\right]$ contains a term of $\left(n_{k}\right)_{k}$ different from $n_{1}$. Call this term $t_{2}$. Let

$$
\alpha_{3}=t_{2}^{1 / k_{2}}, \quad \beta_{3}=\left(t_{2}+\frac{1}{2}\right)^{1 / k_{2}}
$$

As before, $\left[\alpha_{3}, \beta_{3}\right] \subset\left[\alpha_{2}, \beta_{2}\right]$ and $\left\lfloor x^{k_{2}}\right\rfloor=t_{2}$ for any $x \in\left[\alpha_{3}, \beta_{3}\right]$. Repeat the construction infinitely many times. By Cantor's nested intervals theorem, the intersection of the decreasing sequence of intervals $\left[\alpha_{j}, \beta_{j}\right], j=1,2, \ldots$, is nonempty. Let $\gamma$ be an element of this intersection. Then $\left\lfloor\gamma^{k_{j}}\right\rfloor=t_{j}, j=1,2, \ldots$, which shows that the sequence $\left(\left\lfloor\gamma^{j}\right\rfloor\right)_{j}$ contains a subset of the sequence $\left(n_{k}\right)_{k}$. This proves the claim. To conclude the solution to the problem, assume that the sequence $\left(a_{n}\right)_{n}$ does not converge to 0 . Then it has some subsequence $\left(a_{n_{k}}\right)_{k}$ that approaches a nonzero (finite or infinite) limit as $n \rightarrow \infty$. But we saw above that this subsequence has infinitely many terms in common with a sequence that converges to zero, namely with some $\left(a_{\left\lfloor\gamma^{k}\right\rfloor}\right)_{k}$. This is a contradiction. Hence the sequence $\left(a_{n}\right)_{n}$ converges to 0 .

(Soviet Union University Student Mathematical Olympiad, 1975)

351. The solution follows closely that of the previous problem. Replacing $f$ by $|f|$ we may assume that $f \geq 0$. We argue by contradiction. Suppose that there exists $a>0$ such that the set

$$
A=f^{-1}((a, \infty))=\{x \in(0, \infty) \mid f(x)>a\}
$$

is unbounded. We want to show that there exists $x_{0} \in(0, \infty)$ such that the sequence $\left(n x_{0}\right)_{n \geq 1}$ has infinitely many terms in $A$. The idea is to construct a sequence of closed intervals $I_{1} \supset I_{2} \supset I_{3} \supset \cdots$ with lengths converging to zero and a sequence of positive integers $n_{1}<n_{2}<n_{3}<\cdots$ such that $n_{k} I_{k} \subset A$ for all $k \geq 1$.

Let $I_{1}$ be any closed interval in $A$ of length less than 1 and let $n_{1}=1$. Exactly as in the case of the previous problem, we can show that there exists a positive number $m_{1}$ such that $\cup_{m \geq m_{1}} m I_{1}$ is a half-line. Thus there exists $n_{2}>n_{1}$ such that $n_{2} I_{1}$ intersects A. Let $J_{2}$ be a closed interval of length less than 1 in this intersection. Let $I_{2}=\frac{1}{n_{2}} J_{2}$. Clearly, $I_{2} \subset I_{1}$, and the length of $I_{2}$ is less than $\frac{1}{n_{2}}$. Also, $n_{2} I_{2} \subset A$. Inductively, let $n_{k}>n_{k-1}$ be such that $n_{k} I_{k-1}$ intersects $A$, and let $J_{k}$ be a closed interval of length less than 1 in this intersection. Define $I_{k}=\frac{1}{n_{k}} J_{k}$.

We found the decreasing sequence of intervals $I_{1} \supset I_{2} \supset I_{3} \supset \cdots$ and positive integers $n_{1}<n_{2}<n_{3}<\cdots$ such that $n_{k} I_{k} \subset A$. Cantor's nested intervals theorem implies the existence of a number $x_{0}$ in the intersection of these intervals. The subsequence $\left(n_{k} x_{0}\right)_{k}$ lies in $A$, which means that $\left(n x_{0}\right)_{n}$ has infinitely many terms in $A$. This implies that the sequence $f\left(n x_{0}\right)$ does not converge to 0 , since it has a subsequence bounded away from zero. But this contradicts the hypothesis. Hence our assumption was false, and therefore $\lim _{x \rightarrow \infty} f(x)=0$.

Remark. This result is known as Croft's lemma. It has an elegant proof using the Baire category theorem.

352. Adding a few terms of the series, we can guess the identity

$$
\frac{1}{1+x}+\frac{2}{1+x^{2}}+\cdots+\frac{2^{n}}{1+x^{2^{n}}}=\frac{1}{x-1}+\frac{2^{n+1}}{1-x^{2^{n+1}}}, \quad n \geq 1 .
$$

And indeed, assuming that the formula holds for $n$, we obtain

$$
\frac{1}{1+x}+\frac{2}{1+x^{2}}+\cdots+\frac{2^{n}}{1+x^{2^{n}}}+\frac{2^{n+1}}{1+x^{2^{n+1}}}=\frac{1}{x-1}+\frac{2^{n+1}}{1-x^{2^{n+1}}}+\frac{2^{n+1}}{1+x^{2^{n+1}}}
$$



$$
=\frac{1}{x-1}+\frac{2^{n+2}}{1-x^{2^{n+2}}} .
$$

This completes the inductive proof.

Because

$$
\frac{1}{x-1}+\lim _{n \rightarrow \infty} \frac{2^{n+1}}{1-x^{2^{n+1}}}=\frac{1}{x-1}+\lim _{m \rightarrow \infty} \frac{m}{1-x^{m}}=\frac{1}{x-1},
$$

our series converges to $1 /(x-1)$.

(C. Năstăsescu, C. Niţă, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogică, Bucharest, 1983)

353. The series clearly converges for $x=1$. We will show that it does not converge for $x \neq 1$.

The trick is to divide through by $x-1$ and compare to the harmonic series. By the mean value theorem applied to $f(t)=t^{1 / n}$, for each $n$ there exists $c_{n}$ between $x$ and 1 such that

$$
\frac{\sqrt[n]{x}-1}{x-1}=\frac{1}{n} c^{\frac{1}{n}-1} .
$$

It follows that

$$
\frac{\sqrt[n]{x}-1}{x-1}>\frac{1}{n}(\max (1, x))^{\frac{1}{n}-1}>\frac{1}{n}(\max (1, x))^{-1} .
$$

Summing, we obtain

$$
\sum_{n=1}^{\infty} \frac{\sqrt[n]{x}-1}{x-1} \geq(\max (1, x))^{-1} \sum_{n=1}^{\infty} \frac{1}{n}=\infty,
$$

which proves that the series diverges.

(G.T. Gilbert, M.I. Krusemeyer, L.C. Larson, The Wohascum County Problem Book, MAA, 1996)

354. Using the AM-GM inequality we have

$$
\sum_{n=1}^{\infty} \sqrt{a_{n} a_{n+1}} \leq \sum_{n=1}^{\infty} \frac{a_{n}+a_{n+1}}{2}=\frac{1}{2} \sum_{n=1}^{\infty} a_{n}+\frac{1}{2} \sum_{n=2}^{\infty} a_{n}<\infty .
$$

Therefore, the series converges.

355. There are exactly $8 \cdot 9^{n-1} n$-digit numbers in $S$ (the first digit can be chosen in 8 ways, and all others in 9 ways). The least of these numbers is $10^{n}$. We can therefore write 

$$
\begin{aligned}
\sum_{x_{j}<10^{n}} \frac{1}{x_{j}} &=\sum_{i=1}^{n} \sum_{10^{i-1} \leq x_{j}<10^{i}} \frac{1}{x_{j}}<\sum_{i=1}^{n} \sum_{10^{i-1} \leq x_{j}<10^{i}} \frac{1}{10^{i-1}} \\
&=\sum_{i=1}^{n} \frac{8 \cdot 9^{i-1}}{10^{i-1}}=80\left(1-\left(\frac{9}{10}\right)^{n}\right)
\end{aligned}
$$

Letting $n \rightarrow \infty$, we obtain the desired inequality.

356. Define the sequence

$$
y_{n}=x_{n}+1+\frac{1}{2^{2}}+\cdots+\frac{1}{(n-1)^{2}}, \quad n \geq 2 .
$$

By the hypothesis, $\left(y_{n}\right)_{n}$ is a decreasing sequence; hence it has a limit. But

$$
1+\frac{1}{2^{2}}+\cdots+\frac{1}{(n-1)^{2}}+\cdots
$$

converges to a finite limit (which is $\frac{\pi^{2}}{6}$ as shown by Euler), and therefore

$$
x_{n}=y_{n}-1-\frac{1}{2^{2}}-\cdots-\frac{1}{(n-1)^{2}}, \quad n \geq 2,
$$

has a limit.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

357. We have

$$
\sin \pi \sqrt{n^{2}+1}=(-1)^{n} \sin \pi\left(\sqrt{n^{2}+1}-n\right)=(-1)^{n} \sin \frac{\pi}{\sqrt{n^{2}+1}+n} .
$$

Clearly, the sequence $x_{n}=\frac{\pi}{\sqrt{n^{2}+1}+n}$ lies entirely in the interval $\left(0, \frac{\pi}{2}\right)$, is decreasing, and converges to zero. It follows that $\sin x_{n}$ is positive, decreasing, and converges to zero. By Riemann's convergence criterion, $\sum_{k \geq 1}(-1)^{n} \sin x_{n}$, which is the series in question, is convergent.

(Gh. Sireţchi, Calcul Diferential sुi Integral (Differential and Integral Calculus), Editura Ştiinţifică şi Enciclopedică, 1985)

358. (a) We claim that the answer to the first question is yes. We construct the sequences $\left(a_{n}\right)_{n}$ and $\left(b_{n}\right)_{n}$ inductively, in a way inspired by the proof that the harmonic series diverges. At step 1 , let $a_{1}=1, b_{1}=\frac{1}{2}$. Then at step 2 , let $a_{2}=a_{3}=\frac{1}{8}$ and $b_{2}=b_{3}=\frac{1}{2}$. In general, at step $k$ we already know $a_{1}, a_{2}, \ldots, a_{n_{k}}$ and $b_{1}, b_{2}, \ldots, b_{n_{k}}$ for some integer $n_{k}$. We want to define the next terms. If $k$ is even, and if

$$
b_{n_{k}}=\frac{1}{2^{r_{k}}},
$$

let

$$
b_{n_{k}+1}=\cdots=b_{n_{k}+2^{r_{k}}}=\frac{1}{2^{r_{k}}}
$$

and

$$
a_{n_{k}+1}=\cdots=a_{n_{k}+2^{r_{k}}}=\frac{1}{2^{k} \cdot 2^{r_{k}}} .
$$

If $k$ is odd, we do precisely the same thing, with the roles of the sequences $\left(a_{n}\right)_{n}$ and $\left(b_{n}\right)_{n}$ exchanged. As such we have

$$
\begin{aligned}
\sum_{n} b_{n} & \geq \sum_{k \text { odd }} 2^{r_{k}} \frac{1}{2^{r_{k}}}=1+1+\cdots=\infty, \\
\sum_{n} a_{n} & \geq \sum_{k \text { even }} 2^{r_{k}} \frac{1}{2^{r_{k}}}=1+1+\cdots=\infty,
\end{aligned}
$$

which shows that both series diverge. On the other hand, if we let $c_{n}=\min \left(a_{n}, b_{n}\right)$, then

$$
\sum_{n} c_{n}=\sum_{k} 2^{r_{k}} \frac{1}{2^{k} 2^{r_{k}}}=\sum_{k} \frac{1}{2^{k}},
$$

which converges to 1 . The example proves our claim.

(b) The answer to the second question is no, meaning that the situation changes if we work with the harmonic series. Suppose there is a series $\sum_{n} a_{n}$ with the given property. If $c_{n}=\frac{1}{n}$ for only finitely many $n$ 's, then for large $n, a_{n}=c_{n}$, meaning that both series diverge. Hence $c_{n}=\frac{1}{n}$ for infinitely many $n$. Let $\left(k_{m}\right)_{m}$ be a sequence of integers satisfying $k_{m+1} \geq 2 k_{m}$ and $c_{k_{m}}=\frac{1}{k_{m}}$. Then

$$
\sum_{k=k_{m}+1}^{k_{m+1}} c_{k} \geq\left(k_{m+1}-k_{m}\right) c_{k_{m+1}}=\left(k_{m+1}-k_{m}\right) \frac{1}{k_{m+1}}=\frac{1}{2} .
$$

This shows that the series $\sum_{n} c_{n}$ diverges, a contradiction.

(short list of the 44th International Mathematical Olympiad, 2003)

359. For $n \geq 1$, define the function $f_{n}:(0,1) \rightarrow \mathbb{R}, f_{n}(x)=x-n x^{2}$. It is easy to see that $0<f_{n}(x) \leq \frac{1}{4 n}$, for all $x \in(0,1)$. Moreover, on $\left(0, \frac{1}{2 n}\right]$ the function is decreasing. With this in mind, we prove by induction that

$$
0<x_{n}<\frac{2}{n^{2}},
$$

for $n \geq 2$. We verify the first three cases: 

$$
\begin{aligned}
&0=f_{1}(0)<x_{2}=f_{1}\left(x_{1}\right)=x_{1}-x_{1}^{2} \leq \frac{1}{4}<\frac{2}{4}, \\
&0=f_{2}(0)<x_{3}=f_{2}\left(x_{2}\right)=x_{2}-2 x_{2}^{2} \leq \frac{1}{8}<\frac{2}{9}, \\
&0=f_{3}(0)<x_{4}=f_{3}\left(x_{3}\right)=x_{3}-3 x_{3}^{2} \leq \frac{1}{12}<\frac{2}{16} .
\end{aligned}
$$

Here we used the inequality $x_{1}-x_{1}^{2}-\frac{1}{4}=-\left(x_{1}-\frac{1}{2}\right)^{2} \leq 0$ and the like. Now assume that the inequality is true for $n \geq 4$ and prove it for $n+1$. Since $n \geq$, we have $x_{n} \leq \frac{2}{n^{2}} \leq \frac{1}{2 n}$. Therefore,

$$
0=f_{n}(0)<x_{n+1}=f_{n}\left(x_{n}\right) \leq f_{n}\left(\frac{2}{n^{2}}\right)=\frac{2}{n^{2}}-n \cdot \frac{4}{n^{4}}=\frac{2 n-4}{n^{3}} .
$$

It is an easy exercise to check that

$$
\frac{2 n-4}{n^{3}}<\frac{2}{(n+1)^{2}},
$$

which then completes the induction.

We conclude that the series $\sum_{n} x_{n}$ has positive terms and is bounded from above by the convergent $p$-series $2 \sum_{n} \frac{1}{n^{2}}$, so it is itself convergent.

(Gazeta Matematic $\breve{a}$ (Mathematics Gazette, Bucharest), 1980, proposed by L. Panaitopol)

360. The series is convergent because it is bounded from above by the geometric series with ratio $\frac{1}{2}$. Assume that its sum is a rational number $\frac{a}{b}$. Choose $n$ such that $b<2^{n}$. Then

$$
\frac{a}{b}-\sum_{k=1}^{n} \frac{1}{2^{k^{2}}}=\sum_{k \geq n+1} \frac{1}{2^{k^{2}}} .
$$

But the sum $\sum_{k=1}^{n} \frac{1}{2^{k^{2}}}$ is equal to $\frac{m}{2^{n^{2}}}$ for some integer $n$. Hence

$$
\frac{a}{b}-\sum_{k=1}^{n} \frac{1}{2^{k^{2}}}=\frac{a}{b}-\frac{m}{2^{n^{2}}}>\frac{1}{2^{n^{2}} b}>\frac{1}{2^{n^{2}+n}}>\frac{1}{2^{(n+1)^{2}-1}}=\sum_{k \geq(n+1)^{2}} \frac{1}{2^{k}}>\sum_{k \geq n+1} \frac{1}{2^{k^{2}}},
$$

a contradiction. This shows that the sum of the series is an irrational number.

Remark. In fact, this number is transcendental.

361. The series is bounded from above by the geometric series $\left|a_{0}\right|\left(1+|z|+|z|^{2}+\cdots\right)$, so it converges absolutely. Using the discrete version of integration by parts, known as the Abel summation formula, we can write 

$$
\begin{aligned}
&a_{0}+a_{1} z+a_{2} z^{2}+\cdots+a_{n} z^{n}+\cdots \\
&\quad=\left(a_{0}-a_{1}\right)+\left(a_{1}-a_{2}\right)(1+z)+\cdots+\left(a_{n}-a_{n+1}\right)\left(1+z+\cdots+z^{n}\right)+\cdots
\end{aligned}
$$

Assume that this is equal to zero. Multiplying by $1-z$, we obtain

$$
\left(a_{0}-a_{1}\right)(1-z)+\left(a_{1}-a_{2}\right)\left(1-z^{2}\right)+\cdots+\left(a_{n}-a_{n+1}\right)\left(1-z^{n+1}\right)+\cdots=0
$$

Define the sequence $b_{n}=a_{n}-a_{n+1}, n \geq 0$. It is positive and $\sum_{n} b_{n}=a_{0}$. Because $|z|<1$, the series $\sum_{n} b_{n} z^{n}$ converges absolutely. This allows us in the above inequality to split the left-hand side into two series and move one to the right to obtain

$$
b_{0}+b_{1}+\cdots+b_{n}+\cdots=b_{0} z+b_{1} z^{2}+\cdots+b_{n} z^{n+1}+\cdots
$$

Applying the triangle inequality to the expression on the right gives

$$
\begin{aligned}
\left|b_{0} z+b_{1} z^{2}+\cdots+b_{n} z^{n+1}\right| & \leq b_{0}|z|+b_{1}\left|z^{2}\right|+\cdots+b_{n}\left|z^{n}\right|+\cdots \\
&<b_{0}+b_{1}+\cdots+b_{n}+\cdots,
\end{aligned}
$$

which implies that equality cannot hold. We conclude that the sum of the series is not equal to zero.

362. If such a sequence exists, then the numbers

$$
\frac{1}{p_{0} p_{1}}-\frac{1}{p_{0} p_{1} p_{2}}+\frac{1}{p_{0} p_{1} p_{2} p_{3}}-\cdots \quad \text { and } \quad \frac{1}{p_{0} p_{1} p_{2}}-\frac{1}{p_{0} p_{1} p_{2} p_{3}}+\cdots
$$

should both be positive. It follows that

$$
0<\frac{1}{p_{0}}-w=\frac{1}{p_{0} p_{1}}-\frac{1}{p_{0} p_{1} p_{2}}+\frac{1}{p_{0} p_{1} p_{2} p_{3}}-\cdots<\frac{1}{p_{0} p_{1}}<\frac{1}{p_{0}\left(p_{0}+1\right)}
$$

Hence $p_{0}$ has to be the unique integer with the property that

$$
\frac{1}{p_{0}+1}<w<\frac{1}{p_{0}}
$$

This integer satisfies the double inequality

$$
p_{0}<\frac{1}{w}<p_{0}+1
$$

which is equivalent to $0<1-p_{0} w<w$.

Let $w_{1}=1-p_{0} w$. Then

$$
w=\frac{1}{p_{0}}-\frac{w_{1}}{p_{0}} .
$$

The problem now repeats for $w_{1}$, which is irrational and between 0 and 1 . Again $p_{1}$ has to be the unique integer with the property that

$$
\frac{1}{p_{1}+1}<1-p_{0} w<\frac{1}{p_{1}} .
$$

If we set $w_{2}=1-p_{1} w_{1}$, then

$$
w=\frac{1}{p_{0}}-\frac{1}{p_{0} p_{1}}+\frac{w_{2}}{p_{0} p_{1}} .
$$

Now the inductive pattern is clear. At each step we set $w_{k+1}=1-p_{k} w_{k}$, which is an irrational number between 0 and 1 . Then choose $p_{k+1}$ such that

$$
\frac{1}{p_{k+1}+1}<w_{k+1}<\frac{1}{p_{k+1}} .
$$

Note that

$$
w_{k+1}=1-p_{k} w_{k}<1-p_{k} \frac{1}{p_{k}+1}=\frac{1}{p_{k}+1},
$$

and therefore $p_{k+1} \geq p_{k}+1>p_{k}$.

Once the numbers $p_{0}, p_{1}, p_{2}, \ldots$ have been constructed, it is important to observe that since $w_{k} \in(0,1)$ and $p_{0} p_{1} \cdots p_{k} \geq(k+1) !$, the sequence

$$
\frac{1}{p_{0}}-\frac{1}{p_{0} p_{1}}+\cdots+(-1)^{k+1} \frac{w_{k+1}}{p_{1} p_{2} \cdots p_{k}}
$$

converges to $w$. So $p_{0}, p_{1}, \ldots, p_{k}, \ldots$ have the required properties, and as seen above, they are unique.

(13th W.L. Putnam Mathematical Competition, 1953)

363. First, denote by $M$ the set of positive integers greater than 1 that are not perfect powers (i.e., are not of the form $a^{n}$, where $a$ is a positive integer and $n \geq 2$ ). Note that the terms of the series are positive, so we can freely permute them. The series is therefore equal to

$$
\sum_{m \in M} \sum_{k=2}^{\infty} \frac{1}{m^{k}-1} .
$$

Expanding each term as a geometric series, we transform this into 

$$
\sum_{m \in M} \sum_{k=2}^{\infty} \sum_{j=1}^{\infty} \frac{1}{m^{k j}}=\sum_{m \in M} \sum_{j=1}^{\infty} \sum_{k=2}^{\infty} \frac{1}{m^{k j}}
$$

Again, we can change the order of summation because the terms are positive. The innermost series should be summed as a geometric series to give

$$
\sum_{m \in M} \sum_{j=1}^{\infty} \frac{1}{m^{j}\left(m^{j}-1\right)}
$$

This is the same as

$$
\sum_{n=2}^{\infty} \frac{1}{n(n-1)}=\sum_{n=2}^{\infty}\left(\frac{1}{n-1}-\frac{1}{n}\right)=1
$$

as desired.

(Ch. Goldbach, solution from G.M. Fihtenholts, Kurs Differentsial' novo i Integral'novo Ischisleniya (Course in Differential and Integral Calculus), Gosudarstvennoe Izdatel'stvo Fiziko-Matematicheskoi Literatury, Moscow 1964)

364. Let us make the convention that the letter $p$ always denotes a prime number. Consider the set $A(n)$ consisting of those positive integers that can be factored into primes that do not exceed $n$. Then

$$
\prod_{p \leq n}\left(1+\frac{1}{p}+\frac{1}{p^{2}}+\cdots\right)=\sum_{m \in A(n)} \frac{1}{m}
$$

This sum includes $\sum_{m=1}^{n} \frac{1}{m}$, which is known to exceed $\ln n$. Thus, after summing the geometric series, we obtain

$$
\prod_{p \leq n}\left(1-\frac{1}{p}\right)^{-1}>\ln n
$$

For the factors of the product we use the estimate

$$
e^{t+t^{2}} \geq(1-t)^{-1}, \quad \text { for } 0 \leq t \leq \frac{1}{2}
$$

To prove this estimate, rewrite it as $f(t) \geq 1$, where $f(t)=(1-t) e^{t+t^{2}}$. Because $f^{\prime}(t)=t(1-2 t) e^{t+t^{2}} \geq 0$ on $\left[0, \frac{1}{2}\right], f$ is increasing; thus $f(t) \geq f(0)=1$.

Returning to the problem, we have

$$
\prod_{p \leq n} \exp \left(\frac{1}{p}+\frac{1}{p^{2}}\right) \geq \prod_{p \leq n}\left(1-\frac{1}{p}\right)^{-1}>\ln n
$$

Therefore,

$$
\sum_{p \leq n} \frac{1}{p}+\sum_{p \leq n} \frac{1}{p^{2}}>\ln \ln n .
$$

But

$$
\sum_{p \leq n} \frac{1}{p^{2}}<\sum_{n=2}^{\infty} \frac{1}{k^{2}}=\frac{\pi^{2}}{6}-1<1 .
$$

Hence

$$
\sum_{p \leq n} \frac{1}{p} \geq \ln \ln n-1,
$$

as desired.

(proof from I. Niven, H.S. Zuckerman, H.L. Montgomery, An Introduction to the Theory of Numbers, Wiley, 1991)

365. We have

$$
\begin{aligned}
\left(k^{2}+1\right) k ! &=\left(k^{2}+k-k+1\right) k !=k(k+1) k !-(k-1) k ! \\
&=k(k+1) !-(k-1) k !=a_{k+1}-a_{k},
\end{aligned}
$$

where $a_{k}=(k-1) k !$. The sum collapses to $a_{n+1}-a_{1}=n(n+1) !$ !.

366. If $\zeta$ is an $m$ th root of unity, then all terms of the series starting with the $m$ th are zero. We are left to prove that

$$
\zeta^{-1}=\sum_{n=0}^{m-1} \zeta^{n}(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right) .
$$

Multiplying both sides by $\zeta$ yields the equivalent identity

$$
1=\sum_{n=0}^{m-1} \zeta^{n+1}(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right) .
$$

The sum telescopes as follows:

$$
\begin{aligned}
&\sum_{n=0}^{m-1} \zeta^{n+1}(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right) \\
&=\sum_{n=0}^{m-1}\left(1-\left(1-\zeta^{n+1}\right)\right)(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right)
\end{aligned}
$$



$$
\begin{aligned}
&=\sum_{n=0}^{m-1}\left[(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n}\right)-(1-\zeta)\left(1-\zeta^{2}\right) \cdots\left(1-\zeta^{n+1}\right)\right] \\
&=1-0=1,
\end{aligned}
$$

and the identity is proved.

367. We have

$$
\begin{aligned}
1+\sum_{k=0}^{r-1}\left(\begin{array}{l}
r \\
k
\end{array}\right) S_{k}(n) &=1+\sum_{k=0}^{r-1}\left(\begin{array}{l}
r \\
k
\end{array}\right) \sum_{p=1}^{n} p^{k}=1+\sum_{p=1}^{n} \sum_{k=0}^{r-1}\left(\begin{array}{l}
r \\
k
\end{array}\right) p^{k} \\
&=1+\sum_{p=1}^{n}\left[(p+1)^{r}-p^{r}\right]=(n+1)^{r} .
\end{aligned}
$$

368. Set $b_{n}=\sqrt{2 n-1}$ and observe that $4 n=b_{n+1}^{2}+b_{n}^{2}$. Then

$$
\begin{aligned}
a_{n} &=\frac{b_{n+1}^{2}+b_{n}^{2}+b_{n+1} b_{n}}{b_{n+1}+b_{n}}=\frac{\left(b_{n+1}-b_{n}\right)\left(b_{n+1}^{2}+b_{n+1} b_{n}+b_{n-1}^{2}\right)}{\left(b_{n+1}-b_{n}\right)\left(b_{n+1}+b_{n}\right)} \\
&=\frac{b_{n+1}^{3}-b_{n}^{3}}{b_{n+1}^{2}-b_{n}^{2}}=\frac{1}{2}\left(b_{n+1}^{3}-b_{n}^{3}\right) .
\end{aligned}
$$

So the sum under discussion telescopes as

$$
\begin{aligned}
a_{1}+a_{2}+\cdots+a_{40} &=\frac{1}{2}\left(b_{2}^{3}-b_{1}^{3}\right)+\frac{1}{2}\left(b_{3}^{3}-b_{2}^{3}\right)+\cdots+\frac{1}{2}\left(b_{41}^{3}-b_{40}^{3}\right) \\
&=\frac{1}{2}\left(b_{41}^{3}-b_{1}^{3}\right)=\frac{1}{2}\left(\sqrt{81^{3}}-1\right)=364,
\end{aligned}
$$

and we are done.

(Romanian Team Selection Test for the Junior Balkan Mathematical Olympiad, proposed by T. Andreescu)

369. The important observation is that

$$
\frac{(-1)^{k+1}}{1^{2}-2^{2}+3^{2}-\cdots+(-1)^{k+1} k^{2}}=\frac{2}{k(k+1)} .
$$

Indeed, this is true for $k=1$, and inductively, assuming it to be true for $k=l$, we obtain

$$
1^{2}-2^{2}+3^{2}-\cdots+(-1)^{l+1} l^{2}=(-1)^{l+1} \frac{l(l+1)}{2} .
$$

Then 

$$
\begin{aligned}
1^{2}-2^{2}+3^{2}-\cdots+(-1)^{l+2}(l+1)^{2} &=(-1)^{l+1} \frac{l(l+1)}{2}+(-1)^{l+2}(l+1)^{2} \\
&=(-1)^{l+2}(l+1)\left(-\frac{l}{2}+l+1\right),
\end{aligned}
$$

whence

$$
\frac{(-1)^{l+2}}{1^{2}-2^{2}+3^{3}-\cdots+(-1)^{l+2}(l+1)^{2}}=\frac{2}{(l+1)(l+2)},
$$

as desired. Hence the given sum equals

$$
\sum_{k=1}^{n} \frac{2}{k(k+1)}=2 \sum_{k=1}^{n}\left(\frac{1}{k}-\frac{1}{k+1}\right),
$$

telescoping to

$$
2\left(1-\frac{1}{n+1}\right)=\frac{2 n}{n+1} .
$$

\section{(T. Andreescu)}

370. The sum telescopes once we rewrite the general term as

$$
\begin{aligned}
\frac{1}{(\sqrt{n}+\sqrt{n+1})(\sqrt[4]{n}+\sqrt[4]{n+1})} &=\frac{\sqrt[4]{n+1}-\sqrt[4]{n}}{(\sqrt{n+1}+\sqrt{n})(\sqrt[4]{n+1}+\sqrt[4]{n})(\sqrt[4]{n+1}-\sqrt[4]{n})} \\
&=\frac{\sqrt[4]{n+1}-\sqrt[4]{n}}{(\sqrt{n+1}+\sqrt{n})(\sqrt{n+1}-\sqrt{n})} \\
&=\frac{\sqrt[4]{n+1}-\sqrt[4]{n}}{n+1-n}=\sqrt[4]{n+1}-\sqrt[4]{n} .
\end{aligned}
$$

The sum from the statement is therefore equal to $\sqrt[4]{10000}-1=10-1=9$.

(Mathematical Reflections, proposed by T. Andreescu)

371. As usual, the difficulty lies in finding the "antiderivative" of the general term. We have

$$
\begin{aligned}
\frac{1}{\sqrt{1+\left(1+\frac{1}{n}\right)^{2}}+\sqrt{1+\left(1-\frac{1}{n}\right)^{2}}} &=\frac{\sqrt{1+\left(1+\frac{1}{n}\right)^{2}}-\sqrt{1+\left(1-\frac{1}{n}\right)^{2}}}{1+\left(1+\frac{1}{n}\right)^{2}-1-\left(1-\frac{1}{n}\right)^{2}} \\
&=\frac{\sqrt{1+\left(1+\frac{1}{n}\right)^{2}}-\sqrt{1+\left(1-\frac{1}{n}\right)^{2}}}{\frac{4}{n}}
\end{aligned}
$$



$$
\begin{aligned}
&=\frac{1}{4}\left(\sqrt{n^{2}+(n+1)^{2}}-\sqrt{n^{2}+(n-1)^{2}}\right) \\
&=\frac{1}{4}\left(b_{n+1}-b_{n}\right)
\end{aligned}
$$

where $b_{n}=\sqrt{n^{2}+(n-1)^{2}}$. Hence the given sum collapses to $\frac{1}{4}(29-1)=7$.

(Mathematical Reflections, proposed by T. Andreescu)

372. Let us look at the summation over $n$ first. Multiplying each term by $(m+n+2)-$ $(n+1)$ and dividing by $m+1$, we obtain

$$
\frac{m !}{m+1} \sum_{n=0}^{\infty}\left(\frac{n !}{(m+n+1) !}-\frac{(n+1) !}{(m+n+2) !}\right)
$$

This is a telescopic sum that adds up to

$$
\frac{m !}{m+1} \cdot \frac{0 !}{(m+1) !} .
$$

Consequently, the expression we are computing is equal to

$$
\sum_{m=0}^{\infty} \frac{1}{(m+1)^{2}}=\frac{\pi^{2}}{6} .
$$

(Mathematical Mayhem, 1995)

373. This problem is similar to the last example from the introduction. We start with

$$
\begin{aligned}
a_{k}-b_{k} &=\frac{1}{2}\left[4 k+(k+1)+(k-1)-4 \sqrt{k^{2}+k}+4 \sqrt{k^{2}-k}+2 \sqrt{k^{2}-1}\right] \\
&=\frac{1}{2}(2 \sqrt{k}-\sqrt{k+1}-\sqrt{k-1})^{2} .
\end{aligned}
$$

From here we obtain

$$
\begin{aligned}
\sqrt{a_{k}-b_{k}} &=\frac{1}{\sqrt{2}}(2 \sqrt{k}-\sqrt{k+1}-\sqrt{k-1}) \\
&=-\frac{1}{\sqrt{2}}(\sqrt{k+1}-\sqrt{k})+\frac{1}{\sqrt{2}}(\sqrt{k}-\sqrt{k+1})
\end{aligned}
$$

The sum from the statement telescopes to

$$
-\frac{1}{\sqrt{2}}(\sqrt{50}-\sqrt{1})+\frac{1}{\sqrt{2}}(\sqrt{49}-\sqrt{0})=-5+4 \sqrt{2} .
$$

(Romanian Mathematical Olympiad, 2004, proposed by T. Andreescu) 

374. First solution: Let $S_{n}=\sum_{k=0}^{n}(-1)^{k}(n-k) !(n+k)$ !. Reordering the terms of the sum, we have

$$
\begin{aligned}
S_{n} &=(-1)^{n} \sum_{k=0}^{n}(-1)^{k} k !(2 n-k) ! \\
&=(-1)^{n} \frac{1}{2}\left((-1)^{n} n ! n !+\sum_{k=0}^{2 n}(-1)^{k} k !(2 n-k) !\right) \\
&=\frac{(n !)^{2}}{2}+(-1)^{n} \frac{T_{n}}{2},
\end{aligned}
$$

where $T_{n}=\sum_{k=0}^{2 n}(-1)^{k} k !(2 n-k)$ !. We now focus on the sum $T_{n}$. Observe that

$$
\frac{T_{n}}{(2 n) !}=\sum_{k=0}^{2 n} \frac{(-1)^{k}}{\left(\begin{array}{c}
2 n \\
k
\end{array}\right)}
$$

and

$$
\frac{1}{\left(\begin{array}{c}
2 n \\
k
\end{array}\right)}=\frac{2 n+1}{2(n+1)}\left[\frac{1}{\left(\begin{array}{c}
2 n+1 \\
k
\end{array}\right)}+\frac{1}{\left(\begin{array}{c}
2 n+1 \\
k+1
\end{array}\right)}\right] .
$$

Hence

$$
\frac{T_{n}}{(2 n) !}=\frac{2 n+1}{2(n+1)}\left[\frac{1}{\left(\begin{array}{c}
2 n+1 \\
0
\end{array}\right)}+\frac{1}{\left(\begin{array}{c}
2 n+1 \\
1
\end{array}\right)}-\frac{1}{\left(\begin{array}{c}
2 n+1 \\
1
\end{array}\right)}-\frac{1}{\left(\begin{array}{c}
2 n+1 \\
2
\end{array}\right)}+\cdots+\frac{1}{\left(\begin{array}{c}
2 n+1 \\
2 n
\end{array}\right)}+\frac{1}{\left(\begin{array}{c}
2 n+1 \\
2 n+1
\end{array}\right)}\right] .
$$

This sum telescopes to

$$
\frac{2 n+1}{2(n+1)}\left[\frac{1}{\left(\begin{array}{c}
2 n+1 \\
0
\end{array}\right)}+\frac{1}{\left(\begin{array}{c}
2 n+1 \\
2 n+1
\end{array}\right)}\right]=\frac{2 n+1}{n+1} .
$$

Thus $T_{n}=\frac{(2 n+1) !}{n+1}$, and therefore

$$
S_{n}=\frac{(n !)^{2}}{2}+(-1)^{n} \frac{(2 n+1) !}{2(n+1)} .
$$

Second solution: Multiply the $k$ th term in $S_{n}$ by $(n-k+1)+(n+k+1)$ and divide by $2(n+1)$ to obtain

$$
S_{n}=\frac{1}{2(n+1)} \sum_{k=0}^{n}\left[(-1)^{k}(n-k+1) !(n+k) !+(-1)^{k}(n-k) !(n+k+1) !\right] .
$$

This telescopes to

$$
\frac{1}{2(n+1)}\left[n !(n+1) !+(-1)^{n}(2 n+1) !\right] .
$$

(T. Andreescu, second solution by R. Stong)

375. The sequence is obviously strictly decreasing. Because $a_{k}-a_{k+1}=1-\frac{1}{a_{k}+1}$, we have

$$
\begin{aligned}
a_{n} &=a_{0}+\left(a_{1}-a_{0}\right)+\cdots+\left(a_{n}-a_{n-1}\right)=1994-n+\frac{1}{a_{0}+1}+\cdots+\frac{1}{a_{n-1}+1} \\
&>1994-n .
\end{aligned}
$$

Also, because the sequence is strictly decreasing, for $1 \leq n \leq 998$,

$$
\frac{1}{a_{0}+1}+\cdots+\frac{1}{a_{n-1}+1}<\frac{n}{a_{n-1}+1}<\frac{998}{a_{997}+1}<1,
$$

since we have seen above that $a_{997}>1994-997=997$. Hence $\left\lfloor a_{n}\right\rfloor=1994-n$, as desired.

(short list of the 35th International Mathematical Olympiad, 1994, proposed by T. Andreescu)

376. Let $x_{1}=k+\sqrt{k^{2}+1}$ and $x_{2}=k-\sqrt{k^{2}+1}$. We have $\left|x_{2}\right|=\frac{1}{x_{1}}<\frac{1}{2 k} \leq \frac{1}{2}$, so $-\left(\frac{1}{2}\right)^{2} \leq x_{2}^{n} \leq\left(\frac{1}{2}\right)^{n}$. Hence

$$
x_{1}^{n}+x_{2}^{n}-1<x_{1}^{n}+\left(\frac{1}{2}\right)^{n}-1<a_{n} \leq x_{1}^{n}-\left(\frac{1}{2}\right)^{n}+1<x_{1}^{n}+x_{2}^{n}+1,
$$

for all $n \geq 1$. From

$$
\begin{aligned}
x_{1}^{n+1}+x_{2}^{n+1} &=\left(x_{1}+x_{2}\right)\left(x_{1}^{n}+x_{2}^{n}\right)-x_{1} x_{2}\left(x_{1}^{n-1}+x_{2}^{n-1}\right) \\
&=2 k\left(x_{1}^{n}+x_{2}^{n}\right)+\left(x_{1}^{n-1}+x_{2}^{n-1}\right)
\end{aligned}
$$

for $n \geq 1$, we deduce that $x_{1}^{n}+x_{2}^{n}$ is an integer for all $n$. We obtain the more explicit formula $a_{n}=x_{1}^{n}+x_{2}^{n}$ for $n \geq 0$, and consequently the recurrence relation $a_{n+1}=$ $2 k a_{n}+a_{n-1}$, for all $n \geq 1$. Then

$$
\frac{1}{a_{n-1} a_{n+1}}=\frac{1}{2 k a_{n}} \cdot \frac{2 k a_{n}}{a_{n-1} a_{n+1}}=\frac{1}{2 k} \cdot \frac{a_{n+1}-a_{n-1}}{a_{n-1} a_{n} a_{n+1}}=\frac{1}{2 k}\left(\frac{1}{a_{n-1} a_{n}}-\frac{1}{a_{n} a_{n+1}}\right) .
$$

It follows that

$$
\sum_{n=1}^{\infty} \frac{1}{a_{n-1} a_{n+1}}=\frac{1}{2 k}\left(\frac{1}{a_{0} a_{1}}-\lim _{N \rightarrow \infty} \frac{1}{a_{N} a_{N+1}}\right)=\frac{1}{2 k a_{0} a_{1}}=\frac{1}{8 k^{2}} .
$$

377. For $N \geq 2$, define

$$
a_{N}=\left(1-\frac{4}{1}\right)\left(1-\frac{4}{9}\right)\left(1-\frac{4}{25}\right) \cdots\left(1-\frac{4}{(2 N-1)^{2}}\right) .
$$

The problem asks us to find $\lim _{N \rightarrow \infty} a_{N}$. The defining product for $a_{N}$ telescopes as follows:

$$
\begin{aligned}
a_{N} &=\left[\left(1-\frac{2}{1}\right)\left(1+\frac{2}{1}\right)\right]\left[\left(1-\frac{2}{3}\right)\left(1+\frac{2}{3}\right)\right] \cdots\left[\left(1-\frac{2}{2 N-1}\right)\left(1+\frac{2}{2 N-1}\right)\right] \\
&=(-1 \cdot 3)\left(\frac{1}{3} \cdot \frac{5}{3}\right)\left(\frac{3}{5} \cdot \frac{7}{5}\right) \cdots\left(\frac{2 N-3}{2 N-1} \cdot \frac{2 N+1}{2 N-1}\right)=-\frac{2 N+1}{2 N-1} .
\end{aligned}
$$

Hence the infinite product is equal to

$$
\lim _{N \rightarrow \infty} a_{N}=-\lim _{N \rightarrow \infty} \frac{2 N+1}{2 N-1}=-1 .
$$

378. Define the sequence $\left(a_{N}\right)_{N}$ by

$$
a_{N}=\prod_{n=1}^{N}\left(1+x^{2^{n}}\right) .
$$

Note that $(1-x) a_{N}$ telescopes as

$$
\begin{aligned}
(1-x) &(1+x)\left(1+x^{2}\right)\left(1+x^{4}\right) \cdots\left(1+x^{2^{N}}\right) \\
=&\left(1-x^{2}\right)\left(1+x^{2}\right)\left(1+x^{4}\right) \cdots\left(1+x^{2^{N}}\right) \\
=&\left(1-x^{4}\right)\left(1+x^{4}\right) \cdots\left(1+x^{2^{N}}\right) \\
=& \cdots=\left(1-x^{2^{N+1}}\right) .
\end{aligned}
$$

Hence $(1-x) a_{N} \rightarrow 1$ as $N \rightarrow \infty$, and therefore

$$
\prod_{n \geq 0}\left(1+x^{2^{n}}\right)=\frac{1}{1-x} .
$$

379. Let $P_{N}=\prod_{n=1}^{N}\left(1-\frac{x^{n}}{x_{n+1}}\right), N \geq 1$. We want to examine the behavior of $P_{N}$ as $N \rightarrow \infty$. Using the recurrence relation we find that this product telescopes as

$$
P_{N}=\prod_{n=1}^{N}\left(\frac{x_{n+1}-x^{n}}{x_{n+1}}\right)=\prod_{n=1}^{N} \frac{n x_{n}}{x_{n+1}}=\frac{N !}{x_{N+1}} .
$$

Hence

$$
\frac{1}{P_{n+1}}-\frac{1}{P_{n}}=\frac{x_{n+2}}{(n+1) !}-\frac{x_{n+1}}{n !}=\frac{x_{n+2}-(n+1) x_{n+1}}{(n+1) !}=\frac{x^{n+1}}{(n+1) !}, \quad \text { for } n \geq 1
$$

Adding up these relations for $1 \leq n \leq N+1$, and using the fact that the sum on the left telescopes, we obtain

$$
\begin{aligned}
\frac{1}{P_{N+1}} &=\frac{1}{P_{1}}+\frac{x^{2}}{2 !}+\frac{x^{3}}{3 !}+\cdots+\frac{x^{N+1}}{(N+1) !} \\
&=1+\frac{x}{1 !}+\frac{x^{2}}{2 !}+\cdots+\frac{x^{N+1}}{(N+1) !}
\end{aligned}
$$

Because this last expression converges to $e^{x}$, we obtain that $\lim _{N \rightarrow \infty} P_{N}=e^{-x}$, as desired.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu and D. Andrica)

380. We are supposed to find $m$ and $n$ such that

$$
\lim _{x \rightarrow \infty} \sqrt[3]{8 x^{3}+m x^{2}}-n x=1 \quad \text { or } \quad \lim _{x \rightarrow-\infty} \sqrt[3]{8 x^{3}+m x}-n x=1 .
$$

We compute

$$
\sqrt[3]{8 x^{3}+m x^{2}}-n x=\frac{\left(8-n^{3}\right) x^{3}+m x^{2}}{\sqrt[3]{\left(8 x^{3}+m x^{2}\right)^{2}}+n x \sqrt[3]{8 x^{3}+m x^{2}}+n^{2} x^{2}} .
$$

For this to have a finite limit at either $+\infty$ or $-\infty, 8-n^{3}$ must be equal to 0 (otherwise the highest degree of $x$ in the numerator would be greater than the highest degree of $x$ in the denominator). We have thus found that $n=2$.

Next, factor out and cancel an $x^{2}$ to obtain

$$
f(x)=\frac{m}{\sqrt[3]{\left(8+\frac{m}{x}\right)^{2}}+2 \sqrt[3]{8+\frac{m}{x}}+4} .
$$

We see that $\lim _{x \rightarrow \infty} f(x)=\frac{m}{12}$. For this to be equal to $1, m$ must be equal to 12 . Hence the answer to the problem is $(m, n)=(12,2)$.

381. This is a limit of the form $1^{\infty}$. It can be computed as follows:

$$
\begin{aligned}
\lim _{x \rightarrow \pi / 2}(\sin x)^{\frac{1}{\cos x}} &=\lim _{x \rightarrow \pi / 2}(1+\sin x-1)^{\frac{1}{\sin x-1} \cdot \frac{\sin x-1}{\cos x}} \\
&=\left(\lim _{t \rightarrow 0}(1+t)^{1 / t}\right)^{\lim _{x \rightarrow \pi / 2} \frac{\sin x-1}{\cos x}}=\exp \left(\lim _{u \rightarrow 0} \frac{\cos u-1}{\sin u}\right)
\end{aligned}
$$



$$
=\exp \left(\frac{\cos u-1}{u} \cdot \frac{u}{\sin u}\right)=e^{0.1}=e^{0}=1 .
$$

The limit therefore exists.

382. Without loss of generality, we may assume that $m>n$. Write the limit as

$$
\lim _{x \rightarrow 0} \frac{\sqrt[m n]{\cos ^{n} x}-\sqrt[m n]{\cos ^{m} x}}{x^{2}} .
$$

Now we can multiply by the conjugate and obtain

$$
\begin{aligned}
\lim _{x \rightarrow 0} & \frac{\cos ^{n} x-\cos ^{m} x}{x^{2}\left(\sqrt[m n]{\left(\cos ^{n} x\right)^{m n-1}}+\cdots+\sqrt[m n]{\left(\cos ^{m} x\right)^{m n-1}}\right)} \\
&=\lim _{x \rightarrow 0} \frac{\cos ^{n} x\left(1-\cos ^{m-n} x\right)}{m n x^{2}}=\lim _{x \rightarrow 0} \frac{1-\cos ^{m-n} x}{m n x^{2}} \\
&=\lim _{x \rightarrow 0} \frac{(1-\cos x)\left(1+\cos x+\cdots+\cos ^{m-n-1} x\right)}{m n x^{2}} \\
&=\frac{m-n}{m n} \lim _{x \rightarrow 0} \frac{1-\cos x}{x^{2}}=\frac{m-n}{2 m n} .
\end{aligned}
$$

We are done.

383. For $x>1$ define the sequence $\left(x_{n}\right)_{n \geq 0}$ by $x_{0}=x$ and $x_{n+1}=\frac{x_{n}^{2}+1}{2}, n \geq 0$. The sequence is increasing because of the AM-GM inequality. Hence it has a limit $L$, finite or infinite. Passing to the limit in the recurrence relation, we obtain $L=\frac{L^{2}+1}{2}$; hence either $L=1$ or $L=\infty$. Since the sequence is increasing, $L \geq x_{0}>1$, so $L=\infty$. We therefore have

$$
f(x)=f\left(x_{0}\right)=f\left(x_{1}\right)=f\left(x_{2}\right)=\cdots=\lim _{n \rightarrow \infty} f\left(x_{n}\right)=\lim _{x \rightarrow \infty} f(x) .
$$

This implies that $f$ is constant, which is ruled out by the hypothesis. So the answer to the question is negative.

384. We can assume that $m>1$; otherwise, we can flip the fraction and change $t$ to $\frac{1}{m} t$. There is an integer $n$ such that $m<2^{n}$. Because $f$ is increasing, $f(t)<f(m t)<f\left(2^{n} t\right)$. We obtain

$$
1<\frac{f(m t)}{f(t)}<\frac{f\left(2^{n} t\right)}{f(t)} .
$$

The right-hand side is equal to the telescopic product

$$
\frac{f\left(2^{n} t\right)}{f\left(2^{n-1} t\right)} \cdot \frac{f\left(2^{n-1} t\right)}{f\left(2^{n-2} t\right)} \cdots \frac{f(2 t)}{f(t)},
$$

whose limit as $t$ goes to infinity is 1 . The squeezing principle implies that

$$
\lim _{t \rightarrow \infty} \frac{f(m t)}{f(t)}=1,
$$

as desired.

\section{(V. Radu)}

385. The sum under discussion is the derivative of $f$ at 0 . We have

$$
\begin{aligned}
\left|\sum_{k=1}^{n} k a_{k}\right| &=\left|f^{\prime}(0)\right|=\lim _{x \rightarrow 0}\left|\frac{f(x)-f(0)}{x-0}\right| \\
&=\lim _{x \rightarrow 0}\left|\frac{f(x)}{x}\right|=\lim _{x \rightarrow 0}\left|\frac{f(x)}{\sin x}\right| \cdot\left|\frac{\sin x}{x}\right| \leq 1 .
\end{aligned}
$$

The inequality is proved.

(28th W.L. Putnam Mathematics Competition, 1967)

386. The condition from the statement implies that $f(x)=f(-x)$, so it suffices to check that $f$ is constant on $[0, \infty)$. For $x \geq 0$, define the recursive sequence $\left(x_{n}\right)_{\geq 0}$, by $x_{0}=x$, and $x_{n+1}=\sqrt{x_{n}}$, for $n \geq 0$. Then

$$
f\left(x_{0}\right)=f\left(x_{1}\right)=f\left(x_{2}\right)=\cdots=f\left(\lim _{n \rightarrow \infty} x_{n}\right) .
$$

And $\lim _{n \rightarrow \infty} x_{n}=1$ if $x>0$. It follows that $f$ is constant and the problem is solved.

387. The answer is yes, there is a tooth function with this property. We construct $f$ to have local maxima at $\frac{1}{2^{2 n+1}}$ and local minima at 0 and $\frac{1}{2^{2 n}}, n \geq 0$. The values of the function at the extrema are chosen to be $f(0)=f(1)=0, f\left(\frac{1}{2}\right)=\frac{1}{2}$, and $f\left(\frac{1}{2^{2 n+1}}\right)=\frac{1}{2^{n}}$ and $f\left(\frac{1}{2^{2 n}}\right)=\frac{1}{2^{n+1}}$ for $n \geq 1$. These are connected through segments. The graph from Figure 66 convinces the reader that $f$ has the desired properties. dapest $)$ )

(Kozépiskolai Matematikai Lapok (Mathematics Gazette for High Schools, Bu-

388. We prove by induction on $n$ that $f\left(\frac{m}{3^{n}}\right)=0$ for all integers $n \geq 0$ and all integers $0 \leq m \leq 3^{n}$. The given conditions show that this is true for $n=0$. Assuming that it is true for $n-1 \geq 0$, we prove it for $n$.

If $m \equiv 0(\bmod 3)$, then

$$
f\left(\frac{m}{3^{n}}\right)=f\left(\frac{\frac{m}{3}}{3^{n-1}}\right)=0
$$

by the induction hypothesis.

If $m \equiv 1(\bmod 3)$, then $1 \leq m \leq 3^{n}-2$ and 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-517.jpg?height=449&width=657&top_left_y=243&top_left_x=539)

Figure 66

$$
3 f\left(\frac{m}{3^{n}}\right)=2 f\left(\frac{\frac{m-1}{3}}{3^{n-1}}\right)+f\left(\frac{\frac{m+2}{3}}{3^{n-1}}\right)=0+0=0
$$

Thus $f\left(\frac{m}{3^{n}}\right)=0$.

Finally, if $m \equiv 2(\bmod 3)$, then $2 \leq m \leq 3^{n}-1$ and

$$
3 f\left(\frac{m}{3^{n}}\right)=2 f\left(\frac{\frac{m+1}{3}}{3^{n-1}}\right)+f\left(\frac{\frac{m-2}{3}}{3^{n-1}}\right)=0+0=0 .
$$

Hence $f\left(\frac{m}{3^{n}}\right)=0$ in this case, too, finishing our induction.

Because the set $\left\{\frac{m}{3^{n}} ; m, n \in \mathbb{N}\right\}$ is dense in $[0,1]$ and $f$ is equal to zero on this set, $f$ is identically equal to zero.

(Vietnamese Mathematical Olympiad, 1999)

389. We argue by contradiction. Assume that there exist $a<b$ such that $f(a) \neq f(b)$, say, $f(a)>f(b)$.

Let $g: \mathbb{R} \rightarrow \mathbb{R}, g(x)=f(x)+\lambda x$, where $\lambda>0$ is chosen very small such that $g(a)>g(b)$. We note that

$$
\lim _{h \rightarrow 0^{+}} \frac{g(x+2 h)-g(x+h)}{h}=\lambda>0, \quad \text { for all } x \in \mathbb{R}
$$

Since $g$ is a continuous function on a closed and bounded interval, $g$ has a maximum. Let $c \in[a, b]$ be the point where $g$ attains its maximum. It is important that this point is not $b$, since $g(a)>g(b)$. Fix $0<\epsilon<\lambda$. Then there exists $\delta=\delta(\epsilon)>0$ such that

$$
0<\lambda-\epsilon<\frac{g(c+2 h)-g(c+h)}{h}<\lambda+\epsilon, \quad \text { for all } 0<h<\delta .
$$

Fix $0<h_{0}<\min \left\{\delta, \frac{b-c}{2}\right\}$. The above inequality written for $h=h_{0}, \frac{h_{0}}{2}, \frac{h_{0}}{4}$, etc., yields 

$$
g\left(c+2 h_{0}\right)>g\left(c+h_{0}\right)>g\left(c+\frac{h_{0}}{2}\right)>\cdots>g\left(c+\frac{h_{0}}{2^{n}}\right)>\cdots .
$$

Passing to the limit, we obtain that $g(c+2 h)>g(c)$, contradicting the maximality of c. The contradiction proves that our initial assumption was false, and the conclusion follows.

390. From the given condition, it follows that $f$ is one-to-one. Indeed, if $f(x)=f(y)$, then $f(f(x))=f(f(y))$, so $b x=b y$, which implies $x=y$. Because $f$ is continuous and one-to-one, it is strictly monotonic.

We will show that $f$ has a fixed point. Assume by way of contradiction that this is not the case. So either $f(x)>x$ for all $x$, or $f(x)<x$ for all $x$. In the first case $f$ must be strictly increasing, and then we have the chain of implications

$$
f(x)>x \Rightarrow f(f(x))>f(x) \Rightarrow a f(x)+b x>f(x) \Rightarrow f(x)<\frac{b x}{1-a},
$$

for all $x \in \mathbb{R}$. In particular, $f(1)<\frac{b}{1-a}<1$, contradicting our assumption.

In the second case the simultaneous inequalities $f(x)<x$ and $f(f(x))<f(x)$ show that $f$ must be strictly increasing again. Again we have a chain of implications

$$
f(x)<x \Rightarrow f(f(x))<f(x) \Rightarrow f(x)>a f(x)+b x \Rightarrow f(x)>\frac{b x}{1-a},
$$

for all $x \in \mathbb{R}$. In particular, $f(-1)>-\frac{b}{1-a}>-1$, again a contradiction.

In conclusion, there exists a real number $c$ such that $f(c)=c$. The condition $f(f(c))=a f(c)+b c$ implies $c=a c+b c$; thus $c(a+b-1)=0$. It follows that $c=0$, and we obtain $f(0)=0$.

Remark. This argument can be simplified if we use the fact that a decreasing monotonic function on $\mathbb{R}$ always has a unique fixed point. (Prove it!)

(45th W.L. Putnam Mathematical Competition, 2002, proposed by T. Andreescu)

391. Being continuous on the closed interval $[0,1]$, the function $f$ is bounded and has a maximum and a minimum. Let $M$ be the maximum and $m$ the minimum. Then $\frac{m}{2^{n}} \leq \frac{f\left(x^{n}\right)}{2^{n}} \leq \frac{M}{2^{n}}$, which implies that the series is absolutely convergent and its limit is a number in the interval $[m, M]$.

Let $a \in(0,1)$ and $m_{a}$ and $M_{a}$ be the minimum and the maximum of $f$ on $[0, a]$. If $\alpha \in[0, a]$ is such that $f(\alpha)=M_{a}$, then

$$
M_{a}=f(\alpha)=\sum_{n=1}^{\infty} \frac{f\left(\alpha^{n}\right)}{2^{n}} \leq M_{a} \sum_{n=1}^{\infty} \frac{1}{2^{n}}=M_{a},
$$

whence we must have equality in the above inequality, so $f\left(\alpha^{n}\right)=M_{a}$. Since $\lim _{n \rightarrow \infty} \alpha^{n}=0$, it follows that $M_{a}$ must equal $\lim _{x \rightarrow 0} f(x)=f(0)$. Similarly, $m_{a}=f(0)$, and hence $f$ is constant on $[0, a]$. Passing to the limit with $a \rightarrow 1$, we conclude that $f$ is constant on the interval $[0,1]$. Clearly, constant functions satisfy the property, providing all solutions to the problem.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by M. Bălună)

392. Let $\phi:[0,1] \times[0,1]$ be a continuous surjection. Define $\psi$ to be the composition

$$
[0,1] \stackrel{\phi}{\longrightarrow}[0,1] \times[0,1] \stackrel{\phi \times i d}{\longrightarrow}[0,1] \times[0,1] \times[0,1] \stackrel{p r_{12}}{\longrightarrow}[0,1] \times[0,1],
$$

where $p r_{12}:[0,1] \times[0,1] \times[0,1] \rightarrow[0,1] \times[0,1]$ is the projection of the cube onto the bottom face. Each function in the above chain is continuous and surjective, so the composition is continuous and surjective. Moreover, because the projection takes each value infinitely many times, so does $\psi$. Therefore, $\psi$ provides the desired example.

393. The first example of such a function was given by Weierstrass. The example we present here, of a function $f:[0,1] \rightarrow[0,1]$, was published by S. Marcus in the Mathematics Gazette, Bucharest.

If $0 \leq x \leq 1$ and $x=0 . a_{1} a_{2} a_{3} \ldots$ is the ternary expansion of $x$, we let the binary representation of $f(x)$ be $0 . b_{1} b_{2} b_{3} \ldots$, where the binary digits $b_{1}, b_{2}, b_{3}, \ldots$ are uniquely determined by the conditions

(i) $b_{1}=1$ if and only if $a_{1}=1$,

(ii) $b_{n+1}=b_{n}$ if and only if $a_{n+1}=a_{n}, n \geq 1$.

It is not hard to see that $f(x)$ does not depend on which ternary representation you choose for $x$. For example,

$$
f(0.0222 \ldots)=0.0111 \cdots=0.1000 \cdots=f(0.1000 \ldots) .
$$

Let us prove first that the function is continuous. If $x$ is a number that has a unique ternary expansion and $\left(x_{n}\right)_{n}$ is a sequence converging to $x$, then the first $m$ digits of $x_{n}$ become equal to the first $m$ digits of $x$ for $n$ sufficiently large. It follows from the definition of $f$ that the first $m$ binary digits of $f\left(x_{n}\right)$ become equal to the first $m$ binary digits of $f(x)$ for $n$ sufficiently large. Hence $f\left(x_{n}\right)$ converges to $f(x)$, so $f$ is continuous at $x$.

If $x$ is a number that has two possible ternary expansions, then in one expansion $x$ has only finitely many nonzero digits $x=0 . a_{1} a_{2} \ldots a_{k} 00 \ldots$, with $a_{k} \neq 0$. The other expansion is $0 . a_{1} a_{2} \ldots a_{k}^{\prime} 222 \ldots$, with $a_{k}^{\prime}=a_{k}-1(=0$ or 1 ). Given a sequence $\left(x_{n}\right)_{n}$ that converges to $x$, for sufficiently large $n$ the first $k-1$ digits of $x_{n}$ are equal to $a_{1}, a_{2}, \ldots, a_{k-1}$, while the next $m-k+1$ are either $a_{k}, 0,0, \ldots, 0$, or $a_{k}^{\prime}, 2,2, \ldots, 2$. If $f(x)=f\left(0 . a_{1} a_{2} \ldots a_{k} 00 \ldots\right)=0 . b_{1} b_{2} b_{3} \ldots$, then for $n$ sufficiently large, the first $k-1$ digits of $f\left(x_{n}\right)$ are $b_{1}, b_{2}, \ldots, b_{k-1}$, while the next $m-k+1$ are either $b_{k}, b_{k+1}=$ $b_{k+2}=\cdots=b_{m}$ (the digits of $\left.f(x)\right)$ or $1-b_{k}, 1-b_{k+1}=\cdots=1-b_{m}$. The two possible binary numbers are $0 . b_{1} b_{2} \ldots b_{k-1} 0111 \ldots$ and $0 . b_{1} b_{2} \ldots b_{k-1} 1000 \ldots$; they differ from $f(x)$ by at most $\frac{1}{2^{m+1}}$. We conclude again that as $n \rightarrow \infty, f\left(x_{n}\right) \rightarrow f(x)$. This proves the continuity of $f$.

Let us show next that $f$ does not have a finite derivative from the left at any point $x \in(0,1]$. For such $x$ consider the ternary expansion $x=0 . a_{1} a_{2} a_{3} \ldots$ that has infinitely many nozero digits, and, applying the definition of $f$ for this expansion, let $f(x)=$ $0 . b_{1} b_{2} b_{3} \ldots$. Now consider an arbitrary positive number $n$, and let $k_{n} \geq n$ be such that $a_{k_{n}} \neq 0$. Construct a number $x^{\prime} \in(0,1)$ whose first $k_{n}-1$ digits are the same as those of $x$, whose $k_{n}$ th digit is zero, and all of whose other digits are equal to 0 if $b_{k_{n}+1}=1$ and to 1 if $b_{k_{n}+1}=0$. Then

$$
0<x-x^{\prime}<2 \cdot 3^{-k_{n}}+0 . \underbrace{00 \ldots 0}_{k_{n}} 22 \ldots, 0=3^{-k_{n}+1},
$$

while in the first case,

$$
\left|f(x)-f\left(x^{\prime}\right)\right| \geq 0 . \underbrace{00 \ldots 0}_{k_{n}} b_{k_{n}+1}=0 . \underbrace{00 \ldots 0}_{k_{n}} 1,
$$

and in the second case,

$$
\left|f(x)-f\left(x^{\prime}\right)\right| \geq 0 . \underbrace{00 \ldots 0}_{k_{n}} 11 \ldots 1-0 . \underbrace{00 \ldots 0}_{k_{n}} 0 b_{k_{n}+2 \ldots,}
$$

and these are both greater than or equal to $2^{-k_{n}-1}$. Since $k_{n} \geq n$, we have $0<x-x^{\prime}<$ $3^{-n+1}$ and

$$
\left|\frac{f(x)-f\left(x^{\prime}\right)}{x-x^{\prime}}\right|>\frac{2^{-k_{n}-1}}{3^{-k_{n}+1}}=\frac{1}{6}\left(\frac{3}{2}\right)^{k_{n}} \geq \frac{1}{6}\left(\frac{3}{2}\right)^{n} .
$$

Letting $n \rightarrow \infty$, we obtain

$$
x^{\prime} \rightarrow x, \quad \text { while }\left|\frac{f(x)-f\left(x^{\prime}\right)}{x-x^{\prime}}\right| \rightarrow \infty .
$$

This proves that $f$ does not have a derivative on the left at $x$. The argument that $f$ does not have a derivative on the right at $x$ is similar and is left to the reader.

Remark. S. Banach has shown that in some sense, there are far more continuous functions that are not differentiable at any point than continuous functions that are differentiable at least at some point.

394. We apply the intermediate value property to the function $g:[a, b] \rightarrow[a, b]$, $g(x)=f(x)-x$. Because $f(a) \geq a$ and $f(b) \leq b$, it follows that $g(a) \leq 0$ and $g(b) \geq 0$. Hence there is $c \in[a, b]$ such that $g(c)=0$. This $c$ is a fixed point of $f$. 

395. Let $L$ be the length of the trail and $T$ the total duration of the climb, which is the same as the total duration of the descent. Counting the time from the beginning of the voyage, denote by $f(t)$ and $g(t)$ the distances from the monk to the temple at time $t$ on the first and second day, respectively. The functions $f$ and $g$ are continuous; hence so is $\phi:[0, T] \rightarrow \mathbb{R}, \phi(t)=f(t)-g(t)$. It follows that $\phi$ has the intermediate value property. Because $\phi(0)=f(0)-g(0)=L-0=L>0$ and $\phi(T)=f(T)-g(T)=0-L<0$, there is a time $t_{0}$ with $\phi\left(t_{0}\right)=0$. At $t=t_{0}$ the monk reached the same spot on both days. 

396. The fact that $f$ is decreasing implies immediately that

$$
\lim _{x \rightarrow-\infty}(f(x)-x)=\infty \text { and } \lim _{x \rightarrow \infty}(f(x)-x)=-\infty .
$$

By the intermediate value property, there is $x_{0}$ such that $f\left(x_{0}\right)-x_{0}=0$, that is, $f\left(x_{0}\right)=$ $x_{0}$. The function cannot have another fixed point because if $x$ and $y$ are fixed points, with $x<y$, then $x=f(x) \geq f(y)=y$, impossible.

The triple $\left(x_{0}, x_{0}, x_{0}\right)$ is a solution to the system. And if $(x, y, z)$ is a solution then $f(f(f(x)))=x$. The function $f \circ f \circ f$ is also continuous and decreasing, so it has a unique fixed point. And this fixed point can only be $x_{0}$. Therefore, $x=y=z=x_{0}$, proving that the solution is unique.

397. The inequality from the statement implies right away that $f$ is injective, and also that $f$ transforms unbounded intervals into unbounded intervals. The sets $f((-\infty, 0])$ and $f([0, \infty))$ are unbounded intervals that intersect at one point. They must be two intervals that cover the entire real axis.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

398. Let $x$ denote the distance along the course, measured in miles from the starting line. For each $x \in[0,5]$, let $f(x)$ denote the time that elapses for the mile from the point $x$ to the point $x+1$. Note that $f$ depends continuously on $x$. We are given that

$$
f(0)+f(1)+f(2)+f(3)+f(4)+f(5)=30 .
$$

It follows that not all of $f(0), f(1), \ldots, f(5)$ are smaller than 5 , and not all of them are larger than 5 . Choose $a, b \in\{0,1, \ldots, 5\}$ such that $f(a) \leq 5 \leq f(b)$. By the intermediate value property, there exists $c$ between $a$ and $b$ such that $f(c)=5$. The mile between $c$ and $c+1$ was run in exactly 5 minutes.

(L.C. Larson, Problem-Solving Through Problems, Springer-Verlag, 1990)

399. Without loss of generality, we may assume that the cars traveled on one day from $A$ to $B$ keeping a distance of at most one mile between them, and on the next day they traveled in opposite directions in the same time interval, which we assume to be of length one unit of time.

Since the first car travels in both days on the same road and in the same direction, it defines two parametrizations of that road. Composing the motions of both cars during the second day of travel with a homeomorphism (continuous bijection) of the time interval $[0,1]$, we can ensure that the motion of the first car yields the same parametrization of the road on both days. Let $f(t)$ be the distance from the second car to $A$ when the first is at $t$ on the first day, and $g(t)$ the distance from the second car to $A$ when the first is at $t$ on the second day. These two functions are continuous, so their difference is also continuous. But $f(0)-g(0)=-\operatorname{dist}(A, B)$, and $f(1)-g(1)=\operatorname{dist}(A, B)$, where $\operatorname{dist}(A, B)$ is the distance between the cities.

The intermediate value property implies that there is a moment $t$ for which $f(t)-$ $g(t)=0$. At that moment the two cars are in the same position as they were the day before, so they are at distance at most one mile. Hence the answer to the problem is no. 

400. We compute

$$
\begin{aligned}
\sum_{j=0}^{n} P\left(2^{j}\right) &=\sum_{j=0}^{n} \sum_{k=0}^{n} a_{k} 2^{k j}=\sum_{k=0}^{n}\left(\sum_{j=0}^{n} 2^{k j}\right) a_{k} \\
&=\sum_{k=0}^{n} \frac{2^{k(n+1)}-1}{2^{k}-1}=Q\left(2^{n+1}\right)-Q(1)=0 .
\end{aligned}
$$

It follows that $P(1)+P(2)+\cdots+P\left(2^{n}\right)=0$. If $P\left(2^{k}\right)=0$ for some $k<n$, we are done. Otherwise, there exist $1 \leq i, j \leq n$ such that $P\left(2^{i}\right) P\left(2^{j}\right)<0$, and by the intermediate value property, $P(x)$ must have a zero between $2^{i}$ and $2^{j}$.

(proposed for the USA Mathematical Olympiad by R. Gelca)

401. Consider the lines fixed, namely the $x$-and the $y$-axes, and vary the position of the surface in the plane. Rotate the surface by an angle $\phi$, then translate it in such a way that the $x$-axis divides it into two regions of equal area. The coordinate axes divide it now into four regions of areas $A, B, C, D$, counted counterclockwise starting with the first quadrant. Further translate it such that $A=B$. The configuration is now uniquely determined by the angle $\phi$. It is not hard to see that $A=A(\phi), B=B(\phi), C=C(\phi)$, and $D=D(\phi)$ are continuous functions of $\phi$.

If $C\left(0^{\circ}\right)=D\left(0^{\circ}\right)$, then the equality of the areas of the regions above and below the $x$-axis implies $A\left(0^{\circ}\right)=B\left(0^{\circ}\right)=C\left(0^{\circ}\right)=D\left(0^{\circ}\right)$, and we are done.

If $C\left(0^{\circ}\right)>D\left(0^{\circ}\right)$, then the line that divides the region below the $x$-axis into two polygons of equal area lies to the left of the $y$-axis (see Figure 67). This means that after a $180^{\circ}$-rotation the line that determines the regions $A\left(180^{\circ}\right)$ and $B\left(180^{\circ}\right)$ will divide the other region into $C\left(180^{\circ}\right)$ and $D\left(180^{\circ}\right)$ in such a way that $C\left(180^{\circ}\right)<D\left(180^{\circ}\right)$. Similarly, if $C\left(0^{\circ}\right)<D\left(0^{\circ}\right)$, then $C\left(180^{\circ}\right)>D\left(180^{\circ}\right)$.

It follows that the continuous function $C(\phi)-D(\phi)$ assumes both positive and negative values on the interval $\left[0^{\circ}, 180^{\circ}\right]$, so by the intermediate value property there is an angle $\phi_{0}$ for which $C\left(\phi_{0}\right)=D\left(\phi_{0}\right)$. Consequently, $A\left(\phi_{0}\right)=B\left(\phi_{0}\right)=C\left(\phi_{0}\right)=D\left(\phi_{0}\right)$, and the problem is solved. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-523.jpg?height=411&width=640&top_left_y=264&top_left_x=552)

Figure 67

Remark. This result is known as the "pancake theorem."

402. Assume that $f$ is not continuous at some point $a$. Then there exists $\epsilon>0$ and a sequence $x_{n} \rightarrow a$ such that $\left|f\left(x_{n}\right)-f(a)\right|>\epsilon$ for all $n \geq 1$. Without loss of generality, we may assume that there is a subsequence $\left(x_{n_{k}}\right)_{k}$ such that $f\left(x_{n_{k}}\right)<f(a)$, for all $k$, in which case $f\left(x_{n_{k}}\right) \leq f(a)-\epsilon$. Choose $\gamma$ in the interval $(f(a)-\epsilon, f(a))$. Since $f$ has the intermediate value property, and $f\left(x_{n_{k}}\right)<\gamma<f(a)$, for each $k$ there exists $y_{k}$ between $x_{n_{k}}$ and $a$ such that $f\left(y_{k}\right)=\gamma$. The set $f^{-1}(\gamma)$ contains the sequence $\left(y_{k}\right)_{k}$, but does not contain its limit $a$, which contradicts the fact that the set is closed. This contradiction proves that the initial assumption was false; hence $f$ is continuous on the interval $I$.

\section{(A.M. Gleason)}

403. The function is continuous off 0 , so it maps any interval that does not contain 0 onto an interval. Any interval containing 0 is mapped onto $[-1,1]$, which proves that $f$ has the intermediate value property for any $a \in[-1,1]$.

For the second part of the problem, we introduce the function

$$
F(x)= \begin{cases}x^{2} \sin \frac{1}{x} & \text { for } x \neq 0, \\ 0 & \text { for } x=0 .\end{cases}
$$

One can verify easily that

$$
F^{\prime}(x)=\left\{\begin{array}{ll}
2 x \sin \frac{1}{x} & \text { for } x \neq 0, \\
0 & \text { for } x=0,
\end{array}+ \begin{cases}\cos \frac{1}{x} & \text { for } x \neq 0, \\
0 & \text { for } x=0 .\end{cases}\right.
$$

The only place where this computation might pose some difficulty is $x=0$, which can be done using L'Hôpital's theorem. The first function is continuous; hence it is the derivative of a function. Because the differentiation operator is linear we find that the second function, which is $f_{0}(x)$, is a derivative. And because when $a \neq 0$, 

$$
f_{a}(x)-f_{0}(x)= \begin{cases}0 & \text { for } x \neq 0, \\ a & \text { for } x=0,\end{cases}
$$

does not have the intermediate value property, so it is not the derivative of a function, $f_{a}(x)$ itself cannot be the derivative of a function. This completes the solution.

(Romanian high school textbook)

404. Define the function $f: \mathbb{R} \rightarrow \mathbb{R}, f(x)=e^{x}-x-1$. Its first derivative $f^{\prime}(x)=e^{x}-1$ has the unique zero $x=0$, and the second derivative $f^{\prime \prime}(x)=e^{x}$ is strictly positive. It follows that $x=0$ is a global minimum of $f$, and because $f(0)=0, f(x)>0$ for $x \neq 0$. Hence the inequality.

405. Taking the logarithm, transform the equation into the equivalent $x \ln 2=2 \ln x$. Define the function $f: \mathbb{R} \rightarrow \mathbb{R}, f(x)=x \ln 2-2 \ln x$. We are to find the zeros of $f$. Differentiating, we obtain

$$
f^{\prime}(x)=\ln 2-\frac{2}{x},
$$

which is strictly increasing. The unique zero of the derivative is $\frac{2}{\ln 2}$, and so $f^{\prime}$ is negative for $x<2 / \ln 2$ and positive for $x>\frac{2}{\ln 2}$. Note also that $\lim _{x \rightarrow 0} f(x)=\lim _{x \rightarrow \infty} f(x)=$ $\infty$. There are two possibilities: either $f\left(\frac{2}{\ln 2}\right)>0$, in which case the equation $f(x)=0$ has no solutions, or $f\left(\frac{2}{\ln 2}\right)<0$, in which case the equation $f(x)=0$ has exactly two solutions. The latter must be true, since $f(2)=f(4)=0$. Therefore, $x=2$ and $x=4$ are the only solutions to $f(x)=0$, and hence also to the original equation.

406. If $f(x) \geq 0$ for all $x$, then the function $g(x)=\left(x-a_{1}\right)\left(x-a_{2}\right)\left(x-a_{3}\right)$ is increasing, since its derivative is $f$. It follows that $g$ has only one zero, and we conclude that $a_{1}=a_{2}=a_{3}$.

\section{(V. Boskoff)}

407. Let $f: \mathbb{C} \rightarrow \mathbb{C}, f(z)=z^{3}-z+2$. We have to determine $\max _{|z|=1}|f(z)|^{2}$. For this, we switch to real coordinates. If $|z|=1$, then $z=x+i y$ with $y^{2}=1-x^{2}$, $-1 \leq x \leq 1$. View the restriction of $|f(z)|^{2}$ to the unit circle as a function depending on the real variable $x$ :

$$
\begin{aligned}
|f(z)|^{2} &=\left|(x+i y)^{3}-(x+i y)+2\right|^{2} \\
&=\left|\left(x^{3}-3 x y^{2}-x+2\right)+i y\left(3 x^{2}-y^{2}-1\right)\right|^{2} \\
&=\left|\left(x^{3}-3 x\left(1-x^{2}\right)-x+2\right)+i y\left(3 x^{2}-\left(1-x^{2}\right)-1\right)\right|^{2} \\
&=\left(4 x^{3}-4 x+2\right)^{2}+\left(1-x^{2}\right)\left(4 x^{2}-2\right)^{2} \\
&=16 x^{3}-4 x^{2}-16 x+8 .
\end{aligned}
$$

Call this last expression $g(x)$. Its maximum on $[-1,1]$ is either at a critical point or at an endpoint of the interval. The critical points are the roots of $g^{\prime}(x)=48 x^{2}-8 x-16=0$, namely, $x=\frac{2}{3}$ and $x=-\frac{1}{2}$. We compute $g(-1)=4, g\left(-\frac{1}{2}\right)=13, g\left(\frac{2}{3}\right)=\frac{8}{27}$, $g(1)=4$. The largest of them is 13 , which is therefore the answer to the problem. It is attained when $z=-\frac{1}{2} \pm \frac{\sqrt{3}}{2} i$

(8th W.L. Putnam Mathematical Competition, 1947)

408. After we bring the function into the form

$$
f(x)=\frac{\left(x-1+\frac{1}{x}\right)^{3}}{x^{3}-1+\frac{1}{x^{3}}},
$$

the substitution $x+\frac{1}{x}=s$ becomes natural. We are to find the minimum of the function

$$
h(s)=\frac{(s-1)^{3}}{s^{3}-3 s-1}=1+\frac{-3 s^{2}+6 s}{s^{3}-3 s-1}
$$

over the domain $(-\infty,-2] \cup[2, \infty)$. Setting the first derivative equal to zero yields the equation

$$
3(s-1)\left(s^{3}-3 s^{2}+2\right)=0 .
$$

The roots are $s=1$ (double root) and $s=1 \pm \sqrt{3}$. Of these, only $s=1+\sqrt{3}$ lies in the domain of the function.

We compute

$$
\lim _{x \rightarrow \pm \infty} h(s)=1, \quad h(2)=1, \quad h(-2)=9, \quad h(1+\sqrt{3})=\frac{\sqrt{3}}{2+\sqrt{3}} .
$$

Of these the last is the least. Hence the minimum of $f$ is $\sqrt{3} /(2+\sqrt{3})$, which is attained when $x+\frac{1}{x}=1+\sqrt{3}$, that is, when $x=(1+\sqrt{3} \pm \sqrt[4]{12}) / 2$.

(Mathematical Reflections, proposed by T. Andreescu)

409. Let $f(x)=\sin (\sin (\sin (\sin (\sin (x)))))$. The first solution is $x=0$. We have

$$
\begin{aligned}
f^{\prime}(0) &=\cos 0 \cos (\sin 0) \cos (\sin (\sin 0)) \cos (\sin (\sin (\sin 0))) \cos (\sin (\sin (\sin (\sin 0)))) \\
&=1>\frac{1}{3} .
\end{aligned}
$$

Therefore, $f(x)>\frac{x}{3}$ in some neighborhood of 0 . On the other hand, $f(x)<1$, whereas $\frac{x}{3}$ is not bounded as $x \rightarrow \infty$. Therefore, $f\left(x_{0}\right)=\frac{x_{0}}{3}$ for some $x_{0}>0$. Because $f$ is odd, $-x_{0}$ is also a solution. The second derivative of $f$ is

$$
\begin{aligned}
&-\cos (\sin x) \cos (\sin (\sin x)) \cos (\sin (\sin (\sin x))) \cos (\sin (\sin (\sin (\sin x)))) \sin x \\
&\quad-\cos ^{2} x \cos (\sin (\sin x)) \cos (\sin (\sin (\sin x))) \cos (\sin (\sin (\sin (\sin x)))) \sin (\sin x)
\end{aligned}
$$



$$
\begin{aligned}
&-\cos ^{2} x \cos ^{2}(\sin x) \cos (\sin (\sin (\sin x))) \cos (\sin (\sin (\sin (\sin x)))) \sin (\sin (\sin x)) \\
&-\cos ^{2} x \cos ^{2}(\sin x) \cos ^{2}(\sin (\sin x)) \cos (\sin (\sin (\sin (\sin x))) \sin (\sin (\sin (\sin x))) \\
&\left.-\cos ^{2} x \cos ^{2}(\sin x)\right) \cos ^{2}(\sin (\sin x)) \cos ^{2}(\sin (\sin (\sin x))) \sin (\sin (\sin (\sin (\sin x)))
\end{aligned}
$$

which is clearly nonpositive for $0 \leq x \leq 1$. This means that $f^{\prime}(x)$ is monotonic. Therefore, $f^{\prime}(x)$ has at most one root $x^{\prime}$ in $[0,+\infty)$. Then $f(x)$ is monotonic at $\left[0, x^{\prime}\right]$ and $\left[x^{\prime},+\infty\right)$ and has at most two nonnegative roots. Because $f(x)$ is an odd function, it also has at most two nonpositive roots. Therefore, $-x_{0}, 0, x_{0}$ are the only solutions. 

410. Define the function $G: \mathbb{R} \rightarrow \mathbb{R}, G(x)=\left(\int_{0}^{x} f(t) d t\right)^{2}$. It satisfies

$$
G^{\prime}(x)=2 f(x) \int_{0}^{x} f(t) d t .
$$

Because $G^{\prime}(0)=0$ and $G^{\prime}(x)=g(x)$ is nonincreasing it follows that $G^{\prime}$ is nonnegative on $(-\infty, 0)$ and nonpositive on $(0, \infty)$. This implies that $G$ is nondecreasing on $(-\infty, 0)$ and nonincreasing on $(0, \infty)$. And this, combined with the fact that $G(0)=0$ and $G(x) \geq 0$ for all $x$, implies $G(x)=0$ for all $x$. Hence $\int_{0}^{x} f(t) d t=0$. Differentiating with respect to $x$, we conclude that $f(x)=0$ for all $x$, and we are done.

(Romanian Olympiad, 1978, proposed by S. Rădulescu)

411. Consider the function

$$
F(t)=\left[\int_{0}^{t} f(x) d x\right]^{2}-\int_{0}^{t}[f(x)]^{3} d x \quad \text { for } t \in[0,1] .
$$

We want to show that $F(t) \geq 0$, from which the conclusion would then follow. Because $F(0)=0$, it suffices to show that $F$ is increasing. To prove this fact we differentiate and obtain

$$
F^{\prime}(t)=f(t)\left[2 \int_{0}^{t} f(x) d x-f^{2}(t)\right] .
$$

It remains to check that $G(t)=2 \int_{0}^{t} f(x) d x-f^{2}(t)$ is positive on $[0,1]$. Because $G(0)=0$, it suffices to prove that $G$ itself is increasing on $[0,1]$. We have

$$
G^{\prime}(t)=2 f(t)-2 f(t) f^{\prime}(t) .
$$

This function is positive, since on the one hand $f^{\prime}(0) \leq 1$, and on the other hand $f$ is increasing, having a positive derivative, and so $f(t) \geq f(0)=0$. This proves the inequality. An example in which equality holds is the function $f:[0,1] \rightarrow \mathbb{R}, f(x)=x$.

(34th W.L. Putnam Mathematical Competition, 1973)

412. (a) To avoid the complicated exponents, divide the inequality by the right-hand side; then take the natural logarithm. Next, fix positive numbers $y$ and $z$, and then introduce the function $f:(0, \infty) \rightarrow \mathbb{R}$, 

$$
\begin{aligned}
f(x)=&(x+y+z) \ln (x+y+z)+x \ln x+y \ln y+z \ln z \\
&-(x+y) \ln (x+y)-(y+z) \ln (y+z)-(z+x) \ln (z+x) .
\end{aligned}
$$

Differentiating $f(x)$ with respect to $x$, we obtain

$$
f^{\prime}(x)=\ln \frac{(x+y+z) x}{(x+y)(z+x)}=\ln \frac{x^{2}+y x+z x}{x^{2}+y x+z x+y z}<\ln 1=0,
$$

for all positive numbers $x$. It follows that $f(x)$ is strictly decreasing, so $f(x)<$ $\lim _{t \rightarrow 0} f(t)=0$, for all $x>0$. Hence $e^{f(x)}<1$ for all $x>0$, which is equivalent to the first inequality from the statement.

(b) We apply the same idea, fixing $y, z>0$ and considering the function $g:(0, \infty)$ $\rightarrow \mathbb{R}$

$$
\begin{aligned}
g(x)=&(x+y+z)^{2} \ln (x+y+z)+x^{2} \ln x+y^{2} \ln y+z^{2} \ln z \\
&-(x+y)^{2} \ln (x+y)-(y+z)^{2} \ln (y+z)-(z+x)^{2} \ln (z+x) .
\end{aligned}
$$

Differentiating with respect to $x$, we obtain

$$
g^{\prime}(x)=2 \ln \frac{(x+y+z)^{x+y+z} x^{x}}{(x+y)^{x+y}(z+x)^{z+x}} .
$$

We would like to show this time that $g$ is increasing, for then $g(x)>\lim _{t \rightarrow 0} g(t)=0$, from which the desired inequality is obtained by exponentiation. We are left to prove that $g^{\prime}(x)>0$, which is equivalent to

$$
(x+y+z)^{x+y+z} x^{x}>(x+y)^{x+y}(z+x)^{z+x}, \quad \text { for } x, y, z>0 .
$$

And we take the same path as in (a). Because we want to make the derivative as simple as possible, we fix $x, y>0$ and define $h:(0, \infty) \rightarrow \mathbb{R}$,

$$
h(z)=(x+y+z) \ln (x+y+z)+x \ln x-(x+y) \ln (x+y)-(z+x) \ln (z+x) .
$$

Then

$$
h^{\prime}(z)=\ln \frac{x+y+z}{z+x}>\ln 1=0,
$$

for $z>0$. Hence $h(z)>\lim _{t \rightarrow 0} h(t)=0, z>0$. This implies the desired inequality and completes the solution.

(American Mathematical Monthly, proposed by Sz. András, solution by H.-J. Seiffert)

413. Let us examine the function $F(x)=f(x)-g(x)$. Because $F^{(n)}(a) \neq 0$, we have $F^{(n)}(x) \neq 0$ for $x$ in a neighborhood of $a$. Hence $F^{(n-1)}(x) \neq 0$ for $x \neq a$ and $x$ in a neighborhood of $a$ (otherwise, this would contradict Rolle's theorem). Then $F^{(n-2)}(x)$ is monotonic to the left, and to the right of $a$, and because $F^{(n-2)}(a)=0, F^{(n-2)}(x) \neq 0$ for $x \neq a$ and $x$ in a neighborhood of $a$. Inductively, we obtain $F^{\prime}(x) \neq 0$ and $f(x) \neq 0$ in some neighborhood of $a$.

The limit from the statement can be written as

$$
\lim _{x \rightarrow a} e^{g(x)} \frac{e^{f(x)-g(x)}-1}{f(x)-g(x)} .
$$

We only have to compute the limit of the fraction, since $g(x)$ is a continuous function. We are in a $\frac{0}{0}$ situation, and can apply L'Hôpital's theorem:

$$
\lim _{x \rightarrow a} \frac{e^{f(x)-g(x)}-1}{f(x)-g(x)}=\lim _{x \rightarrow a} \frac{\left(f^{\prime}(x)-g^{\prime}(x)\right) e^{f(x)-g(x)}}{f^{\prime}(x)-g^{\prime}(x)}=e^{0}=1 .
$$

Hence the limit from the statement is equal to $e^{g(a)}=e^{\alpha}$.

(N. Georgescu-Roegen)

414. The function $h:[1, \infty) \rightarrow[1, \infty)$ given by $h(t)=t(1+\ln t)$ is strictly increasing, and $h(1)=1, \lim _{t \rightarrow \infty} h(t)=\infty$. Hence $h$ is bijective, and its inverse is clearly the function $f:[1, \infty) \rightarrow[1, \infty), \lambda \rightarrow f(\lambda)$. Since $h$ is differentiable, so is $f$, and

$$
f^{\prime}(\lambda)=\frac{1}{h^{\prime}(x(\lambda))}=\frac{1}{2+\ln f(\lambda)} .
$$

Also, since $h$ is strictly increasing and $\lim _{t \rightarrow \infty} h(t)=\infty, f(\lambda)$ is strictly increasing, and its limit at infinity is also infinity. Using the defining relation for $f(\lambda)$, we see that

$$
\frac{f(\lambda)}{\frac{\lambda}{\ln \lambda}}=\ln \lambda \cdot \frac{f(\lambda)}{\lambda}=\frac{\ln \lambda}{1+\ln f(\lambda)} .
$$

Now we apply L'Hôpital's theorem and obtain

$$
\lim _{\lambda \rightarrow \infty} \frac{f(\lambda)}{\frac{\lambda}{\ln \lambda}}=\lim _{\lambda \rightarrow \infty} \frac{\frac{1}{f(\lambda)}}{\frac{1}{\lambda} \cdot \frac{1}{2+\ln f(\lambda)}}=\lim _{\lambda \rightarrow \infty} \frac{f(\lambda)}{\lambda}(2+\ln f(\lambda))=\lim _{\lambda \rightarrow \infty} \frac{2+\ln f(\lambda)}{1+\ln f(\lambda)}=1,
$$

where the next-to-last equality follows again from $f(\lambda)(1+\ln f(\lambda))=\lambda$. Therefore, the required limit is equal to 1.

(Gazeta Matematica (Mathematics Gazette, Bucharest), proposed by I. Tomescu)

415. If all four zeros of the polynomial $P(x)$ are real, then by Rolle's theorem all three zeros of $P^{\prime}(x)$ are real, and consequently both zeros of $P^{\prime \prime}(x)=12 x^{2}-6 \sqrt{7} x+8$ are real. But this quadratic polynomial has the discriminant equal to $-132$, which is negative, and so it has complex zeros. The contradiction implies that not all zeros of $P(x)$ are real. 

416. Replacing $f$ by $-f$ if necessary, we may assume $f(b)>f(c)$, hence $f(a)>f(c)$ as well. Let $\xi$ be an absolute minimum of $f$ on $[a, b]$, which exists because the function is continuous. Then $\xi \in(a, b)$ and therefore $f^{\prime}(\xi)=0$.

417. Consider the function $f:[2, \infty) \rightarrow \mathbb{R}, f(x)=x \cos \frac{\pi}{x}$. By the mean value theorem there exists $u \in[x, x+1]$ such that $f^{\prime}(u)=f(x+1)-f(x)$. The inequality from the statement will follow from the fact that $f^{\prime}(u)>1$. Since $f^{\prime}(u)=\cos \frac{\pi}{u}+\frac{\pi}{u} \sin \frac{\pi}{u}$, we have to prove that

$$
\cos \frac{\pi}{u}+\frac{\pi}{u} \sin \frac{\pi}{u}>1,
$$

for all $u \in[2, \infty)$. Note that $f^{\prime \prime}(u)=-\frac{\pi^{2}}{u^{3}} \cos \frac{\pi}{u}<0$, for $u \in[2, \infty)$, so $f^{\prime}$ is strictly decreasing. This implies that $f^{\prime}(u)>\lim _{v \rightarrow \infty} f^{\prime}(v)=1$ for all $u$, as desired. The conclusion follows.

(Romanian college admission exam, 1987)

418. Let $\alpha$ be the slope of the line through the collinear points $\left(a_{i}, f\left(a_{i}\right)\right), i=0,1, \ldots, n$, on the graph of $f$. Then

$$
\frac{f\left(a_{i}\right)-f\left(a_{i-1}\right)}{a_{i}-a_{i-1}}=\alpha, \quad i=1,2, \ldots, n .
$$

From the mean value theorem it follows that there exist points $c_{i} \in\left(a_{i-1}, a_{i}\right)$ such that $f^{\prime}\left(c_{i}\right)=\alpha, i=1,2, \ldots, n$. Consider the function $F:\left[a_{0}, a_{n}\right] \rightarrow \mathbb{R}, F(x)=f^{\prime}(x)-\alpha$. It is continuous, $(n-1)$-times differentiable, and has $n$ zeros in $\left[a_{0}, a_{n}\right]$. Applying successively Rolle's theorem, we conclude that $F^{(n-1)}=f^{(n)}$ has a zero in $[a, b]$, and the problem is solved.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by G. Sireţchi)

419. The functions $\phi, \psi:[a, b] \rightarrow \mathbb{R}, \phi(x)=\frac{f(x)}{x-\alpha}$ and $\psi(x)=\frac{1}{x-\alpha}$ satisfy the conditions of Cauchy's theorem. Hence there exists $c \in(a, b)$ such that

$$
\frac{\phi(b)-\phi(a)}{\psi(b)-\psi(a)}=\frac{\phi^{\prime}(c)}{\psi^{\prime}(c)} .
$$

Replacing $\phi$ and $\psi$ with their formulas gives

$$
\frac{(a-\alpha) f(b)-(b-\alpha) f(a)}{a-b}=f(c)-(c-\alpha) f^{\prime}(c) .
$$

On the other hand, since $M$ lies on the line determined by $(a, f(a)),(b, f(b))$, the coordinates of $M$ are related by

$$
\beta=\frac{(a-\alpha) f(b)-(b-\alpha) f(a)}{a-b} .
$$

This implies that $\beta=f^{\prime}(c)(c-\alpha)+f(c)$, which shows that $M(\alpha, \beta)$ lies on the tangent to the graph of $f$ at $(c, f(c))$, and we are done.

420. Consider the function $F:[a, b] \rightarrow \mathbb{R}$,

$$
F(x)=f^{\prime}(x) e^{-\lambda f(x)}, \quad \lambda \in \mathbb{R} .
$$

Because $f$ is twice differentiable, $F$ is differentiable. We have $F(a)=F(b)$, which by Rolle's theorem implies that there exists $c \in(a, b)$ with $F^{\prime}(c)=0$. But

$$
F^{\prime}(x)=e^{-\lambda f(x)}\left(f^{\prime \prime}(x)-\lambda\left(f^{\prime}(x)\right)^{2}\right),
$$

so $f^{\prime \prime}(c)-\lambda\left(f^{\prime}(c)\right)^{2}=0$. We are done.

(D. Andrica)

421. First solution: Let us assume that such numbers do exist. If $x=y$ it follows that $x\left(2^{x}+2^{-x}\right)=2 x$, which implies $x=y=0$. This is impossible because $x$ and $y$ are assumed to be positive.

Hence $x$ should be different from $y$. Let $x_{1}>x_{2}>x_{3}>0$ be such that $y=x_{1}-x_{2}$ and $x=x_{2}-x_{3}$. The relation from the statement can be written as

$$
\frac{2^{x_{1}-x_{2}}-1}{1-2^{x_{3}-x_{2}}}=\frac{x_{1}-x_{2}}{x_{2}-x_{3}},
$$

or

$$
\frac{2^{x_{1}}-2^{x_{2}}}{x_{1}-x_{2}}=\frac{2^{x_{2}}-2^{x_{3}}}{x_{2}-x_{3}} .
$$

Applying the mean value theorem to the exponential, we deduce the existence of the numbers $\theta_{1} \in\left(x_{2}, x_{1}\right)$ and $\theta_{2} \in\left(x_{3}, x_{2}\right)$ such that

$$
\begin{aligned}
&\frac{2^{x_{1}}-2^{x_{2}}}{x_{1}-x_{2}}=2^{\theta_{1}} \ln 2, \\
&\frac{2^{x_{2}}-2^{x_{3}}}{x_{2}-x_{3}}=2^{\theta_{2}} \ln 2 .
\end{aligned}
$$

But this implies $2^{\theta_{1}} \ln 2=2^{\theta_{2}} \ln 2$, or $\theta_{1}=\theta_{2}$, which is impossible since the two numbers lie in disjoint intervals. This contradiction proves the claim.

Second solution: Define $F(z)=\left(2^{z}-1\right) / z$. Note that by L'Hôpital's rule, defining $F(0)=\log 2$ extends $F$ continuously to $z=0$. Rearrange the equality to give

$$
F(-x)=\frac{2^{-x}-1}{-x}=\frac{2^{y}-1}{y}=F(y) .
$$

Thus the lack of solutions will follow if we show that $F$ is strictly increasing. Recall that $e^{-t}>1-t$ for $t \neq 0$, hence $2^{-z}>1-z \log 2$ for $z \neq 0$. Hence

$$
F^{\prime}(z)=\frac{2^{z}\left(z \log 2-1+2^{-z}\right)}{z^{2}}>0
$$

for $z \neq 0$ and hence $F$ is strictly increasing.

(T. Andreescu, second solution by R. Stong)

422. Clearly, $\alpha$ is nonnegative. Define $\Delta f(x)=f(x+1)-f(x)$, and $\Delta^{(k)} f(x)=$ $\Delta\left(\Delta^{(k-1)} f(x)\right), k \geq 2$. By the mean value theorem, there exists $\theta_{1} \in(0,1)$ such $f(x+1)-f(x)=f^{\prime}\left(x+\theta_{1}\right)$, and inductively for every $k$, there exists $\theta_{k} \in(0, k)$ such that $\Delta^{(k)} f(x)=f^{(k)}(x)$. Applying this to $f(x)=x^{\alpha}$ and $x=n$, we conclude that for every $k$ there exists $\theta_{k} \in(0, k)$ such that $f^{(k)}\left(n+\theta_{k}\right)$ is an integer. Choose $k=\lfloor\alpha\rfloor+1$. Then

$$
\Delta^{(k)} f(n+\theta)=\frac{\alpha(\alpha-1) \cdots(\alpha+1-k)}{\left(n+\theta_{k}\right)^{k-\alpha}} .
$$

This number is an integer by hypothesis. It is not hard to see that it is also positive and less than 1 . The only possibility is that it is equal to 0 , which means that $\alpha=k-1$, and the conclusion follows.

\section{(W.L. Putnam Mathematical Competition)}

423. The equation is $a^{3}+b^{3}+c^{3}=3 a b c$, with $a=2^{x}, b=-3^{x-1}$, and $c=-1$. Using the factorization

$$
a^{3}+b^{3}+c^{3}-3 a b c=\frac{1}{2}(a+b+c)\left[(a-b)^{2}+(b-c)^{2}+(c-a)^{2}\right]
$$

we find that $a+b+c=0$ (the other factor cannot be zero since, for example, $2^{x}$ cannot equal $-1)$. This yields the simpler equation

$$
2^{x}=3^{x-1}+1 .
$$

Rewrite this as

$$
3^{x-1}-2^{x-1}=2^{x-1}-1 .
$$

We immediately notice the solutions $x=1$ and $x=2$. Assume that another solution exists, and consider the function $f(t)=t^{x-1}$. Because $f(3)-f(2)=f(2)-f(1)$, by the mean value theorem there exist $t_{1} \in(2,3)$ and $t_{2} \in(1,2)$ such that $f^{\prime}\left(t_{1}\right)=f^{\prime}\left(t_{2}\right)$. This gives rise to the impossible equality $(x-1) t_{1}^{x-2}=(x-1) t_{2}^{x-2}$. We conclude that there are only two solutions: $x=1$ and $x=2$.

(Mathematical Reflections, proposed by T. Andreescu) 

424. We first show that $P(x)$ has rational coefficients. Let $k$ be the degree of $P(x)$, and for each $n$, let $x_{n}$ be the rational root of $P(x)=n$. The system of equations in the coefficients

$$
P\left(x_{n}\right)=n, \quad n=0,1,2, \ldots, k,
$$

has a unique solution since its determinant is Vandermonde. Cramer's rule yields rational solutions for this system, hence rational coefficients for $P(x)$. Multiplying by the product of the denominators, we may thus assume that $P(x)$ has integer coefficients, say $P(x)=$ $a_{k} x^{k}+\cdots+a_{1} x+a_{0}$, that $a_{k}>0$, and that $P(x)=N n$ has a rational solution $x_{n}$ for all $n \geq 1$, where $N$ is some positive integer (the least common multiple of the previous coefficients).

Because $x_{n}$ is a rational number, its representation as a fraction in reduced form has the numerator a divisor of $a_{0}-n$ and the denominator a divisor of $a_{k}$. If $m \neq n$, then $x_{m} \neq x_{n}$, so

$$
\left|x_{m}-x_{n}\right| \geq \frac{1}{a_{k}} .
$$

Let us now show that under this hypothesis the derivative of the polynomial is constant. Assume the contrary. Then $\lim _{|x| \rightarrow \infty}\left|P^{\prime}(x)\right|=\infty$. Also, $\lim _{n \rightarrow \infty} P\left(x_{n}\right)=$ $\lim _{n \rightarrow \infty} n=\infty$. Hence $\left|x_{n}\right| \rightarrow \infty$, and so $\left|P^{\prime}\left(x_{n}\right)\right| \rightarrow \infty$, for $n \rightarrow \infty$.

For some $n$, among the numbers $x_{n}, x_{n+1}, x_{n+2}$ two have the same sign, call them $x$ and $y$. Then, by the mean value theorem, there exists a $c_{n}$ between $x$ and $y$ such that

$$
P^{\prime}\left(c_{n}\right)=\frac{P(y)-P(x)}{y-x} .
$$

Taking the absolute value, we obtain

$$
\left|P^{\prime}\left(c_{n}\right)\right| \leq \frac{(n+2)-n}{|y-x|} \leq 2 a_{k},
$$

where we use the fact that $x$ and $y$ are at least $1 / a_{k}$ apart. But $c_{n}$ tends to infinity, and so $\left|P^{\prime}\left(c_{n}\right)\right|$ must also tend to infinity, a contradiction. This shows that our assumption was false, so $P^{\prime}(x)$ is constant. We conclude that $P(x)$ is linear.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by M. Dădărlat) 

425. Arrange the $x_{i}$ 's in increasing order $x_{1} \leq x_{2} \leq \cdots \leq x_{n}$. The function

$$
f(a)=\left|a-x_{1}\right|+\left|a-x_{2}\right|+\cdots+\left|a-x_{n}\right|
$$

is convex, being the sum of convex functions. It is piecewise linear. The derivative at a point $a$, in a neighborhood of which $f$ is linear, is equal to the difference between the number of $x_{i}$ 's that are less than $a$ and the number of $x_{i}$ 's that are greater than $a$. The global minimum is attained where the derivative changes sign. For $n$ odd, this happens precisely at $x_{\lfloor n / 2\rfloor+1}$. If $n$ is even, the minimum is achieved at any point of the interval $\left[x_{\lfloor n / 2\rfloor}, x_{\lfloor n / 2\rfloor+1}\right]$ at which the first derivative is zero and the function is constant.

So the answer to the problem is $a=x_{\lfloor n / 2\rfloor+1}$ if $n$ is odd, and $a$ is any number in the interval $\left[x_{\lfloor n / 2\rfloor}, x_{\lfloor n / 2\rfloor+1}\right]$ if $n$ is even.

Remark. The required number $x$ is called the median of $x_{1}, x_{2}, \ldots, x_{n}$. In general, if the numbers $x \in \mathbb{R}$ occur with probability distribution $d \mu(x)$ then their median $a$ minimizes

$$
E(|x-a|)=\int_{-\infty}^{\infty}|x-a| d \mu(x) .
$$

The median is any number such that

$$
\int_{-\infty}^{a} d \mu(x)=P(x \leq a) \geq \frac{1}{2}
$$

and

$$
\int_{a}^{\infty} d \mu(x)=P(x \geq a) \geq \frac{1}{2} .
$$

In the particular case of our problem, the numbers $x_{1}, x_{2}, \ldots, x_{n}$ occur with equal probability, so the median lies in the middle.

426. The function $f(t)=t^{c}$ is convex, while $g(t)=x^{t}$ is convex and increasing. Therefore, $h(t)=g(f(t))=x^{t^{c}}$ is convex. We thus have

$$
x^{a^{c}}+x^{b^{c}}=h(a)+h(b) \geq 2 h\left(\frac{a+b}{2}\right)=2 x^{\left(\frac{a+b}{2}\right)^{2 c}} \geq 2 x^{(a b)^{c / 2}} .
$$

This completes the solution.

(P. Alexandrescu)

427. We can assume that the triangle is inscribed in a circle of diameter 1, so that $a=\sin A$, $b=\sin B, c=\sin C, A \geq B \geq C$. The sine function is concave on the interval $[0, \pi]$, and since $B$ is between $A$ and $C$, and all three angles lie in this interval, we have

$$
\frac{\sin B-\sin C}{B-C} \geq \frac{\sin A-\sin C}{A-C} .
$$

Multiplying out, we obtain

$$
(A-C)(\sin B-\sin C) \geq(B-C)(\sin A-\sin C),
$$

or

$$
A \sin B-A \sin C-C \sin B \geq B \sin A-C \sin A-B \sin C
$$

Moving the negative terms to the other side and substituting the sides of the triangle for the sines, we obtain the inequality from the statement.

428. Fix $x_{0} \in(a, b)$ and let $\alpha$ and $\beta$ be two limit points of $f: \alpha$ from the left and $\beta$ from the right. We want to prove that they are equal. If not, without loss of generality we can assume $\alpha<\beta$. We argue from Figure 68. Choose $x<x_{0}$ and $y>x_{0}$ very close to $x_{0}$ such that $|f(x)-\alpha|$ and $|f(y)-\beta|$ are both very small. Because $\beta$ is a limit point of $f$ at $x_{0}$, there will exist points on the graph of $f$ close to $\left(x_{0}, \beta\right)$, hence above the segment joining $(x, f(x))$ and $(y, f(y))$. But this contradicts the convexity of $f$. Hence $\alpha=\beta$.

Because all limit points from the left are equal to all limit points from the right, $f$ has a limit at $x_{0}$. Now redo the above argument for $x=x_{0}$ to conclude that the limit is equal to the value of the function at $x_{0}$. Hence $f$ is continuous at $x_{0}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-534.jpg?height=508&width=698&top_left_y=970&top_left_x=516)

\section{Figure 68}

429. The key point of the solution is Cauchy's method of backward induction discussed in the first chapter of the book. We first prove that for any positive integer $k$ and points $x_{1}, x_{2}, \ldots, x_{2^{k}}$, we have

$$
f\left(\frac{x_{1}+x_{2}+\cdots+x_{2^{k}}}{2^{k}}\right) \leq \frac{f\left(x_{1}\right)+f\left(x_{2}\right)+\cdots+f\left(x_{2^{k}}\right)}{2^{k}} .
$$

The base case is contained in the statement of the problem, while the inductive step is

$$
\begin{aligned}
f\left(\frac{x_{1}+\cdots+x_{2^{k}}+x_{2^{k}+1}+\cdots+x_{2^{k+1}}}{2^{k+1}}\right) & \leq \frac{f\left(\frac{x_{1}+\cdots+x_{2^{k}}}{2^{k}}\right)+f\left(\frac{x_{2^{k}+1}+\cdots+x_{2^{k+1}}}{2^{k}}\right)}{2} \\
& \leq \frac{\frac{f\left(x_{1}\right)+\cdots+f\left(x_{2^{k}}\right)}{2^{k}}+\frac{f\left(x_{2^{k}+1}\right)+\cdots+f\left(x_{2^{k+1}}\right)}{2^{k}}}{2}
\end{aligned}
$$



$$
=\frac{f\left(x_{1}\right)+\cdots+f\left(x_{2^{k}}\right)+f\left(x_{2^{k}}+1\right)+\cdots+f\left(x_{2^{k}+1}\right)}{2^{k+1}} .
$$

Next, we show that

$$
f\left(\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}\right) \leq \frac{f\left(x_{1}\right)+f\left(x_{2}\right)+\cdots+f\left(x_{n}\right)}{n}, \quad \text { for all } x_{1}, x_{2} \ldots, x_{n}
$$

Assuming that the inequality holds for any $n$ points, we prove that it holds for any $n-1$ points as well. Consider the points $x_{1}, x_{2}, \ldots, x_{n-1}$ and define $x_{n}=\frac{x_{1}+x_{2}+\cdots+x_{n-1}}{n-1}$. Using the induction hypothesis, we can write

$$
f\left(\frac{x_{1}+\cdots+x_{n-1}+\frac{x_{1}+\cdots+x_{n-1}}{n-1}}{n}\right) \leq \frac{f\left(x_{1}\right)+\cdots+f\left(x_{n-1}\right)+f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right)}{n} .
$$

This is the same as

$$
f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right) \leq \frac{f\left(x_{1}\right)+\cdots+f\left(x_{n-1}\right)}{n}+\frac{1}{n} f\left(\frac{x_{1}+\cdots+x_{n-1}}{n-1}\right) .
$$

Moving the last term on the right to the other side gives the desired inequality. Starting with a sufficiently large power of 2 we can cover the case of any positive integer $n$.

In the inequality

$$
f\left(\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}\right) \leq \frac{f\left(x_{1}\right)+f\left(x_{2}\right)+\cdots+f\left(x_{n}\right)}{n}
$$

that we just proved, for some $m<n$ set $x_{1}=x_{2}=\cdots=x_{m}=x$ and $x_{m+1}=x_{m+2}=$ $\cdots=x_{n}=y$. Then

$$
f\left(\frac{m}{n} x+\left(1-\frac{m}{n}\right) y\right) \leq \frac{m}{n} f(x)+\left(1-\frac{m}{n}\right) f(y)
$$

Because $f$ is continuous we can pass to the limit with $\frac{m}{n} \rightarrow \lambda$ to obtain the desired

$$
f(\lambda x+(1-\lambda) y) \leq \lambda f(x)+(1-\lambda) f(y),
$$

which characterizes convex functions.

430. First solution: Fix $n \geq 1$. For each integer $i$, define

$$
\Delta_{i}=f\left(\frac{i+1}{n}\right)-f\left(\frac{i}{n}\right) \text {. }
$$

If in the inequality from the statement we substitute $x=\frac{i+2}{n}$ and $y=\frac{i}{n}$, we obtain 

$$
\frac{f\left(\frac{i+2}{n}\right)+f\left(\frac{i}{n}\right)}{2} \geq f\left(\frac{i+1}{n}\right)+\frac{2}{n}, \quad i=1,2, \ldots, n,
$$

or

$$
f\left(\frac{i+2}{n}\right)-f\left(\frac{i+1}{n}\right) \geq f\left(\frac{i+1}{n}\right)-f\left(\frac{i}{n}\right)+\frac{4}{n}, \quad i=1,2, \ldots, n .
$$

In other words, $\Delta_{i+1} \geq \Delta_{i}+\frac{4}{n}$. Combining this for $n$ consecutive values of $i$ gives

$$
\Delta_{i+n} \geq \Delta_{i}+4 .
$$

Summing this inequality for $i=0$ to $n-1$ and canceling terms yields

$$
f(2)-f(1) \geq f(1)-f(0)+4 n .
$$

This cannot hold for all $n \geq 1$. Hence, there are no very convex functions.

Second solution: We show by induction on $n$ that the given inequality implies

$$
\frac{f(x)+f(y)}{2}-f\left(\frac{x+y}{2}\right) \geq 2^{n}|x-y|, \quad \text { for } n \geq 0 .
$$

This will yield a contradiction, because for fixed $x$ and $y$ the right-hand side gets arbitrarily large, while the left-hand side remains fixed.

The statement of the problem gives us the base case $n=0$. Now, if the inequality holds for a given $n$, then for two real numbers $a$ and $b$,

$$
\begin{aligned}
\frac{f(a)+f(a+2 b)}{2} & \geq f(a+b)+2^{n+1}|b|, \\
f(a+b)+f(a+3 b) & \geq 2\left(f(a+2 b)+2^{n+1}|b|\right),
\end{aligned}
$$

and

$$
\frac{f(a+2 b)+f(a+4 b)}{2} \geq f(a+3 b)+2^{n+1}|b| .
$$

Adding these three inequalities and canceling terms yields

$$
\frac{f(a)+f(a+4 b)}{2} \geq f(a+2 b)+2^{n+3}|b| .
$$

Setting $x=a, y=a+4 b$, we obtain

$$
\frac{f(x)+f(y)}{2} \geq f\left(\frac{x+y}{2}\right)+2^{n+1}|x-y|,
$$

completing the induction. Hence the conclusion.

(USA Mathematical Olympiad, 2000, proposed by B. Poonen)

431. The case $x=y=z$ is straightforward, so let us assume that not all three numbers are equal. Without loss of generality, we may assume that $x \leq y \leq z$. Let us first discuss the case $y \leq \frac{x+y+z}{3}$. Then $y \leq \frac{x+z}{2}$, and so

$$
\frac{x+y+z}{3} \leq \frac{x+z}{2} \leq z .
$$

Obviously $x \leq(x+y+z) / 3$, and consequently

$$
\frac{x+y+z}{3} \leq \frac{y+z}{2} \leq z .
$$

It follows that there exist $s, t \in[0,1]$ such that

$$
\begin{aligned}
&\frac{x+z}{2}=s \frac{x+y+z}{3}+(1-s) z, \\
&\frac{y+z}{2}=t \frac{x+y+z}{3}+(1-t) z .
\end{aligned}
$$

Adding up these inequalities and rearranging yields

$$
\frac{x+y-2 z}{2}=(s+t) \frac{x+y-2 z}{3} .
$$

Since $x+y<2 z$, this equality can hold only if $s+t=\frac{3}{2}$. Writing the fact that $f$ is a convex function, we obtain

$$
\begin{aligned}
f\left(\frac{x+z}{2}\right) &=f\left(s \frac{x+y+z}{3}+(1-s) z\right) \leq s f\left(\frac{x+y+z}{3}\right)+(1-s) f(z), \\
f\left(\frac{y+z}{2}\right) &=f\left(t \frac{x+y+z}{3}+(1-t) z\right) \leq t f\left(\frac{x+y+z}{3}\right)+(1-t) f(z), \\
f\left(\frac{x+y}{2}\right) & \leq \frac{1}{2} f(x)+\frac{1}{2} f(y) .
\end{aligned}
$$

Adding the three, we obtain

$$
\begin{aligned}
&f\left(\frac{x+y}{2}\right)+f\left(\frac{y+z}{2}\right)+f\left(\frac{z+x}{2}\right) \\
&\quad \leq(s+t) f\left(\frac{x+y+z}{3}\right)+\frac{1}{2} f(x)+\frac{1}{2} f(y)+(2-s-t) f(z) \\
&\quad=\frac{2}{3} f\left(\frac{x+y+z}{3}\right)+\frac{1}{2} f(x)+\frac{1}{2} f(y)+\frac{1}{2} f(z),
\end{aligned}
$$

and the inequality is proved.

(T. Popoviciu, solution published by Gh. Eckstein in Timişoara Mathematics Gazette)

432. The fact that all sequences $\left(a^{n} b_{n}\right)_{n}$ are convex implies that for any real number $a$, $a^{n+1} b_{n+1}-2 a^{n} b_{n}+a^{n-1} b_{n-1} \geq 0$. Hence $b_{n+1} a^{2}-2 b_{n} a+b_{n-1} \geq 0$ for all $a$. Viewing the left-hand side as a quadratic function in $a$, its discriminant must be less than or equal to zero. This is equivalent to $b_{n}^{2} \leq b_{n+1} b_{n-1}$ for all $n$. Taking the logarithm, we obtain that $2 \ln b_{n} \leq \ln b_{n+1}+\ln b_{n-1}$, proving that the sequence $\left(\ln b_{n}\right)_{n}$ is convex.

433. We will show that the largest such constant is $C=\frac{1}{2}$. For example, if we consider the sequence $a_{1}=\epsilon, a_{2}=1, a_{3}=\epsilon$, with $\epsilon$ a small positive number, then the condition from the statement implies

$$
C \leq \frac{1}{2} \cdot \frac{(1+2 \epsilon)^{2}}{1+2 \epsilon^{2}} .
$$

Here if we let $\epsilon \rightarrow 0$, we obtain $C \leq \frac{1}{2}$.

Let us now show that $C=\frac{1}{2}$ satisfies the inequality for all concave sequences. For every $i$, concavity forces the elements $a_{1}, a_{2}, \ldots, a_{i}$ to be greater than or equal to the corresponding terms in the arithmetic progression whose first term is $a_{1}$ and whose $i$ th term is $a_{i}$. Consequently,

$$
a_{1}+a_{2}+\cdots+a_{i} \geq i\left(\frac{a_{1}+a_{i}}{2}\right) .
$$

The same argument repeated for $a_{i}, a_{i+1}, \ldots, a_{n}$ shows that

$$
a_{i}+a_{i+1}+\cdots+a_{n} \geq(n-i+1)\left(\frac{a_{i}+a_{n}}{2}\right) .
$$

Adding the two inequalities, we obtain

$$
\begin{aligned}
a_{1}+a_{2}+\cdots+a_{n} & \geq i\left(\frac{a_{1}+a_{i}}{2}\right)+(n-i+1)\left(\frac{a_{i}+a_{n}}{2}\right)-a_{i} \\
&=i \frac{a_{1}}{2}+(n-i+1) \frac{a_{n}}{2}+\frac{(n-1) a_{i}}{2} \\
& \geq\left(\frac{n-1}{2}\right) a_{i} .
\end{aligned}
$$

Multiplying by $a_{i}$ and summing the corresponding inequalities for all $i$ gives

$$
\left(a_{1}+a_{2}+\cdots+a_{n}\right)^{2} \geq \frac{n-1}{2}\left(a_{1}^{2}+a_{2}^{2}+\cdots+a_{n}^{2}\right) .
$$

This shows that indeed $C=\frac{1}{2}$ is the answer to our problem.

(Mathematical Olympiad Summer Program, 1994) 

434. We assume that $\alpha \leq \beta \leq \gamma$, the other cases being similar. The expression is a convex function in each of the variables, so it attains its maximum for some $x, y, z=a$ or $b$.

Now let us fix three numbers $x, y, z \in[a, b]$, with $x \leq y \leq z$. We have

$$
E(x, y, z)-E(x, z, y)=(\gamma-\alpha)\left((z-x)^{2}-(y-z)^{2}\right) \geq 0,
$$

and hence $E(x, y, z) \geq E(x, z, y)$. Similarly, $E(x, y, z) \geq E(y, x, z)$ and $E(z, y, x) \geq$ $E(y, z, x)$. So it suffices to consider the cases $x=a, z=b$ or $x=b$ and $z=a$. For these cases we have

$$
E(a, a, b)=E(b, b, a)=(\beta+\gamma)(b-a)^{2}
$$

and

$$
E(a, b, b)=E(b, a, a)=(\alpha+\gamma)(b-a)^{2} .
$$

We deduce that the maximum of the expression under discussion is $(\beta+\gamma)(b-a)^{2}$, which is attained for $x=y=a, z=b$ and for $x=y=b, z=a$.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by D. Andrica and I. Raşa)

435. The left-hand side of the inequality under discussion is a convex function in each $x_{i}$. Hence in order to maximize this expression we must choose some of the $x_{i}$ 's equal to $a$ and the others equal to $b$. For such a choice, denote by $u$ the sum of the $t_{i}$ 's for which $x_{i}=a$ and by $v$ the sum of the $t_{i}$ 's for which $x_{i}=b$. It remains to prove the simpler inequality

$$
(u a+b v)\left(\frac{u}{a}+\frac{v}{b}\right) \leq \frac{(a+b)^{2}}{4 a b}(u+b)^{2} .
$$

This is equivalent to

$$
4(u a+v b)(u b+v a) \leq(u a+v b+u b+v a)^{2},
$$

which is the AM-GM inequality applied to $u a+v b$ and $u b+v a$.

(L.V. Kantorovich)

436. Expanding with Newton's binomial formula, we obtain

$$
(1+x)^{n}+(1-x)^{n}=\sum_{k=0}^{\left\lfloor\frac{n}{2}\right\rfloor}\left(\begin{array}{c}
n \\
2 k
\end{array}\right) x^{2 k} .
$$

The coefficients in the expansion are positive, so the expression is a convex function in $x$ (being a sum of power functions that are convex). Its maximum is attained when $|x|=1$, in which case the value of the expression is $2^{n}$. This proves the inequality.

(C. Năstăsescu, C. Niţ̆a, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogică, Bucharest, 1983) 

437. Without loss of generality, we may assume that $b$ is the number in the middle. The inequality takes the form

$$
a+b+c-3 \sqrt[3]{a b c} \leq 3(a+c-2 \sqrt{a c}) .
$$

For fixed $a$ and $c$, define $f:[a, c] \rightarrow \mathbb{R}, f(b)=3(a+c-2 \sqrt{a c})-a-b-c+3 \sqrt{a b c}$. This function is concave because $f^{\prime \prime}(b)=-\frac{2}{3}(a c)^{1 / 3} b^{-5 / 3}<0$, so it attains its minimum at one of the endpoints of the interval $[a, c]$. Thus the minimum is attained for $b=a$ or $b=c$. Let us try the case $b=a$. We may rescale the variables so that $a=b=1$. The inequality becomes

$$
\frac{2 c+3 c^{1 / 3}+1}{6} \geq c^{1 / 2},
$$

and this is just an instance of the generalized AM-GM inequality. The case $a=c$ is similar.

(USA Team Selection Test for the International Mathematical Olympiad, 2002, proposed by T. Andreescu)

438. For (a) we apply Sturm's principle. Given $x \in(a, b)$ choose $h>0$ such that $a<$ $x-h<x+h<b$. The mean value theorem implies that $f(x) \leq \max _{x-h \leq y \leq x+y} f(y)$, with equality only when $f$ is constant on $[x-h, x+h]$. Hence $f(x)$ is less than or equal to the maximum of $f$ on $[a, b]$, with equality if and only if $f$ is constant on $[a, b]$. We know that the maximum of $f$ is attained on $[a, b]$. It can be attained at $x$ only if $f$ is constant on $[a, b]$. This proves that the maximum is attained at one of the endpoints of the interval.

To prove (b) we define the linear function

$$
L(x)=\frac{(x-a) f(b)+(b-x) f(a)}{b-a} .
$$

It is straightforward to verify that $L$ itself satisfies the mean value inequality from the statement with equality, and so does $-L$. Therefore, the function $G(x)=f(x)-L(x)$ satisfies the mean value inequality, too. It follows that $G$ takes its maximum value at $a$ or at $b$. A calculation shows that $G(a)=G(b)=0$. Therefore, $G(x) \leq 0$ for $x \in[a, b]$. This is equivalent to

$$
f(x) \leq \frac{(x-a) f(b)+(b-x) f(a)}{b-a},
$$

which is, in fact, the condition for $f$ to be convex.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

439. The function $f(t)=\sin t$ is concave on the interval $[0, \pi]$. Jensen's inequality yields

$$
\sin A+\sin B+\sin C \geq 3 \sin \frac{A+B+C}{3}=3 \sin \frac{\pi}{3}=\frac{3 \sqrt{3}}{2} .
$$

440. If we set $y_{i}=\ln x_{i}$, then $x_{i} \in(0,1]$ implies $y_{i} \leq 0, i=1,2, \ldots, n$. Consider the function $f:(-\infty, 0] \rightarrow \mathbb{R}, f(y)=\left(1+e^{y}\right)^{-1}$. This function is twice differentiable and

$$
f^{\prime \prime}(y)=e^{y}\left(e^{y}-1\right)\left(1+e^{y}\right)^{-3} \leq 0, \quad \text { for } y \leq 0 .
$$

It follows that this function is concave, and we can apply Jensen's inequality to the points $y_{1}, y_{2}, \ldots, y_{n}$ and the weights $a_{1}, a_{2}, \ldots, a_{n}$. We have

$$
\begin{aligned}
\sum_{i=1}^{n} \frac{a_{i}}{1+x_{i}} &=\sum_{i=1}^{n} \frac{a_{i}}{1+e_{i}^{y}} \leq \frac{1}{1+e^{n=1} a_{i} y_{i}} \\
&=\frac{1}{1+\prod_{i=1}^{n} e^{a_{i} y_{i}}}=\frac{1}{1+\prod_{i=1}^{n} x_{i}^{a_{i}}},
\end{aligned}
$$

which is the desired inequality.

(D. Buşneag, I. Maftei, Teme pentru cercurile şi concursurile de matematic ă (Themes for mathematics circles and contests), Scrisul Românesc, Craiova)

441. First solution: Apply Jensen's inequality to the convex function $f(x)=x^{2}$ and to

$$
\begin{aligned}
& x_{1}=\frac{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}{2 a_{2} a_{3}}, \quad x_{2}=\frac{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}{2 a_{3} a_{1}}, \quad x_{3}=\frac{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}{2 a_{1} a_{2}}, \\
& \lambda_{1}=\frac{a_{1}^{2}}{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}, \quad \lambda_{2}=\frac{a_{2}^{2}}{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}}, \quad \lambda_{3}=\frac{a_{3}^{2}}{a_{1}^{2}+a_{2}^{2}+a_{3}^{2}} .
\end{aligned}
$$

The inequality

$$
f\left(\lambda_{1} x_{2}+\lambda_{2} x_{2}+\lambda_{3} x_{3}\right) \leq \lambda_{1} f\left(x_{1}\right)+\lambda_{2} f\left(x_{2}\right)+\lambda_{3} f\left(x_{3}\right)
$$

translates to

$$
\frac{\left(a_{1}^{3}+a_{2}^{3}+a_{3}^{3}\right)^{2}}{4 a_{1}^{2} a_{2}^{2} a_{3}^{2}} \leq \frac{\left(a_{1}^{4}+a_{2}^{4}+a_{3}^{4}\right)\left(a_{1}^{2}+a_{2}^{2}+a_{3}^{2}\right)}{4 a_{1}^{2} a_{2}^{2} a_{3}^{2}},
$$

and the conclusion follows.

Second solution: The inequality from the statement is equivalent to 

$$
\left(a_{1}^{2}+a_{2}^{2}+a_{3}^{2}\right)\left(a_{1}^{4}+a_{2}^{4}+a_{3}^{4}\right) \geq\left(a_{1}^{3}+a_{2}^{3}+a_{3}^{3}\right)^{2} .
$$

This is just the Cauchy-Schwarz inequality applied to $a_{1}, a_{2}, a_{3}$, and $a_{1}^{2}, a_{2}^{2}, a_{3}^{2}$.

\section{(Gazeta Matematică (Mathematics Gazette), Bucharest)}

442. Take the natural logarithm of both sides, which are positive because $x_{i} \in(0, \pi)$, $i=1,2, \ldots, n$, to obtain the equivalent inequality

$$
\sum_{i=1}^{n} \ln \frac{\sin x_{i}}{x_{i}} \leq n \ln \frac{\sin x}{x} .
$$

All we are left to check is that the function $f(t)=\ln \frac{\sin t}{t}$ is concave on $(0, \pi)$.

Because $f(t)=\ln \sin t-\ln t$, its second derivative is

$$
f^{\prime \prime}(t)=-\frac{1}{\sin ^{2} t}+\frac{1}{t^{2}} .
$$

The fact that this is negative follows from $\sin t<t$ for $t>0$, and the inequality is proved.

(39th W.L. Putnam Mathematical Competition, 1978)

443. The function $f:(0,1) \rightarrow \mathbb{R}, f(x)=\frac{x}{\sqrt{1-x}}$ is convex. By Jensen's inequality,

$$
\frac{1}{n} \sum_{i=1}^{n} \frac{x_{i}}{\sqrt{1-x_{i}}} \geq \frac{\frac{1}{n} \sum_{i=1}^{n} x_{i}}{\sqrt{1-\frac{1}{n} \sum_{i=1}^{n} x_{i}}}=\frac{1}{\sqrt{n(n-1)}} .
$$

We have thus found that

$$
\frac{x_{1}}{\sqrt{1-x_{1}}}+\frac{x_{2}}{\sqrt{1-x_{2}}}+\cdots+\frac{x_{n}}{\sqrt{1-x_{n}}} \geq \sqrt{\frac{n}{n-1}} .
$$

On the other hand, by the Cauchy-Schwarz inequality

$$
n=n \sum_{i=1}^{n} x_{i} \geq\left(\sum_{i=1}^{n} \sqrt{x_{i}}\right)^{2},
$$

whence $\sum_{i=1}^{n} \sqrt{x_{i}} \leq \sqrt{n}$. It follows that

$$
\frac{\sqrt{x_{1}}+\sqrt{x_{2}}+\cdots+\sqrt{x_{n}}}{\sqrt{n-1}} \leq \sqrt{\frac{n}{n-1}} .
$$

Combining the two inequalities, we obtain the one from the statement. 

444. Split the integral as

$$
\int e^{x^{2}} d x+\int 2 x^{2} e^{x^{2}} d x .
$$

Denote the first integral by $I_{1}$. Then use integration by parts to transform the second integral as

$$
\int 2 x^{2} e^{x^{2}} d x=x e^{x^{2}}-\int e^{x^{2}} d x=x e^{x^{2}}-I_{1} .
$$

The integral from the statement is therefore equal to

$$
I_{1}+x e^{x^{2}}-I_{1}=x e^{x^{2}}+C .
$$

445. Adding and subtracting $e^{x}$ in the numerator, we obtain

$$
\begin{aligned}
\int \frac{x+\sin x-\cos x-1}{x+e^{x}+\sin x} d x &=\int \frac{x+e^{x}+\sin x-1-e^{x}-\cos x}{x+e^{x}+\sin x} d x \\
&=\int \frac{x+e^{x}+\sin x}{x+e^{x}+\sin x} d x-\int \frac{1+e^{x}+\cos x}{x+e^{x}+\sin x} d x \\
&=x+\ln \left(x+e^{x}+\sin x\right)+C .
\end{aligned}
$$

(Romanian college entrance exam)

446. The trick is to bring a factor of $x$ inside the cube root:

$$
\int\left(x^{6}+x^{3}\right) \sqrt[3]{x^{3}+2} d x=\int\left(x^{5}+x^{2}\right) \sqrt[3]{x^{6}+2 x^{3}} d x .
$$

The substitution $u=x^{6}+2 x^{3}$ now yields the answer

$$
\frac{1}{6}\left(x^{6}+2 x^{3}\right)^{4 / 3}+C .
$$

(G.T. Gilbert, M.I. Krusemeyer, L.C. Larson, The Wohascum County Problem Book, MAA, 1993)

447. We want to avoid the lengthy method of partial fraction decomposition. To this end, we rewrite the integral as

$$
\int \frac{x^{2}\left(1+\frac{1}{x^{2}}\right)}{x^{2}\left(x^{2}-1+\frac{1}{x^{2}}\right)} d x=\int \frac{1+\frac{1}{x^{2}}}{x^{2}-1+\frac{1}{x^{2}}} d x .
$$

With the substitution $x-\frac{1}{x}=t$ we have $\left(1+\frac{1}{x^{2}}\right) d x=d t$, and the integral takes the form

$$
\int \frac{1}{t^{2}+1} d t=\arctan t+C
$$

We deduce that the integral from the statement is equal to

$$
\arctan \left(x-\frac{1}{x}\right)+C
$$

448. Substitute $u=\sqrt{\frac{e^{x}-1}{e^{x}+1}}, 0<u<1$. Then $x=\ln \left(1+u^{2}\right)-\ln \left(1-u^{2}\right)$, and $d x=\left(\frac{2 u}{1+u^{2}}+\frac{2 u}{1-u^{2}}\right) d u$. The integral becomes

$$
\begin{aligned}
\int u\left(\frac{2 u}{u^{2}+1}+\frac{2 u}{u^{2}-1}\right) d u &=\int\left(4-\frac{2}{u^{2}+1}+\frac{2}{u^{2}-1}\right) d u \\
&=4 u-2 \arctan u+\int\left(\frac{1}{u+1}+\frac{1}{1-u}\right) d u \\
&=4 u-2 \arctan u+\ln (u+1)-\ln (u-1)+C .
\end{aligned}
$$

In terms of $x$, this is equal to

$$
4 \sqrt{\frac{e^{x}-1}{e^{x}+1}}-2 \arctan \sqrt{\frac{e^{x}-1}{e^{x}+1}}+\ln \left(\sqrt{\frac{e^{x}-1}{e^{x}+1}}+1\right)-\ln \left(\sqrt{\frac{e^{x}-1}{e^{x}+1}}-1\right)+C
$$

449. If we naively try the substitution $t=x^{3}+1$, we obtain

$$
f(t)=\sqrt{t+1-2 \sqrt{t}}+\sqrt{t+9-6 \sqrt{t}}
$$

Now we recognize the perfect squares, and we realize that

$$
f(x)=\sqrt{\left(\sqrt{x^{3}+1}-1\right)^{2}}+\sqrt{\left(\sqrt{x^{3}+1}-3\right)^{2}}=\left|\sqrt{x^{3}+1}-1\right|+\left|\sqrt{x^{3}+1}-3\right| .
$$

When $x \in[0,2], 1 \leq \sqrt{x^{3}+1} \leq 3$. Therefore,

$$
f(x)=\sqrt{x^{3}+1}-1+3-\sqrt{x^{3}+1}=2 .
$$

The antiderivatives of $f$ are therefore the linear functions $f(x)=2 x+C$, where $C$ is a constant.

(communicated by E. Craina)

450. Let $f_{n}=1+x+\frac{x^{2}}{2 !}+\cdots+\frac{x^{n}}{n !}$. Then $f^{\prime}(x)=1+x+\cdots+\frac{x^{n-1}}{(n-1) !}$. The integral in the statement becomes 

$$
\begin{aligned}
I_{n} &=\int \frac{n !\left(f_{n}(x)-f_{n}^{\prime}(x)\right)}{f_{n}(x)} d x=n ! \int\left(1-\frac{f_{n}^{\prime}(x)}{f_{n}(x)}\right) d x=n ! x-n ! \ln f_{n}(x)+C \\
&=n ! x-n ! \ln \left(1+x+\frac{x^{2}}{2 !}+\cdots+\frac{x^{n}}{n !}\right)+C .
\end{aligned}
$$

(C. Mortici, Probleme Pregătitoare pentru Concursurile de Matematic $\breve{a}$ (Training Problems for Mathematics Contests), GIL, 1999)

451. The substitution is

$$
u=\frac{x}{\sqrt[4]{2 x^{2}-1}}
$$

for which

$$
d u=\frac{x^{2}-1}{\left(2 x^{2}-1\right) \sqrt[4]{2 x^{2}-1}} d x
$$

We can transform the integral as follows:

$$
\begin{aligned}
\int \frac{2 x^{2}-1}{-\left(x^{2}-1\right)^{2}} \cdot \frac{x^{2}-1}{\left(2 x^{2}-1\right) \sqrt[4]{2 x^{2}-1}} d x &=\int \frac{1}{\frac{-x^{4}+2 x^{2}-1}{2 x^{2}-1}} \cdot \frac{x^{2}-1}{\left(2 x^{2}-1\right) \sqrt[4]{2 x^{2}-1}} d x \\
&=\int \frac{1}{1-\frac{x^{4}}{2 x^{2}-1}} \cdot \frac{x^{2}-1}{\left(2 x^{2}-1\right) \sqrt[4]{2 x^{2}-1}} d x \\
&=\int \frac{1}{1-u^{4}} d u
\end{aligned}
$$

This is computed using Jacobi's method for rational functions, giving the final answer to the problem

$$
\frac{1}{4} \ln \frac{\sqrt[4]{2 x^{2}-1}+x}{\sqrt[4]{2 x^{2}-1}-x}-\frac{1}{2} \arctan \frac{\sqrt[4]{2 x^{2}-1}}{x}+C
$$

452. Of course, Jacobi's partial fraction decomposition method can be applied, but it is more laborious. However, in the process of applying it we factor the denominator as $x^{6}+1=\left(x^{2}+1\right)\left(x^{4}-x^{2}+1\right)$, and this expression can be related somehow to the numerator. Indeed, if we add and subtract an $x^{2}$ in the numerator, we obtain

$$
\frac{x^{4}+1}{x^{6}+1}=\frac{x^{4}-x^{2}+1}{x^{6}+1}+\frac{x^{2}}{x^{6}+1}
$$

Now integrate as follows:

$$
\int \frac{x^{4}+1}{x^{6}+1} d x=\int \frac{x^{4}-x^{2}+1}{x^{6}+1} d x+\int \frac{x^{2}}{x^{6}+1} d x=\int \frac{1}{x^{2}+1} d x+\int \frac{1}{3} \frac{\left(x^{3}\right)^{\prime}}{\left(x^{3}\right)^{2}+1} d x
$$



$$
=\arctan x+\frac{1}{3} \arctan x^{3} .
$$

To write the answer in the required form we should have

$$
3 \arctan x+\arctan x^{3}=\arctan \frac{P(x)}{Q(x)} .
$$

Applying the tangent function to both sides, we deduce

$$
\frac{\frac{3 x-x^{3}}{1-3 x^{2}}+x^{3}}{1-\frac{3 x-x^{3}}{1-3 x^{2}} \cdot x^{3}}=\tan \left(\arctan \frac{P(x)}{Q(x)}\right) .
$$

From here

$$
\arctan \frac{P(x)}{Q(x)}=\arctan \frac{3 x-3 x^{5}}{1-3 x^{2}-3 x^{4}+x^{6}},
$$

and hence $P(x)=3 x-3 x^{5}, Q(x)=1-3 x^{2}-3 x^{4}+x^{6}$. The final answer is

$$
\frac{1}{3} \arctan \frac{3 x-3 x^{5}}{1-3 x^{2}-3 x^{4}+x^{6}}+C .
$$

453. The function $f:[-1,1] \rightarrow \mathbb{R}$,

$$
f(x)=\frac{\sqrt[3]{x}}{\sqrt[3]{1-x}+\sqrt[3]{1+x}},
$$

is odd; therefore, the integral is zero.

454. We use the example from the introduction for the particular function $f(x)=\frac{x}{1+x^{2}}$ to transform the integral into

$$
\pi \int_{0}^{\frac{\pi}{2}} \frac{\sin x}{1+\sin ^{2} x} d x .
$$

This is the same as

$$
\pi \int_{0}^{\frac{\pi}{2}}-\frac{d(\cos x)}{2-\cos ^{2} x},
$$

which with the substitution $t=\cos x$ becomes

$$
\pi \int_{0}^{1} \frac{1}{2-t^{2}} d t=\left.\frac{\pi}{2 \sqrt{2}} \ln \frac{\sqrt{2}+t}{\sqrt{2}-t}\right|_{0} ^{1}=\frac{\pi}{2 \sqrt{2}} \ln \frac{\sqrt{2}+1}{\sqrt{2}-1} .
$$

455. Denote the value of the integral by $I$. With the substitution $t=\frac{a b}{x}$ we have

$$
I=\int_{a}^{b} \frac{e^{\frac{b}{t}}-e^{\frac{t}{a}}}{\frac{a b}{t}} \cdot \frac{-a b}{t^{2}} d t=-\int_{a}^{b} \frac{e^{\frac{t}{a}}-e^{\frac{b}{t}}}{t} d t=-I .
$$

Hence $I=0$.

456. The substitution $t=1-x$ yields

$$
I=\int_{0}^{1} \sqrt[3]{2(1-t)^{3}-3(1-t)^{2}-(1-t)+1} d t=-\int_{0}^{1} \sqrt[3]{2 t^{3}-3 t^{2}-t+1} d t=-I .
$$

Hence $I=0$.

(Mathematical Reflections, proposed by T. Andreescu)

457. Using the substitutions $x=a \sin t$, respectively, $x=a \cos t$, we find the integral to be equal to both the integral

$$
L_{1}=\int_{0}^{\pi / 2} \frac{\sin t}{\sin t+\cos t} d t
$$

and the integral

$$
L_{2}=\int_{0}^{\pi / 2} \frac{\cos t}{\sin t+\cos t} d t .
$$

Hence the desired integral is equal to

$$
\frac{1}{2}\left(L_{1}+L_{2}\right)=\frac{1}{2} \int_{0}^{\frac{\pi}{2}} 1 d t=\frac{\pi}{4} .
$$

458. Denote the integral by $I$. With the substitution $t=\frac{\pi}{4}-x$ the integral becomes

$$
\begin{aligned}
I &=\int_{\frac{\pi}{4}}^{0} \ln \left(1+\tan \left(\frac{\pi}{4}-t\right)\right)(-1) d t=\int_{0}^{\frac{\pi}{4}} \ln \left(1+\frac{1-\tan t}{1+\tan t}\right) d t \\
&=\int_{0}^{\frac{\pi}{4}} \ln \frac{2}{1+\tan t} d t=\frac{\pi}{4} \ln 2-I .
\end{aligned}
$$

Solving for $I$, we obtain $I=\frac{\pi}{8} \ln 2$.

459. With the substitution $\arctan x=t$ the integral takes the form

$$
I=\int_{0}^{\frac{\pi}{4}} \ln (1+\tan t) d t .
$$

This we already computed in the previous problem. ("Happiness is longing for repetition," says M. Kundera.) So the answer to the problem is $\frac{\pi}{8} \ln 2$.

(66th W.L. Putnam Mathematical Competition, 2005, proposed by T. Andreescu)

460. The function $\ln x$ is integrable near zero, and the function under the integral sign is dominated by $x^{-3 / 2}$ near infinity; hence the improper integral converges. We first treat the case $a=1$. The substitution $x=1 / t$ yields

$$
\int_{0}^{\infty} \frac{\ln x}{x^{2}+1} d x=\int_{\infty}^{0} \frac{\ln \frac{1}{t}}{\frac{1}{t^{2}}+1}\left(-\frac{1}{t^{2}}\right) d t=-\int_{0}^{\infty} \frac{\ln t}{t^{2}+1} d t
$$

which is the same integral but with opposite sign. This shows that for $a=1$ the integral is equal to 0 . For general $a$ we compute the integral using the substitution $x=a / t$ as follows

$$
\begin{aligned}
\int_{0}^{\infty} \frac{\ln x}{x^{2}+a^{2}} d x &=\int_{\infty}^{0} \frac{\ln a-\ln t}{\left(\frac{a}{t}\right)^{2}+a^{2}} \cdot\left(-\frac{a}{t^{2}}\right) d t=\frac{1}{a} \int_{0}^{\infty} \frac{\ln a-\ln t}{1+t^{2}} d t \\
&=\frac{\ln a}{a} \int_{0}^{\infty} \frac{d t}{t^{2}+1}-\frac{1}{a} \int_{0}^{\infty} \frac{\ln t}{t^{2}+1} d t=\frac{\pi \ln a}{2 a}
\end{aligned}
$$

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

461. The statement is misleading. There is nothing special about the limits of integration! The indefinite integral can be computed as follows:

$$
\begin{aligned}
\int \frac{x \cos x-\sin x}{x^{2}+\sin ^{2} x} d x &=\int \frac{\frac{\cos x}{x}-\frac{\sin x}{x^{2}}}{1+\left(\frac{\sin x}{x}\right)^{2}} d x=\int \frac{1}{1+\left(\frac{\sin x}{x}\right)^{2}}\left(\frac{\sin x}{x}\right)^{\prime} d x \\
&=\arctan \left(\frac{\sin x}{x}\right)+C .
\end{aligned}
$$

Therefore,

$$
\int_{0}^{\frac{\pi}{2}} \frac{x \cos x-\sin x}{x^{2}+\sin ^{2} x} d x=\arctan \frac{2}{\pi}-\frac{\pi}{4} .
$$

(Z. Ahmed)

462. If $\alpha$ is a multiple of $\pi$, then $I(\alpha)=0$. Otherwise, use the substitution $x=$ $\cos \alpha+t \sin \alpha$. The indefinite integral becomes

$$
\int \frac{\sin \alpha d x}{1-2 x \cos \alpha+x^{2}}=\int \frac{d t}{1+t^{2}}=\arctan t+C .
$$

It follows that the definite integral $I(\alpha)$ has the value 

$$
\arctan \left(\frac{1-\cos \alpha}{\sin \alpha}\right)-\arctan \left(\frac{-1-\cos \alpha}{\sin \alpha}\right)
$$

where the angles are to be taken between $-\frac{\pi}{2}$ and $\frac{\pi}{2}$. But

$$
\frac{1-\cos \alpha}{\sin \alpha} \times \frac{-1-\cos \alpha}{\sin \alpha}=-1 \text {. }
$$

Hence the difference between these angles is $\pm \frac{\pi}{2}$. Notice that the sign of the integral is the same as the sign of $\alpha$. Hence $I(\alpha)=\frac{\pi}{2}$ if $\alpha \in(2 k \pi,(2 k+1) \pi)$ and $-\frac{\pi}{2}$ if $\alpha \in((2 k+1) \pi,(2 k+2) \pi)$ for some integer $k$.

Remark. This is an example of an integral with parameter that does not depend continuously on the parameter.

(E. Goursat, A Course in Mathematical Analysis, Dover, NY, 1904)

463. First, note that $1 / \sqrt{x}$ has this property for $p>2$. We will alter slightly this function to make the integral finite for $p=2$. Since we know that logarithms grow much slower than power functions, a possible choice might be

$$
f(x)=\frac{1}{\sqrt{x} \ln x}
$$

Then

$$
\int_{2}^{\infty} f^{2}(x) d x=\int_{2}^{\infty} \frac{1}{x \ln ^{2} x}=-\left.\frac{1}{\ln x}\right|_{2} ^{\infty}=\frac{1}{\ln 2}<\infty
$$

Consequently, the integral of $f^{p}$ is finite for all real numbers $p \geq 2$.

Let us see what happens for $p<2$. An easy application of L'Hôpital's theorem gives

$$
\lim _{x \rightarrow \infty} \frac{f(x)^{p}}{x^{-1}}=\lim _{x \rightarrow \infty} \frac{x^{-\frac{p}{2}} \ln ^{-p} x}{x^{-1}}=\lim _{x \rightarrow \infty} \frac{x^{1-\frac{p}{2}}}{\ln ^{p} x}=\infty
$$

and hence the comparison test implies that for $p<2$ the integral is infinite. Therefore, $f(x)=\frac{1}{\sqrt{x} \ln x}$ satisfies the required condition.

Remark. Examples like the above are used in measure theory to prove that inclusions between $L^{p}$ spaces are strict.

464. Let $n$ be the degree of $P(x)$. Integrating successively by parts, we obtain

$$
\begin{aligned}
\int_{0}^{t} e^{-x} P(x) d t &=-\left.e^{-x} P(x)\right|_{0} ^{t}+\int_{0}^{t} e^{-x} P^{\prime}(x) d x \\
&=-\left.e^{-x} P(x)\right|_{0} ^{t}-\left.e^{-x} P^{\prime}(x)\right|_{0} ^{t}+\int_{0}^{t} e^{-x} P^{\prime}(x) d x=\cdots
\end{aligned}
$$



$$
=-\left.e^{-x} P(x)\right|_{0} ^{t}-\left.e^{-x} P^{\prime}(x)\right|_{0} ^{t}-\cdots-\left.e^{-x} P^{(n)}(x)\right|_{0} ^{t}
$$

Because $\lim _{t \rightarrow \infty} e^{-t} P^{(k)}(t)=0, k=0,1, \ldots, n$, when passing to the limit we obtain

$$
\lim _{t \rightarrow \infty} \int_{0}^{t} e^{-x} P(x) d x=P(0)+P^{\prime}(0)+P^{\prime \prime}(0)+\cdots
$$

hence the conclusion.

465. First, note that by L'Hôpital's theorem,

$$
\lim _{x \rightarrow 0} \frac{1-\cos n x}{1-\cos x}=n^{2},
$$

which shows that the absolute value of the integrand is bounded as $x$ approaches 0 , and hence the integral converges.

Denote the integral by $I_{n}$. Then

$$
\begin{aligned}
\frac{I_{n+1}+I_{n-1}}{2} &=\int_{0}^{\pi} \frac{2-\cos (n+1) x-\cos (n-1) x}{2(1-\cos x)} d x=\int_{0}^{\pi} \frac{1-\cos n x \cos x}{1-\cos x} d x \\
&=\int_{0}^{\pi} \frac{(1-\cos n x)+\cos n x(1-\cos x)}{1-\cos x} d x=I_{n}+\int_{0}^{\pi} \cos n x d x=I_{n}
\end{aligned}
$$

Therefore,

$$
I_{n}=\frac{1}{2}\left(I_{n+1}+I_{n-1}\right), \quad n \geq 1
$$

This shows that $I_{0}, I_{1}, I_{2}, \ldots$ is an arithmetic sequence. From $I_{0}=0$ and $I_{1}=\pi$ it follows that $I_{n}=n \pi, n \geq 1$.

466. Integration by parts gives

$$
\begin{aligned}
I_{n} &=\int_{0}^{\pi / 2} \sin ^{n} x d x=\int_{0}^{\pi / 2} \sin ^{n-1} x \sin x d x \\
&=-\left.\sin ^{n-1} x \cos ^{2} x\right|_{0} ^{\pi / 2}+(n-1) \int_{0}^{\pi / 2} \sin ^{n-2} x \cos ^{2} x d x \\
&=(n-1) \int_{0}^{\pi / 2} \sin ^{n-2} x\left(1-\sin ^{2} x\right) d x=(n-1) I_{n-2}-(n-1) I_{n} .
\end{aligned}
$$

We obtain the recursive formula

$$
I_{n}=\frac{n-1}{n} I_{n-2}, \quad n \geq 2 .
$$

This combined with $I_{0}=\frac{\pi}{2}$ and $I_{1}=1$ yields 

$$
I_{n}= \begin{cases}\frac{1 \cdot 3 \cdot 5 \cdots(2 k-1)}{2 \cdot 4 \cdot 6 \cdots(2 k)} \cdot \frac{\pi}{2}, & \text { if } n=2 k, \\ \frac{2 \cdot 4 \cdot 6 \cdots(2 k)}{1 \cdot 3 \cdot 5 \cdots(2 k+1)}, & \text { if } n=2 k+1 .\end{cases}
$$

To prove the Wallis formula, we use the obvious inequality $\sin ^{2 n+1} x<\sin ^{2 n} x<$ $\sin ^{2 n-1} x, x \in\left(0, \frac{\pi}{2}\right)$ to deduce that $I_{2 n+1}<I_{2 n}<I_{2 n-1}, n \geq 1$. This translates into

$$
\frac{2 \cdot 4 \cdot 6 \cdots(2 n)}{1 \cdot 3 \cdot 5 \cdots(2 n+1)}<\frac{1 \cdot 3 \cdot 5 \cdots(2 n-1)}{2 \cdot 4 \cdot 6 \cdots(2 n)} \cdot \frac{\pi}{2}<\frac{2 \cdot 4 \cdot 6 \cdots(2 n-2)}{1 \cdot 3 \cdot 5 \cdots(2 n-1)},
$$

which is equivalent to

$$
\left[\frac{2 \cdot 4 \cdot 6 \cdots(2 n)}{1 \cdot 3 \cdot 5 \cdots(2 n-1)}\right]^{2} \cdot \frac{2}{2 n+1}<\pi<\left[\frac{2 \cdot 4 \cdot 6 \cdots(2 n)}{1 \cdot 3 \cdot 5 \cdots(2 n-1)}\right]^{2} \cdot \frac{2}{2 n} .
$$

We obtain the double inequality

$$
\pi<\left[\frac{2 \cdot 4 \cdot 6 \cdots(2 n)}{1 \cdot 3 \cdot 5 \cdots(2 n-1)}\right]^{2} \cdot \frac{1}{n}<\pi \cdot \frac{2 n+1}{2 n} .
$$

Passing to the limit and using the squeezing principle, we obtain the Wallis formula.

467. Denote the integral from the statement by $I_{n}, n \geq 0$. We have

$$
I_{n}=\int_{-\pi}^{0} \frac{\sin n x}{\left(1+2^{x}\right) \sin x} d x+\int_{0}^{\pi} \frac{\sin n x}{\left(1+2^{x}\right) \sin x} d x .
$$

In the first integral change $x$ to $-x$ to further obtain

$$
\begin{aligned}
I_{n} &=\int_{0}^{\pi} \frac{\sin n x}{\left(1+2^{-x}\right) \sin x} d x+\int_{0}^{\pi} \frac{\sin n x}{\left(1+2^{x}\right) \sin x} d x \\
&=\int_{0}^{\pi} \frac{2^{x} \sin n x}{\left(1+2^{x}\right) \sin x} d x+\int_{0}^{\pi} \frac{\sin n x}{\left(1+2^{x}\right) \sin x} d x \\
&=\int_{0}^{\pi} \frac{\left(1+2^{x}\right) \sin n x}{\left(1+2^{x}\right) \sin x} d x=\int_{0}^{\pi} \frac{\sin n x}{\sin x} d x .
\end{aligned}
$$

And these integrals can be computed recursively. Indeed, for $n \geq 0$ we have

$$
I_{n+2}-I_{n}=\int_{0}^{\pi} \frac{\sin (n+2) x-\sin n x}{\sin x} d x=2 \int_{0}^{\pi} \cos (n-1) x d x=0,
$$

a very simple recurrence. Hence for $n$ even, $I_{n}=I_{0}=0$, and for $n$ odd, $I_{n}=I_{1}=\pi$.

(3rd International Mathematics Competition for University Students, 1996) 

468. We have

$$
\begin{aligned}
s_{n} &=\frac{1}{\sqrt{4 n^{2}-1^{2}}}+\frac{1}{\sqrt{4 n^{2}-2^{2}}}+\cdots+\frac{1}{\sqrt{4 n^{2}-n^{2}}} \\
&=\frac{1}{n}\left[\frac{1}{\sqrt{4-\left(\frac{1}{n}\right)^{2}}}+\frac{1}{\sqrt{4-\left(\frac{2}{n}\right)^{2}}}+\cdots+\frac{1}{\sqrt{4-\left(\frac{n}{n}\right)^{2}}}\right] .
\end{aligned}
$$

Hence $s_{n}$ is the Riemann sum of the function $f:[0,1] \rightarrow \mathbb{R}, f(x)=\frac{1}{\sqrt{4-x^{2}}}$ associated to the subdivision $x_{0}=0<x_{1}=\frac{1}{n}<x_{2}=\frac{2}{n}<\cdots<x_{n}=\frac{n}{n}=1$, with the intermediate points $\xi_{i}=\frac{i}{n} \in\left[x_{i}, x_{i+1}\right]$. The answer to the problem is therefore

$$
\lim _{n \rightarrow \infty} s_{n}=\int_{0}^{1} \frac{1}{\sqrt{4-x^{2}}} d x=\left.\arcsin \frac{x}{2}\right|_{0} ^{1}=\frac{\pi}{6} .
$$

469. Write the inequality as

$$
\frac{1}{n} \sum_{i=1}^{n} \frac{1}{\sqrt{2 \frac{i}{n}+5}}<\sqrt{7}-\sqrt{5}
$$

The left-hand side is the Riemann sum of the strictly decreasing function $f(x)=\frac{1}{\sqrt{2 x+5}}$. This Riemann sum is computed at the right ends of the intervals of the subdivision of $[0,1]$ by the points $\frac{i}{n}, i=1,2, \ldots, n-1$. It follows that

$$
\frac{1}{n} \sum_{i=1}^{n} \frac{1}{\sqrt{2 \frac{i}{n}+5}}<\int_{0}^{1} \frac{1}{\sqrt{2 x+5}} d x=\left.\sqrt{2 x+5}\right|_{0} ^{1}=\sqrt{7}-\sqrt{5},
$$

the desired inequality.

(communicated by E. Craina)

470. We would like to recognize the general term of the sequence as being a Riemann sum. This, however, does not seem to happen, since we can only write

$$
\sum_{i=1}^{n} \frac{2^{i / n}}{n+\frac{1}{i}}=\frac{1}{n} \sum_{i=1}^{n} \frac{2^{i / n}}{1+\frac{1}{n i}} .
$$

But for $i \geq 2$,

$$
2^{i / n}>\frac{2^{i / n}}{1+\frac{1}{n i}},
$$

and, using the inequality $e^{x}>1+x$,

$$
\frac{2^{i / n}}{1+\frac{1}{n i}}=2^{(i-1) / n} \frac{2^{1 / n}}{1+\frac{1}{n i}}=2^{(i-1) / n} \frac{e^{\ln 2 / n}}{1+\frac{1}{n i}}>2^{(i-1) / n} \frac{1+\frac{\ln 2}{n}}{1+\frac{1}{n i}}>2^{(i-1) / n},
$$

for $i \geq 2$. By the intermediate value property, for each $i \geq 2$ there exists $\xi_{i} \in\left[\frac{i-1}{n}, \frac{i}{n}\right]$ such that

$$
\frac{2^{i / n}}{1+\frac{1}{n i}}=2^{\xi_{i}} .
$$

Of course, the term corresponding to $i=1$ can be neglected when $n$ is large. Now we see that our limit is indeed the Riemann sum of the function $2^{x}$ integrated over the interval $[0,1]$. We obtain

$$
\lim _{n \rightarrow \infty}\left(\frac{2^{1 / n}}{n+1}+\frac{2^{2 / n}}{n+\frac{1}{2}}+\cdots+\frac{2^{n / n}}{n+\frac{1}{n}}\right)=\int_{0}^{1} 2^{x} d x=\frac{1}{\ln 2}
$$

(Soviet Union University Student Mathematical Olympiad, 1976)

471. This is an example of an integral that is determined using Riemann sums. Divide the interval $[0, \pi]$ into $n$ equal parts and consider the Riemann sum

$$
\begin{array}{r}
\frac{\pi}{n}\left[\ln \left(a^{2}-2 a \cos \frac{\pi}{n}+1\right)+\ln \left(a^{2}-2 a \cos \frac{2 \pi}{n}+1\right)+\cdots\right. \\
\left.+\ln \left(a^{2}-2 a \cos \frac{(n-1) \pi}{n}+1\right)\right] .
\end{array}
$$

This expression can be written as

$$
\frac{\pi}{n} \ln \left(a^{2}-2 a \cos \frac{\pi}{n}+1\right)\left(a^{2}-2 a \cos \frac{2 \pi}{n}+1\right) \ldots\left(a^{2}-2 a \cos \frac{(n-1) \pi}{n}+1\right) .
$$

The product inside the natural logarithm factors as

$$
\prod_{k=1}^{n-1}\left[a-\left(\cos \frac{k \pi}{n}+i \sin \frac{k \pi}{n}\right)\right]\left[a-\left(\cos \frac{k \pi}{n}-i \sin \frac{k \pi}{n}\right)\right] .
$$

These are exactly the factors in $a^{2 n}-1$, except for $a-1$ and $a+1$. The Riemann sum is therefore equal to

$$
\frac{\pi}{n} \ln \frac{a^{2 n}-1}{a^{2}-1} .
$$

We are left to compute the limit of this expression as $n$ goes to infinity. If $a \leq 1$, this limit is equal to 0 . If $a>1$, the limit is

$$
\lim _{n \rightarrow \infty} \pi \ln \sqrt[n]{\frac{a^{2 n}-1}{a^{2}-1}}=2 \pi \ln a .
$$

(S.D. Poisson)

472. The condition $f(x) f(2 x) \cdots f(n x) \leq a n^{k}$ can be written equivalently as

$$
\sum_{j=1}^{n} \ln f(j x) \leq \ln a+k \ln n, \quad \text { for all } x \in \mathbb{R}, n \geq 1 .
$$

Taking $\alpha>0$ and $x=\frac{\alpha}{n}$, we obtain

$$
\sum_{j=1}^{n} \ln f\left(\frac{j \alpha}{n}\right) \leq \ln a+k \ln n
$$

or

$$
\sum_{j=1}^{n} \frac{\alpha}{n} \ln f\left(\frac{j \alpha}{n}\right) \leq \frac{\alpha \ln a+k \alpha \ln n}{n} .
$$

The left-hand side is a Riemann sum for the function $\ln f$ on the interval $[0, \alpha]$. Because $f$ is continuous, so is $\ln f$, and thus $\ln f$ is integrable. Letting $n$ tend to infinity, we obtain

$$
\int_{0}^{1} \ln f(x) d x \leq \lim _{n \rightarrow \infty} \frac{\alpha \ln a+k \alpha \ln n}{n}=0 .
$$

The fact that $f(x) \geq 1$ implies that $\ln f(x) \geq 0$ for all $x$. Hence $\ln f(x)=0$ for all $x \in[0, \alpha]$. Since $\alpha$ is an arbitrary positive number, $f(x)=1$ for all $x \geq 0$. A similar argument yields $f(x)=1$ for $x<0$. So there is only one such function, the constant function equal to 1 .

(Romanian Mathematical Olympiad, 1999, proposed by R. Gologan)

473. The relation from the statement can be rewritten as

$$
\int_{0}^{1}\left(x f(x)-f^{2}(x)\right) d x=\int_{0}^{1} \frac{x^{2}}{4} d x .
$$

Moving everything to one side, we obtain

$$
\int_{0}^{1}\left(f^{2}(x)-x f(x)+\frac{x^{2}}{4}\right) d x=0 .
$$

We now recognize a perfect square and write this as

$$
\int_{0}^{1}\left(f(x)-\frac{x}{2}\right)^{2} d x=0 .
$$

The integral of the nonnegative continuous function $\left(f(x)-\frac{x}{2}\right)^{2}$ is strictly positive, unless the function is identically equal to zero. It follows that the only function satisfying the condition from the statement is $f(x)=\frac{x}{2}, x \in[0,1]$.

(Revista de Matematica din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

474. Performing the substitution $x^{\frac{1}{k}}=t$, the given conditions become

$$
\int_{0}^{1}(f(t))^{n-k} t^{k-1} d t=\frac{1}{n}, \quad k=1,2, \ldots, n-1 .
$$

Observe that this equality also holds for $k=n$. With this in mind we write

$$
\begin{aligned}
\int_{0}^{1}(f(t)-t)^{n-1} d t &=\int_{0}^{1} \sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)(-1)^{k}(f(t))^{n-1-k} t^{k} d t \\
&=\int_{0}^{1} \sum_{k=1}^{n}\left(\begin{array}{c}
n-1 \\
k-1
\end{array}\right)(-1)^{k-1}(f(t))^{n-k} t^{k-1} d t \\
&=\sum_{k=1}^{n}(-1)^{k-1}\left(\begin{array}{c}
n-1 \\
k-1
\end{array}\right) \int_{0}^{1}(f(t))^{n-k} t^{k-1} d t \\
&=\sum_{k=1}^{n}(-1)^{k-1}\left(\begin{array}{c}
n-1 \\
k-1
\end{array}\right) \frac{1}{n}=\frac{1}{n}(1-1)^{n-1}=0 .
\end{aligned}
$$

Because $n-1$ is even, $(f(t)-t)^{n-1} \geq 0$. The integral of this function can be zero only if $f(t)-t=0$ for all $t \in[0,1]$. Hence the only solution to the problem is $f:[0,1] \rightarrow \mathbb{R}$, $f(x)=x$.

(Romanian Mathematical Olympiad, 2002, proposed by T. Andreescu)

475. Note that the linear function $g(x)=6 x-2$ satisfies the same conditions as $f$. Therefore,

$$
\int_{0}^{1}(f(x)-g(x)) d x=\int_{0}^{1} x(f(x)-g(x)) d x=0 .
$$

Considering the appropriate linear combination of the two integrals, we obtain

$$
\int_{0}^{1} p(x)(f(x)-g(x)) d x=0 .
$$

We have

$$
\begin{aligned}
0 & \leq \int_{0}^{1}(f(x)-g(x))^{2} d x=\int_{0}^{1} f(x)(f(x)-g(x)) d x-\int_{0}^{1} g(x)(f(x)-g(x)) d x \\
&=\int_{0}^{1} f^{2}(x)-f(x) g(x) d x=\int_{0}^{1} f^{2}(x) d x-6 \int_{0}^{1} x f(x) d x+2 \int_{0}^{1} f(x) d x \\
&=\int_{0}^{1} f^{2}(x) d x-4 .
\end{aligned}
$$

The inequality is proved.

(Romanian Mathematical Olympiad, 2004, proposed by I. Raşa)

476. We change this into a minimum problem, and then relate the latter to an inequality of the form $x \geq 0$. Completing the square, we see that

$$
\left.x(f(x))^{2}-x^{2} f(x)=\sqrt{x} f(x)\right)^{2}-2 \sqrt{x} f(x) \frac{x^{\frac{3}{2}}}{2}=\left(\sqrt{x} f(x)-\frac{x^{\frac{3}{2}}}{2}\right)^{2}-\frac{x^{3}}{4}
$$

Hence, indeed,

$$
J(f)-I(f)=\int_{0}^{1}\left(\sqrt{x} f(x)-\frac{x^{\frac{3}{2}}}{2}\right)^{2} d x-\int_{0}^{1} \frac{x^{3}}{4} d x \geq-\frac{1}{16}
$$

It follows that $I(f)-J(f) \leq \frac{1}{16}$ for all $f$. The equality holds, for example, for $f:[0,1] \rightarrow \mathbb{R}, f(x)=\frac{x}{2}$. We conclude that

$$
\max _{f \in \mathcal{C}^{0}([0,1])}(I(f)-J(f))=\frac{1}{16} .
$$

(49th W.L. Putnam Mathematical Competition, 2006, proposed by T. Andreescu) 

477. We can write the inequality as

$$
\sum_{i, j} x_{i} x_{j}\left(a_{i}+a_{j}-2 \min \left(a_{i}, a_{j}\right)\right) \leq 0 .
$$

Note that

$$
\sum_{i, j} x_{i} x_{j} a_{i}=x_{j} \sum_{i=1}^{n} a_{i} x_{i}=0,
$$

and the same stays true if we exchange $i$ with $j$. So it remains to prove that

$$
\sum_{i, j} x_{i} x_{j} \min \left(a_{i}, a_{j}\right) \geq 0 .
$$

If $\chi_{\left[0, a_{i}\right]}$ is the characteristic function of the interval $\left[0, a_{i}\right]$ (equal to 1 on the interval and to 0 outside), then our inequality is, in fact,

$$
\int_{0}^{\infty}\left(\sum_{i=1}^{n} x_{i} \chi_{\left[0, a_{i}\right]}(t)\right)^{2} d t \geq 0
$$

which is obvious. Equality holds if and only if $\sum_{i=1}^{n} x_{i} \chi_{\left[0, a_{i}\right]}=0$ everywhere except at finitely many points. It is not hard to see that this is equivalent to the condition from the statement.

\section{(G. Dospinescu)}

478. This is just the Cauchy-Schwarz inequality applied to the functions $f$ and $g, g(t)=1$ for $t \in[0,1]$.

479. By Hölder's inequality,

$$
\int_{0}^{3} f(x) \cdot 1 d x \leq\left(\int_{0}^{3}|f(x)|^{3} d x\right)^{\frac{1}{3}}\left(\int_{0}^{3} 1^{\frac{3}{2}} d x\right)^{\frac{2}{3}}=3^{\frac{2}{3}}\left(\int_{0}^{3}|f(x)|^{3} d x\right)^{\frac{1}{3}} .
$$

Raising everything to the third power, we obtain

$$
\left(\int_{0}^{3} f(x) d x\right)^{3} / \int_{0}^{3} f^{3}(x) d x \leq 9 .
$$

To see that the maximum 9 can be achieved, choose $f$ to be constant.

480. The argument relies on Figure 69. The left-hand side is the area of the shaded region (composed of the subgraph of $f$ and the subgraph of $f^{-1}$ ). The product $a b$ is the area of the rectangle $[0, a] \times[0, b]$, which is contained inside the shaded region. Equality holds if and only if the two regions coincide, which is the case exactly when $b=f(a)$.

(Young's inequality)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-557.jpg?height=495&width=640&top_left_y=1623&top_left_x=552)

Figure 69 

481. Suppose that $x>y$. Transform the inequality successively into

$$
m n(x-y)\left(x^{m+n-1}-y^{m+n-1}\right) \geq(m+n-1)\left(x^{m}-y^{m}\right)\left(x^{n}-y^{n}\right),
$$

and then

$$
\frac{x^{m+n-1}-y^{m+n-1}}{(m+n-1)(x-y)} \geq \frac{x^{m}-y^{m}}{m(x-y)} \cdot \frac{x^{n}-y^{n}}{n(x-y)} .
$$

The last one can be written as

$$
(x-y) \int_{y}^{x} t^{m+n-2} d t \geq \int_{y}^{x} t^{m-1} d t \cdot \int_{y}^{x} t^{n-1} d t .
$$

Here we recognize Chebyshev's inequality applied to the integrals of the functions $f, g$ : $[y, x] \rightarrow \mathbb{R}, f(t)=t^{m-1}$ and $g(t)=t^{n-1}$.

(Austrian-Polish Competition, 1995)

482. Observe that $f$ being monotonic, it is automatically Riemann integrable. Taking the mean of $f$ on the intervals $[0, \alpha]$ and $[1-\alpha, 1]$ and using the monotonicity of the function, we obtain

$$
\frac{1}{1-\alpha} \int_{\alpha}^{1} f(x) d x \leq \frac{1}{\alpha} \int_{0}^{\alpha} f(x) d x,
$$

whence

$$
\alpha \int_{\alpha}^{1} f(x) d x \leq(1-\alpha) \int_{0}^{\alpha} f(x) d x .
$$

Adding $\int_{0}^{\alpha} f(x) d x$ to both sides gives

$$
\alpha \int_{0}^{1} f(x) d x \leq \int_{0}^{\alpha} f(x) d x,
$$

as desired.

(Soviet Union University Student Mathematical Olympiad, 1976)

483. For $x \in[0,1]$, we have $f^{\prime}(x) \leq f^{\prime}(1)$, and so

$$
\frac{f^{\prime}(1)}{f^{2}(x)+1} \leq \frac{f^{\prime}(x)}{f^{2}(x)+1} \text {. }
$$

Integrating, we obtain

$$
f^{\prime}(1) \int_{0}^{1} \frac{d x}{f^{2}(x)+1} \leq \int_{0}^{1} \frac{f^{\prime}(x)}{f^{2}(x)+1}=\arctan f(1)-\arctan f(0)=\arctan f(1) .
$$

Because $f^{\prime}(1)>0$ and $\arctan y \leq y$ for $y \geq 0$, we further obtain

$$
\int_{0}^{1} \frac{d x}{f^{2}(x)+1} \leq \frac{\arctan f(1)}{f^{\prime}(1)} \leq \frac{f(1)}{f^{\prime}(1)},
$$

proving the inequality. In order for equality to hold we must have $\arctan f(1)=f(1)$, which happens only when $f(1)=0$. Then $\int_{0}^{1} \frac{d x}{f^{2}(x)+1}=0$. But this cannot be true since the function that is integrated is strictly positive. It follows that the inequality is strict. This completes the solution.

(Romanian Mathematical Olympiad, 1978, proposed by R. Gologan)

484. The Leibniz-Newton fundamental theorem of calculus gives

$$
f(x)=\int_{a}^{x} f^{\prime}(t) d t .
$$

Squaring both sides and applying the Cauchy-Schwarz inequality, we obtain

$$
f(x)^{2}=\left(\int_{a}^{b} f^{\prime}(t) d t\right)^{2} \leq(b-a) \int_{a}^{b} f^{\prime}(t)^{2} d t .
$$

The right-hand side is a constant, while the left-hand side depends on $x$. Integrating the inequality with respect to $x$ yields

$$
\int_{a}^{b} f(x)^{2} d x \leq(b-a)^{2} \int_{a}^{b} f^{\prime}(t)^{2} d t .
$$

Substitute $t$ by $x$ to obtain the inequality as written in the statement of the problem.

485. This is an example of a problem in which it is important to know how to organize the data. We start by letting $A$ be the subset of $[0,1]$ on which $f$ is nonnegative, and $B$ its complement. Let $m(A)$, respectively, $m(B)$ be the lengths (measures) of these sets, and $I_{A}$ and $I_{B}$ the integrals of $|f|$ on $A$, respectively, $B$. Without loss of generality, we can assume $m(A) \geq \frac{1}{2}$; otherwise, change $f$ to $-f$.

We have

$$
\begin{aligned}
\int_{0}^{1} \int_{0}^{1}|f(x)+f(y)| d x d y \\
=& \int_{A} \int_{A}(f(x)+f(y)) d x d y+\int_{B} \int_{B}(|f(x)|+|f(y)|) d x d y \\
&+2 \int_{A} \int_{B}|f(x)+f(y)| d x d y .
\end{aligned}
$$

Let us first try a raw estimate by neglecting the last term. In this case we would have to prove 

$$
2 m(A) I_{A}+2 m(B) I_{B} \geq I_{A}+I_{B} .
$$

Since $m(A)+m(B)=1$, this inequality translates into

$$
\left(m(A)-\frac{1}{2}\right)\left(I_{A}-I_{B}\right) \geq 0,
$$

which would be true if $I_{A} \geq I_{B}$. However, if this last assumption does not hold, we can return to the term that we neglected, and use the triangle inequality to obtain

$$
\int_{A} \int_{B}|f(x)+f(y)| d x d y \geq \int_{A} \int_{B}|f(x)|-|f(y)| d x d y=m(A) I_{B}-m(B) I_{A} .
$$

The inequality from the statement would then follow from

$$
2 m(A) I_{A}+2 m(B) I_{B}+2 m(A) I_{B}-2 m(B) I_{A} \geq I_{A}+I_{B},
$$

which is equivalent to

$$
\left(m(A)-\frac{1}{2}\right)\left(I_{A}+I_{B}\right)+m(B)\left(I_{B}-I_{A}\right) \geq 0 .
$$

This is true since both terms are positive.

(64th W.L. Putnam Mathematical Competition, 2003)

486. Combining the Taylor series expansions

$$
\begin{aligned}
\cos x &=1-\frac{x^{2}}{2 !}+\frac{x^{4}}{4 !}-\frac{x^{6}}{6 !}+\frac{x^{8}}{8 !}+\cdots \\
\cosh x &=1+\frac{x^{2}}{2 !}+\frac{x^{4}}{4 !}+\frac{x^{6}}{6 !}+\frac{x^{8}}{8 !}+\cdots
\end{aligned}
$$

we see that the given series is the Taylor series of $\frac{1}{2}(\cos x+\cosh x)$.

(The Mathematics Gazette Competition, Bucharest, 1935)

487. Denote by $p$ the numerator and by $q$ the denominator of this fraction. Recall the Taylor series expansion of the sine function,

$$
\sin x=\frac{x}{1 !}-\frac{x^{3}}{3 !}+\frac{x^{5}}{5 !}-\frac{x^{7}}{7 !}+\frac{x^{9}}{9 !}+\cdots .
$$

We recognize the denominators of these fractions inside the expression that we are computing, and now it is not hard to see that $p \pi-q \pi^{3}=\sin \pi=0$. Hence $p \pi=q \pi^{3}$, and the value of the expression from the statement is $\pi^{2}$.

(Soviet Union University Student Mathematical Olympiad, 1975) 

488. Expand the cosine in a Taylor series,

$$
\cos a x=1-\frac{(a x)^{2}}{2 !}+\frac{(a x)^{4}}{4 !}-\frac{(a x)^{6}}{6 !}+\cdots
$$

Let us forget for a moment the coefficient $\frac{(-1)^{n} 2^{2 n}}{(2 n) !}$ and understand how to compute

$$
\int_{-\infty}^{\infty} e^{-x^{2}} x^{2 n} d x .
$$

If we denote this integral by $I_{n}$, then integration by parts yields the recursive formula $I_{n}=\frac{2 n-1}{2} I_{n-1}$. Starting with

$$
I_{0}=\int_{-\infty}^{\infty} e^{-x^{2}} d x=\sqrt{\pi},
$$

we obtain

$$
I_{n}=\frac{(2 n) ! \sqrt{\pi}}{4^{n} n !} .
$$

It follows that the integral in question is equal to

$$
\sum_{n=0}^{\infty}(-1)^{n} \frac{a^{2 n}}{(2 n) !} \cdot \frac{(2 n) ! \sqrt{\pi}}{4^{n} n !}=\sqrt{\pi} \sum_{n=0}^{\infty} \frac{\left(-\frac{a^{2}}{4}\right)^{n}}{n !},
$$

and this is clearly equal to $\sqrt{\pi} e^{-a^{2} / 4}$.

One thing remains to be explained: why are we allowed to perform the expansion and then the summation of the integrals? This is because the series that consists of the integrals of the absolute values of the terms converges itself. Indeed,

$$
\sum_{n=1}^{\infty} \frac{a^{2 n}}{(2 n) !} \int_{-\infty}^{\infty} e^{-x^{2}} x^{2 n}=\sqrt{\pi} \sum_{1}^{\infty} \frac{\left(\frac{a^{2}}{4}\right)^{n}}{n !}=\sqrt{\pi} e^{a^{2} / 4}<\infty .
$$

With this the problem is solved.

(G.B. Folland, Real Analysis, Modern Techniques and Their Applications, Wiley, 1999)

489. Consider the Taylor series expansion around 0 ,

$$
\frac{1}{x-4}=-\frac{1}{4}-\frac{1}{16} x-\frac{1}{64} x^{2}-\frac{1}{256} x^{3}-\cdots .
$$

A good guess is to truncate this at the third term and let 

$$
P(x)=\frac{1}{4}+\frac{1}{16} x+\frac{1}{64} x^{2} .
$$

By the residue formula for Taylor series we have

$$
\left|P(x)+\frac{1}{x-4}\right|=\frac{x^{3}}{256}+\frac{1}{(\xi-4)^{4}} x^{5},
$$

for some $\xi \in(0, x)$. Since $|x| \leq 1$ and also $|\xi| \leq 1$, we have $\frac{x^{3}}{256} \leq \frac{1}{256}$ and $x^{4} /(\xi-4)^{5} \leq$ $\frac{1}{243}$. An easy numerical computation shows that $\frac{1}{256}+\frac{1}{243}<\frac{1}{100}$, and we are done.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1979, proposed by O. Stănăşilă)

490. The Taylor series expansion of $\cos \sqrt{x}$ around 0 is

$$
\cos \sqrt{x}=1-\frac{x}{2 !}+\frac{x^{2}}{4 !}-\frac{x^{3}}{6 !}+\frac{x^{4}}{8 !}-\cdots .
$$

Integrating term by term, we obtain

$$
\int_{0}^{1} \cos \sqrt{x} d x=\left.\sum_{n=1}^{\infty} \frac{(-1)^{n-1} x^{n}}{(n+1)(2 n) !}\right|_{0} ^{1}=\sum_{n=0}^{\infty} \frac{(-1)^{n-1}}{(n+1)(2 n) !} .
$$

Grouping consecutive terms we see that

$$
\begin{aligned}
\left(\frac{1}{5 \cdot 8 !}-\frac{1}{6 \cdot 10 !}\right)+\left(\frac{1}{7 \cdot 12 !}-\frac{1}{8 \cdot 14 !}\right)+\cdots &<\frac{1}{2 \cdot 10^{4}}+\frac{1}{2 \cdot 10^{5}}+\frac{1}{2 \cdot 10^{6}}+\cdots \\
&<\frac{1}{10^{4}} .
\end{aligned}
$$

Also, truncating to the fourth decimal place yields

$$
0.7638<1-\frac{1}{4}+\frac{1}{72}-\frac{1}{2880}<0.7639 .
$$

We conclude that

$$
\int_{0}^{1} \cos \sqrt{x} d x \approx 0.763 .
$$

491. Consider the Newton binomial expansion

$$
(x+1)^{-\frac{1}{2}}=\sum_{k=0}^{\infty}\left(\begin{array}{c}
-\frac{1}{2} \\
k
\end{array}\right) x^{k}=\sum_{k=0}^{\infty} \frac{\left(-\frac{1}{2}\right)\left(-\frac{1}{2}-1\right)\left(-\frac{1}{2}-2\right) \cdots\left(-\frac{1}{2}-k+1\right)}{k !} x^{k}
$$



$$
\begin{aligned}
&=\sum_{k=0}^{\infty}(-1)^{k} \frac{1 \cdot 3 \cdots(2 k-1)}{2^{k} \cdot k !} x^{k}=\sum_{k=0}^{\infty}(-1)^{k} \frac{(2 k) !}{2^{2 k} \cdot k ! \cdot k !} x^{k} \\
&=\sum_{k=0}^{\infty}(-1)^{k} \frac{1}{2^{2 k}}\left(\begin{array}{c}
2 k \\
k
\end{array}\right) x^{k} .
\end{aligned}
$$

Replacing $x$ by $-x^{2}$ then taking antiderivatives, we obtain

$$
\begin{aligned}
\arcsin x &=\int_{0}^{x}\left(1-t^{2}\right)^{-\frac{1}{2}} d t=\sum_{k=0}^{\infty} \frac{1}{2^{2 k}}\left(\begin{array}{c}
2 k \\
k
\end{array}\right) \int_{0}^{x} t^{2 k} d t \\
&=\sum_{k=0}^{\infty} \frac{1}{2^{2 k}(2 k+1)}\left(\begin{array}{c}
2 k \\
k
\end{array}\right) x^{2 k+1},
\end{aligned}
$$

as desired.

492. (a) Differentiating the identity from the second example from the introduction, we obtain

$$
\frac{2 \arcsin x}{\sqrt{1-x^{2}}}=\sum_{k \geq 1} \frac{1}{k\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k} x^{2 k-1},
$$

whence

$$
\frac{x \arcsin x}{\sqrt{1-x^{2}}}=\sum_{k \geq 1} \frac{1}{k\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k-1} x^{2 k} .
$$

Differentiating both sides and multiplying by $x$, we obtain

$$
x \frac{\arcsin x+x \sqrt{1-x^{2}}}{\left(1-x^{2}\right)^{3 / 2}}=\sum_{k \geq 0} \frac{1}{\left(\begin{array}{c}
2 k \\
k
\end{array}\right)} 2^{2 k} x^{2 k} .
$$

Substituting $\frac{x}{2}$ for $x$, we obtain the desired identity.

Part (b) follows from (a) if we let $x=1$.

(S. Rădulescu, M. Rădulescu, Teoreme şi Probleme de Analiză Matematică (Theorems and Problems in Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1982).

493. Consider the function $f$ of period $2 \pi$ defined by $f(x)=x$ if $0 \leq x<2 \pi$. This function is continuous on $(0,2 \pi)$, so its Fourier series converges (pointwise) on this interval. We compute

$$
a_{0}=\frac{1}{2 \pi} \int_{0}^{2 \pi} x d x=\pi, \quad a_{m}=0, \quad \text { for } m \geq 1,
$$



$$
b_{m}=\frac{1}{\pi} \int_{0}^{2 \pi} x \sin m x d x=-\left.\frac{x \cos m x}{m \pi}\right|_{0} ^{2 \pi}+\frac{1}{m \pi} \int_{0}^{2 \pi} \cos m x d x=-\frac{2}{m}, \quad \text { for } m \geq 1 \text {. }
$$

Therefore,

$$
x=\pi-\frac{2}{1} \sin x-\frac{2}{2} \sin 2 x-\frac{2}{3} \sin 3 x-\cdots
$$

Divide this by 2 to obtain the identity from the statement. Substituting $x=\frac{\pi}{2}$, we obtain the Leibniz series

$$
\frac{\pi}{4}=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots
$$

In the series

$$
\frac{\pi-x}{2}=\sum_{n=1}^{\infty} \frac{\sin n x}{n}
$$

replace $x$ by $2 x$, and then divide by 2 to obtain

$$
\frac{\pi}{4}-\frac{x}{2}=\sum_{k=1}^{\infty} \frac{\sin 2 k x}{2 k}, \quad x \in(0, \pi)
$$

Subtracting this from the original formula, we obtain

$$
\frac{\pi}{4}=\sum_{k=1}^{\infty} \frac{\sin (2 k-1) x}{2 k-1}, \quad x \in(0, \pi) .
$$

494. One computes

$$
\begin{gathered}
\int_{0}^{1} f(x) d x=0, \\
\int_{0}^{1} f(x) \cos 2 \pi n x d x=0, \quad \text { for all } n \geq 1 \\
\int_{0}^{1} f(x) \sin 2 \pi n x d x=\frac{1}{2 \pi k}, \quad \text { for all } n \geq 1
\end{gathered}
$$

Recall that for a general Fourier expansion

$$
f(x)=a_{0}+\sum_{n=1}^{\infty}\left(a_{n} \cos \frac{2 \pi}{T} n x+b_{n} \sin \frac{2 \pi}{T} n x\right)
$$

one has Parseval's identity 

$$
\frac{1}{T} \int_{0}^{T}|f(x)|^{2} d x=a_{0}^{2}+2 \sum_{n=1}^{\infty}\left(a_{n}^{2}+b_{n}^{2}\right) .
$$

Our particular function has the Fourier series expansion

$$
f(x)=\frac{1}{2 \pi} \sum_{n=-\infty}^{\infty} \frac{1}{n} \cos 2 \pi n x,
$$

and in this case Parseval's identity reads

$$
\int_{0}^{1}|f(x)|^{2} d x=\frac{1}{2 \pi^{2}} \sum_{n=1}^{\infty} \frac{1}{n^{2}}
$$

The left-hand side is $\int_{0}^{1}|f(x)|^{2} d x=\frac{1}{12}$, and the formula follows.

495. This problem uses the Fourier series expansion of $f(x)=|x|, x \in[-\pi, \pi]$. A routine computation yields

$$
|x|=\frac{\pi}{2}-\frac{4}{\pi} \sum_{k=0}^{\infty} \frac{\cos (2 k+1) x}{(2 k+1)^{2}}, \quad \text { for } x \in[-\pi, \pi] .
$$

Setting $x=0$, we obtain the identity from the statement.

496. We will use only trigonometric considerations, and compute no integrals. A first remark is that the function is even, so only terms involving cosines will appear. Using Euler's formula

$$
e^{i \alpha}=\cos \alpha+i \sin \alpha
$$

we can transform the identity

$$
\sum_{k=1}^{n} e^{2 i k x}=\frac{e^{2 i(n+1) x}-1}{e^{2 i x}-1}
$$

into the corresponding identities for the real and imaginary parts:

$$
\begin{aligned}
&\cos 2 x+\cos 4 x+\cdots+\cos 2 n x=\frac{\sin n x \cos (n+1) x}{\sin x} \\
&\sin 2 x+\sin 4 x+\cdots+\sin 2 n x=\frac{\sin n x \sin (n+1) x}{\sin x}
\end{aligned}
$$

These two relate to our function as

$$
\frac{\sin ^{2} n x}{\sin ^{2} x}=\left(\frac{\sin n x \cos (n+1) x}{\sin x}\right)^{2}+\left(\frac{\sin n x \sin (n+1) x}{\sin x}\right)^{2},
$$

which allows us to write the function as an expression with no fractions:

$$
f(x)=(\cos 2 x+\cos 4 x+\cdots+\cos 2 n x)^{2}+(\sin 2 x+\sin 4 x+\cdots+\sin 2 n x)^{2} .
$$

Expanding the squares, we obtain

$$
\begin{aligned}
f(x) &=n+\sum_{1 \leq l<k \leq n}(2 \sin 2 l x \sin 2 k x+2 \cos 2 l x \cos 2 k x) \\
&=n+2 \sum_{1 \leq l<k \leq n} \cos 2(k-l) x=n+\sum_{m=1}^{n-1} 2(n-m) \cos 2 m x .
\end{aligned}
$$

In conclusion, the nonzero Fourier coefficients of $f$ are $a_{0}=n$ and $a_{2 m}=2(n-m)$, $m=1,2, \ldots, n-1$.

(D. Andrica)

497. Expand the function $f$ as a Fourier series

$$
f(x)=\sum_{n=1}^{\infty} a_{n} \sin n x,
$$

where

$$
a_{n}=\frac{2}{\pi} \int_{0}^{\pi} f(t) \sin n t d t .
$$

This is possible, for example, since $f$ can be extended to an odd function on $[-\pi, \pi]$.

Fix $n \geq 2$, and consider the function $g:[0, \pi] \rightarrow \mathbb{R}, g(x)=n \sin x-\sin n x$. The function $g$ is nonnegative because of the inequality $n|\sin x| \geq|\sin n x|, x \in \mathbb{R}$, which was proved in the section on induction.

Integrating repeatedly by parts and using the hypothesis, we obtain

$$
(-1)^{m} \int_{0}^{\pi} f^{(2 m)}(t) \sin n t d t=n^{2 m} a_{n} \frac{\pi}{2}, \quad \text { for } m \geq 0 .
$$

It follows that

$$
(-1)^{m} \int_{0}^{\pi} f^{(2 m)}(x)(n \sin x-\sin n x) d x=\left(n a_{1}-n^{2 m} a_{n}\right) \frac{\pi}{2} \geq 0 .
$$

Indeed, the first term is the integral of a product of two nonnegative functions. This must hold for any integer $m$; hence $a_{n} \leq 0$ for any $n \geq 2$.

On the other hand, $f(x) \geq 0$, and $f^{\prime \prime}(x) \leq 0$ for $x \in[0, \pi]$; hence $f(x)-f^{\prime \prime}(x) \geq 0$ on $[0, \pi]$. Integrating twice by parts, we obtain 

$$
\int_{0}^{\pi} f^{\prime \prime}(x)(n \sin x-\sin n x) d x=\frac{\pi}{2}\left(n a_{1}-n^{2} a_{n}\right)
$$

Therefore,

$$
\begin{aligned}
0 \leq \int_{0}^{\pi}\left(f(x)-f^{\prime \prime}(x)\right)(n \sin x-\sin n x) d x &=\frac{\pi}{2}\left(n a_{1}-a_{n}-n a_{1}+n^{2} a_{n}\right) \\
&=\frac{\pi}{2}\left(n^{2}-1\right) a_{n}
\end{aligned}
$$

This implies that $a_{n} \geq 0$, for $n \geq 2$. We deduce that $a_{n}=0$ for $n \geq 2$, and so $f(x)=a_{1} \sin x$, for any $x \in[0, \pi]$

(S. Rădulescu, M. Rădulescu, Teoreme şi Probleme de Analiză Matematica (Theorems and Problems in Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, $1982)$

498. This is an exercise in the product and chain rules. We compute

$$
\begin{aligned}
\frac{\partial v}{\partial t}(x, t)=& \frac{\partial}{\partial t}\left(t^{-\frac{1}{2}} e^{-\frac{x^{2}}{4 t}} u\left(x t^{-1},-t^{-1}\right)\right) \\
=&-\frac{1}{2} t^{-\frac{3}{2}} e^{-\frac{x^{2}}{4 t}} v(x, t)+\frac{x^{2} t^{-\frac{5}{2}}}{4} e^{-\frac{x^{2}}{4 t}} v(x, t)-x t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial u}{\partial x}\left(x t^{-1},-t^{-1}\right) \\
&+t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial u}{\partial t}\left(x t^{-1},-t^{-1}\right),
\end{aligned}
$$

then

$$
\frac{\partial v}{\partial x}(x, t)=t^{-\frac{1}{2}} e^{-\frac{x^{2}}{4 t}}\left(-\frac{1}{2} t^{-1} x\right) u\left(x t^{-1},-t^{-1}\right)+t^{-\frac{3}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial u}{\partial x}\left(x t^{-1},-t^{-1}\right)
$$

and

$$
\begin{aligned}
\frac{\partial^{2} v}{\partial x^{2}}(x, t)=& \frac{1}{4} x^{2} t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} v(x, t)-\frac{1}{2} t^{-\frac{3}{2}} e^{-\frac{x^{2}}{4 t}} v(x, t)-\frac{1}{2} x t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial u}{\partial x}\left(x t^{-1},-t^{-1}\right) \\
&-\frac{1}{2} x t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial u}{\partial x}\left(x t^{-1},-t^{-1}\right)+t^{-\frac{5}{2}} e^{-\frac{x^{2}}{4 t}} \frac{\partial^{2} u}{\partial x^{2}}\left(x t^{-1},-t^{-1}\right) .
\end{aligned}
$$

Comparing the two formulas and using the fact that $\frac{\partial u}{\partial t}=\frac{\partial^{2} u}{\partial t^{2}}$, we obtain the desired equality.

Remark. The equation

$$
\frac{\partial u}{\partial t}=\frac{\partial^{2} u}{\partial x^{2}}
$$

is called the heat equation. It describes how heat spreads through a long, thin metal bar. 

499. We switch to polar coordinates, where the homogeneity condition becomes the simpler

$$
u(r, \theta)=r^{n} g(\theta),
$$

where $g$ is a one-variable function of period $2 \pi$. Writing the Laplacian $\Delta=\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}$ in polar coordinates, we obtain

$$
\Delta=\frac{\partial^{2}}{\partial r^{2}}+\frac{1}{r} \frac{\partial}{\partial r}+\frac{1}{r^{2}} \frac{\partial^{2}}{\partial \theta^{2}} .
$$

For our harmonic function,

$$
\begin{aligned}
0 &=\Delta u=\Delta\left(r^{n} g(\theta)\right)=n(n-1) r^{n-2} g(\theta)+n r^{n-2} g(\theta)+r^{n-2} g^{\prime \prime}(\theta) \\
&=r^{n-2}\left(n^{2} g(\theta)+g^{\prime \prime}(\theta)\right) .
\end{aligned}
$$

Therefore, $g$ must satisfy the differential equation $g^{\prime \prime}+n^{2} g=0$. This equation has the general solution $g(\theta)=A \cos n \theta+B \sin n \theta$. In order for such a solution to be periodic of period $2 \pi, n$ must be an integer.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

500. Assume the contrary and write $P(x, y)=\left(x^{2}+y^{2}\right)^{m} R(x, y)$, where $R(x, y)$ is not divisible by $x^{2}+y^{2}$. The harmonicity condition can be written explicitly as

$$
\begin{aligned}
4 m^{2}\left(x^{2}+y^{2}\right)^{m-1} R &+2 m\left(x^{2}+y^{2}\right)^{m-1}\left(x \frac{\partial R}{\partial x}+y \frac{\partial R}{\partial y}\right) \\
+\left(x^{2}+y^{2}\right)^{m}\left(\frac{\partial^{2} R}{\partial x^{2}}+\frac{\partial^{2} R}{\partial y^{2}}\right) &=0 .
\end{aligned}
$$

If $R(x, y)$ were $n$-homogeneous for some $n$, then Euler's formula would allow us to simplify this to

$$
\left(4 m^{2}+2 m n\right)\left(x^{2}+y^{2}\right)^{m-1} R+\left(x^{2}+y^{2}\right)^{m}\left(\frac{\partial^{2} R}{\partial x^{2}}+\frac{\partial^{2} R}{\partial y^{2}}\right)=0 .
$$

If this were true, it would imply that $R(x, y)$ is divisible by $x^{2}+y^{2}$, a contradiction. But the polynomial $x^{2}+y^{2}$ is 2-homogeneous and $R(x, y)$ can be written as a sum of $n$-homogeneous polynomials, $n=0,1,2, \ldots$ Since the Laplacian $\frac{\partial}{\partial x^{2}}+\frac{\partial}{\partial y^{2}}$ maps an $n$-homogeneous polynomial to an $(n-2)$-homogeneous polynomial, the nonzero homogeneous parts of $R(x, y)$ can be treated separately to reach the above-mentioned contradiction. Hence $P(x, y)$ is identically equal to zero.

Remark. The solution generalizes in a straightforward manner to the case of $n$ variables, which was the subject of a Putnam problem in 2005. But as I.M. Vinogradov said, "it is the first nontrivial example that counts." 

501. Using the Leibniz-Newton fundamental theorem of calculus, we can write

$$
f(x, y)-f(0,0)=\int_{0}^{x} \frac{\partial f}{\partial x}(s, 0) d s+\int_{0}^{y} \frac{\partial f}{\partial y}(x, t) d t .
$$

Using the changes of variables $s=x \sigma$ and $t=y \tau$, and the fact that $f(0,0)=0$, we obtain

$$
f(x, y)=x \int_{0}^{1} \frac{\partial f}{\partial x}(x \sigma, 0) d \sigma+y \int_{0}^{1} \frac{\partial f}{\partial y}(x, y \tau) d \tau .
$$

Hence if we set $g_{1}(x, y)=\int_{0}^{1} \frac{\partial f}{\partial x}(x \sigma, 0) d \sigma$ and $g_{2}(x, y)=\int_{0}^{1} \frac{\partial f}{\partial y}(x, y \tau) d \tau$, then $f(x, y)=x g_{1}(x, y)+y g_{2}(x, y)$. Are $g_{1}$ and $g_{2}$ continuous? The answer is yes, and we prove it only for $g_{1}$, since for the other function the proof is identical. Our argument is based on the following lemma.

Lemma. If $\phi:[a, b] \rightarrow \mathbb{R}$ is continuous, then for every $\epsilon>0$ there is $\delta>0$ such that whenever $|x-y|<\delta$, we have $|f(x)-f(y)|<\epsilon$.

Proof. The property is called uniform continuity; the word "uniform" signifies the fact that the " $\delta$ " from the definition of continuity is the same for all points in $[a, b]$.

We argue by contradiction. Assume that the property is not true. Then there exist two sequences $\left(x_{n}\right)_{n \geq 1}$ and $\left(y_{n}\right)_{n \geq 1}$ such that $x_{n}-y_{n} \rightarrow 0$, but $\left|f\left(x_{n}\right)-f\left(y_{n}\right)\right| \geq \epsilon$ for some $\epsilon>0$. Because any sequence in $[a, b]$ has a convergent subsequence, passing to subsequences we may assume that $\left(x_{n}\right)_{n}$ and $\left(y_{n}\right)_{n}$ converge to some $c$ in $[a, b]$. Then by the triangle inequality,

$$
\epsilon \leq\left|f\left(x_{n}\right)-f\left(y_{n}\right)\right| \leq\left|f\left(x_{n}\right)-f(c)\right|+\left|f(c)-f\left(y_{n}\right)\right|,
$$

which is absurd because the right-hand side can be made arbitrarily close to 0 by taking $n$ sufficiently large. This proves the lemma.

Returning to the problem, note that as $x^{\prime}$ ranges over a small neighborhood of $x$ and $\sigma$ ranges between 0 and 1 , the numbers $x \sigma$ and $x^{\prime} \sigma$ lie inside a small interval of the real axis. Note also that $\left|x \sigma-x^{\prime} \sigma\right| \leq\left|x-x^{\prime}\right|$ when $0 \leq \sigma \leq 1$. Combining these two facts with the lemma, we see that for every $\epsilon>0$, there exists $\delta>0$ such that for $\left|x-x^{\prime}\right|<\delta$ we have

$$
\left|\frac{\partial f}{\partial x}(x \sigma, 0)-\frac{\partial f}{\partial x}\left(x^{\prime} \sigma, 0\right)\right|<\epsilon .
$$

In this case,

$$
\int_{0}^{1}\left|\frac{\partial f}{\partial x}(x \sigma, 0)-\frac{\partial f}{\partial x}\left(x^{\prime} \sigma, 0\right)\right| d \sigma<\epsilon,
$$

showing that $g_{1}$ is continuous. This concludes the solution.

502. First, observe that if $|x|+|y| \rightarrow \infty$ then $f(x, y) \rightarrow \infty$, hence the function indeed has a global minimum. The critical points of $f$ are solutions to the system of equations

$$
\begin{aligned}
&\frac{\partial f}{\partial x}(x, y)=4 x^{3}+12 x y^{2}-\frac{9}{4}=0, \\
&\frac{\partial f}{\partial y}(x, y)=12 x^{2} y+4 y^{3}-\frac{7}{4}=0 .
\end{aligned}
$$

If we divide the two equations by 4 and then add, respectively, subtract them, we obtain $x^{3}+3 x^{2} y+3 x y^{2}+y^{3}-1=0$ and $x^{3}-3 x^{2} y+3 x y^{3}-y^{3}=\frac{1}{8}$. Recognizing the perfect cubes, we write these as $(x+y)^{3}=1$ and $(x-y)^{3}=\frac{1}{8}$, from which we obtain $x+y=1$ and $x-y=\frac{1}{2}$. We find a unique critical point $x=\frac{3}{4}, y=\frac{1}{4}$. The minimum of $f$ is attained at this point, and it is equal to $f\left(\frac{3}{4}, \frac{1}{4}\right)=-\frac{51}{32}$.

(R. Gelca)

503. The diameter of the sphere is the segment that realizes the minimal distance between the lines. So if $P(t+1,2 t+4,-3 t+5)$ and $Q(4 s-12,-t+8, t+17)$, we have to minimize the function

$$
\begin{aligned}
|P Q|^{2} &=(s-4 t+13)^{2}+(2 s+t-4)^{2}+(-3 s-t-12)^{2} \\
&=14 s^{2}+2 s t+18 t^{2}+82 s-88 t+329 .
\end{aligned}
$$

To minimize this function we set its partial derivatives equal to zero:

$$
\begin{aligned}
&28 s+2 t+82=0, \\
&2 s+36 t-88=0 .
\end{aligned}
$$

This system has the solution $t=-782 / 251, s=657 / 251$. Substituting into the equation of the line, we deduce that the two endpoints of the diameter are $P\left(-\frac{531}{251},-\frac{560}{251}, \frac{3601}{251}\right)$ and $Q\left(-\frac{384}{251}, \frac{1351}{251}, \frac{4924}{251}\right)$. The center of the sphere is $\frac{1}{502}(-915,791,8252)$, and the radius $\frac{147}{\sqrt{1004}}$. The equation of the sphere is

$$
(502 x+915)^{2}+(502 y-791)^{2}+(502 z-8525)^{2}=251(147)^{2} .
$$

(20th W.L. Putnam Competition, 1959)

504. Writing $C=\pi-A-B$, the expression can be viewed as a function in the independent variables $A$ and $B$, namely,

$$
f(A, B)=\cos A+\cos B-\cos (A+B) .
$$

And because $A$ and $B$ are angles of a triangle, they are constrained to the domain $A, B>0$, $A+B<\pi$. We extend the function to the boundary of the domain, then study its extrema. The critical points satisfy the system of equations 

$$
\begin{aligned}
&\frac{\partial f}{\partial A}(A, B)=-\sin A+\sin (A+B)=0, \\
&\frac{\partial f}{\partial B}(A, B)=-\sin B+\sin (A+B)=0 .
\end{aligned}
$$

From here we obtain $\sin A=\sin B=\sin (A+B)$, which can happen only if $A=B=\frac{\pi}{3}$. This is the unique critical point, for which $f\left(\frac{\pi}{3}, \frac{\pi}{3}\right)=\frac{3}{2}$. On the boundary, if $A=0$ or $B=0$, then $f(A, B)=1$. Same if $A+B=\pi$. We conclude that the maximum of $\cos A+\cos B+\cos C$ is $\frac{3}{2}$, attained for the equilateral triangle, while the minimum is 1 , which is attained only for a degenerate triangle in which two vertices coincide.

505. We rewrite the inequality as

$$
\sin \alpha \cos \beta \cos \gamma+\cos \alpha \sin \beta \cos \gamma+\cos \alpha \cos \beta \sin \gamma \leq \frac{2}{\sqrt{3}},
$$

and prove it for $\alpha, \beta, \gamma \in\left[0, \frac{\pi}{2}\right]$. To this end, we denote the left-hand side by $f(\alpha, \beta, \gamma)$ and find its maximum in the specified region. The critical points in the interior of the domain are solutions to the system of equations

$$
\begin{aligned}
\cos \alpha \cos \beta \cos \gamma-\sin \alpha \sin \beta \cos \gamma-\sin \alpha \cos \beta \sin \gamma &=0, \\
-\sin \alpha \sin \beta \cos \gamma+\cos \alpha \cos \beta \cos \gamma-\cos \alpha \sin \beta \sin \gamma &=0, \\
-\sin \alpha \cos \beta \sin \gamma-\cos \alpha \sin \beta \sin \gamma+\cos \alpha \cos \beta \cos \gamma &=0
\end{aligned}
$$

Bring this system into the form

$$
\begin{aligned}
&\cos \alpha \cos \beta \cos \gamma=\sin \alpha \sin (\beta+\gamma), \\
&\cos \alpha \cos \beta \cos \gamma=\sin \beta \sin (\gamma+\alpha), \\
&\cos \alpha \cos \beta \cos \gamma=\sin \gamma \sin (\alpha+\beta) .
\end{aligned}
$$

From the first two equations, we obtain

$$
\frac{\sin \alpha}{\sin (\alpha+\gamma)}=\frac{\sin \beta}{\sin (\beta+\gamma)} \text {. }
$$

The function $g:\left(0, \frac{\pi}{2}\right), g(t)=\frac{\sin t}{\sin (t+\gamma)}$ is strictly increasing, since

$$
g^{\prime}(t)=\frac{\cos t \sin (t+\gamma)-\sin t \cos (t+\gamma)}{(\sin (t+\gamma))^{2}}=\frac{\sin \gamma}{(\sin (t+\gamma))^{2}}>0 .
$$

Hence $g(\alpha)=g(\beta)$ implies $\alpha=\beta$. Similarly, $\beta=\gamma$. The condition that $(\alpha, \alpha, \alpha)$ is a critical point is the trigonometric equation $\cos ^{3} \alpha=\sin \alpha \sin 2 \alpha$, which translates into $\cos ^{3} \alpha=2\left(1-\cos ^{2} \alpha\right) \cos \alpha$. We obtain $\cos \alpha=\sqrt{\frac{2}{3}}$, and $f(\alpha, \alpha, \alpha)=\frac{2}{\sqrt{3}}$. This will be the maximum once we check that no value on the boundary of the domain exceeds this number.

But when one of the three numbers, say $\alpha$, is zero, then $f(0, \beta, \gamma)=\sin (\beta+\gamma) \leq 1$. Also, if $\alpha=\frac{\pi}{2}$, then $f\left(\frac{\pi}{2}, \beta, \gamma\right)=\cos \beta \cos \gamma \leq 1$. Hence the maximum of $f$ is $\frac{2}{\sqrt{3}}$ and the inequality is proved.

506. If $a b c d=0$ the inequality is easy to prove. Indeed, if say $d=0$, the inequality becomes $3\left(a^{2}-a b+b^{2}\right) c^{2} \geq 2 a^{2} c^{2}$, which is equivalent to the obvious

$$
c^{2}\left(\left(a-\frac{3}{2} b\right)^{2}+\frac{3}{4} b^{2}\right) \geq 0 .
$$

If $a b c d \neq 0$, divide through by $b^{2} d^{2}$ and set $x=\frac{a}{b}, y=\frac{c}{d}$. The inequality becomes

$$
3\left(x^{2}-x+1\right)\left(y^{2}-y+1\right) \geq 2\left((x y)^{2}-x y+1\right),
$$

or

$$
3\left(x^{2}-x+1\right)\left(y^{2}-y+1\right)-2\left((x y)^{2}-x y+1\right) \geq 0 .
$$

The expression on the left is a two-variable function $f(x, y)$ defined on the whole plane. To find its minimum we need to determine the critical points. These are solutions to the system of equations

$$
\begin{aligned}
&\frac{\partial f}{\partial x}(x, y)=2\left(y^{2}-3 y+3\right) x-\left(3 y^{2}-5 y+3\right)=0, \\
&\frac{\partial f}{\partial y}(x, y)=2\left(x^{2}-3 x+3\right) y-\left(3 x^{2}-5 x+3\right)=0 .
\end{aligned}
$$

The system can be rewritten as

$$
\begin{aligned}
&2 x=\frac{3 y^{2}-5 y+3}{y^{2}-3 y+3}, \\
&2 y=\frac{3 x^{2}-5 x+3}{x^{2}-3 x+3},
\end{aligned}
$$

or

$$
\begin{aligned}
&2 x=3+\frac{4 y-6}{y^{2}-3 y+3}, \\
&2 y=3+\frac{4 x-6}{x^{2}-3 x+3} .
\end{aligned}
$$

A substitution becomes natural: $u=2 x-3, v=2 y-3$. The system now reads 

$$
\begin{aligned}
&u=\frac{8 v}{v^{2}+3}, \\
&v=\frac{8 u}{u^{2}+3} .
\end{aligned}
$$

This we transform into

$$
\begin{aligned}
&u v^{2}+3 u=8 v, \\
&u^{2} v+3 v=8 u
\end{aligned}
$$

then subtract the second equation from the first, to obtain $u v(v-u)=11(v-u)$. Either $u=v$ or $u v=11$. The first possibility implies $u=v=0$ or $u=v=\pm \sqrt{5}$. The second implies $u v^{2}+3 u=11 v+3 u=8 v$ so $u=-v$, which gives rise to the equality $u=-\frac{8 u}{u^{2}+3}$. This can hold only when $u=0$. The critical points of $f(x, y)$ are therefore

$$
\left(\frac{3}{2}, \frac{3}{2}\right), \quad\left(\frac{3+\sqrt{5}}{2}, \frac{3+\sqrt{5}}{2}\right), \quad\left(\frac{3-\sqrt{5}}{2}, \frac{3-\sqrt{5}}{2}\right) \text {. }
$$

We compute $f\left(\frac{3}{2}, \frac{3}{2}\right)=\frac{5}{16}$ and $f\left(\frac{3 \pm \sqrt{5}}{2}, \frac{3 \pm \sqrt{5}}{2}\right)=0$.

What about the behavior of $f$ when $|x|+|y| \rightarrow \infty$ ? We compute that

$$
f(x, y)=x^{2} y^{2}-3 x y^{2}-3 x^{2} y+5 x y+3 x^{2}+3 y^{2}-3 x-3 y+1 .
$$

Note that when $|x|+|y| \rightarrow \infty$,

$$
\begin{aligned}
&\frac{1}{2} x^{2}+\frac{1}{2} y^{2}-3 x-3 y+1 \rightarrow \infty \\
&\frac{5}{2} x^{2}+\frac{5}{2} y^{2}+5 x y=\frac{5}{2}(x+y)^{2} \geq 0, \\
&x^{2} y^{2}-3 x y^{2}-3 x^{2} y=x^{2}\left(y-\frac{3}{2}\right)^{2}+y^{2}\left(x-\frac{3}{2}\right)^{2}-\frac{9}{2} \geq-\frac{9}{2} .
\end{aligned}
$$

By adding these we deduce that when $|x|+|y| \rightarrow \infty, f(x, y) \rightarrow \infty$.

We conclude that 0 is the absolute minimum for $f$. This proves the inequality. And as we just saw, equality is achieved when

$$
\frac{a}{b}=\frac{c}{d}=\frac{3+\sqrt{5}}{2} \quad \text { or } \quad \frac{a}{b}=\frac{c}{d}=\frac{3-\sqrt{5}}{2} .
$$

(Mathematical Reflections, proposed by T. Andreescu)

507. Consider a coordinate system in the plane and let the $n$ points be $P_{1}\left(x_{1}, y_{1}\right)$, $P_{2}\left(x_{2}, y_{2}\right), \ldots, P_{n}\left(x_{n}, y_{n}\right)$. For an oriented line $l$, we will denote by $l^{\perp}$ the oriented line passing through the origin that is the clockwise rotation of $l$ by $90^{\circ}$. The origin of the coordinate system of the plane will also be the origin of the coordinate system on $l^{\perp}$.

An oriented line $l$ is determined by two parameters: $\theta$, the angle it makes with the positive side of the $x$-axis, which should be thought of as a point on the unit circle or an element of $\frac{\mathbb{R}}{2 \pi \mathbb{Z}}$; and $x$, the distance from $l$ to the origin, taken with sign on $l^{\perp}$. Define $f:\left(\frac{\mathbb{R}}{2 \pi \mathbb{Z}}\right) \times \mathbb{R} \rightarrow \mathbb{R}$

$$
f(\theta, x)=\sum_{i=1}^{n} \operatorname{dist}\left(P_{i}, l\right),
$$

where $l$ is the line determined by the pair $(\theta, x)$. The function $f$ is continuous and $\lim _{x \rightarrow \pm \infty} f(\theta, x)=\infty$ for all $\theta$; hence $f$ has an absolute minimum $f\left(\theta_{\min }, x_{\min }\right)$.

For fixed $\theta, f(\theta, x)$ is of the form $\sum_{i=1}^{n}\left|x-a_{i}\right|$, which is a piecewise linear convex function. Here $a_{1} \leq a_{2} \leq \cdots \leq a_{n}$ are a permutation of the coordinates of the projections of $P_{1}, P_{2}, \ldots, P_{n}$ onto $l^{\perp}$. It follows from problem 426 that at the absolute minimum of $f, x_{\min }=a_{\lfloor n / 2\rfloor+1}$ if $n$ is odd and $a_{\lfloor n / 2\rfloor} \leq x_{\min } \leq a_{\lfloor n / 2\rfloor+1}$ if $n$ is even (i.e., $x_{\min }$ is the median of the $\left.a_{i}, i=1,2, \ldots, n\right)$.

If two of the points project at $a_{\lfloor n / 2\rfloor+1}$, we are done. If this is not the case, let us examine the behavior of $f$ in the direction of $\theta$. By applying a translation and a rotation of the original coordinate system, we may assume that $a_{i}=x_{i}, i=1,2, \ldots, n$, $x_{\min }=x_{\lfloor n / 2\rfloor+1}=0, y_{\lfloor n / 2\rfloor+1}=0$, and $\theta_{\min }=0$. Then $f(0,0)=\sum_{i}\left|x_{i}\right|$. If we rotate the line by an angle $\theta$ keeping it through the origin, then for small $\theta$,

$$
\begin{aligned}
f(\theta, 0) &=\sum_{i<\lfloor n / 2\rfloor+1}\left(-x_{i} \cos \theta-y_{i} \sin \theta\right)+\sum_{i>\lfloor n / 2\rfloor+1}\left(x_{i} \cos \theta+y_{i} \sin \theta\right) \\
&=\sum_{i=1}^{n}\left|x_{i}\right| \cos \theta+\sum_{i<\lfloor n / 2\rfloor+1}\left(-y_{i}\right) \sin \theta+\sum_{i>\lfloor n / 2\rfloor+1} y_{i} \sin \theta .
\end{aligned}
$$

Of course, the absolute minimum of $f$ must also be an absolute minimum in the first coordinate, so

$$
\frac{\partial f}{\partial \theta}(0,0)=\sum_{i<\lfloor n / 2\rfloor+1}\left(-y_{i}\right)+\sum_{i>\lfloor n / 2\rfloor+1} y_{i}=0 .
$$

The second partial derivative of $f$ with respect to $\theta$ at $(0,0)$ should be positive. But this derivative is

$$
\frac{\partial^{2} f}{\partial \theta^{2}}(0,0)=-\sum_{i=1}^{n}\left|x_{i}\right|<0 .
$$

Hence the second derivative test fails, a contradiction. We conclude that the line for which the minimum is achieved passes through two of the points. It is important to note that the second derivative is strictly negative; the case in which it is zero makes the points collinear, in which case we are done.

Remark. This is the two-dimensional least absolute deviations problem. This method for finding the line that best fits a set of data was used well before Gauss' least squares method, for example by Laplace; its downside is that it can have multiple solutions (for example, if four points form a rectangle, both diagonals give a best approximation). The property proved above also holds in $n$ dimensions, in which case a hyperplane that minimizes the sum of distances from the points passes through $n$ of the given points.

508. We assume that the light ray travels from $A$ to $B$ crossing between media at point $P$. Let $C$ and $D$ be the projections of $A$ and $B$ onto the separating surface. The configuration is represented schematically in Figure 70.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-575.jpg?height=391&width=488&top_left_y=880&top_left_x=630)

Figure 70

Let $A P=x, B P=y$, variables subject to the constraint $g(x, y)=x+y=C D$. The principle that light travels on the fastest path translates to the fact that $x$ and $y$ minimize the function

$$
f(x, y)=\frac{\sqrt{x^{2}+A C^{2}}}{v_{1}}+\frac{\sqrt{y^{2}+B D^{2}}}{v_{2}} .
$$

The method of Lagrange multipliers gives rise to the system

$$
\begin{aligned}
\frac{x}{v_{1} \sqrt{x^{2}+A C^{2}}} &=\lambda, \\
\frac{y}{v_{2} \sqrt{y^{2}+B D^{2}}} &=\lambda, \\
x+y &=C D .
\end{aligned}
$$

From the first two equations, we obtain

$$
\frac{x}{v_{1} \sqrt{x^{2}+A C^{2}}}=\frac{y}{v_{2} \sqrt{y^{2}+B D^{2}}},
$$

which is equivalent to $\frac{\cos A P C}{\cos B P D}=\frac{v_{1}}{v_{2}}$. Snell's law follows once we note that the angles of incidence and refraction are, respectively, the complements of $\angle A P C$ and $\angle B P D$.

509. Let $D, E, F$ be the projections of the incenter onto the sides $B C, A C$, and $A B$, respectively. If we set $x=A F, y=B D$, and $z=C E$, then

$$
\cot \frac{A}{2}=\frac{x}{r}, \quad \cot \frac{B}{2}=\frac{y}{r}, \quad \cot \frac{C}{2}=\frac{z}{r} .
$$

The lengths $x, y, z$ satisfy

$$
\begin{aligned}
x+y+z &=s \\
x^{2}+4 y^{2}+9 z^{2} &=\left(\frac{6 s}{7}\right)^{2}
\end{aligned}
$$

We first determine the triangle similar to the one in question that has semiperimeter equal to 1 . The problem asks us to show that the triangle is unique, but this happens only if the plane $x+y+z=1$ and the ellipsoid $x^{2}+4 y^{2}+9 z^{2}=\frac{36}{49}$ are tangent. The tangency point must be at an extremum of $f(x, y, z)=x+y+z$ with the constraint $g(x, y, z)=x^{2}+4 y^{2}+9 z^{2}=\frac{36}{49}$.

We determine the extrema of $f$ with the given constraint using Lagrange multipliers. The equation $\nabla f=\lambda \nabla g$ becomes

$$
\begin{aligned}
&1=2 \lambda x \\
&1=8 \lambda y \\
&1=18 \lambda z
\end{aligned}
$$

We deduce that $x=\frac{1}{2 \lambda}, y=\frac{1}{8 \lambda}$, and $z=\frac{1}{18 \lambda}$, which combined with the constraint $g(x, y, z)=\frac{36}{49}$ yields $\lambda=\frac{49}{72}$. Hence $x=\frac{36}{49}, y=\frac{9}{49}$, and $z=\frac{4}{49}$, and so $f(x, y, z)=1$. This proves that, indeed, the plane and the ellipsoid are tangent. It follows that the triangle with semiperimeter 1 satisfying the condition from the statement has sides equal to $x+y=\frac{43}{49}, x+z=\frac{45}{49}$, and $y+z=\frac{13}{49}$.

Consequently, the unique triangle whose sides are integers with common divisor equal to 1 and that satisfies the condition from the statement is $45,43,13$.

(USA Mathematical Olympiad, 2002, proposed by T. Andreescu)

510. Let $a, b, c, d$ be the sides of the quadrilateral in this order, and let $x$ and $y$ be the cosines of the angles formed by the sides $a$ and $b$, respectively, $c$ and $d$. The condition that the triangle formed by $a$ and $b$ shares a side with the triangle formed by $c$ and $d$ translates, via the law of cosines, into the relation

$$
a^{2}+b^{2}-2 a b x=c^{2}+d^{2}-2 c d y .
$$

We want to maximize the expression $a b \sqrt{1-x^{2}}+c d \sqrt{1-y^{2}}$, which is twice the area of the rectangle. Let

$$
\begin{aligned}
&f(x, y)=a b \sqrt{1-x^{2}}+c d \sqrt{1-y^{2}}, \\
&g(x, y)=a^{2}+b^{2}-2 a b x-c^{2}-d^{2}+2 c d y .
\end{aligned}
$$

We are supposed to maximize $f(x, y)$ over the square $[-1,1] \times[-1,1]$, with the constraint $g(x, y)=0$. Using Lagrange multipliers we see that any candidate for the maximum that lies in the interior of the domain satisfies the system of equations

$$
\begin{aligned}
&-a b \frac{2 x}{\sqrt{1-x^{2}}}=-\lambda 2 a b, \\
&-c d \frac{2 y}{\sqrt{1-y^{2}}}=\lambda 2 c d,
\end{aligned}
$$

for some $\lambda$. It follows that $\sqrt{1-x^{2}} / x=-\sqrt{1-y^{2}} / y$, and so the tangents of the opposite angles are each the negative of the other. It follows that the angles are supplementary. In this case $x=-y$. The constraint becomes a linear equation in $x$. Solving it and substituting in the formula of the area yields the Brahmagupta formula

$$
A=\sqrt{(s-a)(s-b)(s-c)(s-d)}, \quad \text { where } s=\frac{a+b+c+d}{2} .
$$

Is this the maximum? Let us analyze the behavior of $f$ on the boundary. When $x=1$ or $y=1$, the quadrilateral degenerates to a segment; the area is therefore 0 . Let us see what happens when $y=-1$. Then the quadrilateral degenerates to a triangle, and the area can be computed using Hero's formula

$$
A=\sqrt{s(s-a)(s-b)(s-(c+d))} .
$$

Since $s(s-(c+d))<(s-c)(s-d)$, we conclude that the cyclic quadrilateral maximizes the area.

(E. Goursat, A Course in Mathematical Analysis, Dover, New York, 1904)

511. Without loss of generality, we may assume that the circle has radius 1 . If $a, b, c$ are the sides, and $S(a, b, c)$ the area, then (because of the formula $S=p r$, where $p$ is the semiperimeter) the constraint reads $S=\frac{a+b+c}{2}$. We will maximize the function $f(a, b, c)=S(a, b, c)^{2}$ with the constraint $g(a, b, c)=S(a, b, c)^{2}-\left(\frac{a+b+c}{2}\right)^{2}=0$. Using Hero's formula, we can write

$$
\begin{aligned}
f(a, b, c) &=\frac{a+b+c}{2} \cdot \frac{-a+b+c}{2} \cdot \frac{a-b+c}{2} \cdot \frac{a+b-c}{2} \\
&=\frac{-a^{4}-b^{4}-c^{4}+2\left(a^{2} b^{2}+b^{2} c^{2}+a^{2} c^{2}\right)}{16} .
\end{aligned}
$$

The method of Lagrange multipliers gives rise to the system of equations

$$
\begin{aligned}
(\lambda-1) \frac{-a^{3}+a\left(b^{2}+c^{2}\right)}{4} &=\frac{a+b+c}{2}, \\
(\lambda-1) \frac{-b^{3}+b\left(a^{2}+c^{2}\right)}{4} &=\frac{a+b+c}{2}, \\
(\lambda-1) \frac{-c^{3}+c\left(a^{2}+b^{2}\right)}{4} &=\frac{a+b+c}{2}, \\
g(a, b, c) &=0 .
\end{aligned}
$$

Because $a+b+c \neq 0, \lambda$ cannot be 1 , so this further gives

$$
-a^{3}+a\left(b^{2}+c^{2}\right)=-b^{3}+b\left(a^{2}+c^{2}\right)=-c^{3}+c\left(a^{2}+b^{2}\right) .
$$

The first equality can be written as $(b-a)\left(a^{2}+b^{2}-c^{2}\right)=0$. This can happen only if either $a=b$ or $a^{2}+b^{2}=c^{2}$, so either the triangle is isosceles, or it is right. Repeating this for all three pairs of sides we find that either $b=c$ or $b^{2}+c^{2}=a^{2}$, and also that either $a=c$ or $a^{2}+c^{2}=b^{2}$. Since at most one equality of the form $a^{2}+b^{2}=c^{2}$ can hold, we see that, in fact, all three sides must be equal. So the critical point given by the method of Lagrange multipliers is the equilateral triangle.

Is this the global minimum? We just need to observe that as the triangle degenerates, the area becomes infinite. So the answer is yes, the equilateral triangle minimizes the area.

512. Consider the function $f:\{(a, b, c, d) \mid a, b, c, d \geq 1, a+b+c+d=1\} \rightarrow \mathbb{R}$,

$$
f(a, b, c, d)=\frac{1}{27}+\frac{176}{27} a b c d-a b c-b c d-c d a-d a b .
$$

Being a continuous function on a closed and bounded set in $\mathbb{R}^{4}, f$ has a minimum. We claim that the minimum of $f$ is nonnegative. The inequality $f(a, b, c, d) \geq 0$ is easy on the boundary, for if one of the four numbers is zero, say $d=0$, then $f(a, b, c, 0)=$ $\frac{1}{27}-a b c$, and this is nonnegative by the AM-GM inequality.

Any minimum in the interior of the domain should arise by applying the method of Lagrange multipliers. This method gives rise to the system

$$
\begin{aligned}
& \frac{\partial f}{\partial a}=\frac{176}{27} b c d-b c-c d-d b=\lambda, \\
& \frac{\partial f}{\partial b}=\frac{176}{27} a c d-a c-c d-a d=\lambda, \\
& \frac{\partial f}{\partial c}=\frac{176}{27} a b d-a b-a d-b d=\lambda, \\
& \frac{\partial f}{\partial d}=\frac{176}{27} a b c-a b-b c-a c=\lambda \text {, } \\
& a+b+c+d=1 \text {. } 
\end{aligned}
$$

One possible solution to this system is $a=b=c=d=\frac{1}{4}$, in which case $f\left(\frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4}\right)=$ 0 . Otherwise, let us assume that the numbers are not all equal. If three of them are distinct, say $a, b$, and $c$, then by subtracting the second equation from the first, we obtain

$$
\left(\frac{176}{27} c d-c-d\right)(b-a)=0,
$$

and by subtracting the third from the first, we obtain

$$
\left(\frac{176}{27} b d-b-d\right)(c-a)=0 .
$$

Dividing by the nonzero factors $b-a$, respectively, $c-a$, we obtain

$$
\begin{aligned}
&\frac{176}{27} c d-c-d=0, \\
&\frac{176}{27} b d-b-d=0 ;
\end{aligned}
$$

hence $b=c$, a contradiction. It follows that the numbers $a, b, c, d$ for which a minimum is achieved have at most two distinct values. Modulo permutations, either $a=b=c$ or $a=b$ and $c=d$. In the first case, by subtracting the fourth equation from the third and using the fact that $a=b=c$, we obtain

$$
\left(\frac{176}{27} a^{2}-2 a\right)(d-a)=0 .
$$

Since $a \neq d$, it follows that $a=b=c=\frac{27}{88}$ and $d=1-3 a=\frac{7}{88}$. One can verify that

$$
f\left(\frac{27}{88}, \frac{27}{88}, \frac{27}{88}, \frac{7}{88}\right)=\frac{1}{27}+\frac{6}{88} \cdot \frac{27}{88} \cdot \frac{27}{88}>0 .
$$

The case $a=b$ and $c=d$ yields

$$
\begin{aligned}
&\frac{176}{27} c d-c-d=0, \\
&\frac{176}{27} a b-a-b=0,
\end{aligned}
$$

which gives $a=b=c=d=\frac{27}{88}$, impossible. We conclude that $f$ is nonnegative, and the inequality is proved.

(short list of the 34th International Mathematical Olympiad, 1993, proposed by Vietnam) 

513. Fix $\alpha, \beta, \gamma$ and consider the function

$$
f(x, y, z)=\frac{\cos x}{\sin \alpha}+\frac{\cos y}{\sin \beta}+\frac{\cos z}{\sin \gamma}
$$

with the constraints $x+y+z=\pi, x, y, z \geq 0$. We want to determine the maximum of $f(x, y, z)$. In the interior of the triangle described by the constraints a maximum satisfies

$$
\begin{aligned}
\frac{\sin x}{\sin \alpha} &=-\lambda, \\
\frac{\sin y}{\sin \beta} &=-\lambda, \\
\frac{\sin z}{\sin \beta} &=-\lambda, \\
x+y+z &=\pi .
\end{aligned}
$$

By the law of sines, the triangle with angles $x, y, z$ is similar to that with angles $\alpha, \beta, \gamma$, hence $x=\alpha, y=\beta$, and $z=\gamma$.

Let us now examine the boundary. If $x=0$, then $\cos z=-\cos y$. We prove that

$$
\frac{1}{\sin \alpha}+\cos y\left(\frac{1}{\sin \beta}-\frac{1}{\sin \gamma}\right)<\cot \alpha+\cot \beta+\cot \gamma
$$

This is a linear function in $\cos y$, so the inequality will follow from the corresponding inequalities at the two endpoints of the interval, namely from

$$
\frac{1}{\sin \alpha}+\frac{1}{\sin \beta}-\frac{1}{\sin \gamma}<\cot \alpha+\cot \beta+\cot \gamma
$$

and

$$
\frac{1}{\sin \alpha}+\frac{1}{\sin \beta}-\frac{1}{\sin \gamma}<\cot \alpha+\cot \beta+\cot \gamma .
$$

By symmetry, it suffices to prove just one of these two, the first for example. Eliminating the denominators, we obtain

$$
\begin{gathered}
\sin \beta \sin \gamma+\sin \alpha \sin \gamma-\sin \alpha \sin \beta<\sin \beta \sin \gamma \cos \alpha+\sin \alpha \sin \gamma \cos \beta \\
+\sin \alpha \sin \beta \cos \gamma .
\end{gathered}
$$

The laws of sine and cosine allow us to transform this into the equivalent

$$
b c+a c-a b<\frac{b^{2}+c^{2}-a^{2}}{2}+\frac{a^{2}+c^{2}-b^{2}}{2}+\frac{a^{2}+b^{2}-c^{2}}{2},
$$

and this is equivalent to $(a+b-c)^{2}>0$. Hence the conclusion.

(Kvant (Quantum), proposed by R.P. Ushakov)

514. The domain is bounded by the hyperbolas $x y=1, x y=2$ and the lines $y=x$ and $y=2 x$. This domain can mapped into a rectangle by the transformation

$$
T: \quad u=x y, \quad v=\frac{y}{x} .
$$

Thus it is natural to consider the change of coordinates

$$
T^{-1}: \quad x=\sqrt{\frac{u}{v}}, \quad y=\sqrt{u v} .
$$

The domain becomes the rectangle $D^{*}=\left\{(u, v) \in \mathbb{R}^{2} \mid 1 \leq u \leq 2,1 \leq v \leq 2\right\}$. The Jacobian of $T^{-1}$ is $\frac{1}{2 v} \neq 0$. The integral becomes

$$
\int_{1}^{2} \int_{1}^{2} \sqrt{\frac{u}{v}} \frac{1}{2 v} d u d v=\frac{1}{2} \int_{1}^{2} u^{1 / 2} d u \int_{1}^{2} v^{-3 / 2} d v=\frac{1}{3}(5 \sqrt{2}-6) .
$$

(Gh. Bucur, E. Câmpu, S. Găină, Culegere de Probleme de Calcul Diferenţial şi Integral (Collection of Problems in Differential and Integral Calculus), Editura Tehnică, Bucharest, 1967)

515. Denote the integral by $I$. The change of variable $(x, y, z) \rightarrow(z, y, x)$ transforms the integral into

$$
\iiint_{B} \frac{z^{4}+2 y^{4}}{x^{4}+4 y^{4}+z^{4}} d x d y d z .
$$

Hence

$$
\begin{aligned}
2 I &=\iiint_{B} \frac{x^{4}+2 y^{4}}{x^{4}+4 y^{4}+z^{4}} d x d y d z+\iiint_{B} \frac{2 y^{4}+z^{4}}{x^{4}+4 y^{4}+z^{4}} d x d y d z \\
&=\iiint_{B} \frac{x^{4}+4 y^{4}+z^{4}}{x^{4}+4 y^{4}+z^{4}} d x d y d z=\frac{4 \pi}{3} .
\end{aligned}
$$

It follows that $I=\frac{2 \pi}{3}$.

516. The domain $D$ is depicted in Figure 71 . We transform it into the rectangle $D_{1}=$ $\left[\frac{1}{4}, \frac{1}{2}\right] \times\left[\frac{1}{6}, \frac{1}{2}\right]$ by the change of coordinates

$$
x=\frac{u}{u^{2}+v^{2}}, \quad y=\frac{v}{u^{2}+v^{2}} .
$$

The Jacobian is 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-582.jpg?height=524&width=603&top_left_y=244&top_left_x=570)

Figure 71

$$
J=-\frac{1}{\left(u^{2}+v^{2}\right)^{2}} .
$$

Therefore,

$$
\iint_{D} \frac{d x d y}{\left(x^{2}+y^{2}\right)^{2}}=\iint_{D_{1}} d u d v=\frac{1}{12} .
$$

(D. Flondor, N. Donciu, Algebră şi Analiză Matematică (Algebra and Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1965)

517. In the equation of the curve that bounds the domain

$$
\left(\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}\right)^{2}=\frac{x^{2}}{a^{2}}-\frac{y^{2}}{b^{2}},
$$

the expression on the left suggests the use of generalized polar coordinates, which are suited for elliptical domains. And indeed, if we set $x=a r \cos \theta$ and $y=b r \sin \theta$, the equation of the curve becomes $r^{4}=r^{2} \cos 2 \theta$, or $r=\sqrt{\cos 2 \theta}$. The condition $x \geq 0$ becomes $-\frac{\pi}{2} \leq \theta \leq \frac{\pi}{2}$, and because $\cos 2 \theta$ should be positive we should further have $-\frac{\pi}{4} \leq \theta \leq \frac{\pi}{4}$. Hence the domain of integration is

$$
\left\{(r, \theta) ; \quad 0 \leq r \leq \sqrt{\cos 2 \theta},-\frac{\pi}{4} \leq \theta \leq \frac{\pi}{4}\right\} .
$$

The Jacobian of the transformation is $J=a b r$. Applying the formula for the change of variables, the integral becomes

$$
\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \int_{0}^{\sqrt{\cos 2 \theta}} a^{2} b^{2} r^{3} \cos \theta|\sin \theta| d r d \theta=\frac{a^{2} b^{2}}{4} \int_{0}^{\frac{\pi}{4}} \cos ^{2} 2 \theta \sin 2 \theta d \theta=\frac{a^{2} b^{2}}{24} .
$$

(Gh. Bucur, E. Câmpu, S. Găină, Culegere de Probleme de Calcul Diferenţial şi Integral (Collection of Problems in Differential and Integral Calculus), Editura Tehnică, Bucharest, 1967)

518. The method is similar to that for computing the Fresnel integrals, only simpler. If we denote the integral by $I$, then

$$
I^{2}=\int_{-\infty}^{\infty} e^{-x^{2}} d x \int_{-\infty}^{\infty} e^{-y^{2}} d y=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-\left(x^{2}+y^{2}\right)} d x d y .
$$

Switching to polar coordinates, we obtain

$$
I^{2}=\int_{0}^{2 \pi} \int_{0}^{\infty} e^{-r^{2}} r d r d \theta=\left.\int_{0}^{2 \pi}\left(-\frac{1}{2}\right) e^{-r^{2}}\right|_{0} ^{\infty} d \theta=\int_{0}^{2 \pi} \frac{1}{2} d \theta=\pi .
$$

Hence the desired formula $I=\sqrt{\pi}$.

519. Call the integral $I$. By symmetry, we may compute it over the domain $\{(u, v, w) \in$ $\left.\mathbb{R}^{3} \mid 0 \leq v \leq u \leq 1\right\}$, then double the result. We substitute $u=r \cos \theta, v=r \sin \theta, w=$ $\tan \phi$, taking into account that the limits of integration become $0 \leq \theta, \phi \leq \frac{\pi}{4}$, and $0 \leq r \leq \sec \theta$. We have

$$
\begin{aligned}
I &=2 \int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \int_{0}^{\sec \theta} \frac{r \sec ^{2} \phi}{\left(1+r^{2} \cos ^{2} \theta+r^{2} \sin ^{2} \theta+\tan ^{2} \phi\right)^{2}} d r d \theta d \phi \\
&=2 \int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \int_{0}^{\sec \theta} \frac{r \sec ^{2} \phi}{\left(r^{2}+\sec ^{2} \phi\right)^{2}} d r d \theta d \phi \\
&=\left.2 \int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \sec ^{2} \phi \frac{-1}{2\left(r^{2}+\sec ^{2} \phi\right)}\right|_{r=0} ^{r=\sec \theta} d \theta d \phi \\
&=-\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \frac{\sec ^{2} \phi}{\sec ^{2} \theta+\sec ^{2} \phi} d \theta d \phi+\left(\frac{\pi}{4}\right)^{2} .
\end{aligned}
$$

But notice that this is the same as

$$
\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}}\left(1-\frac{\sec ^{2} \phi}{\sec ^{2} \theta+\sec ^{2} \phi}\right) d \theta d \phi=\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \frac{\sec ^{2} \theta}{\sec ^{2} \theta+\sec ^{2} \phi} d \theta d \phi .
$$

If we exchange the roles of $\theta$ and $\phi$ in this last integral we see that

$$
-\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \frac{\sec ^{2} \phi}{\sec ^{2} \theta+\sec ^{2} \phi} d \theta d \phi+\left(\frac{\pi}{4}\right)^{2}=\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \frac{\sec ^{2} \phi}{\sec ^{2} \theta+\sec ^{2} \phi} d \theta d \phi .
$$

Hence

$$
\int_{0}^{\frac{\pi}{4}} \int_{0}^{\frac{\pi}{4}} \frac{\sec ^{2} \phi}{\sec ^{2} \theta+\sec ^{2} \phi} d \theta d \phi=\frac{\pi^{2}}{32} .
$$

Consequently, the integral we are computing is equal to $\frac{\pi^{2}}{32}$.

(American Mathematical Monthly, proposed by M. Hajja and P. Walker)

520. We have

$$
\begin{aligned}
I &=\iint_{D} \ln |\sin (x-y)| d x d y=\int_{0}^{\pi}\left(\int_{0}^{y} \ln |\sin (y-x)| d x\right) d y \\
&=\int_{0}^{\pi}\left(\int_{0}^{y} \ln \sin t d t\right) d y=\left.y \int_{0}^{y} \ln \sin t d t\right|_{y=0} ^{y=\pi}-\int_{0}^{\pi} y \ln \sin y d y \\
&=\pi A-B,
\end{aligned}
$$

where $A=\int_{0}^{\pi} \ln \sin t d t, B=\int_{0}^{\pi} t \ln \sin t d t$. Note that here we used integration by parts! We compute further

$$
\begin{aligned}
A &=\int_{0}^{\frac{\pi}{2}} \ln \sin t d t+\int_{\frac{\pi}{2}}^{\pi} \ln \sin t d t=\int_{0}^{\frac{\pi}{2}} \ln \sin t d t+\int_{0}^{\frac{\pi}{2}} \ln \cos t d t \\
&=\int_{0}^{\frac{\pi}{2}}(\ln \sin 2 t-\ln 2) d t=-\frac{\pi}{2} \ln 2+\frac{1}{2} A .
\end{aligned}
$$

Hence $A=-\pi \ln 2$. For $B$ we use the substitution $t=\pi-x$ to obtain

$$
B=\int_{0}^{\pi}(\pi-x) \ln \sin x d x=\pi A-B .
$$

Hence $B=\frac{\pi}{2} A$. Therefore, $I=\pi A-B=-\frac{\pi^{2}}{2} \ln 2$, and we are done.

Remark. The identity

$$
\int_{0}^{\frac{\pi}{2}} \ln \sin t d t=-\frac{\pi}{2} \ln 2
$$

belongs to Euler.

(S. Rădulescu, M. Rădulescu, Teoreme şi Probleme de Analiză Matematică (Theorems and Problems in Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1982).

521. This problem applies the discrete version of Fubini's theorem. Define

$$
f(i, j)= \begin{cases}1 & \text { for } j \leq a_{i}, \\ 0 & \text { for } j>a_{i}\end{cases}
$$

The left-hand side is equal to $\sum_{i=1}^{n} \sum_{j=1}^{m} f(i, j)$, while the right-hand side is equal to $\sum_{j=1}^{m} \sum_{i=1}^{n} f(i, j)$. The equality follows. 

522. First, note that for $x>0$,

$$
e^{-s x} x^{-1}|\sin x|<e^{-s x},
$$

so the integral that we are computing is finite.

Now consider the two-variable function

$$
f(x, y)=e^{-s x y} \sin x .
$$

We have

$$
\int_{0}^{\infty} \int_{1}^{\infty}|f(x, y)| d y d x=\int_{0}^{\infty} \int_{1}^{\infty} e^{-s x y}|\sin x| d y d x=\frac{1}{s} \int_{0}^{\infty} e^{-s x} x^{-1}|\sin x| d x,
$$

and we just saw that this is finite. Hence we can apply Fubini's theorem, to conclude that on the one hand,

$$
\int_{0}^{\infty} \int_{1}^{\infty} f(x, y) d y d x=\frac{1}{s} \int_{0}^{\infty} e^{-s x} x^{-1} \sin x d x,
$$

and on the other hand,

$$
\int_{0}^{\infty} \int_{1}^{\infty} f(x, y) d y d x=\int_{1}^{\infty} \frac{1}{s^{2} y^{2}+1} d y .
$$

Here of course we used the fact that

$$
\int_{0}^{\infty} e^{-a x} \sin x d x=\frac{1}{a^{2}+1}, \quad a>0,
$$

a formula that can be proved by integrating by parts. Equating the two expressions that we obtained for the double integral, we obtain

$$
\int_{0}^{\infty} e^{-s x} x^{-1} \sin x d x=\frac{\pi}{2}-\arctan s=\arctan \left(s^{-1}\right),
$$

as desired.

(G.B. Folland, Real Analysis, Modern Techniques and Their Applications, Wiley, 1999)

523. Applying Tonelli's theorem to the function $f(x, y)=e^{-x y}$, we can write

$$
\begin{aligned}
\int_{0}^{\infty} \frac{e^{-a x}-e^{-b x}}{x} d x &=\int_{0}^{\infty} \int_{a}^{b} e^{-x y} d y d x=\int_{a}^{b} \int_{0}^{\infty} e^{-x y} d x d y \\
&=\int_{a}^{b} \frac{1}{y} d y=\ln \frac{b}{a}
\end{aligned}
$$

Remark. This is a particular case of integrals of the form $\int_{0}^{\infty} \frac{f(a x)-f(b x)}{x} d x$, known as Froullani integrals. In general, if $f$ is continuous and has finite limit at infinity, the value of the integral is $\left(f(0)-\lim _{x \rightarrow \infty} f(x)\right) \ln \frac{b}{a}$.

524. We do the proof in the case $0<x<1$, since for $-1<x<0$ the proof is completely analogous, while for $x=0$ the property is obvious. The function $f: \mathbb{N} \times[0, x] \rightarrow \mathbb{R}$, $f(n, t)=t^{n-1}$ satisfies the hypothesis of Fubini's theorem. So integration commutes with summation:

$$
\sum_{n=0}^{\infty} \int_{0}^{x} t^{n-1} d t=\int_{0}^{x} \frac{d t}{1-t} .
$$

This implies

$$
\sum_{n=1}^{\infty} \frac{x^{n}}{n}=-\ln (1-x)
$$

Dividing by $x$, we obtain

$$
\sum_{n=1}^{\infty} \frac{x^{n-1}}{n}=-\frac{1}{x} \ln (1-x)
$$

The right-hand side extends continuously at 0 , since $\lim _{x \rightarrow 0} \frac{1}{t} \ln (1-t)=-1$. Again we can apply Fubini's theorem to $f(n, t)=\frac{t^{n-1}}{n}$ on $\mathbb{N} \times[0, x]$ to obtain

$$
\sum_{n=1}^{\infty} \frac{x^{n}}{n^{2}}=\sum_{n=1}^{\infty} \int_{0}^{x} \frac{t^{n-1}}{n} d t=\int_{0}^{x} \sum_{n=1}^{\infty} \frac{t^{n-1}}{n} d t=-\int_{0}^{x} \frac{1}{t} \ln (1-t) d t
$$

as desired.

525. We can apply Tonelli's theorem to the function $f(x, n)=\frac{1}{x^{2}+n^{4}}$. Integrating term by term, we obtain

$$
\int_{0}^{x} F(t) d t=\int_{0}^{x} \sum_{n=1}^{\infty} f(t, n) d t=\sum_{n=1}^{\infty} \int_{0}^{x} \frac{d t}{t^{2}+n^{4}}=\sum_{n=1}^{\infty} \frac{1}{n^{2}} \arctan \frac{x}{n^{2}} .
$$

This series is bounded from above by $\sum_{n=1}^{\infty} \frac{1}{n^{2}}=\frac{\pi^{2}}{6}$. Hence the summation commutes with the limit as $x$ tends to infinity. We have

$$
\int_{0}^{\infty} F(t) d t=\lim _{x \rightarrow \infty} \int_{0}^{x} F(t) d t=\lim _{x \rightarrow \infty} \sum_{n=1}^{\infty} \frac{1}{n^{2}} \arctan \frac{x}{n^{2}}=\sum_{n=1}^{\infty} \frac{1}{n^{2}} \cdot \frac{\pi}{2} .
$$

Using the identity $\sum_{n \geq 1} \frac{1}{n^{2}}=\frac{\pi^{2}}{6}$, we obtain

$$
\int_{0}^{\infty} F(t) d t=\frac{\pi^{3}}{12} .
$$

(Gh. Sireţchi, Calcul Diferenţial şi Integral (Differential and Integral Calculus), Editura Ştiinţifică şi Enciclopedică, Bucharest, 1985)

526. The integral from the statement can be written as

$$
\oint_{\partial D} x d y-y d x .
$$

Applying Green's theorem for $P(x, y)=-y$ and $Q(x, y)=x$, we obtain

$$
\oint_{\partial D} x d y-y d x=\iint_{D}(1+1) d x d y,
$$

which is twice the area of $D$. The conclusion follows.

527. It can be checked that $\operatorname{div} \vec{F}=0$ (in fact, $\vec{F}$ is the curl of the vector field $e^{y z} \vec{i}+$ $e^{z x} \vec{j}+e^{x y} \vec{k}$ ). If $S$ be the union of the upper hemisphere and the unit disk in the $x y$-plane, then by the divergence theorem $\iint_{S} \vec{F} \cdot \vec{n} d S=0$. And on the unit disk $\vec{F} \cdot \vec{n}=0$, which means that the flux across the unit disk is zero. It follows that the flux across the upper hemisphere is zero as well.

528. We simplify the computation using Stokes' theorem:

$$
\oint_{C} y^{2} d x+z^{2} d y+x^{2} d z=-2 \iint_{S} y d x d y+z d y d z+x d z d x
$$

where $S$ is the portion of the sphere bounded by the Viviani curve. We have

$$
-2 \iint_{S} y d x d y+z d y d z+x d z d x=-2 \iint_{S}(z, x, y) \cdot \vec{n} d \sigma,
$$

where $(z, x, y)$ denotes the three-dimensional vector with coordinates $z, x$, and $y$, while $\vec{n}$ denotes the unit vector normal to the sphere at the point of coordinates $(x, y, z)$. We parametrize the portion of the sphere in question by the coordinates $(x, y)$, which range inside the circle $x^{2}+y^{2}-a x=0$. This circle is the projection of the Viviani curve onto the $x y$-plane.

The unit vector normal to the sphere is

$$
\vec{n}=\left(\frac{x}{a}, \frac{y}{a}, \frac{z}{a}\right)=\left(\frac{x}{a}, \frac{y}{a}, \frac{\sqrt{a^{2}-x^{2}-y^{2}}}{a}\right),
$$

while the area element is

$$
d \sigma=\frac{1}{\cos \alpha} d x d y,
$$

$\alpha$ being the angle formed by the normal to the sphere with the $x y$-plane. It is easy to see that $\cos \alpha=\frac{z}{a}=\frac{\sqrt{a^{2}-x^{2}-y^{2}}}{a}$. Hence the integral is equal to

$$
-2 \iint_{D}\left(z \frac{x}{a}+x \frac{y}{a}+y \frac{z}{a}\right) \frac{a}{z} d x d y=-2 \iint_{D}\left(x+y+\frac{x y}{\sqrt{a^{2}-x^{2}-y^{2}}}\right) d x d y
$$

the domain of integration $D$ being the disk $x^{2}+y^{2}-a x \leq 0$. Split the integral as

$$
-2 \iint_{D}(x+y) d x d y-2 \iint_{D} \frac{x y}{\sqrt{a^{2}-x^{2}-y^{2}}} d x d y .
$$

Because the domain of integration is symmetric with respect to the $y$-axis, the second double integral is zero. The first double integral can be computed using polar coordinates: $x=\frac{a}{2}+r \cos \theta, y=r \sin \theta, 0 \leq r \leq \frac{a}{2}, 0 \leq \theta \leq 2 \pi$. Its value is $-\frac{\pi a^{3}}{4}$, which is the answer to the problem.

(D. Flondor, N. Donciu, Algebră şi Analiză Matematică (Algebra and Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1965)

529. We will apply Stokes' theorem. We begin with

$$
\begin{aligned}
\frac{\partial \phi}{\partial y} \frac{\partial \psi}{\partial z}-\frac{\partial \phi}{\partial z} \frac{\partial \psi}{\partial y} &=\frac{\partial \phi}{\partial y} \frac{\partial \psi}{\partial z}+\phi \frac{\partial^{2} \psi}{\partial y \partial z}-\frac{\partial \phi}{\partial z} \frac{\partial \psi}{\partial y}-\phi \frac{\partial^{2} \psi}{\partial z \partial y} \\
&=\frac{\partial}{\partial y}\left(\phi \frac{\partial \psi}{\partial z}\right)-\frac{\partial}{\partial z}\left(\phi \frac{\partial \psi}{\partial y}\right)
\end{aligned}
$$

which combined with the two other analogous computations gives

$$
\nabla \phi \times \nabla \psi=\operatorname{curl}(\phi \nabla \psi) .
$$

By Stokes' theorem, the integral of the curl of a vector field on a surface without boundary is zero.

(Soviet University Student Mathematical Competition, 1976)

530. For the solution, recall the following identity.

Green's first identity. If $f$ and $g$ are twice-differentiable functions on the solid region $R$ bounded by the closed surface $S$, then

$$
\iiint_{R}\left(f \nabla^{2} g+\nabla f \cdot \nabla g\right) d V=\iint_{S} f \frac{\partial g}{\partial n} d S,
$$

where $\frac{\partial g}{\partial n}$ is the derivative of $g$ in the direction of the normal to the surface. Proof. For the sake of completeness we will prove Green's identity. Consider the vector field $\vec{F}=f \nabla g$. Then

$$
\begin{aligned}
\operatorname{div} \vec{F} &=\frac{\partial}{\partial x}\left(f \frac{\partial g}{\partial x}\right)+\frac{\partial}{\partial y}\left(f \frac{\partial g}{\partial y}\right)+\frac{\partial}{\partial z}\left(f \frac{\partial g}{\partial z}\right) \\
&=f\left(\frac{\partial^{2} g}{\partial x^{2}}+\frac{\partial^{2} g}{\partial y^{2}}+\frac{\partial^{2} g}{\partial z^{2}}\right)+\left(\frac{\partial f}{\partial x} \frac{\partial g}{\partial x}+\frac{\partial f}{\partial y} \frac{\partial g}{\partial y}+\frac{\partial f}{\partial z} \frac{\partial g}{\partial z}\right) .
\end{aligned}
$$

So the left-hand side is $\iiint_{R} \operatorname{div} \vec{F} d V$. By the Gauss-Ostrogradski divergence theorem this is equal to

$$
\iint_{S}(f \nabla g) \cdot \vec{n} d S=\iint_{S} f(\nabla g \cdot \vec{n}) d S=\iint_{S} f \frac{\partial g}{\partial n} d S .
$$

Writing Green's first identity for the vector field $g \nabla f$ and then subtracting it from that of the vector field $f \nabla g$, we obtain Green's second identity

$$
\iiint_{R}\left(f \nabla^{2} g-g \nabla^{2} f\right) d V=\iint_{S}\left(f \frac{\partial g}{\partial n}-g \frac{\partial f}{\partial n}\right) d S .
$$

The fact that $f$ and $g$ are constant along the lines passing through the origin means that on the unit sphere, $\frac{\partial f}{\partial n}=\frac{\partial g}{\partial n}=0$. Hence the conclusion.

531. Because $\vec{F}$ is obtained as an integral of the point-mass contributions of the masses distributed in space, it suffices to prove this equality for a mass $M$ concentrated at one point, say the origin.

Newton's law says that the gravitational force between two masses $m_{1}$ and $m_{2}$ at distance $r$ is equal to $\frac{m_{1} m_{2} G}{r^{2}}$. By Newton's law, a mass $M$ located at the origin generates the gravitational field

$$
\vec{F}(x, y, z)=M G \frac{1}{x^{2}+y^{2}+z^{2}} \cdot \frac{x \vec{i}+y \vec{j}+z \vec{k}}{\sqrt{x^{2}+y^{2}+z^{2}}}=-M G \frac{x \vec{i}+y \vec{j}+z \vec{k}}{\left(x^{2}+y^{2}+z^{2}\right)^{3 / 2}} .
$$

One can easily check that the divergence of this field is zero. Consider a small sphere $S_{0}$ of radius $r$ centered at the origin, and let $V$ be the solid lying between $S_{0}$ and $S$. By the Gauss-Ostrogradski divergence theorem,

$$
\iint_{S} \vec{F} \cdot \vec{n} d S-\iint_{S_{0}} \vec{F} \cdot \vec{n} d S=\iiint_{V} \operatorname{div} \vec{F} d V=0
$$

Hence it suffices to prove the Gauss law for the sphere $S_{0}$. On this sphere the flow $\vec{F} \cdot \vec{n}$ is constantly equal to $-\frac{G M}{r^{2}}$. Integrating it over the sphere gives $-4 \pi M G$, proving the law. 

532. The condition curl $\vec{F}=0$ suggests the use of Stokes' theorem:

$$
\iint_{S} \operatorname{curl} \vec{F} \cdot \vec{n} d S=\oint_{\partial C} \vec{F} \cdot d \vec{R} .
$$

We expect the answer to the question to be no. All we need is to find a surface $S$ whose boundary lies in the $x y$-plane and such that the integral of $\vec{G}(x, y)$ on $\partial S$ is nonzero.

A simple example that comes to mind is the interior $S$ of the ellipse $x^{2}+4 y^{2}=4$. Parametrize the ellipse as $x=2 \cos \theta, y=\sin \theta, \theta \in[0,2 \pi)$. Then

$$
\oint_{\partial S} \vec{G} \cdot d \vec{R}=\int_{0}^{2 \pi}\left(\frac{-\sin \theta}{4}, \frac{2 \cos \theta}{4}, 0\right) \cdot(-2 \sin \theta, \cos \theta, 0) d \theta=\int_{0}^{2 \pi} \frac{1}{2} d \theta=\pi .
$$

By Stokes' theorem this should be equal to the integral of the curl of $\vec{F}$ over the interior of the ellipse. The curl of $\vec{F}$ is zero except at the origin, but we can fix that by adding a smooth tiny upward bump at the origin, which does not alter too much the above computation. The integral should on the one hand be close to 0 , and on the other hand close to $\pi$, which is impossible. This proves that such a vector field $\vec{F}$ cannot exist.

(48th W.L. Putnam Mathematical Competition, 1987, solution from K. Kedlaya, B. Poonen, R. Vakil, The William Lowell Putnam Mathematical Competition 1985-2000, MAA, 2002)

533. Let $D=\left[a_{1}, b_{1}\right] \times\left[a_{2}, b_{2}\right]$ be a rectangle in the plane, and $a, b \in \mathbb{R}, a<b$. We consider the three-dimensional parallelepiped $V=D \times[a, b]$. Denote by $\vec{n}$ the outward normal vector field on the boundary $\partial V$ of $V$ (which is defined everywhere except on the edges). By the Leibniz-Newton fundamental theorem of calculus,

$$
\begin{aligned}
\int_{a}^{b} \frac{d}{d t} \iint_{D} G(x, y, t) d x d y d t &=\int_{a}^{b} \iint_{D} \frac{\partial}{\partial t} G(x, y, t) d x d y d t \\
&=\iint_{D} \int_{a}^{b} \frac{\partial}{\partial t} G(x, y, t) d t d x d y \\
&=\iint_{D} G(x, y, b) d x d y-\iint_{D} G(x, y, a) d x d y \\
&=\int_{D \times\{b\}} G(x, y, t) \vec{k} \cdot d \vec{n}+\int_{D \times\{a\}} G(x, y, t) \vec{k} \cdot d \vec{n},
\end{aligned}
$$

where $\vec{k}$ denotes the unit vector that points in the $z$-direction. With this in mind, we compute

$$
0=\int_{a}^{b}\left(\frac{d}{d t} \iint_{D} G(x, y, t) d x d y+\oint_{C} \vec{F} \cdot d \vec{R}\right) d t
$$



$$
\begin{aligned}
=& \int_{D \times\{b\}} G(x, y, t) \vec{k} \cdot d \vec{n}+\int_{D \times\{a\}} G(x, y, t) \vec{k} \cdot d \vec{n} \\
&+\int_{a}^{b} \int_{a_{1}}^{b_{1}} F_{1}\left(x, a_{2}\right) d x-\int_{a}^{b} \int_{b_{1}}^{a_{1}} F_{1}\left(x, b_{2}\right) d x \\
&+\int_{a}^{b} \int_{a_{2}}^{b_{2}} F_{2}\left(b_{1}, y\right) d y-\int_{a}^{b} \int_{b_{2}}^{a_{2}} F_{2}\left(a_{1}, y\right) d y .
\end{aligned}
$$

If we introduce the vector field $\vec{H}=F_{2} \vec{i}+F_{1} \vec{j}+G \vec{k}$, this equation can be written simply as

$$
\iint_{\partial V} \vec{H} \cdot \vec{n} d S=0
$$

By the divergence theorem,

$$
\iiint_{V} \operatorname{div} \vec{H} d V=\iint_{\partial V} \vec{H} \cdot \vec{n} d S=0
$$

Since this happens in every parallelepiped, div $\vec{H}$ must be identically equal to 0 . Therefore,

$$
\operatorname{div} \vec{H}=\frac{\partial F_{2}}{\partial x}+\frac{\partial F_{1}}{\partial y}+\frac{\partial G}{\partial t}=0
$$

and the relation is proved.

Remark. The interesting case occurs when $\vec{F}$ and $G$ depend on spatial variables (spatial dimensions). Then $G$ becomes a vector field $B$, or better a 2-form, called the magnetic flux, while $F$ becomes the electric field strength $E$. The relation

$$
\frac{d}{d t} \int_{S} B=-\int_{\partial S} E
$$

is Faraday's law of induction. Introducing a fourth dimension (the time), and redoing mutatis mutandis the above computation gives rise to the first group of Maxwell's equations

$$
\operatorname{div} B=0, \quad \frac{\partial B}{\partial t}=\operatorname{curl} E .
$$

534. In the solution we ignore the factor $\frac{1}{4 \pi}$, which is there only to make the linking number an integer. We will use the more general form of Green's theorem applied to the curve $C=C_{1} \cup C_{1}^{\prime}$ and surface $S$ 

$$
\begin{aligned}
\oint_{C} P d x+Q d y+R d z=& \iint_{S}\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right) d x d y+\left(\frac{\partial R}{\partial y}-\frac{\partial Q}{\partial z}\right) d y d z \\
&+\left(\frac{\partial P}{\partial z}-\frac{\partial R}{\partial x}\right) d z d x
\end{aligned}
$$

Writing the parametrization with coordinate functions $\vec{v}_{1}(s)=(x(s), y(s), z(s))$, $\vec{v}_{2}(t)=\left(x^{\prime}(t), y^{\prime}(t), z^{\prime}(t)\right)$, the linking number of $C_{1}$ and $C_{2}$ (with the factor $\frac{1}{4 \pi}$ ignored) becomes

$$
\oint_{C_{1}} \oint_{C_{2}} \frac{\left(x^{\prime}-x\right)\left(d z^{\prime} d y-d y^{\prime} d z\right)+\left(y^{\prime}-y\right)\left(d x^{\prime} d z-d z^{\prime} d x\right)+\left(z^{\prime}-z\right)\left(d y^{\prime} d x-d x^{\prime} d y\right)}{\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{3 / 2}}
$$

The 1-form $P d x+Q d y+R d z$, which we integrate on $C=C_{1} \cup C_{1}^{\prime}$, is

$$
\oint_{C_{2}} \frac{\left(x^{\prime}-x\right)\left(d z^{\prime} d y-d y^{\prime} d z\right)+\left(y^{\prime}-y\right)\left(d x^{\prime} d z-d z^{\prime} d x\right)+\left(z^{\prime}-z\right)\left(d y^{\prime} d x-d x^{\prime} d y\right)}{\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{3 / 2}} .
$$

Note that here we integrate against the variables $x^{\prime}, y^{\prime}, z^{\prime}$, so this expression depends only on $x, y$, and $z$. Explicitly,

$$
\begin{aligned}
P(x, y, z) &=\oint_{C_{2}} \frac{-\left(y^{\prime}-y\right) d z^{\prime}+\left(z^{\prime}-z\right) d y^{\prime}}{\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{3 / 2}}, \\
Q(x, y, z) &=\oint_{C_{2}} \frac{\left(x^{\prime}-x\right) d z^{\prime}-\left(z^{\prime}-z\right) d x^{\prime}}{\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{3 / 2}}, \\
R(x, y, z) &=\oint_{C_{2}} \frac{-\left(x^{\prime}-x\right) d y^{\prime}+\left(y^{\prime}-y\right) d x^{\prime}}{\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{3 / 2}} .
\end{aligned}
$$

By the general form of Green's theorem, $\operatorname{lk}\left(C_{1}, C_{2}\right)=\operatorname{lk}\left(C_{1}^{\prime}, C_{2}\right)$ if

$$
\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}=\frac{\partial R}{\partial y}-\frac{\partial Q}{\partial z}=\frac{\partial P}{\partial z}-\frac{\partial R}{\partial x}=0 .
$$

We will verify only $\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}=0$, the other equalities having similar proofs. The part of it that contains $d z^{\prime}$ is equal to

$$
\begin{aligned}
\oint_{C_{2}}-2 &\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-3 / 2} \\
&+3\left(x^{\prime}-x\right)^{2}\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-5 / 2} \\
&+3\left(y^{\prime}-y\right)^{2}\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-5 / 2} d z^{\prime} \\
=& \oint_{C_{2}}\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-3 / 2} \\
&+3\left(z^{\prime}-z\right)^{2}\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-5 / 2} d z^{\prime}
\end{aligned}
$$



$$
=\oint_{C_{2}} \frac{\partial}{\partial z^{\prime}}\left(\left(x^{\prime}-x\right)^{2}+\left(y^{\prime}-y\right)^{2}+\left(z^{\prime}-z\right)^{2}\right)^{-3 / 2} d z^{\prime}=0,
$$

where the last equality is a consequence of the fundamental theorem of calculus. Of the two, only $\frac{\partial Q}{\partial x}$ has a $d x^{\prime}$ in it, and that part is

$$
\begin{gathered}
3 \oint_{C_{2}}\left(\left(x-x^{\prime}\right)^{2}+\left(y-y^{\prime}\right)^{2}+\left(z-z^{\prime}\right)^{2}\right)^{-5 / 2}\left(x-x^{\prime}\right)\left(z-z^{\prime}\right) d x^{\prime} \\
=\oint_{C_{2}} \frac{\partial}{\partial x^{\prime}} \frac{z-z^{\prime}}{\left(\left(x-x^{\prime}\right)^{2}+\left(y-y^{\prime}\right)^{2}+\left(z-z^{\prime}\right)^{2}\right)^{3 / 2}} d x^{\prime}=0 .
\end{gathered}
$$

The term involving $d y^{\prime}$ is treated similarly. The conclusion follows.

Remark. The linking number is, in fact, an integer, which measures the number of times the curves wind around each other. It was defined by C.F. Gauss, who used it to decide, based on astronomical observations, whether the orbits of certain asteroids were winding around the orbit of the earth.

535. Plugging in $x=y$, we find that $f(0)=0$, and plugging in $x=-1, y=0$, we find that $f(1)=-f(-1)$. Also, plugging in $x=a, y=1$, and then $x=a, y=-1$, we obtain

$$
\begin{aligned}
&f\left(a^{2}-1\right)=(a-1)(f(a)+f(1)), \\
&f\left(a^{2}-1\right)=(a+1)(f(a)-f(1)) .
\end{aligned}
$$

Equating the right-hand sides and solving for $f(a)$ gives $f(a)=f(1) a$ for all $a$.

So any such function is linear. Conversely, a function of the form $f(x)=k x$ clearly satisfies the equation.

(Korean Mathematical Olympiad, 2000)

536. Replace $z$ by $1-z$ to obtain

$$
f(1-z)+(1-z) f(z)=2-z .
$$

Combine this with $f(z)+z f(1-z)=1+z$, and eliminate $f(1-z)$ to obtain

$$
\left(1-z+z^{2}\right) f(z)=1-z+z^{2} .
$$

Hence $f(z)=1$ for all $z$ except maybe for $z=e^{\pm \pi i / 3}$, when $1-z+z^{2}=0$. For $\alpha=e^{i \pi / 3}, \bar{\alpha}=\alpha^{2}=1-\alpha$; hence $f(\alpha)+\alpha f(\bar{\alpha})=1+\alpha$. We therefore have only one constraint, namely $f(\bar{\alpha})=[1+\alpha-f(\alpha)] / \alpha=\bar{\alpha}+1-\bar{\alpha} f(\alpha)$. Hence the solution to the functional equation is of the form

$$
f(z)=1 \quad \text { for } z \neq e^{\pm i \pi / 3},
$$



$$
\begin{aligned}
f\left(e^{i \pi / 3}\right) &=\beta \\
f\left(e^{-i \pi / 3}\right) &=\bar{\alpha}+1-\bar{\alpha} \beta
\end{aligned}
$$

where $\beta$ is an arbitrary complex parameter.

(20th W.L. Putnam Competition, 1959)

537. Successively, we obtain

$$
f(-1)=f\left(-\frac{1}{2}\right)=f\left(-\frac{1}{3}\right)=\cdots=\lim _{n \rightarrow \infty} f\left(-\frac{1}{n}\right)=f(0) .
$$

Hence $f(x)=f(0)$ for $x \in\left\{0,-1,-\frac{1}{2}, \ldots,-\frac{1}{n}, \ldots\right\}$.

If $x \neq 0,-1, \ldots,-\frac{1}{n}, \ldots$, replacing $x$ by $\frac{x}{1+x}$ in the functional equation, we obtain

$$
f\left(\frac{x}{1+x}\right)=f\left(\frac{\frac{x}{1+x}}{1-\frac{x}{1+x}}\right)=f(x) .
$$

And this can be iterated to yield

$$
f\left(\frac{x}{1+n x}\right)=f(x), \quad n=1,2,3 \ldots
$$

Because $f$ is continuous at 0 it follows that

$$
f(x)=\lim _{n \rightarrow \infty} f\left(\frac{x}{1+n x}\right)=f(0) .
$$

This shows that only constant functions satisfy the functional equation.

538. Plugging in $x=t, y=0, z=0$ gives

$$
f(t)+f(0)+f(t) \geq 3 f(t),
$$

or $f(0) \geq f(t)$ for all real numbers $t$. Plugging in $x=\frac{t}{2}, y=\frac{t}{2}, z=-\frac{t}{2}$ gives

$$
f(t)+f(0)+f(0) \geq 3 f(0),
$$

or $f(t) \geq f(0)$ for all real numbers $t$. Hence $f(t)=f(0)$ for all $t$, so $f$ must be constant. Conversely, any constant function $f$ clearly satisfies the given condition.

(Russian Mathematical Olympiad, 2000)

539. No! In fact, we will prove a more general result.

Proposition. Let $S$ be a set and $g: S \rightarrow S$ a function that has exactly two fixed points $\{a, b\}$ and such that $g \circ g$ has exactly four fixed points $\{a, b, c, d\}$. Then there is no function $f: S \rightarrow S$ such that $g=f \circ f$. Proof. Let $g(c)=y$. Then $c=g(g(c))=g(y)$; hence $y=g(c)=g(g(y))$. Thus $y$ is a fixed point of $g \circ g$. If $y=a$, then $a=g(a)=g(y)=c$, leading to a contradiction. Similarly, $y=b$ forces $c=b$. If $y=c$, then $c=g(y)=g(c)$, so $c$ is a fixed point of $g$, again a contradiction. It follows that $y=d$, i.e., $g(c)=d$, and similarly $g(d)=c$.

Suppose there is $f: S \rightarrow S$ such that $f \circ f=g$. Then $f \circ g=f \circ f \circ f=g \circ f$. Then $f(a)=f(g(a))=g(f(a))$, so $f(a)$ is a fixed point of $g$. Examining case by case, we conclude that $f(\{a, b\}) \subset\{a, b\}$ and $f(\{a, b, c, d\}) \subset\{a, b, c, d\}$. Because $f \circ f=g$, the inclusions are, in fact, equalities.

Consider $f(c)$. If $f(c)=a$, then $f(a)=f(f(c))=g(c)=d$, a contradiction since $f(a)$ is in $\{a, b\}$. Similarly, we rule out $f(c)=b$. Of course, $c$ is not a fixed point of $f$, since it is not a fixed point of $g$. We are left with the only possibility $f(c)=d$. But then $f(d)=f(f(c))=g(c)=d$, and this again cannot happen because $d$ is not a fixed point of $g$. We conclude that such a function $f$ cannot exist.

In the particular case of our problem, $g(x)=x^{2}-2$ has the fixed points $-1$ and 2 , and $g(g(x))=\left(x^{2}-2\right)^{2}-2$ has the fixed points $-1,2, \frac{-1+\sqrt{5}}{2}$, and $\frac{-1-\sqrt{5}}{2}$. This completes the solution.

(B.J. Venkatachala, Functional Equations: A Problem Solving Approach, Prism Books PVT Ltd., 2002)

540. The standard approach is to substitute particular values for $x$ and $y$. The solution found by the student S.P. Tungare does quite the opposite. It introduces an additional variable $z$. The solution proceeds as follows:

$$
\begin{aligned}
f(x+&y+z) \\
&=f(x) f(y+z)-c \sin x \sin (y+z) \\
&=f(x)[f(y) f(z)-c \sin y \sin z]-c \sin x \sin y \cos z-c \sin x \cos y \sin z \\
&=f(x) f(y) f(z)-c f(x) \sin y \sin z-c \sin x \sin y \cos z-c \sin x \cos y \sin z .
\end{aligned}
$$

Because obviously $f(x+y+z)=f(y+x+z)$, it follows that we must have

$$
\sin z[f(x) \sin y-f(y) \sin x]=\sin z[\cos x \sin y-\cos y \sin x] .
$$

Substitute $z=\frac{\pi}{2}$ to obtain

$$
f(x) \sin y-f(y) \sin x=\cos x \sin y-\cos y \sin x .
$$

For $x=\pi$ and $y$ not an integer multiple of $\pi$, we obtain $\sin y[f(\pi)+1]=0$, and hence $f(\pi)=-1$.

Then, substituting in the original equation $x=y=\frac{\pi}{2}$ yields

$$
f(\pi)=\left[f\left(\frac{\pi}{2}\right)\right]-c,
$$

whence $f\left(\frac{\pi}{2}\right)=\pm \sqrt{c-1}$. Substituting in the original equation $y=\pi$ we also obtain $f(x+\pi)=-f(x)$. We then have

$$
\begin{aligned}
-f(x) &=f(x+\pi)=f\left(x+\frac{\pi}{2}\right) f\left(\frac{\pi}{2}\right)-c \cos x \\
&=f\left(\frac{\pi}{2}\right)\left(f(x) f\left(\frac{\pi}{2}\right)-c \sin x\right)-c \cos x
\end{aligned}
$$

whence

$$
f(x)\left[\left(f\left(\frac{\pi}{2}\right)\right)^{2}-1\right]=c f\left(\frac{\pi}{2}\right) \sin x-c \cos x .
$$

It follows that $f(x)=f\left(\frac{\pi}{2}\right) \sin x+\cos x$. We find that the functional equation has two solutions, namely,

$$
f(x)=\sqrt{c-1} \sin x+\cos x \text { and } f(x)=-\sqrt{c-1} \sin x+\cos x .
$$

(Indian Team Selection Test for the International Mathematical Olympiad, 2004)

541. Because $|f|$ is bounded and is identically equal to zero, its supremum is a positive number $M$. Using the equation from the statement and the triangle inequality, we obtain that for any $x$ and $y$,

$$
\begin{aligned}
2|f(x)||g(y)| &=|f(x+y)+f(x-y)| \\
& \leq|f(x+y)|+|f(x-y)| \leq 2 M .
\end{aligned}
$$

Hence

$$
|g(y)| \leq \frac{M}{|f(x)|} .
$$

If in the fraction on the right we take the supremum of the denominator, we obtain $|g(y)| \leq \frac{M}{M}=1$ for all $y$, as desired.

Remark. The functions $f(x)=\sin x$ and $g(x)=\cos x$ are an example.

(14th International Mathematical Olympiad, 1972)

542. Substituting for $f$ a linear function $a x+b$ and using the method of undetermined coefficients, we obtain $a=1, b=-\frac{3}{2}$, so $f(x)=x-\frac{3}{2}$ is a solution.

Are there other solutions? Setting $g(x)=f(x)-\left(x-\frac{3}{2}\right)$, we obtain the simpler functional equation

$$
3 g(2 x+1)=g(x), \quad \text { for all } x \in \mathbb{R} .
$$

This can be rewritten as 

$$
g(x)=\frac{1}{3} g\left(\frac{x-1}{2}\right), \quad \text { for all } x \in \mathbb{R}
$$

For $x=-1$ we have $g(-1)=\frac{1}{3} g(-1)$; hence $g(-1)=0$. In general, for an arbitrary $x$, define the recursive sequence $x_{0}=x, x_{n+1}=\frac{x_{n}-1}{2}$ for $n \geq 0$. It is not hard to see that this sequence is Cauchy, for example, because $\left|x_{m+n}-x_{m}\right| \leq \frac{1}{2^{m-2}} \max (1,|x|)$. This sequence is therefore convergent, and its limit $L$ satisfies the equation $L=\frac{L-1}{2}$. It follows that $L=-1$. Using the functional equation, we obtain

$$
g(x)=\frac{1}{3} g\left(x_{1}\right)=\frac{1}{9} g\left(x_{2}\right)=\cdots=\frac{1}{3^{n}} g\left(x_{n}\right)
$$

Passing to the limit, we obtain $g(x)=0$. This shows that $f(x)=x-\frac{3}{2}$ is the unique solution to the functional equation.

(B.J. Venkatachala, Functional Equations: A Problem Solving Approach, Prism Books PVT Ltd., 2002)

543. We will first show that $f(x) \geq x$ for all $x$. From (i) we deduce that $f(3 x) \geq 2 x$, so $f(x) \geq \frac{2 x}{3}$. Also, note that if there exists $k$ such that $f(x) \geq k x$ for all $x$, then $f(x) \geq \frac{k^{3}+2}{3} x$ for all $x$ as well. We can iterate and obtain $f(x) \geq k_{n} x$, where $k_{n}$ are the terms of the recursive sequence defined by $k_{1}=\frac{2}{3}$, and $k_{n+1}=\frac{k_{n}^{3}+2}{3}$ for $k \geq 1$. Let us examine this sequence.

By the AM-GM inequality,

$$
k_{n+1}=\frac{k_{n}^{3}+1^{3}+1^{3}}{3} \geq k_{n}
$$

so the sequence is increasing. Inductively we prove that $k_{n}<1$. Weierstrass' criterion implies that $\left(k_{n}\right)_{n}$ is convergent. Its limit $L$ should satisfy the equation

$$
L=\frac{L^{3}+2}{3}
$$

which shows that $L$ is a root of the polynomial equation $L^{3}-3 L+2=0$. This equation has only one root in $[0,1]$, namely $L=1$. Hence $\lim _{n \rightarrow \infty} k_{n}=1$, and so $f(x) \geq x$ for all $x$.

It follows immediately that $f(3 x) \geq 2 x+f(x)$ for all $x$. Iterating, we obtain that for all $n \geq 1$

$$
f\left(3^{n} x\right)-f(x) \geq\left(3^{n}-1\right) x .
$$

Therefore, $f(x)-x \leq f\left(3^{n} x\right)-3^{n} x$. If we let $n \rightarrow \infty$ and use (ii), we obtain $f(x)-x \leq 0$, that is, $f(x) \leq x$. We conclude that $f(x)=x$ for all $x>0$. Thus the identity function is the unique solution to the functional equation.

(G. Dospinescu) 

544. We should keep in mind that $f(x)=\sin x$ and $g(x)=\cos x$ satisfy the condition. As we proceed with the solution to the problem, we try to recover some properties of $\sin x$ and $\cos x$. First, note that the condition $f(t)=1$ and $g(t)=0$ for some $t \neq 0$ implies $g(0)=1$; hence $g$ is nonconstant. Also, $0=g(t)=g(0) g(t)+f(0) f(t)=f(0)$; hence $f$ is nonconstant. Substituting $x=0$ in the relation yields $g(-y)=g(y)$, so $g$ is even.

Substituting $y=t$, we obtain $g(x-t)=f(x)$, with its shifted version $f(x+t)=$ $g(x)$. Since $g$ is even, it follows that $f(-x)=g(x+t)$. Now let us combine these facts to obtain

$$
\begin{aligned}
f(x-y) &=g(x-y-t)=g(x) g(y+t)+f(x) f(y+t) \\
&=g(x) f(-y)+f(x) g(y) .
\end{aligned}
$$

Change $y$ to $-y$ to obtain $f(x+y)=f(x) g(y)+g(x) f(y)$ (the addition formula for sine).

The remaining two identities are consequences of this and the fact that $f$ is odd. Let us prove this fact. From $g(x-(-y))=g(x+y)=g(-x-y)$, we obtain

$$
f(x) f(-y)=f(y) f(-x)
$$

for all $x$ and $y$ in $\mathbb{R}$. Setting $y=t$ and $x=-t$ yields $f(-t)^{2}=1$, so $f(-t)=\pm 1$. The choice $f(-t)=1$ gives $f(x)=f(x) f(-t)=f(-x) f(t)=f(-x)$; hence $f$ is even. But then

$$
f(x-y)=f(x) g(-y)+g(x) f(-y)=f(x) g(y)+g(x) f(y)=f(x+y),
$$

for all $x$ and $y$. For $x=\frac{z+w}{2}, y=\frac{z-w}{2}$, we have $f(z)=f(w)$, and so $f$ is constant, a contradiction. For $f(-t)=-1$, we obtain $f(-x)=-f(-x) f(-t)=-f(x) f(t)=$ $-f(x)$; hence $f$ is odd. It is now straightforward that

$$
f(x-y)=f(x) g(y)+g(x) f(-y)=f(x) g(y)-g(x) f(y)
$$

and

$$
g(x+y)=g(x-(-y))=g(x) g(-y)+f(x) f(-y)=g(x) g(y)-f(x) f(y),
$$

where in the last equality we also used the fact, proved above, that $g$ is even.

(American Mathematical Monthly, proposed by V.L. Klee, solution by P.L. Kannappan)

545. Because $f(x)=f^{2}(x / 2)>0$, the function $g(x)=\ln f(x)$ is well defined. It satisfies Cauchy's equation and is continuous; therefore, $g(x)=\alpha x$ for some constant $\alpha$. We obtain $f(x)=c^{x}$, with $c=e^{\alpha}$. 

546. Adding 1 to both sides of the functional equation and factoring, we obtain

$$
f(x+y)+1=(f(x)+1)(f(y)+1) .
$$

The continuous function $g(x)=f(x)+1$ satisfies the functional equation $g(x+y)=$ $g(x) g(y)$, and we have seen in the previous problem that $g(x)=c^{x}$ for some nonnegative constant $c$. We conclude that $f(x)=c^{x}-1$ for all $x$.

547. If there exists $x_{0}$ such that $f\left(x_{0}\right)=1$, then

$$
f(x)=f\left(x_{0}+\left(x-x_{0}\right)\right)=\frac{1+f\left(x-x_{0}\right)}{1+f\left(x-x_{0}\right)}=1 .
$$

In this case, $f$ is identically equal to 1 . In a similar manner, we obtain the constant solution $f(x) \equiv-1$.

Let us now assume that $f$ is never equal to 1 or $-1$. Define $g: \mathbb{R} \rightarrow \mathbb{R}, g(x)=\frac{1+f(x)}{1-f(x)}$. To show that $g$ is continuous, note that for all $x$,

$$
f(x)=\frac{2 f\left(\frac{x}{2}\right)}{1+f\left(\frac{x}{2}\right)}<1 .
$$

Now the continuity of $g$ follows from that of $f$ and of the function $h(t)=\frac{1+t}{1-t}$ on $(-\infty, 1)$. Also,

$$
\begin{aligned}
g(x+y) &=\frac{1+f(x+y)}{1-f(x+y)}=\frac{f(x) f(y)+1+f(x)+f(y)}{f(x) f(y)+1-f(x)-f(y)} \\
&=\frac{1+f(x)}{1-f(x)} \cdot \frac{1+f(y)}{1-f(y)}=g(x) g(y)
\end{aligned}
$$

Hence $g$ satisfies the functional equation $g(x+y)=g(x) g(y)$. As seen in problem 545, $g(x)=c^{x}$ for some $c>0$. We obtain $f(x)=\frac{c^{x}-1}{c^{x}+1}$. The solutions to the equation are therefore

$$
f(x)=\frac{c^{x}-1}{c^{x}+1}, \quad f(x)=1, \quad f(x)=-1 .
$$

Remark. You might have recognized the formula for the hyperbolic tangent of the sum. This explains the choice of $g$, by expressing the exponential in terms of the hyperbolic tangent.

548. Rewrite the functional equation as

$$
\frac{f(x y)}{x y}=\frac{f(x)}{x}+\frac{f(y)}{y} .
$$

It now becomes natural to let $g(x)=\frac{f(x)}{x}$, which satisfies the equation

$$
g(x y)=g(x)+g(y) .
$$

The particular case $x=y$ yields $g(x)=\frac{1}{2} g\left(x^{2}\right)$, and hence $g(-x)=\frac{1}{2} g\left((-x)^{2}\right)=$ $\frac{1}{2} g\left(x^{2}\right)=g(x)$. Thus we only need to consider the case $x>0$.

Note that $g$ is continuous on $(0, \infty)$. If we compose $g$ with the continuous function $h: \mathbb{R} \rightarrow(0, \infty), h(x)=e^{x}$, we obtain a continuous function on $\mathbb{R}$ that satisfies Cauchy's equation. Hence $g \circ h$ is linear, which then implies $g(x)=\log _{a} x$ for some positive base $a$. It follows that $f(x)=x \log _{a} x$ for $x>0$ and $f(x)=x \log _{a}|x|$ if $x<0$.

All that is missing is the value of $f$ at 0 . This can be computed directly setting $x=y=0$, and it is seen to be 0 . We conclude that $f(x)=x \log _{a}|x|$ if $x \neq 0$, and $f(0)=0$, where $a$ is some positive number. The fact that any such function is continuous at zero follows from

$$
\lim _{x \rightarrow 0+} x \log _{a} x=0,
$$

which can be proved by applying the L'Hôpital's theorem to the functions $\log _{a} x$ and $\frac{1}{x}$. This concludes the solution.

549. Setting $y=z=0$ yields $\phi(x)=f(x)+g(0)+h(0)$, and similarly $\phi(y)=$ $g(y)+f(0)+h(0)$. Substituting these three relations in the original equation and letting $z=0$ gives rise to a functional equation for $\phi$, namely

$$
\phi(x+y)=\phi(x)+\phi(y)-(f(0)+g(0)+h(0)) .
$$

This should remind us of the Cauchy equation, which it becomes after changing the function $\phi$ to $\psi(x)=\phi(x)-(f(0)+g(0)+h(0))$. The relation $\psi(x+y)=\psi(x)+\psi(y)$ together with the continuity of $\psi$ shows that $\psi(x)=c x$ for some constant $c$. We obtain the solution to the original equation

$$
\phi(x)=c x+\alpha+\beta+\gamma, \quad f(x)=c x+\alpha, \quad g(x)=c x+\beta, \quad h(x)=c x+\gamma,
$$

where $\alpha, \beta, \gamma$ are arbitrary real numbers.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by M. Vlada)

550. This is a generalization of Cauchy's equation. Trying small values of $n$, one can guess that the answer consists of all polynomial functions of degree at most $n-1$ with no constant term (i.e., with $f(0)=0$ ). We prove by induction on $n$ that this is the case.

The case $n=2$ is Cauchy's equation. Assume that the claim is true for $n-1$ and let us prove it for $n$. Fix $x_{n}$ and consider the function $g_{x_{n}}: \mathbb{R} \rightarrow \mathbb{R}, g_{x_{n}}(x)=$ $f\left(x+x_{n}\right)-f(x)-f\left(x_{n}\right)$. It is continuous. More importantly, it satisfies the functional equation for $n-1$. Hence $g_{x_{n}}(x)$ is a polynomial of degree $n-2$. And this is true for all $x_{n}$. It follows that $f\left(x+x_{n}\right)-f(x)$ is a polynomial of degree $n-2$ for all $x_{n}$. In particular, there exist polynomials $P_{1}(x)$ and $P_{2}(x)$ such that $f(x+1)-f(x)=P_{1}(x)$, and $f(x+\sqrt{2})-f(x)=P_{2}(x)$. Note that for any $a$, the linear map from the vector space of polynomials of degree at most $n-1$ to the vector space of polynomials of degree at most $n-2, P(x) \rightarrow P(x+a)-P(x)$, has kernel the one-dimensional space of constant polynomials (the only periodic polynomials). Because the first vector space has dimension $n$ and the second has dimension $n-1$, the map is onto. Hence there exist polynomials $Q_{1}(x)$ and $Q_{2}(x)$ of degree at most $n-1$ such that

$$
\begin{gathered}
Q_{1}(x+1)-Q_{1}(x)=P_{1}(x)=f(x+1)-f(x), \\
Q_{2}(x+\sqrt{2})-Q_{2}(x)=P_{2}(x)=f(x+\sqrt{2})-f(x) .
\end{gathered}
$$

We deduce that the functions $f(x)-Q_{1}(x)$ and $f(x)-Q_{2}(x)$ are continuous and periodic, hence bounded. Their difference $Q_{1}(x)-Q_{2}(x)$ is a bounded polynomial, hence constant. Consequently, the function $f(x)-Q_{1}(x)$ is continuous and has the periods 1 and $\sqrt{2}$. Since the additive group generated by 1 and $\sqrt{2}$ is dense in $\mathbb{R}, f(x)-Q_{1}(x)$ is constant. This completes the induction.

That any polynomial of degree at most $n-1$ with no constant term satisfies the functional equation also follows by induction on $n$. Indeed, the fact that $f$ satisfies the equation is equivalent to the fact that $g_{x_{n}}$ satisfies the equation. And $g_{x_{n}}$ is a polynomial of degree $n-2$.

\section{(G. Dospinescu)}

551. First solution: Assume that such functions do exist. Because $g \circ f$ is a bijection, $f$ is one-to-one and $g$ is onto. Since $f$ is a one-to-one continuous function, it is monotonic, and because $g$ is onto but $f \circ g$ is not, it follows that $f$ maps $\mathbb{R}$ onto an interval $I$ strictly included in $\mathbb{R}$. One of the endpoints of this interval is finite, call this endpoint $a$. Without loss of generality, we may assume that $I=(a, \infty)$. Then as $g \circ f$ is onto, $g(I)=\mathbb{R}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-601.jpg?height=52&width=1339&top_left_y=1533&top_left_x=198)
means that $g$ oscillates in a neighborhood of infinity. But this is impossible because $f(g(x))=x^{2}$ implies that $g$ assumes each value at most twice. Hence the question has a negative answer; such functions do not exist.

Second solution: Since $g \circ f$ is a bijection, $f$ is one-to-one and $g$ is onto. Note that $f(g(0))=0$. Since $g$ is onto, we can choose $a$ and $b$ with $g(a)=g(0)-1$ and $g(b)=$ $g(0)+1$. Then $f(g(a))=a^{2}>0$ and $f(g(b))=b^{2}>0$. Let $c=\min \left(a^{2}, b^{2}\right) / 2>$ 0 . The intermediate value property guarantees that there is an $x_{0} \in(g(a), g(0))$ with $f\left(x_{0}\right)=c$ and an $x_{1} \in(g(0), g(b))$ with $f\left(x_{1}\right)=c$. This contradicts the fact that $f$ is one-to-one. Hence no such functions can exist.

(R. Gelca, second solution by R. Stong)

552. The relation from the statement implies that $f$ is injective, so it must be monotonic. Let us show that $f$ is increasing. Assuming the existence of a decreasing solution $f$ to the functional equation, we can find $x_{0}$ such that $f\left(x_{0}\right) \neq x_{0}$. Rewrite the functional equation as $f(f(x))-f(x)=f(x)-x$. If $f\left(x_{0}\right)<x_{0}$, then $f\left(f\left(x_{0}\right)\right)<f\left(x_{0}\right)$, and if $f\left(x_{0}\right)>x_{0}$, then $f\left(f\left(x_{0}\right)\right)>f\left(x_{0}\right)$, which both contradict the fact that $f$ is decreasing. Thus any function $f$ that satisfies the given condition is increasing.

Pick some $a>b$, and set $\Delta f(a)=f(a)-a$ and $\Delta f(b)=f(b)-b$. By adding a constant to $f$ (which yields again a solution to the functional equation), we may assume that $\Delta f(a)$ and $\Delta f(b)$ are positive. Composing $f$ with itself $n$ times, we obtain $f^{(n)}(a)=$ $a+n \Delta f(a)$ and $f^{(n)}(b)=b+n \Delta f(b)$. Recall that $f$ is an increasing function, so $f^{(n)}$ is increasing, and hence $f^{(n)}(a)>f^{(n)}(b)$, for all $n$. This can happen only if $\Delta f(a) \geq \Delta f(b)$.

On the other hand, there exists $m$ such that $b+m \Delta f(b)=f^{(m)}(b)>a$, and the same argument shows that $\Delta f\left(f^{(m-1)}(b)\right)>\Delta f(a)$. But $\Delta f\left(f^{(m-1)}(b)\right)=\Delta f(b)$, so $\Delta f(b) \geq \Delta f(a)$. We conclude that $\Delta f(a)=\Delta f(b)$, and hence $\Delta f(a)=f(a)-a$ is independent of $a$. Therefore, $f(x)=x+c$, with $c \in \mathbb{R}$, and clearly any function of this type satisfies the equation from the statement.

553. The answer is yes! We have to prove that for $f(x)=e^{x^{2}}$, the equation $f^{\prime} g+f g^{\prime}=$ $f^{\prime} g^{\prime}$ has nontrivial solutions on some interval $(a, b)$. Explicitly, this is the first-order linear equation in $g$,

$$
(1-2 x) e^{x^{2}} g^{\prime}+2 x e^{x^{2}} g=0 .
$$

Separating the variables, we obtain

$$
\frac{g^{\prime}}{g}=\frac{2 x}{2 x-1}=1+\frac{1}{2 x-1},
$$

which yields by integration $\ln g(x)=x+\frac{1}{2} \ln |2 x-1|+C$. We obtain the one-parameter family of solutions

$$
g(x)=a e^{x} \sqrt{|2 x-1|}, \quad a \in \mathbb{R},
$$

on any interval that does not contain $\frac{1}{2}$.

(49th W.L. Putnam Mathematical Competition, 1988)

554. Rewrite the equation $f^{2}+g^{2}=f^{\prime 2}+g^{\prime 2}$ as

$$
(f+g)^{2}+(f-g)^{2}=\left(f^{\prime}+g^{\prime}\right)^{2}+\left(g^{\prime}-f^{\prime}\right)^{2} .
$$

This, combined with $f+g=g^{\prime}-f^{\prime}$, implies that $(f-g)^{2}=\left(f^{\prime}+g^{\prime}\right)^{2}$.

Let $x_{0}$ be the second root of the equation $f(x)=g(x)$. On the intervals $I_{1}=$ $(-\infty, 0), I_{2}=\left(0, x_{0}\right)$, and $I_{3}=\left(x_{0}, \infty\right)$ the function $f-g$ is nonzero; hence so is $f^{\prime}+g^{\prime}$. These two functions maintain constant sign on the three intervals; hence $f-g=\epsilon_{j}\left(f^{\prime}+g^{\prime}\right)$ on $I_{j}$, for some $\epsilon_{j} \in\{-1,1\}, j=1,2,3$. If on any of these intervals $f-g=f^{\prime}+g^{\prime}$, then since $f+g=g^{\prime}-f^{\prime}$ it follows that $f=g^{\prime}$ on that interval, and so $g^{\prime}+g=g^{\prime}-g^{\prime \prime}$. This implies that $g$ satisfies the equation $g^{\prime \prime}+g=0$, or that $g(x)=A \sin x+B \cos x$ on that interval. Also, $f(x)=g^{\prime}(x)=A \cos x-B \sin x$.

If $f-g=-f^{\prime}-g^{\prime}$ on some interval, then using again $f+g=g^{\prime}-f^{\prime}$, we find that $g=g^{\prime}$ on that interval. Hence $g(x)=C_{1} e^{x}$. From the fact that $f=-f^{\prime}$, we obtain $f(x)=C_{2} e^{-x}$.

Assuming that $f$ and $g$ are exponentials on the interval $\left(0, x_{0}\right)$, we deduce that $C_{1}=g(0)=f(0)=C_{2}$ and that $C_{1} e^{x_{0}}=g\left(x_{0}\right)=f\left(x_{0}\right)=C_{2} e^{-x}$. These two inequalities cannot hold simultaneously, unless $f$ and $g$ are identically zero, ruled out by the hypothesis of the problem. Therefore, $f(x)=A \cos x-B \sin x$ and $g(x)=$ $A \sin x+B \cos x$ on $\left(0, x_{0}\right)$, and consequently $x_{0}=\pi$.

On the intervals $(-\infty, 0]$ and $\left[x_{0}, \infty\right)$ the functions $f$ and $g$ cannot be periodic, since then the equation $f=g$ would have infinitely many solutions. So on these intervals the functions are exponentials. Imposing differentiability at 0 and $\pi$, we obtain $B=A$, $C_{1}=A$ on $I_{1}$ and $C_{1}=-A e^{-\pi}$ on $I_{3}$ and similarly $C_{2}=A$ on $I_{1}$ and $C_{2}=-A e^{\pi}$ on $I_{3}$. Hence the answer to the problem is

$$
\begin{aligned}
&f(x)= \begin{cases}A e^{-x} & \text { for } x \in(-\infty, 0], \\
A(\sin x+\cos x) & \text { for } x \in(0, \pi], \\
-A e^{-x+\pi} & \text { for } x \in(\pi, \infty),\end{cases} \\
&g(x)= \begin{cases}A e^{x} & \text { for } x \in(-\infty, 0], \\
A(\sin x-\cos x) & \text { for } x \in(0, \pi], \\
-A e^{x-\pi} & \text { for } x \in(\pi, \infty),\end{cases}
\end{aligned}
$$

where $A$ is some nonzero constant.

(Romanian Mathematical Olympiad, 1976, proposed by V. Matrosenco)

555. The idea is to integrate the equation using an integrating factor. If instead we had the first-order differential equation $\left(x^{2}+y^{2}\right) d x+x y d y=0$, then the standard method finds $x$ as an integrating factor. So if we multiply our equation by $f$ to transform it into

$$
\left(f^{3}+f g^{2}\right) f^{\prime}+f^{2} g g^{\prime}=0,
$$

then the new equation is equivalent to

$$
\left(\frac{1}{4} f^{4}+\frac{1}{2} f^{2} g^{2}\right)^{\prime}=0 .
$$

Therefore, $f$ and $g$ satisfy

$$
f^{4}+2 f^{2} g^{2}=C,
$$

for some real constant $C$. In particular, $f$ is bounded.

(R. Gelca)

556. The idea is to write the equation as

$$
B y d x+A x d y+x^{m} y^{n}(D y d x+C x d y)=0,
$$

then find an integrating factor that integrates simultaneously $B y d x+A x d y$ and $x^{m} y^{n}(D y d x+C x d y)$. An integrating factor of $B y d x+A x d y$ will be of the form $x^{-1} y^{-1} \phi_{1}\left(x^{B} y^{A}\right)$, while an integrating factor of $x^{m} y^{n}(D y d x+C x d y)=D x^{m} y^{n+1} d x+$ $C x^{m+1} y^{n} d y$ will be of the form $x^{-m-1} y^{-n-1} \phi_{2}\left(x^{D} y^{C}\right)$, where $\phi_{1}$ and $\phi_{2}$ are one-variable functions. To have the same integrating factor for both expressions, we should have

$$
x^{m} y^{n} \phi_{1}\left(x^{B} y^{A}\right)=\phi_{2}\left(x^{D} y^{C}\right) .
$$

It is natural to try power functions, say $\phi_{1}(t)=t^{p}$ and $\phi_{2}(t)=t^{q}$. The equality condition gives rise to the system

$$
\begin{aligned}
&A p-C q=-n, \\
&B p-D q=-m
\end{aligned}
$$

which according to the hypothesis can be solved for $p$ and $q$. We find that

$$
p=\frac{B n-A m}{A D-B C}, \quad q=\frac{D n-C m}{A D-B C} .
$$

Multiplying the equation by $x^{-1} y^{-1}\left(x^{B} y^{A}\right)^{p}=x^{-1-m} y^{-1-n}\left(x^{D} y^{C}\right)^{q}$ and integrating, we obtain

$$
\frac{1}{p+1}\left(x^{B} y^{A}\right)^{p+1}+\frac{1}{q+1}\left(x^{D} y^{C}\right)^{q+1}=\text { constant },
$$

which gives the solution in implicit form.

(M. Ghermănescu, Ecuaţii Diferenţiale (Differential Equations), Editura Didactică şi Pedagogică, Bucharest, 1963)

557. The differential equation can be rewritten as

$$
e^{y^{\prime} \ln y}=e^{\ln x} .
$$

Because the exponential function is injective, this is equivalent to $y^{\prime} \ln y=\ln x$. Integrating, we obtain the algebraic equation $y \ln y-y=x \ln x-x+C$, for some constant $C$. The initial condition yields $C=0$. We are left with finding all differentiable functions $y$ such that

$$
y \ln y-y=x \ln x-x .
$$

Let us focus on the function $f(t)=t \ln t-t$. Its derivative is $f^{\prime}(t)=\ln t$, which is negative if $t<1$ and positive if $t>1$. The minimum of $f$ is at $t=1$, and is equal to $-1$. An easy application of L'Hôpital's rule shows that $\lim _{t \rightarrow 0} f(t)=0$. It follows that the equation $f(t)=c$ fails to have a unique solution precisely when $c \in(0,1) \cup(1, e)$, in which case it has exactly two solutions.

If we solve algebraically the equation $y \ln y-y=x \ln x-x$ on $(1, e)$, we obtain two possible continuous solutions, one that is greater than 1 and one that is less than 1 . The continuity of $y$ at $e$ rules out the second, so on the interval $[1, \infty), y(x)=x$. On $(0,1)$ again we could have two solutions, $y_{1}(x)=x$, and some other function $y_{2}$ that is greater than 1 on this interval. Let us show that $y_{2}$ cannot be extended to a solution having continuous derivative at $x=1$. On $(1, \infty), y_{2}(x)=x$, hence $\lim _{x \rightarrow 1^{+}} y_{2}^{\prime}(x)=1$. On $(0,1)$, as seen above, $y_{2}^{\prime} \ln y_{2}=\ln x$, so $y_{2}^{\prime}=\ln x / \ln y_{2}<0$, since $x<1$, and $y_{2}(x)>1$. Hence $\lim _{x \rightarrow 1^{-}} y_{2}^{\prime}(x) \leq 0$, contradicting the continuity of $y_{2}^{\prime}$ at $x=1$. Hence the only solution to the problem is $y(x)=x$ for all $x \in(0, \infty)$.

(R. Gelca)

558. Define

$$
g(x)=f(x) f^{\prime}\left(\frac{a}{x}\right), \quad x \in(0, \infty) .
$$

We want to show that $g$ is a constant function.

Substituting $x \rightarrow \frac{a}{x}$ in the given condition yields

$$
f\left(\frac{a}{x}\right) f^{\prime}(x)=\frac{a}{x},
$$

for all $x>0$. We have

$$
\begin{aligned}
g^{\prime}(x) &=f^{\prime}(x) f\left(\frac{a}{x}\right)+f(x) f^{\prime}\left(\frac{a}{x}\right)\left(-\frac{a}{x^{2}}\right)=f^{\prime}(x) f\left(\frac{a}{x}\right)-\frac{a}{x^{2}} f\left(\frac{a}{x}\right) f(x) \\
&=\frac{a}{x}-\frac{a}{x}=0,
\end{aligned}
$$

so $g$ is identically equal to some positive constant $b$. Using the original equation we can write

$$
b=g(x)=f(x) f\left(\frac{a}{x}\right)=f(x) \cdot \frac{a}{x} \cdot \frac{1}{f^{\prime}(x)},
$$

which gives

$$
\frac{f^{\prime}(x)}{f(x)}=\frac{a}{b x} .
$$

Integrating both sides, we obtain $\ln f(x)=\frac{a}{b} \ln x+\ln c$, where $c>0$. It follows that $f(x)=c x^{\frac{a}{b}}$, for all $x>0$. Substituting back into the original equation yields 

$$
c \cdot \frac{a}{b} \cdot \frac{a^{\frac{a}{b}-1}}{x^{\frac{a}{b}-1}}=\frac{x}{c x^{\frac{a}{b}}}
$$

which is equivalent to

$$
c^{2} a^{\frac{a}{b}}=b
$$

By eliminating $c$, we obtain the family of solutions

$$
f_{b}(x)=\sqrt{b}\left(\frac{x}{\sqrt{a}}\right)^{\frac{a}{b}}, \quad b>0
$$

All such functions satisfy the given condition.

(66th W.L. Putnam Mathematical Competition, 2005, proposed by T. Andreescu)

559. Let us look at the solution to the differential equation

$$
\frac{\partial y}{\partial x}=f(x, y),
$$

passing through some point $\left(x_{0}, y_{0}\right)$. The condition from the statement implies that along this solution, $\frac{d f(x, y)}{d x}=0$, and so along the solution the function $f$ is constant. This means that the solution to the differential equation with the given initial condition is a line $\left(y-y_{0}\right)=f\left(x_{0}, y_{0}\right)\left(x-x_{0}\right)$. If for some $\left(x_{1}, y_{1}\right), f\left(x_{1}, y_{1}\right) \neq f\left(x_{0}, y_{0}\right)$, then the lines $\left(y-y_{0}\right)=f\left(x_{0}, y_{0}\right)\left(x-x_{0}\right)$ and $\left(y-y_{1}\right)=f\left(x_{1}, y_{1}\right)\left(x-x_{1}\right)$ intersect somewhere, providing two solutions passing through the same point, which is impossible. This shows that $f$ is constant, as desired.

(Soviet Union University Student Mathematical Olympiad, 1976)

560. The equation can be rewritten as

$$
(x y)^{\prime \prime}+(x y)=0 .
$$

Solving, we find $x y=C_{1} \sin x+C_{2} \cos x$, and hence

$$
y=C_{1} \frac{\sin x}{x}+C_{2} \frac{\cos x}{x}
$$

on intervals that do not contain 0 .

561. The function $f^{\prime}(x) f^{\prime \prime}(x)$ is the derivative of $\frac{1}{2}\left(f^{\prime}(x)\right)^{2}$. The equation is therefore equivalent to

$$
\left(f^{\prime}(x)\right)^{2}=\text { constant }
$$

And because $f^{\prime}(x)$ is continuous, $f^{\prime}(x)$ itself must be constant, which means that $f(x)$ is linear. Clearly, all linear functions are solutions. 

562. The relation from the statement implies right away that $f$ is differentiable. Differentiating

$$
f(x)+x \int_{0}^{x} f(t) d t-\int_{0}^{x} t f(t) d t=1,
$$

we obtain

$$
f^{\prime}(x)+\int_{0}^{x} f(t) d t+x f(x)-x f(x)=0,
$$

that is, $f^{\prime}(x)+\int_{0}^{x} f(t) d t=0$. Again we conclude that $f$ is twice differentiable, and so we can transform this equality into the differential equation $f^{\prime \prime}+f=0$. The general solution is $f(x)=A \cos x+B \sin x$. Substituting in the relation from the statement, we obtain $A=1, B=0$, that is, $f(x)=\cos x$.

(E. Popa, Analiza Matematică, Culegere de Probleme (Mathematical Analysis, Collection of Problems), Editura GIL, 2005)

563. The equation is of Laplace type, but we can bypass the standard method once we make the following observation. The associated homogeneous equation can be written as

$$
x\left(y^{\prime \prime}+4 y^{\prime}+4 y\right)-\left(y^{\prime \prime}+5 y^{\prime}+6 y\right)=0,
$$

and the equations $y^{\prime \prime}+4 y^{\prime}+4 y=0$ and $y^{\prime \prime}+5 y^{\prime}+6 y=0$ have the common solution $y(x)=e^{-2 x}$. This will therefore be a solution to the homogeneous equation, as well. To find a solution to the inhomogeneous equation, we use the method of variation of the constant. Set $y(x)=C(x) e^{-2 x}$. The equation becomes

$$
(x-1) C^{\prime \prime}-C^{\prime}=x \text {, }
$$

with the solution

$$
C^{\prime}(x)=\lambda(x-1)+(x-1) \ln |x-1|-1 .
$$

Integrating, we obtain

$$
C(x)=\frac{1}{2}(x-1)^{2} \ln |x-1|+\left(\frac{\lambda}{2}-\frac{1}{4}\right)(x-1)^{2}-x+C_{1} .
$$

If we set $c_{2}=\frac{\lambda}{2}-\frac{1}{4}$, then the general solution to the equation is

$$
y(x)=e^{-2 x}\left[C_{1}+C_{2}(x-1)^{2}+\frac{1}{2}(x-1)^{2} \ln |x-1|-x\right] .
$$

(D. Flondor, N. Donciu, Algebră şi Analiză Matematică (Algebra and Mathematical Analysis), Editura Didactică şi Pedagogică, Bucharest, 1965) 

564. Consider the change of variable $x=\cos t$. Then, by the chain rule,

$$
\frac{d y}{d x}=\frac{\frac{d y}{d t}}{\frac{d x}{d t}}=-\frac{\frac{d y}{d t}}{\sin t}
$$

and

$$
\frac{d^{2} y}{d x^{2}}=\frac{\frac{d^{2} y}{d t^{2}}-\frac{d y}{d x} \frac{d^{2} x}{d t^{2}}}{\left(\frac{d x}{d t}\right)^{2}}=\frac{\frac{d^{2} y}{d t^{2}}}{\sin ^{2} t}-\frac{\cos t \frac{d y}{d t}}{\sin ^{3} t} .
$$

Substituting in the original equation, we obtain the much simpler

$$
\frac{d^{2} y}{d t^{2}}+n^{2} y=0 .
$$

This has the function $y(t)=\cos n t$ as a solution. Hence the original equation admits the solution $y(x)=\cos (n \arccos x)$, which is the $n$th Chebyshev polynomial.

565. We interpret the differential equation as being posed for a function $y$ of $x$. In this perspective, we need to write $\frac{d^{2} x}{d y^{2}}$ in terms of the derivatives of $y$ with respect to $x$. We have

$$
\frac{d x}{d y}=\frac{1}{\frac{d y}{d x}},
$$

and using this fact and the chain rule yields

$$
\begin{aligned}
\frac{d^{2} x}{d y^{2}} &=\frac{d}{d y}\left(\frac{1}{\frac{d y}{d x}}\right)=\frac{d}{d x}\left(\frac{1}{\frac{d y}{d x}}\right) \cdot \frac{d x}{d y} \\
&=-\frac{1}{\left(\frac{d y}{d x}\right)^{2}} \cdot \frac{d^{2} y}{d x^{2}} \cdot \frac{d x}{d y}=-\frac{1}{\left(\frac{d y}{d x}\right)^{3}} \cdot \frac{d^{2} y}{d x^{2}} .
\end{aligned}
$$

The equation from the statement takes the form

$$
\frac{d^{2} y}{d x^{2}}\left(1-\frac{1}{\left(\frac{d y}{d x}\right)^{3}}\right)=0 .
$$

This splits into

$$
\frac{d^{2} y}{d x^{2}}=0 \quad \text { and } \quad\left(\frac{d y}{d x}\right)^{3}=1 .
$$

The first of these has the solutions $y=a x+b$, with $a \neq 0$, because $y$ has to be one-toone, while the second reduces to $y^{\prime}=1$, whose family of solutions $y=x+c$ is included in the first. Hence the answer to the problem consists of the nonconstant linear functions.

(M. Ghermănescu, Ecuaţii Diferenţiale (Differential Equations), Editura Didactică şi Pedagogică, Bucharest, 1963)

566. First solution: Multiplying the equation by $e^{-x} y^{\prime}$ and integrating from 0 to $x$, we obtain

$$
y^{2}(x)-y^{2}(0)+2 \int_{0}^{x} e^{-t} y^{\prime} y^{\prime \prime} d t=0 .
$$

The integral in this expression is positive. To prove this we need the following lemma.

Lemma. Let $f:[0, a] \rightarrow \mathbb{R}$ be a continuous function and $\phi:[0, a] \rightarrow \mathbb{R}$ a positive, continuously differentiable, decreasing function with $\phi(0)=1$. Then there exists $c \in$ $[0, a]$ such that

$$
\int_{0}^{a} \phi(t) f(t) d t=\int_{0}^{c} f(t) d t .
$$

Proof. Let $F(x)=\int_{0}^{x} f(t) d t, x \in[0, a]$, and let $\alpha$ be the negative of the derivative of $\phi$, which is a positive function. Integrating by parts, we obtain

$$
\int_{0}^{a} \phi(t) f(t) d t=\phi(a) F(a)+\int_{0}^{a} \alpha(t) F(t) d t=F(a)-\int_{0}^{a}(F(a)-F(t)) \alpha(t) d t .
$$

We are to show that there exists a point $c$ such that

$$
F(a)-F(c)=\int_{0}^{a}(F(a)-F(t)) \alpha(t) d t .
$$

If $\int_{0}^{a} \alpha(t) d t$ were equal to 1 , this would be true by the mean value theorem applied to the function $F(a)-F(t)$ and the probability measure $\alpha(t) d t$. But in general, this integral is equal to some subunitary number $\theta$, so we can find $c^{\prime}$ such that the integral is equal to $\theta\left(F(a)-F\left(c^{\prime}\right)\right)$. But this number is between $F(a)-F(a)$ and $F(a)-F\left(c^{\prime}\right)$, so by the intermediate value property, there is a $c$ such that $\theta\left(F(a)-F\left(c^{\prime}\right)\right)=F(a)-F(c)$. This proves the lemma. Returning to the problem, we see that there exists $c \in[0, x]$ such that

$$
\int_{0}^{x} e^{-t} y^{\prime} y^{\prime \prime} d t=\int_{0}^{c} y^{\prime} y^{\prime \prime} d t=\frac{1}{2}\left[\left(\left(y^{\prime}(c)\right)^{2}-\left(y^{\prime}(0)\right)^{2}\right] .\right.
$$

In conclusion,

$$
(y(x))^{2}+\left(y^{\prime}(c)\right)^{2}=(y(0))^{2}+\left(y^{\prime}(0)\right)^{2}, \quad \text { for } x>0,
$$

showing that $y$ is bounded as $x \rightarrow \infty$.

Second solution: Use an integrating factor as in the previous solution to obtain

$$
y^{2}(x)-y^{2}(0)+2 \int_{0}^{x} e^{-t} y^{\prime} y^{\prime \prime} d t=0 .
$$

Then integrate by parts to obtain

$$
y^{2}(x)+e^{-x}\left(y^{\prime}(x)\right)^{2}+\int_{0}^{x} e^{-t}\left(y^{\prime}(t)\right)^{2} d t=y^{2}(0)+\left(y^{\prime}(0)\right)^{2} .
$$

Because every term on the left is nonnegative, it follows immediately that

$$
|y(x)| \leq\left(y^{2}(0)+\left(y^{\prime}(0)\right)^{2}\right)^{1 / 2}
$$

is bounded, and we are done.

(27th W.L. Putnam Mathematical Competition, 1966)

567. We have

$$
y_{1}^{\prime \prime}(t)+y_{1}(t)=\int_{0}^{\infty} \frac{t^{2} e^{-t x}}{1+t^{2}} d t+\int_{0}^{\infty} \frac{e^{-t x}}{1+t^{2}} d t=\int_{0}^{\infty} e^{-t x} d t=\frac{1}{x} .
$$

Also, integrating by parts, we obtain

$$
\begin{aligned}
y_{2}(x) &=\left.\frac{-\cos t}{t+x}\right|_{0} ^{\infty}-\int_{0}^{\infty} \frac{\cos t}{(t+x)^{2}} d t=\frac{1}{x}-\left.\frac{\sin t}{(t+x)^{2}}\right|_{0} ^{\infty}-\int_{0}^{\infty} \frac{2 \sin t}{(t+x)^{3}} d t \\
&=\frac{1}{x}-y_{2}^{\prime \prime}(x)
\end{aligned}
$$

Since the functions $y_{1}$ and $y_{2}$ satisfy the same inhomogeneous equation, their difference $y_{1}-y_{2}$ satisfies the homogeneous equation $y^{\prime \prime}+y=0$, and hence is of the form $A \cos x+B \sin x$. On the other hand,

$$
\lim _{x \rightarrow \infty}\left(y_{1}(x)-y_{2}(x)\right)=\lim _{x \rightarrow \infty} y_{1}(x)-\lim _{x \rightarrow \infty} y_{2}(x)=0,
$$

which implies that $A=B=0$, and therefore $y_{1}=y_{2}$, as desired.

(M. Ghermănescu, Ecuaţii Diferenţiale (Differential Equations), Editura Didactică şi Pedagogică, Bucharest, 1963)

568. Let $F(t)=\int_{0}^{t} f(s) d s$ be the antiderivative of $f$ that is 0 at the origin. The inequality from the problem can be written as

$$
\frac{F^{\prime}(t)}{\sqrt{1+2 F(t)}} \leq 1,
$$

which now reminds us of the method of separation of variables. The left-hand side is the derivative of $\sqrt{1+2 F(t)}$, a function whose value at the origin is 1 . Its derivative is dominated by the derivative of $g(t)=t+1$, another function whose value at the origin is also 1. Integrating, we obtain

$$
\sqrt{1+2 F(t)} \leq t+1 .
$$

Look at the relation from the statement. It says that $f(t) \leq \sqrt{1+2 F(t)}$. Hence the conclusion.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

569. We will use the "integrating factor" $e^{x}$. The inequality $f^{\prime \prime}(x) e^{x}+2 f^{\prime}(x) e^{x}+$ $f(x) e^{x} \geq 0$ is equivalent to $\left(f(x) e^{x}\right)^{\prime \prime} \geq 0$. So the function $f(x) e^{x}$ is convex, which means that it attains its maximum at one of the endpoints of the interval of definition. We therefore have $f(x) e^{x} \leq \max (f(0), f(1) e)=0$, and so $f(x) \leq 0$ for all $x \in[0,1]$.

(P.N. de Souza, J.N. Silva, Berkeley Problems in Mathematics, Springer, 2004)

570. Assume that such a function exists. Because $f^{\prime}(x)=f(f(x))>0$, the function is strictly increasing.

The monotonicity and the positivity of $f$ imply that $f(f(x))>f(0)$ for all $x$. Thus $f(0)$ is a lower bound for $f^{\prime}(x)$. Integrating the inequality $f(0)<f^{\prime}(x)$ for $x<0$, we obtain

$$
f(x)<f(0)+f(0) x=(x+1) f(0) .
$$

But then for $x \leq-1$, we would have $f(x) \leq 0$, contradicting the hypothesis that $f(x)>0$ for all $x$. We conclude that such a function does not exist.

(9th International Mathematics Competition for University Students, 2002)

571. We use the separation of variables, writing the relation from the statement as

$$
\sum_{i=1}^{n} \frac{P^{\prime}(x)}{P(x)-x_{i}}=\frac{n^{2}}{x} .
$$

Integrating, we obtain 

$$
\sum_{i=1}^{n} \ln \left|P(x)-x_{i}\right|=n^{2} \ln C|x|
$$

where $C$ is some positive constant. After adding the logarithms on the left we have

$$
\ln \prod_{i=1}^{n}\left|P(x)-x_{i}\right|=\ln C^{n^{2}}|x|^{n^{2}}
$$

and so

$$
\left|\prod_{i=1}^{n}\left(P(x)-x_{i}\right)\right|=k|x|^{n^{2}},
$$

with $k=C^{n^{2}}$. Eliminating the absolute values, we obtain

$$
P(P(x))=\lambda x^{n^{2}}, \quad \lambda \in \mathbb{R} .
$$

We end up with an algebraic equation. An easy induction can prove that the coefficient of the term of $k$ th degree is 0 for $k<n$. Hence $P(x)=a x^{n}$, with $a$ some constant, are the only polynomials that satisfy the relation from the statement.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu)

572. The idea is to use an "integrating factor"' that transforms the quantity under the integral into the derivative of a function. We already encountered this situation in a previous problem, and should recognize that the integrating factor is $e^{-x}$. We can therefore write

$$
\begin{aligned}
\int_{0}^{1}\left|f^{\prime}(x)-f(x)\right| d x &=\int_{0}^{1}\left|f^{\prime}(x) e^{-x}-f(x) e^{-x}\right| e^{x} d x=\int_{0}^{1}\left|\left(f(x) e^{-x}\right)^{\prime}\right| e^{x} d x \\
& \geq \int_{0}^{1}\left(f(x) e^{-x}\right)^{\prime} \mid d x=f(1) e^{-1}-f(0) e^{-0}=\frac{1}{e}
\end{aligned}
$$

We have found a lower bound. We will prove that it is the greatest lower bound. Define $f_{a}:[0,1] \rightarrow \mathbb{R}$

$$
f_{a}(x)= \begin{cases}\frac{e^{a-1}}{a} x & \text { for } x \in[0, a] \\ e^{x-1} & \text { for } x \in[a, 1]\end{cases}
$$

The functions $f_{a}$ are continuous but not differentiable at $a$, but we can smooth this "corner"' without altering too much the function or its derivative. Ignoring this problem, we can write

$$
\int_{0}^{1}\left|f_{a}^{\prime}(x)-f_{a}(x)\right| d x=\int_{0}^{a}\left|\frac{e^{a-1}}{a}-\frac{e^{a-1}}{a} x\right| d x=\frac{e^{a-1}}{a}\left(a-\frac{a^{2}}{2}\right)=e^{a-1}\left(1-\frac{a}{2}\right)
$$

As $a \rightarrow 0$, this expression approaches $\frac{1}{e}$. This proves that $\frac{1}{e}$ is the desired greatest lower bound.

(41st W.L. Putnam Mathematical Competition, 1980) 

\section{Geometry and Trigonometry}

573. This is the famous Jacobi identity. Identifying vectors with so(3) matrices, we compute

$$
\begin{aligned}
\vec{u} \times &(\vec{v} \times \vec{w})+\vec{v} \times(\vec{w} \times \vec{u})+\vec{w} \times(\vec{u} \times \vec{v}) \\
=& U(V W-W V)-(V W-W V) U+V(W U-U W)-(W U-U W) V \\
& \quad+W(U V-V U)-(U V-V U) W \\
=& U V W-U W V-V W U+W V U+V W U-V U W-W U V+U W V \\
& \quad+W U V-W V U-U V W+V U W .
\end{aligned}
$$

All terms of the latter sum cancel, giving the answer zero.

574. One checks easily that $\vec{u}+\vec{v}+\vec{w}=0$; hence $\vec{u}, \vec{v}, \vec{w}$ form a triangle. We compute

$$
\vec{u} \cdot \vec{c}=(\vec{b} \cdot \vec{c})(\vec{a} \cdot \vec{c})-(\vec{c} \cdot \vec{a})(\vec{b} \cdot \vec{c})=0 .
$$

It follows that $\vec{u}$ and $\vec{c}=0$ are orthogonal. Similarly, we prove that $\vec{v}$ is orthogonal to $\vec{a}$, and $\vec{w}$ is orthogonal to $\vec{b}$. Hence the sides of the triangle formed with $\vec{u}, \vec{v}, \vec{w}$ are perpendicular to the sides of the triangle formed with $\vec{a}, \vec{b}, \vec{c}$. This shows that the two triangles have equal angles hence are similar, and we are done.

(Romanian Mathematical Olympiad, 1976, proposed by M. Chiriţă)

575. Multiply the second equation on the left by $\vec{a}$ to obtain

$$
\vec{a} \times(\vec{x} \times \vec{b})=\vec{a} \times \vec{c} .
$$

Using the formula for the double cross-product, also known as the cab-bac formula, we transform this into

$$
(\vec{a} \cdot \vec{b}) \vec{x}-(\vec{a} \cdot \vec{x}) \vec{b}=\vec{a} \times \vec{c}
$$

Hence the solution to the equation is

$$
\vec{x}=\frac{m}{\vec{a} \cdot \vec{b}} \vec{b}+\frac{1}{\vec{a} \cdot \vec{b}} \vec{a} \times \vec{c} .
$$

(C. Coşniţă, I. Sager, I. Matei, I. Dragotă, Culegere de probleme de Geometrie Analitica (Collection of Problems in Analytical Geometry), Editura Didactică şi Pedagogică, Bucharest, 1963)

576. The vectors $\vec{b}-\vec{a}$ and $\vec{c}-\vec{a}$ belong to the plane under discussion, so the vector $(\vec{b}-\vec{a}) \times(\vec{c}-\vec{a})$ is perpendicular to this plane. Multiplying out, we obtain

$$
\begin{aligned}
(\vec{b}-\vec{a}) \times(\vec{c}-\vec{a}) &=\vec{b} \times \vec{c}-\vec{a} \times \vec{c}-\vec{b} \times \vec{a} \\
&=\vec{b} \times \vec{c}+\vec{c} \times \vec{a}+\vec{a} \times \vec{b} .
\end{aligned}
$$

Hence the conclusion.

577. The hypothesis implies that

$$
(\vec{a} \times \vec{b})-(\vec{b} \times \vec{c})=\overrightarrow{0} .
$$

It follows that $\vec{b} \times(\vec{a}+\vec{c})=\overrightarrow{0}$, hence $\vec{b}=\lambda(\vec{a}+\vec{c})$, where $\lambda$ is a scalar. Analogously, we deduce $\vec{c} \times(\vec{a}+\vec{b})=\overrightarrow{0}$, and substituting the formula we found for $\vec{b}$, we obtain

$$
\vec{c} \times(\vec{a}+\lambda \vec{a}+\lambda \vec{c})=\overrightarrow{0} .
$$

Hence $(1+\lambda) \vec{c} \times \vec{a}=\overrightarrow{0}$. It follows that $\lambda=-1$ and so $\vec{b}=-\vec{a}-\vec{c}$. Therefore, $\vec{a}+\vec{b}+\vec{c}=\overrightarrow{0}$

(C. Coşniţă, I. Sager, I. Matei, I. Dragotă, Culegere de probleme de Geometrie Analitica (Collection of Problems in Analytical Geometry), Editura Didactică şi Pedagogică, Bucharest, 1963)

578. Differentiating the equation from the statement, we obtain

$$
\vec{u}^{\prime} \times \vec{u}^{\prime}+\vec{u} \times \vec{u}^{\prime \prime}=\vec{u} \times \vec{u}^{\prime \prime}=\vec{v}^{\prime}
$$

It follows that the vectors $\vec{u}$ and $\vec{v}^{\prime}$ are perpendicular. But the original equation shows that $\vec{u}$ and $\vec{v}$ are also perpendicular, which means that $\vec{u}$ stays parallel to $\vec{v} \times \overrightarrow{v^{\prime}}$. Then we can write $\vec{u}=f \vec{v} \times \vec{v}$ ' for some scalar function $f=f(t)$. The left-hand side of the original equation is therefore equal to

$$
f\left(\vec{v} \times \vec{v}^{\prime}\right) \times\left[f^{\prime} \vec{v} \times \overrightarrow{v^{\prime}}+f \vec{v}^{\prime} \times \vec{v}^{\prime}+f \vec{v} \times \vec{v}^{\prime \prime}\right]
$$



$$
=f^{2}\left(\vec{v} \times \vec{v}^{\prime}\right) \times\left(\vec{v} \times \vec{v}^{\prime \prime}\right) .
$$

By the $c a b-b a c$ formula this is further equal to

$$
f^{2}\left(\vec{v}^{\prime \prime} \cdot\left(\vec{v} \times \vec{v}^{\prime}\right) \vec{v}-\vec{v} \cdot\left(\vec{v} \times \vec{v}^{\prime}\right) \vec{v}\right)=f^{2}\left(\left(\vec{v} \times \vec{v}^{\prime}\right) \cdot \vec{v}^{\prime \prime}\right) \vec{v} .
$$

The equation reduces therefore to

$$
f^{2}\left(\left(\vec{v} \times \vec{v}^{\prime}\right) \cdot \vec{v}^{\prime \prime}\right) \vec{v}=\vec{v} .
$$

By hypothesis $\vec{v}$ is never equal to $\overrightarrow{0}$, so the above equality implies

$$
f=\frac{1}{\sqrt{\left(\vec{v} \times \vec{v}^{\prime}\right) \cdot \vec{v}^{\prime \prime}}} .
$$

So the equation can be solved only if the frame $\left(\vec{v}, \vec{v}^{\prime}, \vec{v}^{\prime \prime}\right)$ consists of linearly independent vectors and is positively oriented and in that case the solution is

$$
\vec{u}=\frac{1}{\sqrt{\operatorname{Vol}\left(\vec{v}, \vec{v}^{\prime}, \vec{v}^{\prime \prime}\right)}} \vec{v} \times \vec{v}^{\prime},
$$

where $\operatorname{Vol}\left(\vec{v}, \vec{v}^{\prime}, \vec{v}^{\prime \prime}\right)$ denotes the volume of the parallelepiped determined by the three vectors.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by M. Ghermănescu)

579. (a) Yes: simply rotate the plane $90^{\circ}$ about some axis perpendicular to it. For example, in the $x y$-plane we could map each point $(x, y)$ to the point $(y,-x)$.

(b) Suppose such a bijection existed. In vector notation, the given condition states that

$$
(\vec{a}-\vec{b}) \cdot(f(\vec{a})-f(\vec{b}))=0
$$

for any three-dimensional vectors $\vec{a}$ and $\vec{b}$.

Assume without loss of generality that $f$ maps the origin to itself; otherwise, $g(\vec{p})=$ $f(\vec{p})-f(\overrightarrow{0})$ is still a bijection and still satisfies the above equation. Plugging $\vec{b}=$ $(0,0,0)$ into the above equation, we obtain that $\vec{a} \cdot f(\vec{a})=0$ for all $\vec{a}$. The equation reduces to

$$
\vec{a} \cdot f(\vec{b})-\vec{b} \cdot f(\vec{a})=0
$$

Given any vectors $\vec{a}, \vec{b}, \vec{c}$ and any real numbers $m, n$, we then have

$$
m(\vec{a} \cdot f(\vec{b})+\vec{b} \cdot f(\vec{a}))=0,
$$



$$
\begin{array}{r}
n(\vec{a} \cdot f(\vec{c})+\vec{c} \cdot f(\vec{a}))=0, \\
a \cdot f(m \vec{b}+n \vec{c})+(m \vec{b}+n \vec{c}) \cdot f(\vec{a})=0 .
\end{array}
$$

Adding the first two equations and subtracting the third gives

$$
\vec{a} \cdot(m f(\vec{b})+n f(\vec{c})-f(m \vec{b}+n \vec{c}))=0 .
$$

Because this is true for any vector $\vec{a}$, we must have

$$
f(m \vec{b}+n \vec{c})=m f(\vec{b})+n f(\vec{c}) .
$$

Therefore, $f$ is linear, and it is determined by the images of the unit vectors $\vec{i}=(1,0,0)$, $\vec{j}=(0,1,0)$, and $\vec{k}=(0,0,1)$. If

$$
f(\vec{i})=\left(a_{1}, a_{2}, a_{3}\right), \quad f(\vec{j})=\left(b_{1}, b_{2}, b_{3}\right), \quad \text { and } \quad f(\vec{k})=\left(c_{1}, c_{2}, c_{3}\right),
$$

then for a vector $\vec{x}$ we have

$$
f(\vec{x})=\left[\begin{array}{lll}
a_{1} & b_{1} & c_{1} \\
a_{2} & b_{2} & c_{2} \\
a_{3} & b_{3} & c_{3}
\end{array}\right] \vec{x} .
$$

Substituting in $f(\vec{a}) \cdot \vec{a}=0$ successively $\vec{a}=\vec{i}, \vec{j}, \vec{k}$, we obtain $a_{1}=b_{2}=c_{3}=$ 0 . Then substituting in $\vec{a} \cdot f(\vec{b})+\vec{b} \cdot f(\vec{a}),(\vec{a}, \vec{b})=(\vec{i}, \vec{j}),(\vec{j}, \vec{k}),(\vec{k}, \vec{i})$, we obtain $b_{1}=-a_{2}, c_{2}=-b_{3}, c_{1}=-a_{3}$.

Setting $k_{1}=c_{2}, k_{2}=-c_{1}$, and $k_{3}=b_{1}$ yields

$$
f\left(k_{1} \vec{i}+k_{2} \vec{j}+k_{3} \vec{k}\right)=k_{1} f(\vec{i})+k_{2} f(\vec{j})+k_{3} f(\vec{k})=\overrightarrow{0} .
$$

Because $f$ is injective and $f(\overrightarrow{0})=\overrightarrow{0}$, this implies that $k_{1}=k_{2}=k_{3}=0$. Then $f(\vec{x})=0$ for all $\vec{x}$, contradicting the assumption that $f$ was a surjection. Therefore, our original assumption was false, and no such bijection exists.

(Team Selection Test for the International Mathematical Olympiad, Belarus, 1999)

580. The important observation is that

$$
A * B=A B-\frac{1}{2} \operatorname{tr}(A B),
$$

which can be checked by hand. The identity is therefore equivalent to

$$
C B A-B C A+A B C-A C B=-\frac{1}{2} \operatorname{tr}(A C) B+\frac{1}{2} \operatorname{tr}(A B) C .
$$

And this is the cab-bac identity once we notice that $\vec{a} \cdot \vec{b}=-\frac{1}{2} \operatorname{tr}(A B)$.

581. An easy computation shows that the map $f: \mathbb{R}^{3} \rightarrow \operatorname{su}(2)$,

$$
f(x, y, z)=\left(\begin{array}{cc}
-i z & y-i x \\
y+i x & i z
\end{array}\right),
$$

has the desired property.

582. Denoting by $\vec{A}, \vec{B}, \vec{C}, \overrightarrow{A^{\prime}}, \overrightarrow{B^{\prime}}, \overrightarrow{C^{\prime}}$ the position vectors of the vertices of the two triangles, the condition that the triangles have the same centroid reads

$$
\vec{A}+\vec{B}+\vec{C}=\overrightarrow{A^{\prime}}+\overrightarrow{B^{\prime}}+\overrightarrow{C^{\prime}}
$$

Subtracting the left-hand side, we obtain

$$
\overrightarrow{A A^{\prime}}+\overrightarrow{B B^{\prime}}+\overrightarrow{C C^{\prime}}=\overrightarrow{0}
$$

This shows that $\overrightarrow{A A^{\prime}}, \overrightarrow{B B^{\prime}}, \overrightarrow{C C^{\prime}}$ form a triangle, as desired.

583. Set $\overrightarrow{v_{1}}=\overrightarrow{A B}, \overrightarrow{v_{2}}=\overrightarrow{B C}, \overrightarrow{v_{3}}=\overrightarrow{C D}, \overrightarrow{v_{4}}=\overrightarrow{D A}, \overrightarrow{u_{1}}=\overrightarrow{A^{\prime} B^{\prime}}, \overrightarrow{u_{2}}=\overrightarrow{B^{\prime} C^{\prime}}$, $\overrightarrow{u_{3}}=\overrightarrow{C^{\prime} D^{\prime}}, \overrightarrow{u_{4}}=\overrightarrow{D^{\prime} A^{\prime}}$. By examining Figure 72 we can write the system of equations

$$
\begin{aligned}
&2 \overrightarrow{v_{2}}-\overrightarrow{v_{1}}=\overrightarrow{u_{1}}, \\
&2 \overrightarrow{v_{3}}-\overrightarrow{v_{2}}=\overrightarrow{u_{2}}, \\
&2 \overrightarrow{v_{4}}-\overrightarrow{v_{3}}=\overrightarrow{u_{3}}, \\
&2 \overrightarrow{v_{1}}-\overrightarrow{v_{4}}=\overrightarrow{u_{4}},
\end{aligned}
$$

in which the right-hand side is known. Solving, we obtain

$$
\overrightarrow{v_{1}}=\frac{1}{15} \overrightarrow{u_{1}}+\frac{2}{15} \overrightarrow{u_{2}}+\frac{4}{15} \overrightarrow{u_{3}}+\frac{8}{15} \overrightarrow{u_{4}},
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-617.jpg?height=448&width=598&top_left_y=1678&top_left_x=573)

Figure 72 and the analogous formulas for $\overrightarrow{v_{2}}, \overrightarrow{v_{3}}$, and $\overrightarrow{v_{4}}$. Since the rational multiple of a vector and the sum of two vectors can be constructed with straightedge and compass, we can construct the vectors $\overrightarrow{v_{i}}, i=1,2,3,4$. Then we take the vectors $\overrightarrow{A^{\prime} B}=-\overrightarrow{v_{1}}, \overrightarrow{B^{\prime} C}=-\overrightarrow{v_{2}}$, $\overrightarrow{C^{\prime} D}=-\overrightarrow{v_{3}}$, and $\overrightarrow{D^{\prime} A}=-\overrightarrow{v_{4}}$ from the points $A^{\prime}, B^{\prime}, C^{\prime}$, and $D^{\prime}$ to recover the vertices $B, C, D$, and $A$.

Remark. Maybe we should elaborate more on how one effectively does these constructions. The sum of two vectors is obtained by constructing the parallelogram they form. Parallelograms can also be used to translate vectors. An integer multiple of a vector can be constructed by drawing its line of support and then measuring several lengths of the vector with the compass. This construction enables us to obtain segments divided into an arbitrary number of equal parts. In order to divide a given segment into equal parts, form a triangle with it and an already divided segment, then draw lines parallel to the third side and use Thales' theorem.

584. Let $O$ be the intersection of the perpendicular bisectors of $A_{1} A_{2}$ and $B_{1} B_{2}$. We want to show that $O$ is on the perpendicular bisector of $C_{1} C_{2}$. This happens if and only if $\left(\overrightarrow{O C_{1}}+\overrightarrow{O C_{2}}\right) \cdot \overrightarrow{C_{1} C_{2}}=0$.

Set $\overrightarrow{O A}=\vec{l}, \overrightarrow{O B}=\vec{m}, \overrightarrow{O C}=\vec{n}, \overrightarrow{A A_{2}}=\vec{a}, \overrightarrow{B B_{2}}=\vec{b}, \overrightarrow{C C_{2}}=\vec{c}$. That the perpendicular bisectors of $A_{1} A_{2}$ and $B_{1} B_{2}$ pass through $O$ can be written algebraically as

$$
(2 \vec{l}+\vec{a}+\vec{c}) \cdot(\vec{c}-\vec{a})=0 \quad \text { and } \quad(2 \vec{m}+\vec{a}+\vec{b}) \cdot(\vec{a}-\vec{b})=0 .
$$

The orthogonality of the sides of the rectangles translates into formulas as

$$
(\vec{m}-\vec{l}) \cdot \vec{a}=0, \quad(\vec{m}-\vec{n}) \cdot \vec{b}=0, \quad(\vec{n}-\vec{l}) \cdot \vec{c}=0 .
$$

We are required to prove that $(2 \vec{n}+\vec{b}+\vec{c}) \cdot(\vec{b}-\vec{c})=0$. And indeed,

$$
\begin{aligned}
(2 \vec{n}&+\vec{b}+\vec{c}) \cdot(\vec{c}-\vec{b})=2 \vec{n} \cdot \vec{c}-2 \vec{n} \cdot \vec{b}+\vec{c}^{2}-\vec{b}^{2} \\
&=2(\vec{m}-\vec{l}) \cdot \vec{a}+2 \vec{l} \cdot \vec{c}-2 \vec{m} \cdot \vec{b}+\vec{c}^{2}-\vec{b}^{2} \\
&=2 \vec{m} \cdot \vec{a}-2 \vec{m} \cdot \vec{b}+\vec{a}^{2}-\vec{b}^{2}+2 \vec{l} \cdot \vec{c}-2 \vec{l} \cdot \vec{a}-\vec{a}^{2}+\vec{c}^{2}=0 .
\end{aligned}
$$

Hence the conclusion.

585. Let $H^{\prime}$ be the orthocenter of triangle $A C D$. The quadrilaterals $H P B Q$ and $H C H^{\prime} A$ satisfy $H C \perp B P, H^{\prime} C \perp H P, H^{\prime} A \perp H Q, A H \perp B Q, A C \perp H B$ (see Figure 73). The conclusion follows from a more general result.

Lemma. Let $M N P Q$ and $M^{\prime} N^{\prime} P^{\prime} Q^{\prime}$ be two quadrilaterals such that $M N \perp N^{\prime} P^{\prime}$, $N P \perp M^{\prime} N^{\prime}, P Q \perp Q^{\prime} M^{\prime}, Q M \perp P^{\prime} Q^{\prime}$, and $M P \perp N^{\prime} Q^{\prime}$. Then $N Q \perp M^{\prime} P^{\prime}$. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-619.jpg?height=612&width=549&top_left_y=241&top_left_x=593)

Figure 73

Proof. Let $\overrightarrow{M N}=\vec{v}_{1}, \overrightarrow{N P}=\vec{v}_{2}, \overrightarrow{P Q}=\vec{v}_{3}, \overrightarrow{Q M}=\vec{v}_{4}$, and $\overrightarrow{M^{\prime} N^{\prime}}=\vec{w}_{1}$, $\overrightarrow{N^{\prime} P^{\prime}}=\vec{w}_{2}, \overrightarrow{P^{\prime} Q^{\prime}}=\vec{w}_{3}, \overrightarrow{Q^{\prime} M^{\prime}}=\vec{w}_{4}$. The conditions from the statement can be written in vector form as

$$
\begin{array}{r}
\vec{v}_{1} \cdot \vec{w}_{2}=\vec{v}_{2} \cdot \vec{w}_{1}=\vec{v}_{3} \cdot \vec{w}_{4}=\vec{v}_{4} \cdot \vec{w}_{3}=0, \\
\vec{v}_{1}+\vec{v}_{2}+\vec{v}_{3}+\vec{v}_{4}=\vec{w}_{1}+\vec{w}_{2}+\vec{w}_{3}+\vec{w}_{4}=\overrightarrow{0}_{2}, \\
\left(\vec{v}_{1}+\vec{v}_{2}\right) \cdot\left(\vec{w}_{2}+\vec{w}_{3}\right)=0 .
\end{array}
$$

We are to show that

$$
\left(\overrightarrow{v_{2}}+\vec{v}_{3}\right) \cdot\left(\vec{w}_{1}+\vec{w}_{2}\right)=0
$$

First, note that

$$
\begin{aligned}
0 &=\left(\vec{v}_{1}+\vec{v}_{2}\right) \cdot\left(\vec{w}_{2}+\vec{w}_{3}\right)=\vec{v}_{1} \cdot \vec{w}_{2}+\vec{v}_{1} \cdot \vec{w}_{3}+\vec{v}_{2} \cdot \vec{w}_{2}+\vec{v}_{2} \cdot \vec{w}_{3} \\
&=\vec{v}_{1} \cdot \vec{w}_{3}+\vec{v}_{2} \cdot \vec{w}_{2}+\vec{v}_{2} \cdot \vec{w}_{3} .
\end{aligned}
$$

Also, the dot product that we are supposed to show is zero is equal to

$$
\begin{aligned}
\left(\vec{v}_{2}+\vec{v}_{3}\right) \cdot\left(\vec{w}_{1}+\vec{w}_{2}\right) &=\vec{v}_{2} \cdot \vec{w}_{1}+\vec{v}_{2} \cdot \vec{w}_{2}+\vec{v}_{3} \cdot \vec{w}_{1}+\vec{v}_{3} \cdot \vec{w}_{2} \\
&=\vec{v}_{2} \cdot \vec{w}_{2}+\vec{v}_{3} \cdot \vec{w}_{1}+\vec{v}_{3} \cdot \vec{w}_{2} .
\end{aligned}
$$

This would indeed equal zero if we showed that $\vec{v}_{1} \cdot \vec{w}_{3}+\vec{v}_{2} \cdot \vec{w}_{3}=\vec{v}_{3} \cdot \vec{w}_{1}+\vec{v}_{3} \cdot \vec{w}_{2}$. And indeed,

$$
\begin{aligned}
\vec{v}_{1} \cdot \vec{w}_{3}+\vec{v}_{2} \cdot \vec{w}_{3} &=\left(\vec{v}_{1}+\vec{v}_{2}\right) \cdot \vec{w}_{3} \\
&=-\left(\vec{v}_{3}+\vec{v}_{4}\right) \cdot \vec{w}_{3}=-\vec{v}_{3} \cdot \vec{w}_{3}-\vec{v}_{4} \cdot \vec{w}_{3}=-\vec{v}_{3} \cdot \vec{w}_{3} \\
&=-\vec{v}_{3} \cdot \vec{w}_{3}-\vec{v}_{3} \cdot \vec{w}_{4}=-\vec{v}_{3} \cdot\left(\vec{w}_{3}+\vec{w}_{4}\right) \\
&=\vec{v}_{3} \cdot\left(\vec{w}_{1}+\vec{w}_{2}\right)=\vec{v}_{3} \cdot \vec{w}_{1}+\vec{v}_{3} \cdot \vec{w}_{2} .
\end{aligned}
$$

The lemma is proved.

Remark. A. Dang gave an alternative solution by observing that triangles $A H C$ and $Q H P$ are orthological, and then using the property of orthological triangles proved by us in the introduction.

(Indian Team Selection Test for the International Mathematical Olympiad, 2005, proposed by R. Gelca)

586. Let $\vec{a}, \vec{b}, \vec{c}, \vec{d}$, and $\vec{p}$ denote vectors from a common origin to the vertices $A, B, C, D$ of the tetrahedron, and to the point $P$ of concurrency of the four lines. Then the vector equation for the altitude from $A$ is given by

$$
\vec{r}_{a}=\vec{a}+\lambda[(\vec{b}+\vec{c}+\vec{d}) / 3-\vec{p}]
$$

The position vector of the point corresponding to $\lambda=3$ is $\vec{a}+\vec{b}+\vec{c}+\vec{d}-3 \vec{p}$, which is the same for all four vertices of the tetrahedron. This shows that the altitudes are concurrent.

For the converse, if the four altitudes are concurrent at a point $H$ with position vector $\vec{h}$, then the line through the centroid of the face $B C D$ and perpendicular to that face is described by

$$
\vec{r}_{a}^{\prime}=[(\vec{b}+\vec{c}+\vec{d}) / 3]+\lambda^{\prime}(\vec{a}-\vec{h})
$$

This time the common point of the four lines will correspond, of course, to $\lambda^{\prime}=\frac{1}{3}$, and the problem is solved.

(proposed by M. Klamkin for Mathematics Magazine)

587. The double of the area of triangle $O N Q$ is equal to

$$
\|\overrightarrow{O N} \times \overrightarrow{O Q}\|=\left\|\left(\frac{1}{3} \overrightarrow{O A}+\frac{2}{3} \overrightarrow{O B}\right) \times\left(\frac{2}{3} \overrightarrow{O D}+\frac{1}{3} \overrightarrow{O C}\right)\right\|
$$

Since $\overrightarrow{O A}$ is parallel to $\overrightarrow{O C}$ and $\overrightarrow{O B}$ is parallel to $\overrightarrow{O D}$, this is further equal to

$$
\left\|\frac{2}{9}(\overrightarrow{O A} \times \overrightarrow{O D}+\overrightarrow{O B} \times \overrightarrow{O C})\right\| .
$$

A similar computation shows that this is equal to $|\overrightarrow{O M} \times \overrightarrow{O P}|$, which is twice the area of triangle $O M P$. Hence the conclusion.

588. The area of triangle $A M N$ is equal to

$$
\frac{1}{2}\|\overrightarrow{A M} \times \overrightarrow{A N}\|=\frac{1}{8}\|(\overrightarrow{A B}+\overrightarrow{A D}) \times(\overrightarrow{A E} \times \overrightarrow{A C})\|=\frac{1}{8}\|(\overrightarrow{A B} \times \overrightarrow{A C}-\overrightarrow{A E} \times \overrightarrow{A D})\|
$$

Since $\overrightarrow{A B} \times \overrightarrow{A C}$ and $\overrightarrow{A E} \times \overrightarrow{A D}$ are perpendicular to the plane of the triangle and oriented the same way, this is equal to one-fourth of the area of the quadrilateral $B C D E$. Done. 

589. We work in affine coordinates with the diagonals of the quadrilateral as axes. The vertices are $A(a, 0), B(0, b), C(c, 0), D(0, d)$. The midpoints of the sides are $M\left(\frac{a}{2}, \frac{b}{2}\right)$, $N\left(\frac{c}{2} \frac{b}{2}\right), P\left(\frac{c}{2}, \frac{d}{2}\right)$, and $Q\left(\frac{a}{2}, \frac{d}{2}\right)$. The segments $M P$ and $N Q$ have the same midpoint, namely, the centroid $\left(\frac{a+c}{4}, \frac{b+d}{4}\right)$ of the quadrilateral. Hence $M N P Q$ is a parallelogram.

590. Choose a coordinate system that places $M$ at the origin and let the coordinates of $A, B, C$, respectively, be $\left(x_{A}, y_{A}\right),\left(x_{B}, y_{B}\right),\left(x_{C}, y_{C}\right)$. Then the coordinates of the centroids of $M A B, M A C$, and $M B C$ are, respectively,

$$
\begin{aligned}
G_{A} &=\left(\frac{x_{A}+x_{B}}{3}, \frac{y_{B}+y_{B}}{3}\right), \\
G_{B} &=\left(\frac{x_{A}+x_{C}}{3}, \frac{y_{A}+y_{C}}{3}\right), \\
G_{C} &=\left(\frac{x_{B}+x_{C}}{3}, \frac{y_{B}+y_{C}}{3}\right) .
\end{aligned}
$$

The coordinates of $G_{A}, G_{B}, G_{C}$ are obtained by subtracting the coordinates of $A, B$, and $C$ from $\left(x_{A}+x_{B}+x_{C}, y_{A}+y_{B}+y_{C}\right)$, then dividing by 3 . Hence the triangle $G_{A} G_{B} G_{C}$ is obtained by taking the reflection of triangle $A B C$ with respect to the point $\left(x_{A}+x_{B}+x_{C}, y_{A}+y_{B}+y_{C}\right)$, then contracting with ratio $\frac{1}{3}$ with respect to the origin $M$. Consequently, the two triangles are similar.

591. Denote by $\delta(P, M N)$ the distance from $P$ to the line $M N$. The problem asks for the locus of points $P$ for which the inequalities

$$
\begin{aligned}
&\delta(P, A B)<\delta(P, B C)+\delta(P, C A), \\
&\delta(P, B C)<\delta(P, C A)+\delta(P, A B), \\
&\delta(P, C A)<\delta(P, A B)+\delta(P, B C)
\end{aligned}
$$

are simultaneously satisfied.

Let us analyze the first inequality, written as $f(P)=\delta(P, B C)+\delta(P, C A)-$ $\delta(P, A B)>0$. As a function of the coordinates $(x, y)$ of $P$, the distance from $P$ to a line is of the form $m x+n y+p$. Combining three such functions, we see that $f(P)=f(x, y)$ is of the same form, $f(x, y)=\alpha x+\beta y+\gamma$. To solve the inequality $f(x, y)>0$ it suffices to find the line $f(x, y)=0$ and determine on which side of the line the function is positive. The line intersects the side $B C$ where $\delta(P, C A)=\delta(P, A B)$, hence at the point $E$ where the angle bisector from $A$ intersects this side. It intersects side $C A$ at the point $F$ where the bisector from $B$ intersects the side. Also, $f(x, y)>0$ on side $A B$, hence on the same side of the line $E F$ as the segment $A B$. Arguing similarly for the other two inequalities, we deduce that the locus is the interior of the triangle formed by the points where the angle bisectors meet the opposite sides.

592. Consider an affine system of coordinates such that none of the segments determined by the $n$ points is parallel to the $x$-axis. If the coordinates of the midpoints are $\left(x_{i}, y_{i}\right)$, $i=1,2, \ldots, m$, then $x_{i} \neq x_{j}$ for $i \neq j$. Thus we have reduced the problem to the onedimensional situation. So let $A_{1}, A_{2}, \ldots, A_{n}$ lie on a line in this order. The midpoints of $A_{1} A_{2}, A_{1} A_{3}, \ldots, A_{1} A_{n}$ are all distinct and different from the (also distinct) midpoints of $A_{2} A_{n}, A_{3} A_{n}, \ldots, A_{n-1} A_{n}$. Hence there are at least $(n-1)+(n-2)=2 n-3$ midpoints. This bound can be achieved for $A_{1}, A_{2}, \ldots, A_{n}$ the points $1,2, \ldots, n$ on the real axis.

(Középiskolai Matematikai Lapok (Mathematics Magazine for High Schools, Budapest), proposed by M. Salát)

593. We consider a Cartesian system of coordinates with $B C$ and $A D$ as the $x$ - and $y$ axes, respectively (the origin is at $D)$. Let $A(0, a), B(b, 0), C(c, 0), M(0, m)$. Because the triangle is acute, $a, c>0$ and $b<0$. Also, $m>0$. The equation of $B M$ is $m x+b y=b m$, and the equation of $A C$ is $a x+c y=a c$. Their intersection is

$$
E\left(\frac{b c(a-m)}{a b-c m}, \frac{a m(b-c)}{a b-c m}\right) .
$$

Note that the denominator is strictly negative, hence nonzero. The point $E$ therefore exists.

The slope of the line $D E$ is the ratio of the coordinates of $E$, namely,

$$
\frac{a m(b-c)}{b c(a-m)} .
$$

Interchanging $b$ and $c$, we find that the slope of $D F$ is

$$
\frac{a m(c-b)}{b c(a-m)},
$$

which is the negative of the slope of $D E$. It follows that the lines $D E$ and $D F$ are symmetric with respect to the $y$-axis, i.e., the angles $\angle A D E$ and $\angle A D F$ are equal.

(18th W.L. Putnam Mathematical Competition, 1958)

594. We refer everything to Figure 74 . Let $A(c, 0), c$ being the parameter that determines the variable line. Because $B$ has the coordinates $\left(\frac{a}{2}, \frac{b}{2}\right)$, the line $A B$ is given by the equation

$$
y=\frac{b}{a-2 c} x+\frac{b c}{2 c-a} .
$$



![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-623.jpg?height=491&width=712&top_left_y=265&top_left_x=516)

Figure 74

Hence $C$ has coordinates $\left(0, \frac{b c}{2 c-a}\right)$.

The slope of the line $C M$ is $\frac{b}{a}$, so the equation of this line is

$$
y=\frac{b}{a} x+\frac{b c}{2 c-a} \text {. }
$$

Intersecting it with $A P$, whose equation is

$$
y=\frac{b}{a-c} x+\frac{b c}{c-a}
$$

we obtain $M$ of coordinates $\left(\frac{a c}{2 c-a}, \frac{2 b c}{2 c-a}\right)$. This point lies on the line $y=\frac{2 b}{a} x$, so this line might be the locus.

One should note, however, that $A=O$ yields an ambiguous construction, so the origin should be removed from the locus. On the other hand, any $(x, y)$ on this line yields a point $c$, namely, $c=\frac{a x}{2 x-a}$, except for $x=\frac{a}{2}$. Hence the locus consists of the line of slope $\frac{2 b}{a}$ through the origin with two points removed.

(A. Myller, Geometrie Analitică (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972)

595. First, assume that $A B C D$ is a rectangle (see Figure 75). Let $H$ be the intersection point of $F G$ and $B D$. In the right triangles $A B C$ and $F B G$, the segments $B E$ and $B H$ are altitudes. Then $\angle A B E=\angle A C B$ and $\angle B G F=\angle H B C$. Since $\angle H B C=\angle A C B$, it follows that $\angle G B E=\angle B G F$ and $B E=G E$. This implies that in the right triangle $B G F, G E=E F$.

For the converse, we employ coordinates. We reformulate the problem as follows:

Given a triangle $A B C$ with $A B \neq B C$, let $B E$ be the altitude from $B$ and $O$ the midpoint of side $A C$. The perpendicular from $E$ to $B O$ intersects $A B$ at $G$ and $B C$ at $F$. Show that if the segments $G E$ and $E F$ are equal, then the angle $\angle B$ is right. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-624.jpg?height=348&width=422&top_left_y=242&top_left_x=661)

Figure 75

Let $E$ be the origin of the rectangular system of coordinates, with line $E B$ as the $y$-axis. Let also $A(-a, 0), B(0, b), C(c, 0)$, where $a, b, c>0$. We have to prove that $b^{2}=a c$.

By standard computations, we obtain the following equations and coordinates:

$$
\begin{aligned}
& \text { line } G F: \quad y=\frac{c-a}{2 b} x \text {; } \\
& \text { line } B C: \quad \frac{x}{c}+\frac{y}{b}=1 \text {; } \\
& \text { point } F: \quad x_{F}=\frac{2 b^{2} c}{2 b^{2}+c^{2}-a c}, \quad y_{F}=\frac{c b(c-a)}{2 b^{2}+c^{2}-a c} \text {; } \\
& \text { line } A B:-\frac{x}{a}+\frac{y}{b}=1 \text {; } \\
& \text { point } G: \quad x_{G}=\frac{2 a b^{2}}{-2 b^{2}+a c-a^{2}}, \quad y_{G}=\frac{a b(c-a)}{-2 b^{2}+a c-a^{2}} .
\end{aligned}
$$

The condition $E G=E F$ is equivalent to $x_{F}=-x_{G}$, that is,

$$
\frac{2 b^{2} c}{2 b^{2}+c^{2}-a c}=\frac{2 a b^{2}}{2 b^{2}-a c+a^{2}} .
$$

This easily gives $b^{2}=a c$ or $a=c$, and since the latter is ruled out by hypothesis, this completes the solution.

(Romanian Mathematics Competition, 2004, proposed by M. Becheanu)

596. The inequality from the statement can be rewritten as

$$
-\frac{\sqrt{2}-1}{2} \leq \sqrt{1-x^{2}}-(p x+q) \leq \frac{\sqrt{2}-1}{2},
$$

or

$$
\sqrt{1-x^{2}}-\frac{\sqrt{2}-1}{2} \leq p x+q \leq \sqrt{1-x^{2}}+\frac{\sqrt{2}-1}{2} .
$$

Let us rephrase this in geometric terms. We are required to include a segment $y=p x+q$, $0 \leq x \leq 1$, between two circular arcs.

The arcs are parts of two circles of radius 1 and of centers $O_{1}\left(0, \frac{\sqrt{2}-1}{2}\right)$ and $\mathrm{O}_{2}\left(0,-\frac{\sqrt{2}-1}{2}\right)$. By examining Figure 76 we will conclude that there is just one such segment. On the first circle, consider the points $A\left(1, \frac{\sqrt{2}-1}{2}\right)$ and $B\left(0, \frac{\sqrt{2}+1}{2}\right)$. The distance from $B$ to $O_{2}$ is $\sqrt{2}$, which is equal to the length of the segment $A B$. In the isosceles triangle $\mathrm{BO}_{2} \mathrm{~A}$, the altitudes from $\mathrm{O}_{2}$ and $A$ must be equal. The altitude from $A$ is equal to the distance from $A$ to the $y$-axis, hence is 1 . Thus the distance from $O_{2}$ to $A B$ is 1 as well. This shows that the segment $A B$ is tangent to the circle centered at $O_{2}$. This segment lies between the two arcs, and above the entire interval $[0,1]$. Being inscribed in one arc and tangent to the other, it is the only segment with this property.

This answers the problem, by showing that the only possibility is $p=-1, q=\frac{\sqrt{2}+1}{2}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-625.jpg?height=467&width=407&top_left_y=914&top_left_x=664)

Figure 76

(Romanian Team Selection Test for the International Mathematical Olympiad, 1983) 

597. The fact that the points $\left(x_{i}, \frac{1}{x_{i}}\right)$ lie on a circle means that there exist numbers $A, B$, and $C$ such that

$$
x_{i}^{2}+\frac{1}{x_{i}^{2}}+2 x_{i} A+2 \frac{1}{x_{i}} B+C=0, \quad \text { for } i=1,2,3,4 .
$$

View this as a system in the unknowns $2 A, 2 B, C$. The system admits a solution only if the determinant of the extended matrix is zero. This determinant is equal to

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-625.jpg?height=268&width=755&top_left_y=1926&top_left_x=386)



$$
=\left(-\frac{1}{x_{1} x_{2} x_{3} x_{4}}+\frac{1}{x_{1}^{2} x_{2}^{2} x_{3}^{2} x_{4}^{2}}\right)\left|\begin{array}{llll}
x_{1}^{3} & x_{1}^{2} & x_{1} & 1 \\
x_{2}^{3} & x_{2}^{2} & x_{2} & 1 \\
x_{3}^{3} & x_{3}^{2} & x_{3} & 1 \\
x_{4}^{3} & x_{4}^{2} & x_{4} & 1
\end{array}\right| .
$$

One of the factors is a determinant of Vandermonde type, hence it cannot be 0 . Thus the other factor is equal to 0 . From this we infer that $x_{1} x_{2} x_{3} x_{4}=1$, which is what had to be proved.

(A. Myller, Geometrie Analitică (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972)

598. Consider complex coordinates with the origin $O$ at the center of the circle. The coordinates of the vertices, which we denote correspondingly by $\alpha, \beta, \gamma, \delta, \eta, \phi$, have absolute value $|r|$. Moreover, because the chords $A B, C D$, and $E F$ are equal to the radius, $\angle A O B=\angle C O D=\angle E O F=\frac{\pi}{3}$. It follows that $\beta=\alpha e^{i \pi / 3}, \delta=\gamma e^{i \pi / 3}$, and $\phi=\eta e^{i \pi / 3}$. The midpoints $P, Q, R$ of $B C, D E, F A$, respectively, have the coordinates

$$
p=\frac{1}{2}\left(\alpha e^{i \pi / 3}+\gamma\right), \quad q=\frac{1}{2}\left(\gamma e^{i \pi / 3}+\eta\right), \quad r=\frac{1}{2}\left(\eta e^{i \pi / 3}+\alpha\right)
$$

We compute

$$
\begin{aligned}
\frac{r-q}{p-q} &=\frac{\alpha e^{i \pi / 3}+\gamma\left(1-e^{i \pi / 3}\right)-\eta}{\alpha-\gamma e^{i \pi / 3}+\eta\left(e^{i \pi / 3}-1\right)} \\
&=\frac{\alpha e^{i \pi / e}-\gamma e^{2 i \pi / 3}+\eta e^{3 i \pi / 3}}{\alpha-\gamma e^{i \pi / 3}+e^{2 i \pi / 3} \eta}=e^{i \pi / 3} .
\end{aligned}
$$

It follows that $R Q$ is obtained by rotating $P Q$ around $Q$ by $60^{\circ}$. Hence the triangle $P Q R$ is equilateral, as desired.

(28th W.L. Putnam Mathematical Competition, 1967)

599. We work in complex coordinates such that the circumcenter is at the origin. Let the vertices be $a, b, c$ on the unit circle. Since the complex coordinate of the centroid is $\frac{a+b+c}{3}$, we have to show that the complex coordinate of the orthocenter is $a+b+c . \mathrm{By}$ symmetry, it suffices to check that the line passing through $a$ and $a+b+c$ is perpendicular to the line passing through $b$ and $c$. This is equivalent to the fact that the argument of $\frac{b-c}{b+c}$ is $\pm \frac{\pi}{2}$. This is true because the vector $b+c$ is constructed as one of the diagonals of the rhombus determined by the vectors (of the same length) $b$ and $c$, while $b-c$ is the other diagonal of the rhombus. And the diagonals of a rhombus are perpendicular. This completes the solution.

(L. Euler)

600. With the convention that the lowercase letter denotes the complex coordinate of the point denoted by the same letter in uppercase, we translate the geometric conditions from the statement into the algebraic equations 

$$
\frac{m-a}{b-a}=\frac{n-c}{b-c}=\frac{p-c}{d-c}=\frac{q-a}{d-a}=\epsilon
$$

where $\epsilon=\cos \frac{\pi}{3}+i \sin \frac{\pi}{3}$. Therefore,

$$
\begin{aligned}
m=a+(b-a) \epsilon, & n=c+(b-c) \epsilon, \\
p=c+(d-c) \epsilon, & q=a+(d-a) \epsilon .
\end{aligned}
$$

It is now easy to see that $\frac{1}{2}(m+p)=\frac{1}{2}(n+q)$, meaning that $M P$ and $N Q$ have the same midpoint. So either the four points are collinear, or they form a parallelogram.

(short list of the 23rd International Mathematical Olympiad, 1982)

601. We refer everything to Figure 77. The triangle $B A Q$ is obtained by rotating the triangle $P A C$ around $A$ by the angle $\alpha$. Hence the angle between the lines $P C$ and $B Q$ is equal to $\alpha$. It follows that in the circumcircle of $B R C$, the measure of the arc $B R C$ is equal to $2 \alpha$, and this is also the measure of $\angle B O C$. We deduce that $O$ is obtained from $B$ through the counterclockwise rotation about $C$ by the complement of $\alpha$ followed by contraction by a factor of $2 \sin \alpha$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-627.jpg?height=420&width=564&top_left_y=1114&top_left_x=590)

Figure 77

Now we introduce complex coordinates with the origin at $A$, with the coordinates of $B$ and $C$ being $b$ and $c$. Set $\omega=e^{i \alpha}$, so that the counterclockwise rotation by $\alpha$ is multiplication by $\omega$, and hence rotation by the complement of $\alpha$ is multiplication by $i / \omega=i \bar{\omega}$. Then the coordinate $z$ of $O$ satisfies

$$
\frac{z-c}{b-c}=\frac{1}{2 \sin \alpha} \cdot \frac{i}{\omega}
$$

from which we compute

$$
z=\frac{b-c}{2 \sin \alpha} \cdot \frac{i}{\omega}+c=\frac{b-c}{-i(\omega-\bar{\omega})} \cdot \frac{i}{\omega}+c=\frac{b-c}{1-\omega^{2}} .
$$

On the other hand, $P$ is obtained by rotating $B$ around $A$ by $-\alpha$, so its coordinate is $p=b \bar{\omega}$. Similarly, the coordinate of $Q$ is $q=c \omega$. It is now straightforward to check that

$$
\frac{q-p}{z-0}=\omega-\frac{1}{\omega},
$$

a purely imaginary number. Hence the lines $P Q$ and $A O$ form a $90^{\circ}$ angle, which is the desired result.

(USA Team Selection Test for the International Mathematical Olympiad, 2006, solution by T. Leung)

602. In the language of complex numbers we are required to find the maximum of $\prod_{k=1}^{n}\left|z-\epsilon^{k}\right|$ as $z$ ranges over the unit disk, where $\epsilon=\cos \frac{2 \pi}{n}+i \sin \frac{2 \pi}{n}$. We have

$$
\prod_{k=1}^{n}\left|z-\epsilon^{k}\right|=\left|\prod_{k=1}^{n}\left(z-\epsilon^{k}\right)\right|=\left|z^{n}-1\right| \leq\left|z^{n}\right|+1=2 .
$$

The maximum is 2 , attained when $z$ is an $n$th root of $-1$.

(Romanian Mathematics Competition "Grigore Moisil," 1992, proposed by D. Andrica)

603. First solution: In a system of complex coordinates, place each vertex $A_{k}, k=$ $0,1, \ldots, n-1$, at $\epsilon^{k}$, where $\epsilon=e^{2 i \pi / n}$. Then

$$
A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{n-1}=\left|(1-\epsilon)\left(1-\epsilon^{2}\right) \cdots\left(1-\epsilon^{n-1}\right)\right| .
$$

Observe that, in general,

$$
\begin{aligned}
(z-\epsilon)\left(z-\epsilon^{2}\right) \cdots\left(z-\epsilon^{n-1}\right) &=\frac{1}{z-1}(z-1)(z-\epsilon) \cdots\left(z-\epsilon^{n-1}\right) \\
&=\frac{1}{z-1}\left(z^{n}-1\right)=z^{n-1}+z^{n-2}+\cdots+1 .
\end{aligned}
$$

By continuity, this equality also holds for $z=1$. Hence

$$
A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{n-1}=1^{n-1}+1^{n-2}+\cdots+1=n,
$$

and the identity is proved.

Second solution: Choose a point $P$ on the ray $\mid O A_{0}$, where $O$ is center of the circumcircle of the polygon, such that $A_{0}$ is between $O$ and $P$. If $O P=x$, then the last problem in the introduction showed that $P A_{0} \cdot P A_{1} \cdots P A_{n-1}=x^{n}-1$. Hence

$$
A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{n-1}=\lim _{x \rightarrow 1} \frac{x^{n}-1}{x-1}=n .
$$

Remark. Let us show how this geometric identity can be used to derive a trigonometric identity. For $n=2 m+1, m$ an integer, $A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{m}=A_{0} A_{2 m}$. $A_{0} A_{2 m-1} \cdots A_{0} A_{m+1}$; hence $A_{0} A_{1} \cdot A_{0} A_{2} \cdots A_{0} A_{m}=\sqrt{2 m+1}$. On the other hand, for $i=1,2, \ldots, m$, in triangle $A_{0} O A_{i}, A A_{i}=2 \sin \frac{2 \pi}{2 m+1}$. We conclude that

$$
\sin \frac{2 \pi}{2 m+1} \sin \frac{4 \pi}{2 m+1} \cdots \sin \frac{2 m \pi}{2 m+1}=\frac{1}{2^{m}} \sqrt{2 m+1} .
$$

(J. Dürschák, Matemaikai Versenytételek, Harmadik kiadás Tankönyviadó, Budapest, $1965)$

604. First solution: We assume that the radius of the circle is equal to 1 . Set the origin at $B$ with $B A$ the positive $x$-semiaxis and $t$ the $y$-axis (see Figure 78). If $\angle B O M=\theta$, then $B P=P M=\tan \frac{\theta}{2}$. In triangle $P Q M, P Q=\tan \frac{\theta}{2} / \sin \theta$. So the coordinates of $Q$ are

$$
\left(\frac{\tan \frac{\theta}{2}}{\sin \theta}, \tan \frac{\theta}{2}\right)=\left(\frac{1}{1+\cos \theta}, \frac{\sin \theta}{1+\cos \theta}\right) .
$$

The $x$ and $y$ coordinates are related as follows:

$$
\left(\frac{\sin \theta}{1+\cos \theta}\right)^{2}=\frac{1-\cos ^{2} \theta}{(1+\cos \theta)^{2}}=\frac{1-\cos \theta}{1+\cos \theta}=2 \frac{1}{1+\cos \theta}-1 .
$$

Hence the locus of $Q$ is the parabola $y^{2}=2 x-1$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-629.jpg?height=475&width=653&top_left_y=1504&top_left_x=541)

Figure 78

Second solution: With $\angle B O M=\theta$ we have $\angle P O M=\angle P O B=\frac{\theta}{2}$. Since $P Q$ is parallel to $O B$, it follows that $\angle O P Q=\frac{\theta}{2}$. So the triangle $O P Q$ is isosceles, and therefore $Q P=O Q$. We conclude that $Q$ lies on the parabola of focus $O$ and directrix $t$. A continuity argument shows that the locus is the entire parabola.

(A. Myller, Geometrie Analitică (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972, solutions found by the students from the Mathematical Olympiad Summer Program, 2004)

605. We will use the equation of the tangent with prescribed slope. Write the parabola in standard form

$$
y^{2}=4 p x .
$$

The tangent of slope $m$ to this parabola is given by

$$
y=m x+\frac{p}{m} .
$$

If $A(p+a, 0)$ and $B(p-a, 0)$ are the two fixed points, $(p, 0)$ being the focus, then the distances to the tangent are

$$
\left|\frac{m(p \pm a)+\frac{p}{m}}{\sqrt{1+m^{2}}}\right| .
$$

The difference of their squares is

$$
\frac{\left(m^{2}(p+a)^{2}+2 p(p+a)+\frac{p^{2}}{m^{2}}\right)-\left(m^{2}(p-a)^{2}+2 p(p-a)+\frac{p^{2}}{m^{2}}\right)}{1+m^{2}} .
$$

An easy computation shows that this is equal to $4 p a$, which does not depend on $m$, meaning that it does not depend on the tangent.

(A. Myller, Geometrie Analitică (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972)

606. The statement of the problem is invariant under affine transformations, so we can assume the hyperbola to have the equation $x y=1$, such that the asymptotes are the coordinate axes. If $P\left(x_{1}, y_{1}\right)$ and $Q\left(x_{2}, y_{2}\right)$ are two of the vertices, then the other two vertices of the parallelogram are $\left(x_{1}, y_{2}\right)$ and $\left(x_{2}, y_{1}\right)$. The line they determine has the equation

$$
y-y_{1}=\frac{y_{2}-y_{1}}{x_{1}-x_{2}}\left(x-x_{2}\right) .
$$

Substituting the coordinates of the origin in this equation yields $-y_{1}=\frac{y_{2}-y_{1}}{x_{1}-x_{2}}\left(-x_{2}\right)$, or $x_{1} y_{1}-x_{2} y_{1}=x_{2} y_{2}-x_{2} y_{1}$. This clearly holds, since $x_{1} y_{1}=x_{2} y_{2}=1$, and the property is proved.

(A. Myller, Geometrie Analitică (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972) 

607. Since the property we are trying to prove is invariant under affine changes of coordinates, we can assume that the equation of the hyperbola is

$$
x y=1 \text {. }
$$

The asymptotes are the coordinate axes. In the two-intercept form, the equation of the line is

$$
\frac{x}{a}+\frac{y}{b}=1 .
$$

Then the coordinates of $A$ and $B$ are, respectively, $(a, 0)$ and $(0, b)$. To find the coordinates of $P$ and $Q$, substitute $y=\frac{1}{x}$ in the equation of the line. This gives rise to the quadratic equation

$$
x^{2}-a x+\frac{a}{b}=0 .
$$

The roots $x_{1}$ and $x_{2}$ of this equation satisfy $x_{1}+x_{2}=a$. Similarly, substituting $x=\frac{1}{y}$ in the same equation yields

$$
y^{2}-b y+\frac{b}{a}=0,
$$

and the two roots $y_{1}$ and $y_{2}$ satisfy $y_{1}+y_{2}=b$. The coordinates of $P$ and $Q$ are, respectively, $\left(x_{1}, y_{1}\right)$ and $\left(x_{2}, y_{2}\right)$. We have

$$
A P^{2}=\left(x_{1}-a\right)^{2}+y_{1}^{2}=\left(a-x_{2}-a\right)^{2}+\left(b-y_{2}\right)^{2}=x_{2}^{2}+\left(b-y_{2}\right)^{2}=B Q^{2} .
$$

The property is proved.

(L.C. Larson, Problem Solving through Problems, Springer-Verlag, 1983)

608. The condition that a line through $\left(x_{0}, y_{0}\right)$ be tangent to the parabola is that the system

$$
\begin{aligned}
y^{2} &=4 p x, \\
y-y_{0} &=m\left(x-x_{0}\right)
\end{aligned}
$$

have a unique solution. This means that the discriminant of the quadratic equation in $x$ obtained by eliminating $y,\left(m x-m x_{0}+y_{0}\right)^{2}-4 p x=0$, is equal to zero. This translates into the condition

$$
m^{2} x_{0}-m y_{0}+p=0 .
$$

The slopes $m$ of the two tangents are therefore the solutions to this quadratic equation. They satisfy 

$$
\begin{aligned}
m_{1}+m_{2} &=\frac{y_{0}}{x_{0}}, \\
m_{1} m_{2} &=\frac{p}{x_{0}} .
\end{aligned}
$$

We also know that the angle between the tangents is $\phi$. We distinguish two situations. First, if $\phi=90^{\circ}$, then $m_{1} m_{2}=-1$. This implies $\frac{p}{x_{0}}=-1$, so the locus is the line $x=-p$, which is the directrix of the parabola.

If $\phi \neq 90^{\circ}$, then

$$
\tan \phi=\frac{m_{1}-m_{2}}{1+m_{1} m_{2}}=\frac{m_{1}-m_{2}}{1+\frac{p}{x_{0}}} .
$$

We thus have

$$
\begin{aligned}
&m_{1}+m_{2}=\frac{y_{0}}{x_{0}}, \\
&m_{1}-m_{2}=\tan \phi+\frac{p}{x_{0}} \tan \phi .
\end{aligned}
$$

We can compute $m_{1} m_{2}$ by squaring the equations and then subtracting them, and we obtain

$$
m_{1} m_{2}=\frac{y_{0}^{2}}{4 x_{0}^{2}}-\left(1+\frac{p}{x_{0}}\right)^{2} \tan ^{2} \phi .
$$

This must equal $\frac{p}{x_{0}}$. We obtain the equation of the locus to be

$$
-y^{2}+(x+p)^{2} \tan ^{2} \phi+4 p x=0,
$$

which is a hyperbola. One branch of the hyperbola contains the points from which the parabola is seen under the angle $\phi$, and one branch contains the points from which the parabola is seen under an angle equal to the suplement of $\phi$.

(A. Myller, Geometrie Analitic ă (Analytical Geometry), 3rd ed., Editura Didactică şi Pedagogică, Bucharest, 1972)

609. Choose a Cartesian system of coordinates such that the equation of the parabola is $y^{2}=4 p x$. The coordinates of the three points are $T_{i}\left(4 p \alpha_{i}^{2}, 4 p \alpha_{i}\right)$, for appropriately chosen $\alpha_{i}, i=1,2,3$. Recall that the equation of the tangent to the parabola at a point $\left(x_{0}, y_{0}\right)$ is $y y_{0}=2 p\left(x+x_{0}\right)$. In our situation the three tangents are given by

$$
2 \alpha_{i} y=x+4 p \alpha_{i}^{2}, \quad i=1,2,3 .
$$

If $P_{i j}$ is the intersection of $t_{i}$ and $t_{j}$, then its coordinates are $\left(4 p \alpha_{i} \alpha_{j}, 2 p\left(\alpha_{i}+\alpha_{j}\right)\right)$. The area of triangle $T_{1} T_{2} T_{3}$ is given by a Vandermonde determinant: 

$$
\pm \frac{1}{2}\left|\begin{array}{lll}
4 p \alpha_{1}^{2} & 4 p \alpha_{1} & 1 \\
4 p \alpha_{2}^{2} & 4 p \alpha_{2} & 1 \\
4 p \alpha_{3}^{2} & 4 p \alpha_{3} & 1
\end{array}\right|=\pm 8 p^{2}\left|\begin{array}{lll}
\alpha_{1}^{2} & \alpha_{1} & 1 \\
\alpha_{2}^{2} & \alpha_{2} & 1 \\
\alpha_{3}^{2} & \alpha_{3} & 1
\end{array}\right|=8 p^{2}\left|\left(\alpha_{1}-\alpha_{2}\right)\left(\alpha_{1}-\alpha_{3}\right)\left(\alpha_{2}-\alpha_{3}\right)\right| .
$$

The area of the triangle $P_{12} P_{23} P_{31}$ is given by

$$
\begin{aligned}
& \pm \frac{1}{2}\left|\begin{array}{lll}4 p \alpha_{1} \alpha_{2} & 2 p\left(\alpha_{1}+\alpha_{2}\right) & 1 \\4 p \alpha_{2} \alpha_{3} & 2 p\left(\alpha_{2}+\alpha_{3}\right) & 1 \\4 p \alpha_{3} \alpha_{1} & 2 p\left(\alpha_{3}+\alpha_{1}\right) & 1\end{array}\right| \\
& =\pm 4 p^{2}\left|\begin{array}{ll}\alpha_{1} \alpha_{2}\left(\alpha_{1}+\alpha_{2}\right) & 1 \\\alpha_{2} \alpha_{3}\left(\alpha_{2}+\alpha_{3}\right) & 1 \\\alpha_{3} \alpha_{1}\left(\alpha_{3}+\alpha_{1}\right) & 1\end{array}\right|=\pm 4 p^{2}\left|\begin{array}{rr}\left(\alpha_{1}-\alpha_{3}\right) \alpha_{2}\left(\alpha_{1}-\alpha_{3}\right) & 0 \\\left(\alpha_{2}-\alpha_{1}\right) \alpha_{3}\left(\alpha_{2}-\alpha_{1}\right) & 0 \\\alpha_{3} \alpha_{1}\left(\alpha_{3}+\alpha_{1}\right) & 1\end{array}\right| \\
& =4 p^{2}\left|\left(\alpha_{1}-\alpha_{3}\right)\left(\alpha_{1}-\alpha_{2}\right)\left(\alpha_{2}-\alpha_{3}\right)\right| \text {. }
\end{aligned}
$$

We conclude that the ratio of the two areas is 2 , regardless of the location of the three points or the shape of the parabola.

(Gh. Călugăriţa, V. Mangu, Probleme de Matematică pentru Treapta I şi a II-a de Liceu (Mathematics Problems for High School), Editura Albatros, Bucharest, 1977)

610. Choose a Cartesian system of coordinates such that the focus is $F(p, 0)$ and the directrix is $x=-p$, in which case the equation of the parabola is $y^{2}=4 p x$. Let the three points be $A\left(\frac{a^{2}}{4 p}, a\right), B\left(\frac{b^{2}}{4 p}, b\right), C\left(\frac{c^{2}}{4 p}, c\right)$.

(a) The tangents $N P, P M$, and $M N$ to the parabola are given, respectively, by

$$
a y=2 p x+\frac{a^{2}}{2}, \quad b y=2 p x+\frac{b^{2}}{2}, \quad c y=2 p x+\frac{c^{2}}{2},
$$

from which we deduce the coordinates of the vertices

$$
M\left(\frac{b c}{4 p}, \frac{b+c}{2}\right), \quad N\left(\frac{c a}{4 p}, \frac{c+a}{2}\right), \quad P\left(\frac{a b}{4 p}, \frac{a+b}{2}\right) .
$$

The intersection of the line $A C$ of equation $4 p x-(c+a) y+c a=0$ with the parallel to the symmetry axis through $B$, which has equation $y=b$, is $L\left(\frac{a b+b c-c a}{4 p}, b\right)$. It is straightforward to verify that the segments $M P$ and $L N$ have the same midpoint, the point with coordinates $\left(\frac{b(c+a)}{8 p}, \frac{a+2 b+c}{4}\right)$. Consequently, $L M N P$ is a parallelogram.

(b) Writing that the equation of the circle $x^{2}+y^{2}+2 \alpha x+2 \beta y+\gamma=0$ is satisfied by the points $M, N, P$ helps us determine the parameters $\alpha, \beta, \gamma$. We obtain the equation of the circumcircle of $M N P$,

$$
x^{2}+y^{2}-\frac{a b+b c+c a+4 p^{2}}{4 p} x+\frac{a b c-4 p^{2}(a+b+c)}{8 p^{2}} y+\frac{a b+b c+c a}{4}=0 .
$$

This equation is satisfied by $(p, 0)$, showing that the focus $F$ is on the circle. (c) Substituting the coordinates of $L$ in the equation of the circle yields

$$
\left(a c+4 p^{2}\right)(a-b)(c-b)=0 .
$$

Since $a \neq b \neq c$, we must have $a c=-4 p^{2}$. Thus the $x$-coordinate of $N$ is $-p$, showing that this point is on the directrix.

(d) The condition for $F$ to be on $A C$ is $4 p^{2}+a c=0$, in which case $N$ is on the directrix. The slope of $B F$ is $m=\frac{4 p b}{b^{2}-4 p^{2}}$. The orthogonality condition is

$$
\frac{4 p b}{b^{2}-4 p^{2}} \cdot \frac{4 p}{c+a}=-1,
$$

which is equivalent to

$$
\left(b^{2}-4 p^{2}\right)(c+a)+16 p^{2} b=0 .
$$

The locus is obtained by eliminating $a, b, c$ from the equations

$$
\begin{aligned}
4 p x-(c+a) y+c a &=0, \\
y &=b, \\
4 p^{2}+a c &=0, \\
\left(b^{2}-4 p^{2}\right)(c+a)+16 p^{2} b &=0 .
\end{aligned}
$$

The answer is the cubic curve

$$
\left(y^{2}-4 p^{2}\right) x+3 p y^{2}+4 p^{3}=0 .
$$

(The Mathematics Gazette Competition, Bucharest, 1938)

611. An equilateral triangle can be inscribed in any closed, non-self-intersecting curve, therefore also in an ellipse. The argument runs as follows. Choose a point $A$ on the ellipse. Rotate the ellipse around $A$ by $60^{\circ}$. The image of the ellipse through the rotation intersects the original ellipse once in $A$, so it should intersect it at least one more time. Let $B$ an be intersection point different from $A$. Note that $B$ is on both ellipses, and its preimage $C$ through rotation is on the original ellipse. The triangle $A B C$ is equilateral.

A square can also be inscribed in the ellipse. It suffices to vary an inscribed rectangle with sides parallel to the axes of the ellipse and use the intermediate value property.

Let us show that these are the only possibilities. Up to a translation, a rotation, and a dilation, the equation of the ellipse has the form

$$
x^{2}+a y^{2}=b, \quad \text { with } a, b>0, a \neq 1 .
$$

Assume that a regular $n$-gon, $n \geq 5$, can be inscribed in the ellipse. Its vertices $\left(x_{i}, y_{i}\right)$ satisfy the equation of the circumcircle: 

$$
x^{2}+y^{2}+c x+d y+e=0, \quad i=1,2, \ldots, n .
$$

Writing the fact that the vertices also satisfy the equation of the ellipse and subtracting, we obtain $(1-a) y_{i}^{2}+c x_{i}+d y_{i}+(e+b)=0$. Hence

$$
y_{i}^{2}=-\frac{c}{1-a} x_{i}-\frac{d}{1-a} y_{i}-\frac{e+b}{1-a} .
$$

The number $c$ cannot be 0 , for otherwise the quadratic equation would have two solutions $y_{i}$ and each of these would yield two solutions $x_{i}$, so the polygon would have four or fewer sides, a contradiction. This means that the regular polygon is inscribed in a parabola. Change the coordinates so that the parabola has the standard equation $y^{2}=4 p x$. Let the new coordinates of the vertices be $\left(\xi_{i}, \eta_{i}\right)$ and the new equation of the circumcircle be $x^{2}+y^{2}+c^{\prime} x+d^{\prime} y+e^{\prime}=0$. That the vertices belong to both the parabola and the circle translates to

$$
\eta_{i}^{2}=4 p \xi_{i} \quad \text { and } \quad \xi_{i}^{2}+\eta_{i}^{2}+c^{\prime} \xi+d^{\prime} \eta+e^{\prime}=0, \quad \text { for } i=1,2, \ldots, n .
$$

So the $\eta_{i}$ 's satisfy the fourth-degree equation

$$
\frac{1}{16 p^{2}} \eta_{i}^{4}+\eta_{i}^{2}+\frac{c^{\prime}}{4 p} \eta_{i}^{2}+d^{\prime} \eta_{i}+e^{\prime}=0 .
$$

This equation has at most four solutions, and each solution yields a unique $x_{i}$. So the regular polygon can have at most four vertices, a contradiction. We conclude that no regular polygon with five or more vertices can be inscribed in an ellipse that is not also a circle.

612. Set $F B_{k}=t_{k}, k=1,2, \ldots, n$. Also, let $\alpha$ be the angle made by the half-line $\mid F B_{1}$ with the $x$-axis and $\alpha_{k}=\alpha+\frac{2(k-1) \pi}{n}, k=2, \ldots, n$. The coordinates of the focus $F$ are $\left(\frac{p}{2}, 0\right)$.

In general, the coordinates of the points on a ray that originates in $F$ and makes an angle $\beta$ with the $x$ axis are $\left(\frac{p}{2}+t \cos \beta, t \sin \beta\right), t>0$ (just draw a ray from the origin of the coordinate system that makes an angle $\beta$ with the $x$-axis; then translate it to $F$ ). It follows that the coordinates of $B_{k}$ are $\left(\frac{p}{2}+t_{k} \cos \alpha_{k}, t_{k} \sin \alpha_{k}\right), k=1,2, \ldots, n$.

The condition that $B_{k}$ belongs to the parabola is written as $t_{k}^{2} \sin ^{2} \alpha_{k}=p^{2}+$ $2 p t_{k} \cos \alpha_{k}$. The positive root of this equation is $t_{k}=p /\left(1-\cos \alpha_{k}\right)$. We are supposed to prove that $t_{1}+t_{2}+\cdots+t_{k}>n p$, which translates to

$$
\frac{1}{1-\cos \alpha_{1}}+\frac{1}{1-\cos \alpha_{2}}+\cdots+\frac{1}{1-\cos \alpha_{n}}>n \text {. }
$$

To prove this inequality, note that

$$
\left(1-\cos \alpha_{1}\right)+\left(1-\cos \alpha_{2}\right)+\cdots+\left(1-\cos \alpha_{n}\right)
$$



$$
\begin{aligned}
&=n-\sum_{k=1}^{n} \cos \left(\alpha+\frac{2(k-1) \pi}{n}\right) \\
&=n-\cos \alpha \sum_{k=1}^{n} \cos \left(\frac{2(k-1) \pi}{n}\right)+\sin \alpha \sum_{k=1}^{n} \sin \left(\frac{2(k-1) \pi}{n}\right)=n .
\end{aligned}
$$

By the Cauchy-Schwarz inequality,

$$
\begin{aligned}
&\left(\frac{1}{1-\cos \alpha_{1}}+\frac{1}{1-\cos \alpha_{2}}+\cdots+\frac{1}{1-\cos \alpha_{n}}\right) \\
&\geq \frac{n^{2}}{\left(1-\cos \alpha_{1}\right)+\left(1-\cos \alpha_{2}\right)+\cdots+\left(1-\cos \alpha_{n}\right)}=\frac{n^{2}}{n}=n .
\end{aligned}
$$

The equality case would imply that all $\alpha_{k}$ 's are equal, which is impossible. Hence the inequality is strict, as desired.

(Romanian Mathematical Olympiad, 2004, proposed by C. Popescu)

613. We solve part (e). Choose a coordinate system such that $B=(-1,0), C=(1,0)$, $S=(0, \sqrt{3}), S^{\prime}=(0,-\sqrt{3})$. Assume that the ellipse has vertices $(0, \pm k)$ with $k>\sqrt{3}$, so its equation is

$$
\frac{x^{2}}{k^{2}-3}+\frac{y^{2}}{k^{2}}=1 .
$$

If we set $r=\sqrt{k^{2}-3}$, then the ellipse is parametrized by $A=(r \cos \theta, k \sin \theta)$. Parts (a) through (d) are covered by the degenerate situation $k=\sqrt{3}$, when the ellipse becomes the line segment $S S^{\prime}$.

Let $A=(r \cos \theta, k \sin \theta)$ with $\theta$ not a multiple of $\pi$. Consider the points $D, E, F$, respectively, on $B C, A C, A B$, given by

$$
\begin{aligned}
D &=((r+k) \cos \theta, 0), \\
E &=\left(\frac{\left(2 k^{2}+r k-3\right) \cos \theta+k-r}{r+2 k+3 \cos \theta}, \frac{k(2 r+k) \sin \theta}{r+2 k+3 \cos \theta}\right), \\
F &=\left(\frac{\left(2 k^{2}+r k-3\right) \cos \theta-k+r}{r+2 k-3 \cos \theta}, \frac{k(2 r+k) \sin \theta}{r+2 k-3 \cos \theta}\right) .
\end{aligned}
$$

The denominators are never zero since $r \geq 0$ and $k \geq \sqrt{3}$. The lines $A D, B E$, and $C F$ intersect at the point

$$
P=\left(\frac{r+2 k}{3} \cos \theta, \frac{2 r+k}{3} \sin \theta\right),
$$

as one can verify, using $r^{2}=k^{2}-3$, that 

$$
\begin{aligned}
P &=\frac{k+2 r}{3 k} A+\frac{2 k-2 r}{3 k} D \\
&=\frac{k-r-3 \cos \theta}{3 k} B+\frac{2 k+r+3 \cos \theta}{3 k} E \\
&=\frac{k-r+3 \cos \theta}{3 k} C+\frac{2 k+r-3 \cos \theta}{3 k} F .
\end{aligned}
$$

An algebraic computation shows that $A D=B E=C F=k$, so $P$ is an equicevian point, and $\frac{A P}{P D}=\frac{(2 k-2 r)}{(k+2 r)}$ is independent of $A$.

To find the other equicevian point note that if we replace $k$ by $-k$ and $\theta$ by $-\theta$, then $A$ remains the same. In this new parametrization, we have the points

$$
\begin{aligned}
D^{\prime} &=((r-k) \cos \theta, 0), \\
E^{\prime} &=\left(\frac{\left(2 k^{2}-r k-3\right) \cos \theta-k-r}{r-2 k+3 \cos \theta}, \frac{k(2 r-k) \sin \theta}{r-2 k+3 \cos \theta}\right), \\
F^{\prime} &=\left(\frac{\left(2 k^{2}-r k-3\right) \cos \theta+k+r}{r-2 k-3 \cos \theta}, \frac{k(2 r-k) \sin \theta}{r-2 k-3 \cos \theta}\right), \\
P^{\prime} &=\left(\frac{r-2 k}{3} \cos \theta, \frac{k-2 r}{3} \sin \theta\right) .
\end{aligned}
$$

Of course, $P^{\prime}$ is again an equicevian point, and $\frac{A P^{\prime}}{P^{\prime} D^{\prime}}=\frac{(2 k+2 r)}{(k-2 r)}$, which is also independent of $A$. When $r \neq 0$, the points $P$ and $P^{\prime}$ are distinct, since $\sin \theta \neq 0$. When $r=0$, the two points $P$ and $P^{\prime}$ coincide when $A=S$, a case ruled out by the hypothesis. As $\theta$ varies, $P$ and $P^{\prime}$ trace an ellipse. Moreover, since

$$
\left(\frac{r \pm 2 k}{3}\right)^{2}-\left(\frac{k \pm 2 r}{3}\right)^{2}=1,
$$

this ellipse has foci at $B$ and $C$.

(American Mathematical Monthly, proposed by C.R. Pranesachar)

614. The interesting case occurs of course when $b$ and $c$ are not both equal to zero. Set $d=\sqrt{b^{2}+c^{2}}$ and define the angle $\alpha$ by the conditions $\cos \alpha=\frac{b}{\sqrt{b^{2}+c^{2}}}$ and $\sin \alpha=$ $\frac{c}{\sqrt{b^{2}+c^{2}}}$. The integral takes the form

$$
\int \frac{d x}{a+d \cos (x-\alpha)},
$$

which, with the substitution $u=x-\alpha$, becomes the simpler

$$
\int \frac{d u}{a+d \cos u} \text {. }
$$

The substitution $t=\tan \frac{u}{2}$ changes this into

$$
\frac{2}{a+d} \int \frac{d t}{1+\frac{a-d}{a+d} t^{2}} .
$$

If $a=d$ the answer to the problem is $\frac{1}{a} \tan \frac{x-\alpha}{2}+C$. If $\frac{a-d}{a+d}>0$, the answer is

$$
\frac{2}{\sqrt{a^{2}-d^{2}}} \arctan \left(\sqrt{\frac{a-d}{a+d}} \tan \frac{x-\alpha}{2}+C\right),
$$

while if $\frac{a-d}{a+d}<0$, the answer is

$$
\frac{1}{\sqrt{d^{2}-a^{2}}} \ln \left|\frac{1+\sqrt{\frac{d-a}{d+a}} \tan \frac{x-\alpha}{2}}{1-\sqrt{\frac{d-a}{d+a}} \tan \frac{x-\alpha}{2}}\right|+C .
$$

615. The first equation is linear, so it is natural to just solve for one of the variables, say $u$, and substitute in the second equation. We obtain

$$
2 x y=z(x+y-z),
$$

or

$$
z^{2}-x z-y z+2 x y=0 .
$$

This is a homogeneous equation. Instead of looking for its integer solutions, we can divide through by one of the variables, and then search for the rational solutions of the newly obtained equation. In fancy language, we switch from a projective curve to an affine curve. Dividing by $y^{2}$ gives

$$
\left(\frac{z}{y}\right)^{2}-\left(\frac{z}{y}\right)\left(\frac{x}{y}\right)-\left(\frac{z}{y}\right)+2\left(\frac{x}{y}\right)=0 .
$$

The new equation is

$$
Z^{2}-Z X-Z+2 X=0,
$$

which defines a hyperbola in the $X Z$-plane. Let us translate the original problem into a problem about this hyperbola. The conditions $x \geq y$ and $m \leq \frac{x}{y}$ become $X \geq 1$ and $X \geq m$. We are asked to find the largest $m$ such that any point $(X, Z)$ with rational coordinates lying on the hyperbola and in the half-plane $X \geq 1$ has $X \geq m$.

There is a standard way to see that the points of rational coordinates are dense in the hyperbola, which comes from the fact that the hyperbola is rational. Substituting $Z=t X$, we obtain 

$$
X\left(t^{2} X-t X-t+2\right)=0 .
$$

The root $X=0$ corresponds to the origin. The other root $X=\frac{t-2}{t^{2}-t}$ gives the desired parametrization of the hyperbola by rational functions $\left(\frac{t-2}{t^{2}-t}, \frac{t^{2}-2 t}{t^{2}-t}\right), t$ real. So the problem has little to do with number theory, and we only need to find the leftmost point on the hyperbola that lies in the half-plane $X \geq 1$. Write the equation of the hyperbola as

$$
\left(Z-\frac{X}{2}\right)^{2}-\left(\frac{X}{2}-2\right)^{2}=6 .
$$

The center is at $(4,2)$, and the asymptotes are $Z=2$ and $Z=X-2$. Let us first minimize $X$ for the points on the hyperbola and in the half-plane $X \geq 4$. We thus minimize the function $f(X, Z)=X$ on the curve $g(X, Z)=Z^{2}-Z X-Z+2 X=0$. The Lagrange multipliers method gives

$$
\begin{aligned}
&1=\lambda(-Z+2), \\
&0=\lambda(2 Z-X-1) .
\end{aligned}
$$

From the second equation we obtain $Z=\frac{X+1}{2}$. Substitute in $g(X, Z)=0$ to obtain $X=3 \pm 2 \sqrt{2}$. The further constraint $X \geq 1$ shows that $X=3+2 \sqrt{2}$ gives the minimum. The same argument shows that the other branch of the hyperbola lies in the half-plane $X<1$, and so the answer to the problem is $m=3+2 \sqrt{2}$.

(short list of the 42nd International Mathematical Olympiad, 2001)

616. We convert to Cartesian coordinates, obtaining the equation of the cardioid

$$
\sqrt{x^{2}+y^{2}}=1+\frac{x}{\sqrt{x^{2}+y^{2}}},
$$

or

$$
x^{2}+y^{2}=\sqrt{x^{2}+y^{2}}+x .
$$

By implicit differentiation, we obtain

$$
2 x+2 y \frac{d y}{d x}=\left(x^{2}+y^{2}\right)^{-1 / 2}\left(x+y \frac{d y}{d x}\right)+1,
$$

which yields

$$
\frac{d y}{d x}=\frac{-2 x+x\left(x^{2}+y^{2}\right)^{-1 / 2}+1}{2 y-y\left(x^{2}+y^{2}\right)^{-1 / 2}} .
$$

The points where the tangent is vertical are among those where the denominator cancels. Solving $2 y-y\left(x^{2}+y^{2}\right)^{-1 / 2}=0$, we obtain $y=0$ or $x^{2}+y^{2}=\frac{1}{4}$. Combining this 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-640.jpg?height=416&width=441&top_left_y=239&top_left_x=647)

Figure 79

with the equation of the cardioid, we find the possible answers to the problem as $(0,0)$, $(2,0),\left(-\frac{1}{4}, \frac{\sqrt{3}}{4}\right)$, and $\left(-\frac{1}{4},-\frac{\sqrt{3}}{4}\right)$. Of these the origin has to be ruled out, since there the cardioid has a corner, while the other three are indeed points where the tangent to the cardioid is vertical.

617. Let $A B=a$ and consider a system of polar coordinates with pole $A$ and axis $A B$. The equation of the curve traced by $M$ is obtained as follows. We have $A M=r$, $A D=\frac{a}{\cos \theta}$, and $A C=a \cos \theta$. The equality $A M=A D-A C$ yields the equation

$$
r=\frac{a}{\cos \theta}-a \cos \theta .
$$

The equation of the locus is therefore $r=\frac{a \sin ^{2} \theta}{\cos \theta}$. This curve is called the cisoid of Diocles (Figure 80).

618. Let $O$ be the center and $a$ the radius of the circle, and let $M$ be the point on the circle. Choose a system of polar coordinates with $M$ the pole and $M O$ the axis. For an arbitrary tangent, let $I$ be its intersection with $M O, T$ the tangency point, and $P$ the projection of $M$ onto the tangent. Then

$$
O I=\frac{O T}{\cos \theta}=\frac{a}{\cos \theta} .
$$

Hence

$$
M P=r=(M O+O I) \cos \theta=\left(a+\frac{a}{\cos \theta}\right) \cos \theta .
$$

We obtain $r=a(1+\cos \theta)$, which is the equation of a cardioid (Figure 80).

619. Working with polar coordinates we place the pole at $O$ and axis $O A$. Denote by $a$ the radius of the circle. We want to find the relation between the polar coordinates 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-641.jpg?height=418&width=420&top_left_y=238&top_left_x=662)

Figure 80

$(r, \theta)$ of the point $L$. We have $A M=A L=2 a \sin \frac{\theta}{2}$. In the isosceles triangle $L A M$, $\angle L M A=\frac{\pi}{2}-\frac{\theta}{2}$; hence

$$
L M=2 A M \cos \left(\frac{\pi}{2}-\frac{\theta}{2}\right)=2 \cdot 2 a \sin \frac{\theta}{2} \cdot \sin \frac{\theta}{2}=4 a \sin ^{2} \frac{\theta}{2} .
$$

Substituting this in the relation $O L=O M-L M$, we obtain

$$
r=a-4 a \sin ^{2} \frac{\theta}{2}=a[1-2 \cdot(1-\cos \theta)] .
$$

The equation of the locus is therefore

$$
r=a(2 \cos \theta-1),
$$

a curve known as Pascal's snail, or limaçon, whose shape is described in Figure 81.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-641.jpg?height=413&width=433&top_left_y=1524&top_left_x=651)

Figure 81

620. As before, we work with polar coordinates, choosing $O$ as the pole and $O A$ as the axis. Denote by $a$ the length of the segment $A B$ and by $P(r, \theta)$ the projection of $O$ onto this segment. Then $O A=\frac{r}{\cos \theta}$ and $O A=A B \sin \theta$, which yield the equation of the locus

$$
r=a \sin \theta \cos \theta=\frac{a}{2} \sin 2 \theta .
$$

This is a four-leaf rose.

621. Choosing a Cartesian system of coordinates whose axes are the asymptotes, we can bring the equation of the hyperbola into the form $x y=a^{2}$. The equation of the tangent to the hyperbola at a point $\left(x_{0}, y_{0}\right)$ is $x_{0} y+y_{0} x-2 a^{2}=0$. Since $a^{2}=x_{0} y_{0}$, the $x$ and $y$ intercepts of this line are $2 x_{0}$ and $2 y_{0}$, respectively.

Let $(r, \theta)$ be the polar coordinates of the foot of the perpendicular from the origin to the tangent. In the right triangle determined by the center of the hyperbola and the two intercepts we have $2 x_{0} \cos \theta=r$ and $2 y_{0} \sin \theta=r$. Multiplying, we obtain the polar equation of the locus

$$
r^{2}=2 a^{2} \sin 2 \theta .
$$

This is the lemniscate of Bernoulli, shown in Figure 82.

(1st W.L. Putnam Mathematical Competition, 1938)

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-642.jpg?height=414&width=420&top_left_y=1173&top_left_x=662)

Figure 82

622. The solution uses complex and polar coordinates. Our goal is to map the circle onto a cardioid of the form

$$
r=a(1+\cos \theta), \quad a>0 .
$$

Because this cardioid passes through the origin, it is natural to work with a circle that itself passes through the origin, for example $|z-1|=1$. If $\phi: \mathbb{C} \rightarrow \mathbb{C}$ maps this circle into the cardioid, then the equation of the cardioid will have the form

$$
\left|\phi^{-1}(z)-1\right|=1 .
$$

So we want to bring the original equation of the cardioid into this form. First, we change it to

$$
r=a \cdot 2 \cos ^{2} \frac{\theta}{2} ;
$$

then we take the square root,

$$
\sqrt{r}=\sqrt{2 a} \cos \frac{\theta}{2} .
$$

Multiplying by $\sqrt{r}$, we obtain

$$
r=\sqrt{2 a} \sqrt{r} \cos \frac{\theta}{2},
$$

or

$$
r-\sqrt{2 a} \sqrt{r} \cos \frac{\theta}{2}=0 .
$$

This should look like the equation of a circle. We modify the expression as follows:

$$
\begin{aligned}
r-\sqrt{2 a} \sqrt{r} \cos \frac{\theta}{2} &=r\left(\cos ^{2} \frac{\theta}{2}+\sin ^{2} \frac{\theta}{2}\right)-\sqrt{2 a} \sqrt{r} \cos \frac{\theta}{2}+1-1 \\
&=\left(\sqrt{r} \cos \frac{\theta}{2}\right)^{2}-\sqrt{2 a} \sqrt{r} \cos \frac{\theta}{2}+1+\left(\sqrt{r} \sin \frac{\theta}{2}\right)^{2}-1 .
\end{aligned}
$$

If we set $a=2$, we have a perfect square, and the equation becomes

$$
\left(\sqrt{r} \cos \frac{\theta}{2}-1\right)^{2}+\left(\sqrt{r} \sin \frac{\theta}{2}\right)^{2}=1,
$$

which in complex coordinates reads $|\sqrt{z}-1|=1$. Of course, there is an ambiguity in taking the square root, but we are really interested in the transformation $\phi$, not in $\phi^{-1}$. Therefore, we can choose $\phi(z)=z^{2}$, which maps the circle $|z-1|=1$ into the cardioid $r=2(1+\cos \theta)$.

Remark. Of greater practical importance is the Zhukovski transformation $z \rightarrow \frac{1}{2}\left(z+\frac{1}{z}\right)$, which maps the unit circle onto the profile of the airplane wing (the so-called aerofoil). Because the Zhukovski map preserves angles, it helps reduce the study of the air flow around an airplane wing to the much simpler study of the air flow around a circle.

623. Let $x+y=s$. Then $x^{3}+y^{3}+3 x y s=s^{3}$, so $3 x y s-3 x y=s^{3}-1$. It follows that the locus is described by

$$
(s-1)\left(s^{2}+s+1-3 x y\right)=0 .
$$

Recalling that $s=x+y$, we have two curves: $x+y=1$ and $(x+y)^{2}+x+y+1-3 x y=0$. The last equality is equivalent to

$$
\frac{1}{2}\left[(x-y)^{2}+(x+1)^{2}+(y+1)^{2}\right]=0,
$$

i.e., $x=y=-1$. Thus the curve in the problem consists of the line $x+y=1$ and the point $(-1,-1)$, which we will call $A$. Points $B$ and $C$ are on the line $x+y=1$ such that they are symmetric to one another with respect to the point $D\left(\frac{1}{2}, \frac{1}{2}\right)$ and such that $B C \frac{\sqrt{3}}{2}=A D$. It is clear that there is only one set $\{B, C\}$ with this property, so we have justified the uniqueness of the triangle $A B C$ (up to the permutation of vertices). Because

$$
A D=\sqrt{\left(\frac{1}{2}+1\right)^{2}+\left(\frac{1}{2}+1\right)^{2}}=\frac{3}{2} \sqrt{2},
$$

it follows that $B C=\sqrt{6}$; hence $\operatorname{Area}(A B C)=\frac{6 \sqrt{3}}{4}=\frac{3 \sqrt{3}}{2}$.

(49th W.L. Putnam Mathematical Competition, 2006, proposed by T. Andreescu)

624. View the parametric equations of the curve as a linear system in the unknowns $t^{n}$ and $t^{p}$ :

$$
\begin{aligned}
&a_{1} t^{n}+b_{1} t^{p}=x-c_{1}, \\
&a_{2} t^{n}+b_{2} t^{p}=y-c_{2}, \\
&a_{3} t^{n}+b_{3} t^{p}=z-c_{3} .
\end{aligned}
$$

This system admits solutions; hence the extended matrix is singular. We thus have

$$
\left|\begin{array}{lll}
a_{1} & b_{1} & x-c_{1} \\
a_{2} & b_{2} & y-c_{2} \\
a_{3} & b_{3} & y-c_{3}
\end{array}\right|=0 .
$$

This is the equation of a plane that contains the given curve.

(C. Ionescu-Bujor, O. Sacter, Exerciţii şi probleme de geometrie analitica şi diferenţiala (Exercises and problems in analytic and differential geometry), Editura Didactică şi Pedagogică, Bucharest, 1963)

625. Let the equation of the curve be $y(x)$. Let $T(x)$ be the tension in the chain at the point $(x, y(x))$. The tension acts in the direction of the derivative $y^{\prime}(x)$. Let $H(x)$ and $V(x)$ be, respectively, the horizontal and vertical components of the tension. Because the chain is in equilibrium, the horizontal component of the tension is constant at all points of the chain (just cut the chain mentally at two different points). Thus $H(x)=H$. The vertical component of the tension is then $V(x)=H y^{\prime}(x)$. On the other hand, for two infinitesimally close points, the difference in the vertical tension is given by $d V=\rho d s$, where $\rho$ is the density of the chain and $d s$ is the length of the arc between the two poins. Since $d s=\sqrt{1+\left(y^{\prime}(x)\right)^{2}} d x$, it follows that $y$ satisfies the differential equation

$$
H y^{\prime \prime}=\rho \sqrt{1+\left(y^{\prime}\right)^{2}} .
$$

If we set $z(x)=y^{\prime}(x)$, we obtain the separable first-order equation

$$
H z^{\prime}=\rho \sqrt{1+z^{2}} .
$$

By integration, we obtain $z=\sinh \left(\frac{\rho}{H} x+C_{1}\right)$. The answer to the problem is therefore

$$
y(x)=\frac{H}{\rho} \cosh \left(\frac{\rho}{H}+C_{1}\right)+C_{2} .
$$

Remark. Galileo claimed that the curve was a parabola, but this was later proved to be false. The correct equation was derived by G.W. Leibniz, Ch. Huygens, and Johann Bernoulli. The curve is called a "catenary" and plays an important role in the theory of minimal surfaces.

626. An edge adjacent to the main diagonal describes a cone. For an edge not adjacent to the main diagonal, consider an orthogonal system of coordinates such that the rotation axis is the $z$-axis and, in its original position, the edge is parallel to the $y$-plane (Figure 83). In the appropriate scale, the line of support of the edge is $y=1, z=\sqrt{3} x$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-645.jpg?height=526&width=477&top_left_y=1395&top_left_x=629)

Figure 83

The locus of points on the surface of revolution is given in parametric form by

$$
(x, y, z)=(t \cos \theta+\sin \theta, \cos \theta-t \sin \theta, \sqrt{3} t), \quad t \in \mathbb{R}, \quad \theta \in[0,2 \pi) .
$$

A glimpse at these formulas suggests the following computation:

$$
\begin{aligned}
x^{2} &+y^{2}-\frac{1}{3} z^{2} \\
&=t^{2} \cos ^{2} \theta+\sin ^{2} \theta+2 t \sin \theta \cos \theta+\cos ^{2} \theta+t^{2} \sin ^{2} \theta-2 t \cos \theta \sin \theta-t^{2} \\
&=t^{2}\left(\cos ^{2} \theta+\sin ^{2} \theta\right)+\cos ^{2} \theta+\sin ^{2} \theta-t^{2}=1 .
\end{aligned}
$$

The locus is therefore a hyperboloid of one sheet, $x^{2}+y^{2}-\frac{1}{3} z^{3}=1$.

Remark. The fact that the hyperboloid of one sheet is a ruled surface makes it easy to build. It is a more resilient structure than the cylinder. This is why the cooling towers of power plants are built as hyperboloids of one sheet.

627. The equation of the plane tangent to the hyperboloid at a point $M\left(x_{0}, y_{0}, z_{0}\right)$ is

$$
\frac{x_{0} x}{a^{2}}+\frac{y_{0} y}{b^{2}}-\frac{z_{0} z}{c^{2}}=1 .
$$

This plane coincides with the one from the statement if and only if

$$
\frac{\frac{x_{0}}{a^{2}}}{\frac{1}{a}}=\frac{\frac{y_{0}}{b^{2}}}{\frac{1}{b}}=\frac{\frac{z_{0}}{c^{2}}}{\frac{1}{c}} .
$$

We deduce that the point of contact has coordinates $(a, b, c)$, and therefore the given plane is indeed tangent to the hyperboloid.

628. The area of the ellipse given by the equation

$$
\frac{x^{2}}{A^{2}}+\frac{y^{2}}{B^{2}}=R^{2}
$$

is $\pi A B R^{2}$. The section perpendicular to the $x$-axis is the ellipse

$$
\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1-\frac{x_{0}^{2}}{a^{2}}
$$

in the plane $x=x_{0}$. Hence $S_{x}=\pi b c\left(1-\frac{x_{0}^{2}}{a^{2}}\right)$. Similarly, $S_{y}=\pi a c\left(1-\frac{y_{0}^{2}}{b^{2}}\right)$ and $S_{x}=\pi a b\left(1-\frac{z_{0}^{2}}{c^{2}}\right)$. We thus have

$$
a S_{x}+b S_{y}+c S_{z}=\pi a b c\left(3-\frac{x_{0}^{2}}{a^{2}}+\frac{y_{0}^{2}}{b^{2}}+\frac{z_{0}^{2}}{c^{2}}\right)=2 \pi a b c,
$$

which, of course, is independent of $M$.

629. Figure 84 describes a generic ellipsoid. Since parallel cross-sections of the ellipsoid are always similar ellipses, any circular cross-section can be increased in size by taking a 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-647.jpg?height=370&width=472&top_left_y=242&top_left_x=631)

Figure 84

parallel cutting plane passing through the origin. Because of the condition $a>b>c$, a circular cross-section cannot lie in the $x y$-, $x z-$, or $y z$-plane. Looking at the intersection of the ellipsoid with the $y z$-plane, we see that some diameter of the circular cross-section is a diameter (segment passing through the center) of the ellipse $x=0, \frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1$. Hence the radius of the circle is at most $b$. The same argument for the $x y$-plane shows that the radius is at least $b$, whence $b$ is a good candidate for the maximum radius.

To show that circular cross-sections of radius $b$ actually exist, consider the intersection of the plane $\left(c \sqrt{a^{2}-b^{2}}\right) x=\left(a \sqrt{b^{2}-c^{2}}\right) z$ with the ellipsoid. We want to compute the distance from a point $\left(x_{0}, y_{0}, z_{0}\right)$ on this intersection to the origin. From the equation of the plane, we obtain by squaring

$$
x_{0}^{2}+z_{0}^{2}=b^{2}\left(\frac{x_{0}^{2}}{a^{2}}+\frac{z_{0}^{2}}{c^{2}}\right) .
$$

The equation of the ellipsoid gives

$$
y_{0}^{2}=b^{2}\left(1-\frac{x_{0}^{2}}{a^{2}}-\frac{z_{0}^{2}}{c^{2}}\right) .
$$

Adding these two, we obtain $x_{0}^{2}+y_{0}^{2}+z_{0}^{2}=1$; hence $\left(x_{0}, y_{0}, z_{0}\right)$ lies on the circle of radius 1 centered at the origin and contained in the plane $\left(c \sqrt{a^{2}-b^{2}}\right) x+\left(a \sqrt{b^{2}-c^{2}}\right) z=0$. This completes the proof.

(31st W.L. Putnam Mathematical Competition, 1970)

630. Without loss of generality, we may assume $a<b<c$. Fix a point $\left(x_{0}, y_{0}, z_{0}\right)$, and let us examine the equation in $\lambda$,

$$
f(\lambda)=\frac{x_{0}^{2}}{a^{2}-\lambda}+\frac{y_{0}^{2}}{b^{2}-\lambda}+\frac{z_{0}^{2}}{c^{2}-\lambda}-1=0 .
$$

For the function $f(\lambda)$ we have the following table of signs:

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-647.jpg?height=107&width=1243&top_left_y=2083&top_left_x=248)

where $\epsilon$ is a very small positive number. Therefore, the equation $f(\lambda)=0$ has three roots, $\lambda_{1}, \lambda_{2}, \lambda_{3}$, with $\lambda_{1}<a^{2}<\lambda_{2}<b^{2}<\lambda_{3}<c^{2}$. These provide the three surfaces, which are an ellipsoid for $\lambda=\lambda_{1}$ (Figure 84), a hyperboloid of one sheet for $\lambda=\lambda_{2}$, and a hyperboloid of two sheets for $\lambda=\lambda_{3}$ (Figure 85).
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-648.jpg?height=400&width=834&top_left_y=478&top_left_x=448)

Figure 85

To show that the surfaces are pairwise orthogonal we have to compute the angle between the normals at an intersection point. We do this for the roots $\lambda_{1}$ and $\lambda_{2}$, the other cases being similar. The normal to the ellipsoid at a point $(x, y, z)$ is parallel to the vector

$$
\overrightarrow{v_{1}}=\left(\frac{x}{a^{2}-\lambda_{1}}, \frac{y}{b^{2}-\lambda_{1}}, \frac{z}{c^{2}-\lambda_{1}}\right),
$$

while the normal to the hyperboloid of one sheet is parallel to the vector

$$
\overrightarrow{v_{2}}=\left(\frac{x}{a^{2}-\lambda_{2}}, \frac{y}{b^{2}-\lambda_{2}}, \frac{z}{c^{2}-\lambda_{2}}\right) .
$$

The dot product of these vectors is

$$
\overrightarrow{v_{1}} \cdot \overrightarrow{v_{2}}=\frac{x}{a^{2}-\lambda_{1}} \cdot \frac{x}{a^{2}-\lambda_{2}}+\frac{y}{b^{2}-\lambda_{1}} \cdot \frac{y}{b^{2}-\lambda_{2}}+\frac{z}{c^{2}-\lambda_{1}} \cdot \frac{z}{c^{2}-\lambda_{2}} .
$$

To prove that this is equal to 0 , we use the fact that the point $(x, y, z)$ belongs to both quadrics, which translates into the relation

$$
\frac{x^{2}}{a^{2}-\lambda_{1}}+\frac{y^{2}}{b^{2}-\lambda_{1}}+\frac{z^{2}}{c^{2}-\lambda_{1}}=\frac{x^{2}}{a^{2}-\lambda_{2}}+\frac{y^{2}}{b^{2}-\lambda_{2}}+\frac{z^{2}}{c^{2}-\lambda_{2}} .
$$

If we write this as

$$
\left(\frac{x^{2}}{a^{2}-\lambda_{1}}-\frac{x^{2}}{a^{2}-\lambda_{2}}\right)+\left(\frac{y^{2}}{b^{2}-\lambda_{1}}-\frac{y^{2}}{b^{2}-\lambda_{2}}\right)+\left(\frac{z^{2}}{c^{2}-\lambda_{1}}-\frac{z^{2}}{c^{2}-\lambda_{2}}\right)=0,
$$

we recognize immediately the left-hand side to be $\left(\lambda_{1}-\lambda_{2}\right) \overrightarrow{v_{1}} \cdot \overrightarrow{v_{2}}$. We obtain the desired $\overrightarrow{v_{1}} \cdot \overrightarrow{v_{2}}=0$, which proves the orthogonality of the two surfaces. This completes the solution.

(C. Ionescu-Bujor, O. Sacter, Exerciţii şi probleme de geometrie analitica şi diferenţiala (Exercises and problems in analytic and differential geometry), Editura Didactică şi Pedagogică, Bucharest, 1963)

631. Using the algebraic identity

$$
\left(u^{3}+v^{3}+w^{3}-3 u v w\right)=\frac{1}{2}(u+v+w)\left[3\left(u^{2}+v^{2}+w^{2}\right)-(u+v+w)^{2}\right],
$$

we obtain

$$
z-3=\frac{3}{2} x y-\frac{1}{2} x^{3},
$$

or

$$
x^{3}-3 x y+2 z-6=0 .
$$

This is the cubic surface from Figure 86.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-649.jpg?height=429&width=564&top_left_y=1247&top_left_x=590)

Figure 86

(C. Coşniţă, I. Sager, I. Matei, I. Dragotă, Culegere de probleme de Geometrie Analitica (Collection of Problems in Analytical Geometry), Editura Didactică şi Pedagogică, Bucharest, 1963)

632. By the $(2 n+1)$-dimensional version of the Pythagorean theorem, the edge $L$ of the cube is the square root of an integer. The volume of the cube is computed as a determinant in coordinates of vertices; hence it is also an integer. We conclude that $L^{2}$ and $L^{2 n+1}$ are both integers. It follows that $L^{2 n+1} /\left(L^{2}\right)^{n}=L$ is a rational number. Because its square is an integer, $L$ is actually an integer, as desired. 

633. The equation of the locus can be expressed in a simple form using determinants as

$$
\left|\begin{array}{cccc}
x_{1} & x_{2} & \cdots & x_{n} \\
x_{n} & x_{1} & \cdots & x_{n-1} \\
\cdots & \cdots & \ddots & \cdots \\
x_{2} & x_{3} & \cdots & x_{1}
\end{array}\right|=0 .
$$

Adding all rows to the first, we see that the determinant has a factor of $x_{1}+x_{2}+\cdots+x_{n}$. Hence the plane $x_{1}+x_{2}+\cdots+x_{n}=0$ belongs to the locus.

634. Without loss of generality, we may assume that the edges of the cube have length equal to 2 , in which case the cube consists of the points $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ with $\max \left|x_{i}\right| \leq 1$. The intersection of the cube with the plane determined by $\vec{a}$ and $\vec{b}$ is

$$
P=\left\{s \vec{a}+t \vec{b}\left|\max _{k}\right| s \cos \frac{2 k \pi}{n}+t \sin \frac{2 k \pi}{n} \mid \leq 1\right\} .
$$

This set is a convex polygon with at most $2 n$ sides, being the intersection of $n$ strips determined by parallel lines, namely the strips

$$
P_{k}=\left\{s \vec{a}+t \vec{b} \| s \cos \frac{2 k \pi}{n}+t \sin \frac{2 k \pi}{n} \mid \leq 1\right\} .
$$

Adding $\frac{2 \pi}{n}$ to all arguments in the coordinates of $\vec{a}$ and $\vec{b}$ permutes the $P_{k}$ 's, leaving $P$ invariant. This corresponds to the transformation

$$
\begin{aligned}
&\vec{a} \longrightarrow \cos \frac{2 \pi}{n} \vec{a}-\sin \frac{2 \pi}{n} \vec{b}, \\
&\vec{b} \longrightarrow \sin \frac{2 \pi}{n} \vec{a}+\cos \frac{2 \pi}{n} \vec{b},
\end{aligned}
$$

which is a rotation by $\frac{2 \pi}{n}$ in the plane of the two vectors. Hence $P$ is invariant under a rotation by $\frac{2 \pi}{n}$, and being a polygon with at most $2 n$ sides, it must be a regular $2 n$-gon.

(V.V. Prasolov, V.M. Tikhomirov, Geometry, AMS, 2001)

635. Consider the unit sphere in $\mathbb{R}^{n}$,

$$
S^{n-1}=\left\{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in \mathbb{R}^{n} \mid \sum_{k=1}^{n} x_{k}^{2}=1\right\} .
$$

The distance between two points $X=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ and $Y=\left(y_{1}, y_{2}, \ldots, y_{n}\right)$ is given by

$$
d(X, Y)=\left(\sum_{k=1}^{n}\left(x_{k}-y_{k}\right)^{2}\right)^{1 / 2} .
$$

Note that $d(X, Y)>\sqrt{2}$ if and only if

$$
d^{2}(X, Y)=\sum_{k=1}^{n} x_{k}^{2}+\sum_{k=1}^{n} y_{k}^{2}-2 \sum_{k=1}^{n} x_{k} y_{k}>2 .
$$

Therefore, $d(X, Y)>\sqrt{2}$ implies $\sum_{k=1}^{n} x_{k} y_{k}<0$.

Now let $A_{1}, A_{2}, \ldots, A_{m_{n}}$ be points satisfying the condition from the hypothesis, with $m_{n}$ maximal. Using the symmetry of the sphere we may assume that $A_{1}=(-1,0, \ldots, 0)$. Let $A_{i}=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ and $A_{j}=\left(y_{1}, y_{2}, \ldots, y_{n}\right), i, j \geq 2$. Because $d\left(A_{1}, A_{i}\right)$ and $d\left(A_{1}, A_{j}\right)$ are both greater than $\sqrt{2}$, the above observation shows that $x_{1}$ and $y_{1}$ are positive.

The condition $d\left(A_{i}, A_{j}\right)>\sqrt{2}$ implies $\sum_{k=1}^{n} x_{k} y_{k}<0$, and since $x_{1} y_{1}$ is positive, it follows that

$$
\sum_{k=2}^{n} x_{k} y_{k}<0 .
$$

This shows that if we normalize the last $n-1$ coordinates of the points $A_{i}$ by

$$
x_{k}^{\prime}=\frac{x_{k}}{\sqrt{\sum_{k=1}^{n-1} x_{k}^{2}}}, \quad k=1,2, \ldots, n-1,
$$

we obtain the coordinates of point $B_{i}$ in $S^{n-2}$, and the points $B_{2}, B_{3}, \ldots, B_{n}$ satisfy the condition from the statement of the problem for the unit sphere in $\mathbb{R}^{n-1}$.

It follows that $m_{n} \leq 1+m_{n-1}$, and $m_{1}=2$ implies $m_{n} \leq n+1$. The example of the $n$-dimensional regular simplex inscribed in the unit sphere shows that $m_{n}=n+1$. To determine explicitly the coordinates of the vertices, we use the additional information that the distance from the center of the sphere to a hyperface of the $n$-dimensional simplex is $\frac{1}{n}$ and then find inductively

$$
\begin{aligned}
A_{1} &=(-1,0,0,0, \ldots, 0,0), \\
A_{2} &=\left(\frac{1}{n},-c_{1}, 0,0, \ldots, 0,0\right), \\
A_{3} &=\left(\frac{1}{n}, \frac{1}{n-1} \cdot c_{1},-c_{2}, 0, \ldots, 0,0\right), \\
A_{4} &=\left(\frac{1}{n}, \frac{1}{n-1} \cdot c_{1}, \frac{1}{n-2} \cdot c_{2}, c_{3}, \ldots, 0,0\right), \\
& \ldots \\
A_{n-1} &=\left(\frac{1}{n}, \frac{1}{n-1} \cdot c_{1}, \ldots, \frac{1}{3} \cdot c_{n-3},-c_{n-2}, 0\right),
\end{aligned}
$$



$$
\begin{aligned}
A_{n} &=\left(\frac{1}{n}, \frac{1}{n-1} \cdot c_{1}, \ldots, \frac{1}{3} \cdot c_{n-3}, \frac{1}{2} \cdot c_{n-2},-c_{n-1}\right) \\
A_{n+1} &=\left(\frac{1}{n}, \frac{1}{n-1} \cdot c_{1}, \ldots, \frac{1}{3} \cdot c_{n-3}, \frac{1}{2} \cdot c_{n-2}, c_{n-1}\right)
\end{aligned}
$$

where

$$
c_{k}=\sqrt{\left(1+\frac{1}{n}\right)\left(1-\frac{1}{n-k+1}\right)}, \quad k=1,2, \ldots, n-1
$$

One computes that the distance between any two points is

$$
\sqrt{2} \sqrt{1+\frac{1}{n}}>\sqrt{2}
$$

and the problem is solved.

(8th International Mathematics Competition for University Students, 2001)

636. View the ring as the body obtained by revolving about the $x$-axis the surface that lies between the graphs of $f, g:[-h / 2, h / 2] \rightarrow \mathbb{R}, f(x)=\sqrt{R^{2}-x^{2}}, g(x)=$ $\sqrt{R^{2}-h^{2} / 4}$. Here $R$ denotes the radius of the sphere. Using the washer method we find that the volume of the ring is

$$
\pi \int_{-h / 2}^{h / 2}\left(\sqrt{R^{2}-x^{2}}\right)^{2}-\left(\sqrt{R^{2}-h^{2} / 4}\right)^{2} d x=\pi \int_{-h / 2}^{h / 2}\left(h^{2} / 4-x^{2}\right) d x=\frac{h^{3} \pi}{12},
$$

which does not depend on $R$.

637. Let the inscribed sphere have radius $R$ and center $O$. For each big face of the polyhedron, project the sphere onto the face to obtain a disk $D$. Then connect $D$ with $O$ to form a cone. Because the interiors of the cones are pairwise disjoint, the cones intersect the sphere in several nonoverlapping regions. Each circular region is a slice of the sphere, of width $R\left(1-\frac{1}{2} \sqrt{2}\right)$. Recall the lemma used in the solution to the first problem from the introduction. We apply it to the particular case in which one of the planes is tangent to the sphere to find that the area of a slice is $2 \pi R^{2}\left(1-\frac{1}{2} \sqrt{2}\right)$, and this is greater than $\frac{1}{7}$ of the sphere's surface. Thus each circular region takes up more than $\frac{1}{7}$ of the total surface area of the sphere. So there can be at most six big faces.

(Russian Mathematical Olympiad, 1999)

638. Keep the line of projection fixed, for example the $x$-axis, and rotate the segments in $A$ and $B$ simultaneously.

Now, given a segment with one endpoint at the origin, the length of its projection onto the $z$-axis is $r|\cos \phi|$, where $(r, \theta, \phi)$ are the spherical coordinates of the second endpoint, i.e., $r$ is the length of the segment, $\phi$ is the angle it makes with the semiaxis $O z$, and $\theta$ is the oriented angle that its projection onto the $x y$-plane makes with $O x$. If we average the lengths of the projections onto the $x$-axis of the segment over all possible rotations, we obtain

$$
\frac{1}{4 \pi} \int_{0}^{\pi} \int_{0}^{2 \pi} r|\cos \phi| \sin \phi d \theta d \phi=\frac{r}{2} .
$$

Denote by $a$ and $b$ the sums of the lengths of the segments in $A$ and $B$, respectively. Then the average of the sum of the lengths of the projections of segments in $A$ is $\frac{r}{2} a$, and the average of the same sum for $B$ is $\frac{r}{2} b$. The second is smaller, proving that there exists a direction such that the sum of the lengths of the projections of the segments from $A$ onto that direction is larger that the corresponding sum for $B$.

639. This is just a two-dimensional version of the previous problem. If we integrate the length of the projection of a segment onto a line over all directions of the line, we obtain twice the length of the segment. Doing this for the sides of a convex polygon, we obtain the perimeter (since the projection is double covered by the polygon). Because the projection of the inner polygon is always smaller than the projection of the outer, the same inequality will hold after integration. Hence the conclusion.

640. For $i=1,2, \ldots, n$, let $a_{i}$ be the lengths of the segments and let $\phi_{i}$ be the angles they make with the positive $x$-axis $\left(0 \leq \phi_{i} \leq \pi\right)$. The length of the projection of $a_{i}$ onto some line that makes an angle $\phi$ with the $x$-axis is $f_{i}(\phi)=a_{i}\left|\cos \left(\phi-\phi_{i}\right)\right|$; denote by $f(\phi)$ the sum of these lengths. The integral mean of $f$ over the interval $[0, \pi]$ is

$$
\begin{aligned}
\frac{1}{\pi} \int_{0}^{\pi} f(\phi) d \phi &=\frac{1}{\pi} \sum_{i=1}^{n} \int_{0}^{\pi} f_{i}(\phi) d \phi \\
&=\frac{1}{\pi} \sum_{i=1}^{n} a_{i} \int_{0}^{\pi}\left|\cos \left(\phi-\phi_{i}\right)\right| d \phi=\frac{2}{\pi} \sum_{i=1}^{n} a_{i}=\frac{2}{\pi} .
\end{aligned}
$$

Here we used the fact that $|\cos x|$ is periodic with period $\pi$. Since the integral mean of $f$ is $\frac{2}{\pi}$ and since $f$ is continuous, by the intermediate value property there exists an angle $\phi$ for which $f(\phi)=\frac{2}{\pi}$. This completes the proof.

641. The law of cosines in triangle $A P B$ gives

$$
A P^{2}=x^{2}+c^{2}-2 x c \cos B
$$

and

$$
x^{2}=c^{2}+A P^{2}=x^{2}+c^{2}-2 x c \cos B-2 c \sqrt{x^{2}+c^{2}-2 x c \cos B} \cos t,
$$

whence 

$$
\cos t=\frac{c-x \cos B}{\sqrt{x^{2}+c^{2}-2 x c \cos B}}
$$

The integral from the statement is

$$
\int_{0}^{a} \cos t(x) d x=\int_{0}^{a} \frac{c-x \cos B}{\sqrt{x^{2}+c^{2}-2 x c \cos B}} d x
$$

Using the standard integration formulas

$$
\begin{aligned}
&\int \frac{d x}{\sqrt{x^{2}+\alpha x+\beta}}=\ln \left(2 x+\alpha+2 \sqrt{x^{2}+\alpha x+\beta}\right) \\
&\int \frac{x d x}{\sqrt{x^{2}+\alpha x+\beta}}=\sqrt{x^{2}+\alpha x+\beta}-\frac{\alpha}{2} \ln \left(2 x+\alpha+2 \sqrt{x^{2}+\alpha x+\beta}\right)
\end{aligned}
$$

we obtain

$$
\begin{aligned}
\int_{0}^{a} \cos t(x) d x=&\left.c \sin ^{2} B \ln \left(2 x+2 c \cos B+2 \sqrt{x^{2}-2 c x \cos B+c^{2}}\right)\right|_{0} ^{a} \\
&-\left.\cos B \sqrt{x^{2}-2 c x \cos B+c^{2}}\right|_{0} ^{a} \\
=& c \sin ^{2} B \ln \frac{a-c \cos B+b}{c(1-\cos B)}+\cos B(c-b)
\end{aligned}
$$

642. It is equivalent to ask that the volume of the dish be half of that of the solid of revolution obtained by rotating the rectangle $0 \leq x \leq a$ and $0 \leq y \leq f(a)$. Specifically, this condition is

$$
\int_{0}^{a} 2 \pi x f(x) d x=\frac{1}{2} \pi a^{2} f(a)
$$

Because the left-hand side is differentiable with respect to $a$ for all $a>0$, the right-hand side is differentiable, too. Differentiating, we obtain

$$
2 \pi a f(a)=\pi a f(a)+\frac{1}{2} \pi a^{2} f^{\prime}(a) .
$$

This is a differential equation in $f$, which can be written as $f^{\prime}(a) / f(a)=\frac{2}{a}$. Integrating, we obtain $\ln f(a)=2 \ln a$, or $f(a)=c a^{2}$ for some constant $c>0$. This solves the problem.

\section{(Math Horizons)}

643. Parametrize the curve by its length as $(x(s), y(s), z(s)), 0 \leq s \leq L$. Then the coordinates $(\xi, \eta, \zeta)$ of its spherical image are given by 

$$
\xi=\frac{d x}{d s}, \quad \eta=\frac{d y}{d s}, \quad \zeta=\frac{d z}{d s}
$$

The fact that the curve is closed simply implies that

$$
\int_{0}^{L} \xi d s=\int_{0}^{L} \eta d s=\int_{0}^{L} \zeta d s=0
$$

Pick an arbitrary great circle of the unit sphere, lying in some plane $\alpha x+\beta y+\gamma z=0$. To show that the spherical image of the curve intersects the circle, it suffices to show that it intersects the plane. We compute

$$
\int_{0}^{L}(\alpha \xi+\beta \eta+\gamma \zeta) d s=0
$$

which implies that the continuous function $\alpha \xi+\beta \eta+\gamma \zeta$ vanishes at least once (in fact, at least twice since it takes the same value at the endpoints of the interval). The equality

$$
\alpha \xi(s)+\beta \eta(x)+\gamma \zeta(s)=0
$$

is precisely the condition that $(\xi(s), \eta(x), \zeta(s))$ is in the plane. The problem is solved.

Remark. The spherical image of a curve was introduced by Gauss.

(K. Löwner)

644. We use Löwner's theorem, which was the subject of the previous problem. The total curvature is the length of the spherical image of the curve. In view of Löwner's theorem, it suffices to show that a curve $\gamma(t)$ that intersects every great circle of the unit sphere has length at least $2 \pi$.

For each $t$, let $H_{t}$ be the hemisphere centered at $\gamma(t)$. The fact that the curve intersects every great circle implies that the union of all the $H_{t}$ 's is the entire sphere. We prove the conclusion under this hypothesis. Let us analyze how the covered area adds up as we travel along the curve. Looking at Figure 87, we see that as we add to a hemisphere $H_{t_{0}}$ the hemisphere $H_{t_{1}}$, the covered surface increases by the portion of the sphere contained within the dihedral angle formed by two planes. The area of such a "wedge"' is directly proportional to the length of the arc of the great circle passing through $\gamma\left(t_{0}\right)$ and $\gamma\left(t_{1}\right)$. When the arc is the whole great circle the area is $4 \pi$, so in general, the area is numerically equal to twice the length of the arc. This means that as we move along the curve from $t$ to $t+\Delta t$, the covered area increases by at most $2\left\|\gamma^{\prime}(t)\right\|$. So after we have traveled along the entire curve, the covered area has increased by at most $2 \int_{C}\left\|\gamma^{\prime}(t)\right\| d t(C$ denotes the curve). For the whole sphere, we should have $2 \int_{C}\left\|\gamma^{\prime}(t)\right\| d t \geq 4 \pi$. This implies that the length of the spherical image, which is equal to $\int_{C}\left\|\gamma^{\prime}(t)\right\| d t$, is at least $2 \pi$, as desired. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-656.jpg?height=386&width=386&top_left_y=259&top_left_x=679)

Figure 87

Remark. More is true, namely that the total curvature is equal to $2 \pi$ if and only if the curve is planar and convex. A result of Milnor and Fáry shows that the total curvature of a knotted curve in space exceeds $4 \pi$.

(W. Fenchel)

645. Consider a coordinate system with axes parallel to the sides of $R$ (and hence to the sides of all rectangles of the tiling). It is not hard to see that if $D=[a, b] \times[c, d]$ is a rectangle whose sides are parallel to the axes, then the four integrals

$$
\begin{array}{ll}
\iint_{D} \sin 2 \pi x \sin 2 \pi y d x d y, & \iint_{D} \sin 2 \pi x \cos 2 \pi y d x d y, \\
\iint_{D} \cos 2 \pi x \sin 2 \pi y d x d y, & \iint_{D} \cos 2 \pi x \cos 2 \pi y d x d y
\end{array}
$$

are simultaneously equal to zero if and only if either $b-a$ or $d-c$ is an integer. Indeed, this is equivalent to the fact that

$$
\begin{aligned}
(\cos 2 \pi b-\cos 2 \pi a)(\cos 2 \pi d-\cos 2 \pi c) &=0, \\
(\cos 2 \pi b-\cos 2 \pi a)(\sin 2 \pi d-\sin 2 \pi c) &=0, \\
(\sin 2 \pi b-\sin 2 \pi a)(\cos 2 \pi d-\cos 2 \pi c) &=0, \\
(\sin 2 \pi b-\sin 2 \pi a)(\sin 2 \pi d-\sin 2 \pi c) &=0,
\end{aligned}
$$

and a case check shows that either $\cos 2 \pi b=\cos 2 \pi a$ and $\sin 2 \pi b=\sin 2 \pi a$, or $\cos 2 \pi d=\cos 2 \pi c$ and $\sin 2 \pi d=\sin 2 \pi c$, which then implies that either $a$ and $b$ or $c$ and $d$ differ by an integer. Because the four integrals are zero on each rectangle of the tiling, by adding they are zero on $R$. Hence at least one of the sides of $R$ has integer length.

(short list of the 30th International Mathematical Olympiad, 1989, proposed by France)

646. We denote by $A(X Y Z)$ the area of triangle $X Y Z$. Look first at the degenerate situation described in Figure 88, when $P$ is on one side of the triangle. With the notation 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-657.jpg?height=314&width=513&top_left_y=261&top_left_x=611)

Figure 88

from that figure, we have

$$
\frac{A(B M P)}{A(A B C)}=\left(\frac{B P}{B C}\right)^{2} \text { and } \frac{A(C N P)}{A(A B C)}=\left(\frac{P C}{B C}\right)^{2} .
$$

Adding up, we obtain

$$
\frac{A(B M P)+A(C N P)}{A(A B C)}=\frac{B P^{2}+P C^{2}}{(B P+P C)^{2}} \geq \frac{1}{2} .
$$

The last inequality follows from the AM-GM inequality: $B P^{2}+P C^{2} \geq 2 B P \cdot P C$. Note that in the degenerate case the inequality is even stronger, with $\frac{1}{3}$ replaced by $\frac{1}{2}$.

Let us now consider the general case, with the notation from Figure 89. By what we just proved, we know that the following three inequalities hold:

$$
\begin{aligned}
S_{1}+S_{2} & \geq \frac{1}{2} A\left(A_{1} B_{2} C\right), \\
S_{1}+S_{3} & \geq \frac{1}{2} A\left(A_{2} B C_{1}\right), \\
S_{2}+S_{3} & \geq \frac{1}{2} A\left(A B_{1} C_{2}\right) .
\end{aligned}
$$

Adding them up, we obtain

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-657.jpg?height=387&width=508&top_left_y=1731&top_left_x=613)

Figure 89 

$$
2 S_{1}+2 S_{2}+2 S_{3} \geq \frac{1}{2}\left(A(A B C)+S_{1}+S_{2}+S_{3}\right) .
$$

The inequality follows.

(M. Pimsner, S. Popa, Probleme de geometrie elementară (Problems in elementary geometry), Editura Didactică şi Pedagogică, Bucharest, 1979)

647. Assume that the two squares do not overlap. Then at most one of them contains the center of the circle. Take the other square. The line of support of one of its sides separates it from the center of the circle. Looking at the diameter parallel to this line, we see that the square is entirely contained in a half-circle, in such a way that one of its sides is parallel to the diameter. Translate the square to bring that side onto the diameter, then translate it further so that the center of the circle is the middle of the side (see Figure 90).
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-658.jpg?height=314&width=1108&top_left_y=829&top_left_x=316)

Figure 90

The square now lies inside another square with two vertices on the diameter and two vertices on the circle. From the Pythagorean theorem compute the side of the larger square to be $\sqrt{\frac{4}{5}}$. This is smaller than $0.9$, a contradiction. Therefore, the original squares overlap.

(R. Gelca)

648. The Möbius band crosses itself if the generating segments at two antipodal points of the unit circle intersect. Let us analyze when this can happen. We refer everything to Figure 91. By construction, the generating segments at the antipodal points $M$ and $N$ are perpendicular. Let $P$ be the intersection of their lines of support. Then the triangle $M N P$ is right, and its acute angles are $\frac{\alpha}{2}$ and $\frac{\pi}{2}-\frac{\alpha}{2}$. The generating segments intersect if they are longer than twice the longest leg of this triangle. The longest leg of this triangle attains its shortest length when the triangle is isosceles, in which case its length is $\sqrt{2}$. We conclude that the maximal length that the generating segment of the Möbius band can have so that the band does not cross itself is $2 \sqrt{2}$.

649. Comparing the perimeters of $A O B$ and $B O C$, we find that $\|A B\|+\|A O\|=$ $\|C B\|+\|C O\|$, and hence $A$ and $C$ belong to an ellipse with foci $B$ and $O$. The same argument applied to triangles $A O D$ and $C O D$ shows that $A$ and $C$ belong to an ellipse with foci $D$ and $O$. The foci of the two ellipses are on the line $B C$; hence the ellipses are symmetric with respect to this line. It follows that $A$ and $C$ are symmetric with respect 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-659.jpg?height=424&width=619&top_left_y=242&top_left_x=558)

Figure 91

to $B C$, hence $A B=B C$ and $A D=D C$. Exchanging the roles of $A$ and $C$ with $B$ and $D$, we find that $A B=A D$ and $B C=C D$. Therefore, $A B=B C=C D=D E$ and the quadrilateral is a rhombus.

The property is no longer true if $O$ is not the intersection of the diagonals. A counterexample consists of a quadrilateral with $A B=B C=3, B C=C D=4, B D=5$, and $O$ on $B D$ such that $O B=3$ and $O D=2$.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1978, proposed by L. Panaitopol)

650. Assume by way of contradiction that the interiors of finitely many parabolas cover the plane. The intersection of a line with the interior of a parabola is a half-line if that line is parallel to the axis of the parabola, and it is void or a segment otherwise. There is a line that is not parallel to the axis of any parabola. The interiors of the parabolas cover the union of finitely many segments on this line, so they do not cover the line entirely. Hence the conclusion.

651. Without loss of generality, we may assume that $A C=1$, and let as usual $A B=c$. We have

$$
B C^{2}=A B^{2}+A C^{2}-2 A B \cdot A C \cos \angle B A C \geq A B^{2}+A C^{2}-A B=c^{2}+1-c,
$$

because $\angle B A C \geq 60^{\circ}$. On the other hand,

$$
C D^{2}=A C^{2}+A D^{2}-2 A C \cdot A D \cos \angle C A D \geq 1+c^{6}+c^{3},
$$

because $\angle C A D \leq 120^{\circ}$. We are left to prove the inequality

$$
c^{6}+c^{3}+1 \leq 3\left(c^{2}-c+1\right)^{3},
$$

which, after dividing both sides by $c^{3}>0$, takes the form

$$
c^{3}+1+\frac{1}{c^{3}} \leq 3\left(c-1+\frac{1}{c}\right)^{3} .
$$

With the substitution $c+\frac{1}{c}=x$, the inequality becomes

$$
x^{3}-3 x+1 \leq 3(x-1)^{3}, \quad \text { for } x \geq 2 .
$$

But this reduces to

$$
(x-2)^{2}(2 x-1) \geq 0,
$$

which is clearly true. Equality holds if and only if $\angle A=60^{\circ}$ and $c=1(A B=A C)$, i.e., when the triangle $A B C$ is equilateral.

(proposed by T. Andreescu for the USA Mathematical Olympiad, 2006)

652. Denote by $a, b, c, d, e, f, g, h$ the lengths of the sides of the octagon. Its angles are all equal to $135^{\circ}$ (see Figure 92). If we project the octagon onto a line perpendicular to side $d$, we obtain two overlapping segments. Writing the equality of their lengths, we obtain

$$
a \frac{\sqrt{2}}{2}+b+c \frac{\sqrt{2}}{2}=e \frac{\sqrt{2}}{2}+f+g \frac{\sqrt{2}}{2} .
$$

Because $a, b, c, e, f, g$ are rational, equality can hold only if $b=f$. Repeating the argument for all sides, we see that the opposite sides of the octagon have equal length. The opposite sides are also parallel. This means that any two consecutive main diagonals intersect at their midpoints, so all main diagonals intersect at their midpoints. The common intersection is the center of symmetry.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-660.jpg?height=405&width=384&top_left_y=1338&top_left_x=680)

Figure 92

653. Let us assume that the three diagonals do not intersect. Denote by $M$ the intersection of $A D$ with $C F$, by $N$ the intersection of $B E$ with $C F$, and by $P$ the intersection of $A D$ with $B E$. There are two possibilities: either $M$ is between $A$ and $P$, or $P$ is between $A$ and $M$. We discuss only the first situation, shown in Figure 93 , and leave the second, which is analogous, to the reader.

Let $A(x)$ denote the area of the polygon $x$. From $A(B C D E)=A(A B E F)$ it follows that 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-661.jpg?height=314&width=330&top_left_y=241&top_left_x=702)

Figure 93

$$
A(E P D)+A(N P D C)+A(B N C)=A(E N F)+A(A M F)+A(M N B A) .
$$

Adding $A(M N P)$ to both sides, we obtain

$$
A(E P D)+A(D M C)+A(B N C)=A(E N F)+A(A M F)+A(A P B) .
$$

Writing the other two similar relations and then subtracting these relations two by two, we obtain

$$
A(A M F)=A(D M C), \quad A(A P B)=A(E P D), \quad A(B N C)=A(E N F) .
$$

The equality $A(A M F)=A(D M C)$ implies that $M F \cdot M A \cdot \sin \angle A M F=M C \cdot M D$. $\sin \angle C M D$, hence $M F \cdot M A=M C \cdot M D$. Similarly, $B N \cdot C N=E N \cdot F N$ and $A P \cdot B P=D P \cdot E P$. If we write $A M=a, A P=\alpha, B N=b, B P=\beta, C N=c$, $C M=\gamma, D P=d, D M=\delta, E P=e, E N=\eta, F M=f, F N=\phi$, then

$$
\frac{a}{\delta}=\frac{\gamma}{f}, \quad \frac{b}{\eta}=\frac{\phi}{c}, \quad \frac{e}{\beta}=\frac{\alpha}{d} .
$$

Also, any Latin letter is smaller than the corresponding Greek letter. Hence

$$
\frac{a}{\delta}=\frac{\gamma}{f}>\frac{c}{\phi}=\frac{\eta}{b}>\frac{e}{\beta}=\frac{\alpha}{d}>\frac{a}{\delta} .
$$

This is a contradiction. The study of the case in which $P$ is between $A$ and $M$ yields a similar contradiction, since $M$ is now between $D$ and $P$, and $D$ can take the role of $A$ above, showing that the three main diagonals must intersect.

\section{(Revista Matematică din Timişoara (Timişoara Mathematics Gazette))}

654. (a) Define $f: \mathbb{Z} \rightarrow[0,1), f(x)=x \sqrt{3}-\lfloor x \sqrt{3}\rfloor$. By the pigeonhole principle, there exist distinct integers $x_{1}$ and $x_{2}$ such that $\left|f\left(x_{1}\right)-f\left(x_{2}\right)\right|<0.001$. Set $a=\left|x_{1}-x_{2}\right|$. Then the distance either between $(a, a \sqrt{3})$ and $(a,\lfloor a \sqrt{3}\rfloor)$ or between $(a, a \sqrt{3})$ and $(a,\lfloor a \sqrt{3}\rfloor+1)$ is less than $0.001$. Therefore, the points $(0,0),(2 a, 0),(a, a \sqrt{3})$ lie in different disks and form an equilateral triangle.

(b) Suppose that $P^{\prime} Q^{\prime} R^{\prime}$ is an equilateral triangle of side $l \leq 96$, whose vertices $P^{\prime}, Q^{\prime}, R^{\prime}$ lie in disks with centers $P, Q, R$, respectively. Then 

$$
l-0.002 \leq P Q, P R, R P \leq l+0.002 .
$$

On the other hand, since there is no equilateral triangle whose vertices have integer coordinates, we may assume that $P Q \neq Q R$. Therefore,

$$
\begin{aligned}
\left|P Q^{2}-Q R^{2}\right| &=(P Q+Q R)|P Q-Q R| \\
& \leq((l+0.002)+(l+0.002))((l+0.002)-(l-0.002)) \\
& \leq 2 \times 96.002 \times 0.004<1 .
\end{aligned}
$$

However, $P Q^{2}-Q R^{2}$ is an integer. This contradiction proves the claim.

(short list of the 44th International Mathematical Olympiad, 2003)

655. Imagine instead that the figure is fixed and the points move on the cylinder, all rigidly linked to each other. Let $P$ be one of the $n$ points; when another point traces $S$, $P$ itself will trace a figure congruent to $S$. So after all the points have traced $S, P$ alone has traced a surface $F$ of area strictly less than $n$.

On the other hand, if we rotate $P$ around the cylinder or translate it back and forth by $\frac{n}{4 \pi r}$, we trace a surface of area exactly equal to $n$. Choose on this surface a point $P^{\prime}$ that does not lie in $F$, and consider the transformation that maps $P$ to $P^{\prime}$. The fact that $P^{\prime}$ is not in $F$ means that at this moment none of the points lies in $S$. This transformation, therefore, satisfies the required condition.

(M. Pimsner, S. Popa, Probleme de geometrie elementară (Problems in elementary geometry), Editura Didactică şi Pedagogică, Bucharest, 1979)

656. The left-hand side is equal to

$$
\begin{aligned}
\cos 20^{\circ} \sin 40^{\circ}-\sin 10^{\circ} \cos 10^{\circ} &=2 \sin 20^{\circ} \cos ^{2} 20^{\circ}-\frac{\sin 20^{\circ}}{2} \\
&=\frac{1}{2}\left(3 \sin 20^{\circ}-4 \sin ^{3} 20^{\circ}\right)=\frac{1}{2} \sin 60^{\circ}=\frac{\sqrt{3}}{4} .
\end{aligned}
$$

(Romanian Mathematical Olympiad, 1967, proposed by C. Ionescu-Tुiu)

657. Because $-\frac{\pi}{2}<-1 \leq \sin x \leq 1<\frac{\pi}{2}, \cos (\sin x)>0$. Hence $\sin (\cos x)>0$, and so $\cos x>0$. So the only possible solutions can lie in the interval $\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$. Note that if $x$ is a solution, then $-x$ is also a solution; thus we can restrict our attention to the first quadrant. Rewrite the equation as

$$
\sin (\cos x)=\sin \left(\frac{\pi}{2}-\sin x\right) .
$$

Then $\cos x=\frac{\pi}{2}-\sin x$, and so $\sin x+\cos x=\frac{\pi}{2}$. This equality cannot hold, since the range of the function $f(x)=\sin x+\cos x=\sqrt{2} \cos \left(\frac{\pi}{4}-x\right)$ is $[-\sqrt{2}, \sqrt{2}]$, and $\frac{\pi}{2}>\sqrt{2}$ 

658. The relation from the statement can be transformed into

$$
\tan ^{2} b=\frac{\tan ^{2} a+1}{\tan ^{2} a-1}=-\frac{1}{\cos 2 a} .
$$

This is further equivalent to

$$
\frac{\sin ^{2} b}{1-\sin ^{2} b}=\frac{1}{2 \sin ^{2} a-1} .
$$

Eliminating the denominators, we obtain

$$
2 \sin ^{2} a \sin ^{2} b=1,
$$

which gives the desired $\sin a \sin b=\pm \frac{\sqrt{2}}{2}=\pm \sin 45^{\circ}$.

(Romanian Mathematical Olympiad, 1959)

659. We have

$$
\begin{aligned}
f(x) &=\sin x \cos x+\sin x+\cos x+1=\frac{1}{2}(\sin x+\cos x)^{2}-\frac{1}{2}+\sin x+\cos x+1 \\
&=\frac{1}{2}\left[(\sin x+\cos x)^{2}+2(\sin x+\cos x)+1\right]=\frac{1}{2}[(\sin x+\cos x)+1]^{2} .
\end{aligned}
$$

This is a function of $y=\sin x+\cos x$, namely $f(y)=\frac{1}{2}(y+1)^{2}$. Note that

$$
y=\cos \left(\frac{\pi}{2}-x\right)+\cos x=2 \cos \frac{\pi}{4} \cos \left(x-\frac{\pi}{4}\right)=\sqrt{2} \cos \left(x-\frac{\pi}{4}\right) .
$$

So $y$ ranges between $-\sqrt{2}$ and $\sqrt{2}$. Hence $f(y)$ ranges between 0 and $\frac{1}{2}(\sqrt{2}+1)^{2}$.

660. Relate the secant and the cosecant to the tangent and cotangent:

$$
\sec ^{2} x=\tan ^{2} x+1 \geq 2 \tan x \quad \text { and } \quad \csc ^{2} x=\cot ^{2} x+1 \geq 2 \cot x,
$$

where the inequalities come from the most particular case of AM-GM. It follows that

$$
\sec ^{2 n} x+\csc ^{2 n} x \geq 2^{n}\left(\tan ^{n} x+\cot ^{n} x\right) .
$$

Now observe that

$$
\tan ^{n} x+\cot ^{n} x=\tan ^{n} x+\frac{1}{\tan ^{n} x} \geq 2,
$$

again by the AM-GM inequality. We obtain

$$
\sec ^{2 n} x+\csc ^{2 n} x \geq 2^{n+1},
$$

as desired.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by D. Andrica)

661. We would like to eliminate the square root, and for that reason we recall the trigonometric identity

$$
\frac{1-\sin t}{1+\sin t}=\frac{\cos ^{2} t}{(1+\sin t)^{2}} .
$$

The proof of this identity is straightforward if we express the cosine in terms of the sine and then factor the numerator. Thus if we substitute $x=\sin t$, then $d x=\cos t d t$ and the integral becomes

$$
\int \frac{\cos ^{2} t}{1+\sin t} d t=\int 1-\sin t d t=t+\cos t+C .
$$

Since $t=\arcsin x$, this is equal to $\arcsin x+\sqrt{1-x^{2}}+C$.

(Romanian high school textbook)

662. We will prove that a function of the form $f(x, y)=\cos (a x+b y), a, b$ integers, can be written as a polynomial in $\cos x, \cos y$, and $\cos (x+k y)$ if and only if $b$ is divisible by $k$.

For example, if $b=k$, then from

$$
\cos (a x+k y)=2 \cos x \cos ((a \pm 1) x+k y)-\cos ((a \pm 2) x+k y),
$$

we obtain by induction on the absolute value of $a$ that $\cos (a x+b y)$ is a polynomial in $\cos x, \cos y, \cos (x+k y)$. In general, if $b=c k$, the identity

$$
\cos (a x+c k y)=2 \cos y \cos (a x+(c \pm 1) k y)-\cos (a x+(c \pm 2) k y)
$$

together with the fact that $\cos a x$ is a polynomial in $\cos x$ allows an inductive proof of the fact that $\cos (a x+b y)$ can be written as a polynomial in $\cos x, \cos y$, and $\cos (x+k y)$ as well.

For the converse, note that by using the product-to-sum formula we can write any polynomial in cosines as a linear combination of cosines. We will prove a more general statement, namely that if a linear combination of cosines is a polynomial in $\cos x, \cos y$, and $\cos (x+k y)$, then it is of the form

$$
\sum_{m}\left[b_{m} \cos m x+\sum_{0 \leq q<|p|} c_{m, p, q}(\cos (m x+(p k+q) y)+\cos (m x+(p k-q) y))\right] \text {. }
$$

This property is obviously true for polynomials of degree one, since any such polynomial is just a linear combination of the three functions. Also, any polynomial in $\cos x, \cos y, \cos (x+k y)$ can be obtained by adding polynomials of lower degrees, and eventually multiplying them by one of the three functions.

Hence it suffices to show that the property is invariant under multiplication by $\cos x, \cos y$, and $\cos (x+k y)$. It can be verified that this follows from

$$
\begin{aligned}
2 \cos (a x+b y) \cos x &=\cos ((a+1) x+b y)+\cos ((a-1) x+b y) \\
2 \cos (a x+b y) \cos y &=\cos (a x+(b+1) y)+\cos (a x+(b-1) y) \\
2 \cos (a x+b y) \cos (x+k y) &=\cos ((a+1) x+(b+k) y)+\cos (a-1) x+(b-k) y)
\end{aligned}
$$

So for $\cos (a x+b y)$ to be a polynomial in $\cos x, \cos y$, and $\cos (x+k y)$, it must be such a sum with a single term. This can happen only if $b$ is divisible by $k$.

The answer to the problem is therefore $k=\pm 1, \pm 3, \pm 9, \pm 11, \pm 33, \pm 99$.

(proposed by R. Gelca for the USA Mathematical Olympiad, 1999)

663. Clearly, this problem is about the addition formula for the cosine. For it to show up we need products of sines and cosines, and to obtain them it is natural to square the relations. Of course, we first separate $a$ and $d$ from $b$ and $c$. We have

$$
\begin{aligned}
(2 \cos a+9 \cos d)^{2} &=(6 \cos b+7 \cos c)^{2}, \\
(2 \sin a-9 \sin d)^{2} &=(6 \sin b-7 \sin c)^{2} .
\end{aligned}
$$

This further gives

$$
\begin{aligned}
4 \cos ^{2} a+36 \cos a \cos d+81 \cos ^{2} d &=36 \cos ^{2} b+84 \cos b \cos c+49 \cos c^{2}, \\
4 \sin ^{2} a-36 \sin a \sin d+81 \sin ^{2} d &=36 \sin ^{2} b-84 \sin b \sin c+49 \sin c^{2} .
\end{aligned}
$$

After adding up and using $\sin ^{2} x+\cos ^{2} x=1$, we obtain

$$
85+36(\cos a \cos d-\sin a \sin d)=85+84(\cos b \cos c-\sin b \sin c) .
$$

Hence $3 \cos (a+d)=7 \cos (b+c)$, as desired.

(Korean Mathematics Competition, 2002, proposed by T. Andreescu)

664. The first equality can be written as

$$
\sin ^{3} a+\cos ^{3} a+\left(-\frac{1}{5}\right)^{3}-3(\sin a)(\cos a)\left(-\frac{1}{5}\right)=0 .
$$

We have seen before that the expression $x^{3}+y^{3}+z^{3}-3 x y z$ factors as

$$
\frac{1}{2}(x+y+z)\left[(x-y)^{2}+(y-z)^{2}+(z-x)^{2}\right] .
$$

Here $x=\sin a, y=\cos a, z=-\frac{1}{5}$. It follows that either $x+y+z=0$ or $x=y=z$. The latter would imply $\sin a=\cos a=-\frac{1}{5}$, which violates the identity $\sin ^{2} a+\cos ^{2} a=1$. Hence $x+y+z=0$, implying $\sin a+\cos a=\frac{1}{5}$. Then $5(\sin a+\cos a)=1$, and so

$$
\sin ^{2} a+2 \sin a \cos a+\cos ^{2} a=\frac{1}{25} .
$$

It follows that $1+2 \sin a \cos a=0.04$; hence

$$
5(\sin a+\cos a)+2 \sin a \cos a=0.04,
$$

as desired.

Conversely,

$$
5(\sin a+\cos a)+2 \sin a \cos a=0.04
$$

implies

$$
125(\sin a+\cos a)=1-50 \sin a \cos a .
$$

Squaring both sides and setting $2 \sin a \cos a=b$ yields

$$
125^{2}+125^{2} b=1-50 b+25^{2} b^{2},
$$

which simplifies to

$$
(25 b+24)(25 b-651)=0 .
$$

We obtain $2 \sin a \cos a=-\frac{24}{25}$, or $2 \sin a \cos a=\frac{651}{25}$. The latter is impossible because $\sin 2 a \leq 1$. Hence $2 \sin a \cos a=-0.96$, and we obtain $\sin a+\cos a=0.2$. Then

$$
\begin{aligned}
5\left(\sin ^{3} a+\cos ^{3} a\right)+3 \sin a \cos a=& 5(\sin a+\cos a)\left(\sin ^{2} a-\sin a \cos a+\cos ^{2} a\right) \\
&+3 \sin a \cos a \\
=& \sin ^{2} a-\sin a \cos a+\cos ^{2} a+3 \sin a \cos a \\
=&(\sin a+\cos a)^{2}=(0.2)^{2}=0.04,
\end{aligned}
$$

as desired.

(Mathematical Reflections, proposed by T. Andreescu)

665. If we set $b_{k}=\tan \left(a_{k}-\frac{\pi}{4}\right), k=0,1, \ldots, n$, then

$$
\tan \left(a_{k}-\frac{\pi}{4}+\frac{\pi}{4}\right)=\frac{1+\tan \left(a_{k}-\frac{\pi}{4}\right)}{1-\tan \left(a_{k}-\frac{\pi}{4}\right)}=\frac{1+b_{k}}{1-b_{k}} .
$$

So we have to prove that

$$
\prod_{k=0}^{n} \frac{1+b_{k}}{1-b_{k}} \geq n^{n+1} .
$$

The inequality from the statement implies

$$
1+b_{k} \geq \sum_{l \neq k}\left(1-b_{l}\right), \quad k=0,1, \ldots, n .
$$

Also, the condition $a_{k} \in\left(0, \frac{\pi}{2}\right)$ implies $-1<b_{k}<1, k=0,1, \ldots, n$, so the numbers $1-b_{k}$ are all positive. To obtain their product, it is natural to apply the AM-GM inequality to the right-hand side of the above inequality, and obtain

$$
1+b_{k} \geq \sqrt[n]{\prod_{l \neq k}\left(1-b_{l}\right)}, \quad k=0,1, \ldots, n .
$$

Multiplying all these inequalities yields

$$
\prod_{k=0}^{n}\left(1+b_{k}\right) \geq n^{n+1} \sqrt[n]{\prod_{l=0}^{n}\left(1-b_{l}\right)^{n}} .
$$

Hence

$$
\prod_{k=0}^{n} \frac{1+b_{k}}{1-b_{k}} \geq n^{n+1},
$$

as desired.

(USA Mathematical Olympiad, 1998, proposed by T. Andreescu)

666. If we multiply the denominator and the numerator of the left-hand side by $\cos t$, and of the right-hand side by $\cos n t$, we obtain the obvious equality

$$
\left(\frac{e^{i t}}{e^{-i t}}\right)^{n}=\frac{e^{i n t}}{e^{-i n t}} .
$$

667. Using the de Moivre formula, we obtain

$$
(1+i)^{n}=\left[\sqrt{2}\left(\cos \frac{\pi}{4}+i \sin \frac{\pi}{4}\right)\right]^{n}=2^{n / 2}\left(\cos \frac{n \pi}{4}+i \sin \frac{n \pi}{4}\right) .
$$

Expanding $(1+i)^{n}$ and equating the real parts on both sides, we deduce the identity from the statement. 

668. Denote the sum in question by $S_{1}$ and let

$$
S_{2}=\left(\begin{array}{l}
n \\
1
\end{array}\right) \sin x+\left(\begin{array}{l}
n \\
2
\end{array}\right) \sin 2 x+\cdots+\left(\begin{array}{l}
n \\
n
\end{array}\right) \sin n x .
$$

Using Euler's formula, we can write

$$
1+S_{1}+i S_{2}=\left(\begin{array}{l}
n \\
0
\end{array}\right)+\left(\begin{array}{l}
n \\
1
\end{array}\right) e^{i x}+\left(\begin{array}{l}
n \\
2
\end{array}\right) e^{2 i x}+\cdots+\left(\begin{array}{l}
n \\
n
\end{array}\right) e^{i n x} .
$$

By the multiplicative property of the exponential we see that this is equal to

$$
\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(e^{i x}\right)^{k}=\left(1+e^{i x}\right)^{n}=\left(2 \cos \frac{x}{2}\right)^{n}\left(e^{i \frac{x}{2}}\right)^{n} .
$$

The sum in question is the real part of this expression less 1 , which is equal to

$$
2^{n} \cos ^{n} \frac{x}{2} \cos \frac{n x}{2}-1 .
$$

669. Combine $f(x)$ with the function $g(x)=e^{x \cos \theta} \sin (x \sin \theta)$ and write

$$
\begin{aligned}
f(x)+i g(x) &=e^{x \cos \theta}(\cos (x \sin \theta)+i \sin (x \sin \theta)) \\
&=e^{x \cos \theta} \cdot e^{i x \sin \theta}=e^{x(\cos \theta+i \sin \theta)} .
\end{aligned}
$$

Using the de Moivre formula we expand this in a Taylor series as

$$
1+\frac{x}{1 !}(\cos \theta+i \sin \theta)+\frac{x^{2}}{2 !}(\cos 2 \theta+i \sin 2 \theta)+\cdots+\frac{x^{n}}{n !}(\cos n \theta+i \sin n \theta)+\cdots .
$$

Consequently, the Taylor expansion of $f(x)$ around 0 is the real part of this series, i.e.,

$$
f(x)=1+\frac{\cos \theta}{1 !} x+\frac{\cos 2 \theta}{2 !} x^{2}+\cdots+\frac{\cos n \theta}{n !} x^{n}+\cdots .
$$

670. Let $z_{j}=r\left(\cos t_{j}+i \sin t_{j}\right)$, with $r \neq 0$ and $t_{j} \in(0, \pi) \cup(\pi, 2 \pi), j=1,2,3$. By hypothesis,

$$
\begin{aligned}
&\sin t_{1}+r \sin \left(t_{2}+t_{3}\right)=0, \\
&\sin t_{2}+r \sin \left(t_{3}+t_{1}\right)=0, \\
&\sin t_{3}+r \sin \left(t_{1}+t_{2}\right)=0 .
\end{aligned}
$$

Let $t=t_{1}+t_{2}+t_{3}$. Then

$$
\sin t_{j}=-r \sin \left(t-t_{i}\right)=-r \sin t \cos t_{j}-r \cos t \sin t_{j}, \quad \text { for } j=1,2,3,
$$

which means that

$$
\cot t_{j} \sin t=\frac{1}{r}-\cos t, \quad \text { for } j=1,2,3 .
$$

If $\sin t \neq 0$, then $\cot t_{1}=\cot t_{2}=\cot t_{3}$. There are only two possible values that $t_{1}, t_{2}, t_{3}$ can take between 0 and $2 \pi$, and so two of the $t_{j}$ are equal, which is ruled out by the hypothesis. It follows that $\sin t=0$. Then on the one hand, $r \cos t-1=0$, and on the other, $\cos t=\pm 1$. This can happen only if $\cos t=1$ and $r=1$. Therefore, $z_{1} z_{2} z_{3}=r^{3} \cos t=1$, as desired.

671. Consider the complex number $\omega=\cos \theta+i \sin \theta$. The roots of the equation

$$
\left(\frac{1+i x}{1-i x}\right)^{n}=\omega^{2 n}
$$

are precisely $a_{k}=\tan \left(\theta+\frac{k \pi}{n}\right), k=1,2, \ldots, n$. Rewriting this as a polynomial equation of degree $n$, we obtain

$$
\begin{aligned}
0 &=(1+i x)^{2}-\omega^{2 n}(1-i x)^{n} \\
&=\left(1-\omega^{2 n}\right)+n i\left(1+\omega^{2 n}\right) x+\cdots+n i^{n-1}\left(1-\omega^{2 n}\right) x^{n-1}+i^{n}\left(1+\omega^{2 n}\right) x^{n} .
\end{aligned}
$$

The sum of the zeros of the latter polynomial is

$$
\frac{-n i^{n-1}\left(1-\omega^{2 n}\right)}{i^{n}\left(1+\omega^{2 n}\right)},
$$

and their product

$$
\frac{-\left(1-\omega^{2 n}\right)}{i^{n}\left(1+\omega^{2 n}\right)} .
$$

Therefore,

$$
\frac{a_{1}+a_{2}+\cdots+a_{n}}{a_{1} a_{2} \cdots a_{n}}=n i^{n-1}=n(-1)^{(n-1) / 2} .
$$

(67th W.L. Putnam Competition, 2006, proposed by T. Andreescu)

672. More generally, for an odd integer $n$, let us compute

$$
S=(\cos \alpha)(\cos 2 \alpha) \cdots(\cos n \alpha)
$$

with $\alpha=\frac{2 \pi}{2 n+1}$. We can let $\zeta=e^{i \alpha}$ and then $S=2^{-n} \prod_{k=1}^{n}\left(\zeta^{k}+\zeta^{-k}\right)$. Since $\zeta^{k}+\zeta^{-k}=$ $\zeta^{2 n+1-k}+\zeta^{-(2 n+1-k)}, k=1,2, \ldots, n$, we obtain 

$$
S^{2}=2^{-2 n} \prod_{k=1}^{2 n}\left(\zeta^{k}+\zeta^{-k}\right)=2^{-2 n} \times \prod_{k=1}^{2 n} \zeta^{-k} \times \prod_{k=1}^{2 n}\left(1+\zeta^{2 k}\right)
$$

The first of the two products is just $\zeta^{-(1+2+\cdots+2 n)}$. Because $1+2+\cdots+2 n=n(2 n+1)$, which is a multiple of $2 n+1$, this product equals 1 .

As for the product $\prod_{k=1}^{2 n}\left(1+\zeta^{2 k}\right)$, note that it can be written as $\prod_{k=1}^{2 n}\left(1+\zeta^{k}\right)$, since the numbers $\zeta^{2 k}$ range over the $(2 n+1)$ st roots of unity other than 1 itself, taking each value exactly once. We compute this using the factorization

$$
z^{n+1}-1=(z-1) \prod_{k=1}^{2 n}\left(z-\zeta^{k}\right)
$$

Substituting $z=-1$ and dividing both sides by $-2$ gives $\prod_{k=1}^{2 n}\left(-1-\zeta^{k}\right)=1$, so $\prod_{k=1}^{2 n}\left(1+\zeta^{k}\right)=1$. Hence $S^{2}=2^{-2 n}$, and so $S=\pm 2^{-n}$. We need to determine the sign.

For $1 \leq k \leq n, \cos k \alpha<0$ when $\frac{\pi}{2}<k \alpha<\pi$. The values of $k$ for which this happens are $\left\lceil\frac{n+1}{2}\right\rceil$ through $n$. The number of such $k$ is odd if $n \equiv 1$ or $2(\bmod 4)$, and even if $n \equiv 0$ or $3(\bmod 4)$. Hence

$$
S= \begin{cases}+2^{-n} & \text { if } n \equiv 1 \text { or } 2(\bmod 4) \\ -2^{-n} & \text { if } n \equiv 0 \text { or } 3(\bmod 4)\end{cases}
$$

Taking $n=999 \equiv 3(\bmod 4)$, we obtain the answer to the problem, $-2^{-999}$.

(proposed by J. Propp for the USA Mathematical Olympiad, 1999)

673. Define the complex numbers $p=x e^{i A}, q=y e^{i B}$, and $r=z e^{i C}$ and consider $f(n)=p^{n}+q^{n}+r^{n}$. Then $F(n)=\operatorname{Im}(f(n))$. We claim by induction that $f(n)$ is real for all $n$, which would imply that $F(n)=0$. We are given that $f(1)$ and $f(2)$ are real, and $f(0)=3$ is real as well.

Now let us assume that $f(k)$ is real for all $k \leq n$ for some $n \geq 3$, and let us prove that $f(n+1)$ is also real. Note that $a=p+q+r=f(1), b=p q+q r+r p=$ $\frac{1}{2}\left(f(1)^{2}-f(2)\right)$, and $c=p q r=x y z e^{i(A+B+C)}$ are all real. The numbers $p, q, r$ are the zeros of the cubic polynomial $P(t)=t^{3}-a t^{2}+b t-c$, which has real coefficients. Using this fact, we obtain

$$
\begin{aligned}
f(n+1) &=p^{n+1}+q^{n+1}+r^{n+1} \\
&=a\left(p^{n}+q^{n}+r^{n}\right)-b\left(p^{n-1}+q^{n-1}+r^{n-1}\right)+c\left(p^{n-2}+q^{n-2}+r^{n-2}\right) \\
&=a f(n)-b f(n-1)+c f(n-2) .
\end{aligned}
$$

Since $f(n), f(n-1)$ and $f(n-2)$ are real by the induction hypothesis, it follows that $f(n+1)$ is real, and we are done. 

674. By eventually changing $\phi(t)$ to $\phi(t)+\frac{\theta}{2}$, where $\theta$ is the argument of $4 P^{2}-2 Q$, we may assume that $4 P^{2}-2 Q$ is real and positive. We can then ignore the imaginary parts and write

$$
\begin{aligned}
4 P^{2}-2 Q=& 4\left(\int_{0}^{\infty} e^{-t} \cos \phi(t) d t\right)^{2}-4\left(\int_{0}^{\infty} e^{-t} \sin \phi(t) d t\right)^{2} \\
&-2 \int_{0}^{\infty} e^{-2 t} \cos 2 \phi(t) d t
\end{aligned}
$$

Ignore the second term. Increase the first term using the Cauchy-Schwarz inequality:

$$
\begin{aligned}
\left(\int_{0}^{\infty} e^{-t} \cos \phi(t) d t\right)^{2} &=\left(\int_{0}^{\infty} e^{-\frac{1}{2} t} e^{-\frac{1}{2} t} \cos \phi(t) d t\right)^{2} \\
& \leq\left(\int_{0}^{\infty} e^{-t} d t\right)\left(\int_{0}^{\infty} e^{-t} \cos ^{2} \phi(t) d t\right) \\
&=\int_{0}^{\infty} e^{-t} \cos ^{2} \phi(t) d t
\end{aligned}
$$

We then have

$$
\begin{aligned}
4 P^{2}-2 Q & \leq 4 \int_{0}^{\infty} e^{-t} \cos ^{2} \phi(t) d t-2 \int_{0}^{\infty} e^{-2 t} \cos 2 \phi(t) d t \\
&=4 \int_{0}^{\infty}\left(e^{-t}-e^{-2 t}\right) \cos ^{2} \phi(t) d t+1 \\
& \leq 4 \int_{0}^{\infty}\left(e^{-t}-e^{-2 t}\right) d t+1=3 .
\end{aligned}
$$

Equality holds only when $\cos ^{2} \phi(t)=1$ for all $t$, and in general if $\phi(t)$ is constant. (K. Löwner, from G. Pólya, G. Szegó, Aufgaben und Lehrsätze aus der Analysis, Springer-Verlag, 1964)

675. The given inequality follows from the easier

$$
\sqrt{a b}+\sqrt{(1-a)(1-b)} \leq 1 .
$$

To prove this one, let $a=\sin ^{2} \alpha$ and $b=\sin ^{2} \beta, \alpha, \beta \in\left[0, \frac{\pi}{2}\right]$. The inequality becomes $\sin \alpha \sin \beta+\cos \alpha \cos \beta \leq 1$, or $\cos (\alpha-\beta) \leq 1$, and this is clearly true.

676. First, note that if $x>2$, then $x^{3}-3 x>4 x-3 x=x>\sqrt{x+2}$, so all solutions $x$ should satisfy $-2 \leq x \leq 2$. Therefore, we can substitute $x=2 \cos a$ for some $a \in[0, \pi]$. Then the given equation becomes

$$
2 \cos 3 a=\sqrt{2(1+\cos a)}=2 \cos \frac{a}{2},
$$

So

$$
2 \sin \frac{7 a}{4} \sin \frac{5 a}{4}=0
$$

meaning that $a=0, \frac{4 \pi}{7}, \frac{4 \pi}{5}$. It follows that the solutions to the original equation are $x=2,2 \cos \frac{4 \pi}{7},-\frac{1}{2}(1+\sqrt{5})$.

677. The points $\left(x_{1}, x_{2}\right)$ and $\left(y_{1}, y_{2}\right)$ lie on the circle of radius $c$ centered at the origin. Parametrizing the circle, we can write $\left(x_{1}, x_{2}\right)=(c \cos \phi, c \sin \phi)$ and $\left(y_{1}, y_{2}\right)=$ $(c \cos \psi, c \sin \psi)$. Then

$$
\begin{aligned}
S &=2-c(\cos \phi+\sin \phi+\cos \psi+\sin \psi)+c^{2}(\cos \phi \cos \psi+\sin \phi \sin \psi) \\
&=2+c \sqrt{2}\left(-\sin \left(\phi+\frac{\pi}{4}\right)-\sin \left(\psi+\frac{\pi}{4}\right)\right)+c^{2} \cos (\phi-\psi)
\end{aligned}
$$

We can simultaneously increase each of $-\sin \left(\phi+\frac{\pi}{4}\right),-\sin \left(\psi+\frac{\pi}{4}\right)$, and $\cos (\phi-\psi)$ to 1 by choosing $\phi=\psi=\frac{5 \pi}{4}$. Hence the maximum of $S$ is $2+2 c \sqrt{2}+c^{2}=(c+\sqrt{2})^{2}$. (proposed by C. Rousseau for the USA Mathematical Olympiad, 2002)

678. Let $a=\tan \alpha, b=\tan \beta, c=\tan \gamma, \alpha, \beta, \gamma \in\left(-\frac{\pi}{2}\right.$, $\left.\frac{\pi}{2}\right)$. Then $a^{2}+1=\sec ^{2} \alpha$, $b^{2}+1=\sec ^{2} \beta, c^{2}+1=\sec ^{2} \gamma$, and the inequality takes the simpler form

$$
|\sin (\alpha-\beta)| \leq|\sin (\alpha-\gamma)|+|\sin (\beta-\gamma)|
$$

This is proved as follows:

$$
\begin{aligned}
|\sin (\alpha-\beta)| &=|\sin (\alpha-\gamma+\gamma-\beta)| \\
&=|\sin (\alpha-\gamma) \cos (\gamma-\beta)+\sin (\gamma-\beta) \cos (\alpha-\gamma)| \\
& \leq|\sin (\alpha-\gamma)||\cos (\gamma-\beta)|+|\sin (\gamma-\beta)||\cos (\alpha-\gamma)| \\
& \leq|\sin (\alpha-\gamma)|+|\sin (\gamma-\beta)| .
\end{aligned}
$$

(N.M. Sedrakyan, A.M. Avoyan, Neravenstva, Metody Dokazatel'stva (Inequalities, Methods of Proof ), FIZMATLIT, Moscow, 2002)

679. Expressions of the form $x^{2}+1$ suggest a substitution by the tangent. We let $a=\tan u$, $b=\tan v, c=\tan w, u, v, w \in\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$. The product on the right-hand side becomes $\sec ^{2} u \sec ^{2} v \sec ^{2} w$, and the inequality can be rewritten as

$$
-1 \leq(\tan u \tan v+\tan u \tan w+\tan v \tan w-1) \cos u \cos v \cos w \leq 1
$$

The expression in the middle is simplified as follows:

$(\tan u \tan v+\tan u \tan w+\tan v \tan w-1) \cos u \cos v \cos w$

$=\sin u \sin v \cos w+\sin u \cos v \sin w+\cos u \sin v \sin w-\cos u \cos v \cos w$ 

$$
=\sin u \sin (v+w)-\cos u \cos (v+w)=-\cos (u+v+w) .
$$

And of course this takes values in the interval $[-1,1]$. The inequality is proved. (T. Andreescu, Z. Feng, 103 Trigonometry Problems, Birkhäuser 2004)

680. The denominators suggest the substitution based on tangents. This idea is further enforced by the identity $x+y+z=x y z$, which characterizes the tangents of the angles of a triangle. Set $x=\tan A, y=\tan B, z=\tan C$, with $A, B, C$ the angles of an acute triangle. Note that

$$
\frac{\tan A}{\sqrt{1+\tan ^{2} A}}=\frac{\tan A}{\sec A}=\sin A,
$$

so the inequality is equivalent to

$$
\sin A+\sin B+\sin C \leq \frac{3 \sqrt{3}}{2} .
$$

This is Jensen's inequality applied to the function $f(x)=\sin x$, which is concave on $\left(0, \frac{\pi}{2}\right)$.

681. If we multiply the inequality through by 2 , thus obtaining

$$
\frac{2 x}{1-x^{2}}+\frac{2 y}{1-y^{2}}+\frac{2 z}{1-z^{2}} \geq 3 \sqrt{3},
$$

the substitution by tangents becomes transparent. This is because we should recognize the double-angle formulas on the left-hand side.

The conditions $0<x, y, z<1$ and $x y+x z+y z=1$ characterize the tangents of the half-angles of an acute triangle. Indeed, if $x=\tan \frac{A}{2}, y=\tan \frac{B}{2}$, and $z=\tan \frac{C}{2}$, then $0<x, y, z<1$ implies $A, B, C \in\left(0, \frac{\pi}{2}\right)$. Also, the equality $x y+x z+y z=1$, which is the same as

$$
\frac{1}{z}=\frac{x+y}{1-x y},
$$

implies

$$
\cot \frac{C}{2}=\tan \frac{A+B}{2} .
$$

And this is equivalent to $\frac{\pi}{2}-\frac{C}{2}=\frac{A+B}{2}$, or $A+B+C=\pi$.

Returning to the problem, with the chosen trigonometric substitution the inequality assumes the much simpler form

$$
\tan A+\tan B+\tan C \geq 3 \sqrt{3} .
$$

And this is Jensen's inequality applied to the tangent function, which is convex on $\left(0, \frac{\pi}{2}\right)$. 

682. From the first equation, it follows that if $x$ is 0 , then so is $y$, making $x^{2}$ indeterminate; hence $x$, and similarly $y$ and $z$, cannot be 0 . Solving the equations, respectively, for $y, z$, and $x$, we obtain the equivalent system

$$
\begin{gathered}
y=\frac{3 x-x^{3}}{1-3 x^{2}}, \\
z=\frac{3 y-y^{3}}{1-3 y^{2}}, \\
x=\frac{3 z-z^{3}}{1-3 z^{2}},
\end{gathered}
$$

where $x, y, z$ are real numbers different from 0 .

There exists a unique number $u$ in the interval $\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$ such that $x=\tan u$. Then

$$
\begin{aligned}
&y=\frac{3 \tan u-\tan ^{3} u}{1-3 \tan ^{2} u}=\tan 3 u, \\
&z=\frac{3 \tan 3 u-\tan ^{3} 3 u}{1-3 \tan ^{2} 3 u}=\tan 9 u, \\
&x=\frac{3 \tan 9 u-\tan ^{3} 9 u}{1-3 \tan ^{2} 9 u}=\tan 27 u .
\end{aligned}
$$

The last equality yields $\tan u=\tan 27 u$, so $u$ and $27 u$ differ by an integer multiple of $\pi$. Therefore, $u=\frac{k \pi}{26}$ for some $k$ satisfying $-\frac{\pi}{2}<\frac{k \pi}{26}<\frac{\pi}{2}$. Besides, $k$ must not be 0 , since $x \neq 0$. Hence the possible values of $k$ are $\pm 1, \pm 2, \ldots, \pm 12$, each of them generating the corresponding triple

$$
x=\tan \frac{k \pi}{26}, \quad y=\tan \frac{3 k \pi}{26}, \quad z=\tan \frac{9 k \pi}{26} .
$$

It is immediately checked that all of these triples are solutions of the initial system.

683. In the case of the sequence $\left(a_{n}\right)_{n}$, the innermost square root suggests one of the substitutions $a_{n}=2 \sin t_{n}$ or $a_{n}=2 \cos t_{n}$, with $t_{n} \in\left[0, \frac{\pi}{2}\right], n \geq 0$. It is the first choice that allows a further application of a half-angle formula:

$$
2 \sin t_{n+1}=a_{n+1}=\sqrt{2-\sqrt{4-4 \sin ^{2} t_{n}}}=\sqrt{2-2 \cos t_{n}}=2 \sin \frac{t_{n}}{2} .
$$

It follows that $t_{n+1}=\frac{t_{n}}{2}$, which combined with $t_{0}=\frac{\pi}{4}$ gives $t_{n}=\frac{\pi}{2^{n+2}}$ for $n \geq 0$. Therefore, $a_{n}=2 \sin \frac{\pi}{2^{n+2}}$ for $n \geq 0$.

For $\left(b_{n}\right)_{n}$, the innermost square root suggests a trigonometric substitution as well, namely $b_{n}=2 \tan u_{n}, n \geq 0$. An easy induction shows that the sequence $\left(b_{n}\right)_{n}$ is positive, so we can choose $u_{n} \in\left[0, \frac{\pi}{2}\right)$. Substituting in the recursive formula, we obtain 

$$
\begin{aligned}
2 \tan u_{n+1} &=b_{n+1}=\frac{2 \tan u_{n}}{2+\sqrt{4+4 \tan u_{n}}}=\frac{4 \tan u_{n}}{2+\frac{2}{\cos u_{n}}} \\
&=2 \cdot \frac{\sin u_{n}}{1+\cos u_{n}}=2 \tan \frac{u_{n}}{2}
\end{aligned}
$$

Therefore, $u_{n+1}=\frac{u_{n}}{2}$, which together with $u_{0}=\frac{\pi}{4}$ implies $u_{n}=\frac{\pi}{2^{n+2}}, n \geq 0$. Hence $b_{n}=2 \tan \frac{\pi}{2^{n+2}}$ for $n \geq 0$.

Returning to the problem, we recall that sine and tangent are decreasing on $\left(0, \frac{\pi}{2}\right)$ and their limit at 0 is 0 . This takes care of (a).

For (b), note that the functions $\sin x / x$ and $\tan x / x$ are increasing, respectively, decreasing, on $\left(0, \frac{\pi}{2}\right)$. Hence $2^{n} a_{n}=\frac{\pi}{2} \sin \frac{\pi}{2^{n+2}} / \frac{\pi}{2^{n+2}}$ is increasing, and $2^{n} b_{n}=$ $\frac{\pi}{2} \tan \frac{\pi}{2^{n+2}} / \frac{\pi}{2^{n+2}}$ is decreasing. Also, since

$$
\lim _{x \rightarrow 0} \frac{\sin x}{x}=\lim _{x \rightarrow 0} \frac{\tan x}{x}=1,
$$

it follows that

$$
\lim _{n \rightarrow \infty} 2^{n} a_{n}=\frac{\pi}{2} \lim _{n \rightarrow \infty} \frac{\sin \frac{\pi}{2^{n+2}}}{\frac{\pi}{2^{n+2}}}=\frac{\pi}{2},
$$

and similarly $\lim _{n \rightarrow \infty} 2^{n} b_{n}=\frac{\pi}{2}$. This answers (b).

The first inequality in (c) follows from the fact that $\tan x>\sin x$ for $x \in\left(0, \frac{\pi}{2}\right)$. For the second inequality we use Taylor series expansions. We have

$$
\tan x-\sin x=x-\frac{x^{3}}{12}+o\left(x^{4}\right)-x+\frac{x^{3}}{6}+o\left(x^{4}\right)=\frac{x^{3}}{12}+o\left(x^{4}\right) .
$$

Hence

$$
b_{n}-a_{n}=2\left(\tan \frac{\pi}{2^{n+2}}-\sin \frac{\pi}{2^{n+2}}\right)=\frac{\pi^{3}}{6 \cdot 2^{6}} \cdot \frac{1}{8^{n}}+o\left(\frac{1}{2^{4 n}}\right) .
$$

It follows that for $C>\frac{\pi^{3}}{6 \cdot 2^{6}}$ we can find $n_{0}$ such that $b_{n}-a_{n}<\frac{C}{8^{n}}$ for $n \geq n_{0}$. Choose $C$ such that the inequality also holds for (the finitely many) $n<n_{0}$. This concludes (c).

(8th International Competition in Mathematics for University Students, 2001)

684. Writing $x_{n}=\tan a_{n}$ for $0^{\circ}<a_{n}<90^{\circ}$, we have

$$
x_{n+1}=\tan a_{n}+\sqrt{1+\tan ^{2} a_{n}}=\tan a_{n}+\sec a_{n}=\frac{1+\sin a_{n}}{\cos a_{n}}=\tan \left(\frac{90^{\circ}+a_{n}}{2}\right) .
$$

Because $a_{1}=60^{\circ}$, we have $a_{2}=75^{\circ}, a_{3}=82.5^{\circ}$, and in general $a_{n}=90^{\circ}-\frac{30^{\circ}}{2^{n-1}}$, whence 

$$
x_{n}=\tan \left(90^{\circ}-\frac{30^{\circ}}{2^{n-1}}\right)=\cot \left(\frac{30^{\circ}}{2^{n-1}}\right)=\cot \theta_{n}, \quad \text { where } \theta_{n}=\frac{30^{\circ}}{2^{n-1}} .
$$

A similar calculation shows that

$$
y_{n}=\tan 2 \theta_{n}=\frac{2 \tan \theta_{n}}{1-\tan ^{2} \theta_{n}},
$$

which implies that

$$
x_{n} y_{n}=\frac{2}{1-\tan ^{2} \theta n} .
$$

Because $0^{\circ}<\theta_{n}<45^{\circ}$, we have $0<\tan ^{2} \theta_{n}<1$ and $x_{n} y_{n}>2$. For $n>1$, we have $\theta_{n}<30^{\circ}$, and hence $\tan ^{2} \theta_{n}<\frac{1}{3}$. It follows that $x_{n} y_{n}<3$, and the problem is solved.

(Team Selection Test for the International Mathematical Olympiad, Belarus, 1999)

685. Let $a=\tan x, b=\tan y, c=\tan z$, where $x, y, z \in\left(0, \frac{\pi}{2}\right)$. From the identity

$$
\tan (x+y+z)=\frac{\tan x+\tan y+\tan z-\tan x \tan y \tan z}{1-\tan x \tan y-\tan y \tan z-\tan x \tan z}
$$

it follows that $a b c=a+b+c$ only if $x+y+z=k \pi$, for some integer $k$. In this case $\tan (3 x+3 y+3 z)=\tan 3 k \pi=0$, and from the same identity it follows that

$$
\tan 3 x \tan 3 y \tan 3 z=\tan 3 x+\tan 3 y+\tan 3 z .
$$

This is the same as

$$
\frac{3 a-a^{3}}{3 a^{2}-1} \cdot \frac{3 b-b^{3}}{3 b^{2}-1} \cdot \frac{3 c-c^{3}}{3 c^{2}-1}=\frac{3 a-a^{3}}{3 a^{2}-1}+\frac{3 b-b^{3}}{3 b^{2}-1}+\frac{3 c-c^{3}}{3 c^{2}-1},
$$

and we are done.

(Mathematical Olympiad Summer Program, 2000, proposed by T. Andreescu)

686. With the substitution $x=\cosh t$, the integral becomes

$$
\begin{aligned}
&\int \frac{1}{\sinh t+\cosh t} \sinh t d t \\
&\quad=\int \frac{e^{t}-e^{-t}}{2 e^{t}} d t=\frac{1}{2} \int\left(1-e^{-2 t}\right) d t=\frac{1}{2} t+\frac{e^{-2 t}}{4}+C \\
&\quad=\frac{1}{2} \ln \left(x+\sqrt{x^{2}-1}\right)+\frac{1}{4} \cdot \frac{1}{2 x^{2}-1+2 x \sqrt{x^{2}-1}}+C .
\end{aligned}
$$

687. Suppose by contradiction that there exists an irrational $a$ and a positive integer $n$ such that the expression from the statement is rational. Substitute $a=\cosh t$, where $t$ is an appropriately chosen real number. Then 

$$
\begin{aligned}
\sqrt[n]{a+\sqrt{a^{2}-1}}+\sqrt[n]{a-\sqrt{a^{2}-1}} &=\sqrt[n]{\cosh t+\sinh t}+\sqrt[n]{\cosh t-\sinh t} \\
&=\sqrt[n]{e^{t}}+\sqrt[n]{e^{-t}}=e^{t / n}+e^{-t / n}=2 \cosh \frac{t}{n}
\end{aligned}
$$

It follows that $\cosh \frac{t}{n}$ is rational. From the recurrence relation

$$
\cosh (k+1) \alpha=2 \cosh \alpha \cosh k \alpha-\cosh (k-1) \alpha, \quad k \geq 1
$$

applied to $\alpha=\frac{t}{n}$, we can prove inductively that $\cosh k \frac{t}{n}$ is rational for all positive integers $k$. In particular, $\cosh n \frac{t}{n}=\cosh t=a$ is rational. This contradicts the hypothesis. Hence our assumption was false and the conclusion follows.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1979, proposed by T. Andreescu)

688. We use the triple-angle formula

$$
\sin 3 x=3 \sin x-4 \sin ^{3} x
$$

which we rewrite as

$$
\sin ^{3} x=\frac{1}{4}(3 \sin x-\sin 3 x) .
$$

The expression on the left-hand side of the identity from the statement becomes

$$
\begin{aligned}
27 \cdot \frac{3 \sin 9^{\circ}-\sin 27^{\circ}}{4} &+9 \cdot \frac{3 \sin 27^{\circ}-\sin 81^{\circ}}{4}+3 \cdot \frac{3 \sin 81^{\circ}-\sin 243^{\circ}}{4} \\
&+\frac{3 \sin 243^{\circ}-\sin 729^{\circ}}{4} .
\end{aligned}
$$

This collapses to

$$
\frac{81 \sin 9^{\circ}-\sin 729^{\circ}}{4}=\frac{81 \sin 9^{\circ}-\sin 9^{\circ}}{4}=20 \sin 9^{\circ} .
$$

\section{(T. Andreescu)}

689. The triple-angle formula for the tangent gives

$$
3 \tan 3 x=\frac{3\left(3 \tan x-\tan ^{3} x\right)}{1-3 \tan ^{2} x}=\frac{3 \tan ^{3} x-9 \tan x}{3 \tan ^{2} x-1}=\tan x-\frac{8 \tan x}{3 \tan ^{2} x-1} .
$$

Hence

$$
\frac{1}{\cot x-3 \tan x}=\frac{\tan x}{1-3 \tan ^{2} x}=\frac{1}{8}(3 \tan 3 x-\tan x) \quad \text { for all } x \neq k \frac{\pi}{2}, k \in \mathbb{Z}
$$

It follows that the left-hand side telescopes as

$$
\begin{gathered}
\frac{1}{8}\left(3 \tan 27^{\circ}-\tan 9^{\circ}+9 \tan 81^{\circ}-3 \tan 27^{\circ}+27 \tan 243^{\circ}-9 \tan 81^{\circ}+81 \tan 729^{\circ}\right. \\
\left.-27 \tan 243^{\circ}\right)=\frac{1}{8}\left(81 \tan 9^{\circ}-\tan 9^{\circ}\right)=10 \tan 9^{\circ} .
\end{gathered}
$$

\section{(T. Andreescu)}

690. Multiply the left-hand side by $\sin 1^{\circ}$ and transform it using the identity

$$
\frac{\sin \left((k+1)^{\circ}-k^{\circ}\right)}{\sin k^{\circ} \sin (k+1)^{\circ}}=\cot k^{\circ}-\cot (k+1)^{\circ} .
$$

We obtain

$\cot 45^{\circ}-\cot 46^{\circ}+\cot 47^{\circ}-\cot 48^{\circ}+\cdots+\cot 131^{\circ}-\cot 132^{\circ}+\cot 133^{\circ}-\cot 134^{\circ}$.

At first glance this sum does not seem to telescope. It does, however, after changing the order of terms. Indeed, if we rewrite the sum as

$$
\begin{aligned}
\cot 45^{\circ}-&\left(\cot 46^{\circ}+\cot 134^{\circ}\right)+\left(\cot 47^{\circ}+\cot 133^{\circ}\right)-\left(\cot 48^{\circ}+\cot 132^{\circ}\right) \\
&+\cdots+\left(\cot 89^{\circ}+\cot 91^{\circ}\right)-\cot 90^{\circ},
\end{aligned}
$$

then the terms in the parentheses cancel, since they come from supplementary angles. The conclusion follows from $\cot 45^{\circ}=1$ and $\cot 90^{\circ}=0$.

(T. Andreescu)

691. The formula

$$
\tan (a-b)=\frac{\tan a-\tan b}{1+\tan a \tan b}
$$

translates into

$$
\arctan \frac{x-y}{1+x y}=\arctan x-\arctan y .
$$

Applied to $x=n+1$ and $y=n-1$, it gives

$$
\arctan \frac{2}{n^{2}}=\arctan \frac{(n+1)-(n-1)}{1+(n+1)(n-1)}=\arctan (n+1)-\arctan (n-1) .
$$

The sum in part (a) telescopes as follows:

$$
\sum_{n=1}^{\infty} \arctan \frac{2}{n^{2}}=\lim _{N \rightarrow \infty} \sum_{n=1}^{N} \arctan \frac{2}{n^{2}}=\lim _{N \rightarrow \infty} \sum_{n=1}^{N}(\arctan (n+1)-\arctan (n-1))
$$



$$
\begin{aligned}
&=\lim _{N \rightarrow \infty}(\arctan (N+1)+\arctan N-\arctan 1-\arctan 0) \\
&=\frac{\pi}{2}+\frac{\pi}{2}-\frac{\pi}{4}=\frac{3 \pi}{4}
\end{aligned}
$$

The sum in part (b) is only slightly more complicated. In the above-mentioned formula for the difference of arctangents we have to substitute $x=\left(\frac{n+1}{\sqrt{2}}\right)^{2}$ and $y=\left(\frac{n-1}{\sqrt{2}}\right)^{2}$. This is because

$$
\frac{8 n}{n^{4}-2 n^{2}+5}=\frac{8 n}{4+\left(n^{2}-1\right)^{2}}=\frac{2\left[(n+1)^{2}-(n-1)^{2}\right]}{4-(n+1)^{2}(n-1)^{2}}=\frac{\left(\frac{n+1}{\sqrt{2}}\right)^{2}-\left(\frac{n-1}{\sqrt{2}}\right)^{2}}{1-\left(\frac{n+1}{\sqrt{2}}\right)^{2}\left(\frac{n-1}{\sqrt{2}}\right)^{2}} .
$$

The sum telescopes as

$$
\begin{aligned}
&\sum_{n=1}^{\infty} \arctan \frac{8 n}{n^{4}-2 n^{2}+5} \\
&=\lim _{N \rightarrow \infty} \sum_{n=1}^{N} \arctan \frac{8 n}{n^{4}-2 n^{2}+5}=\lim _{N \rightarrow \infty} \sum_{n=1}^{N}\left[\arctan \left(\frac{n+1}{\sqrt{2}}\right)^{2}-\arctan \left(\frac{n-1}{\sqrt{2}}\right)^{2}\right] \\
&=\lim _{N \rightarrow \infty}\left[\arctan \left(\frac{N+1}{\sqrt{2}}\right)^{2}+\arctan \left(\frac{N}{\sqrt{2}}\right)^{2}-\arctan 0-\arctan \frac{1}{2}\right]=\pi-\arctan \frac{1}{2} .
\end{aligned}
$$

(American Mathematical Monthly, proposed by J. Anglesio)

692. In order for the series to telescope, we wish to write the general term in the form $\arcsin b_{n}-\arcsin b_{n+1}$. To determine $b_{n}$ let us apply the sine function and write

$$
\frac{\sqrt{n+1}-\sqrt{n}}{\sqrt{n+2} \sqrt{n+1}}=\sin u_{n}=b_{n} \sqrt{1-b_{n+1}^{2}}-b_{n+1} \sqrt{1-b_{n}^{2}} .
$$

If we choose $b_{n}=\frac{1}{\sqrt{n+1}}$, then this equality is satisfied. Therefore,

$$
\begin{aligned}
S &=\lim _{N \rightarrow \infty} \sum_{n=0}^{N}\left(\arcsin \frac{1}{\sqrt{n+1}}-\arcsin \frac{1}{\sqrt{n+2}}\right) \\
&=\arcsin 1-\lim _{N \rightarrow \infty} \arcsin \frac{1}{\sqrt{N+2}}=\frac{\pi}{2} .
\end{aligned}
$$

(The Mathematics Gazette Competition, Bucharest, 1927)

693. The radii of the circles satisfy the recurrence relation $R_{1}=1, R_{n+1}=R_{n} \cos \frac{\pi}{2^{n+1}}$. Hence 

$$
\lim _{n \rightarrow \infty} R_{n}=\prod_{n=1}^{\infty} \cos \frac{\pi}{2^{n}} .
$$

The product can be made to telescope if we use the double-angle formula for sine written as $\cos x=\frac{\sin 2 x}{2 \sin x}$. We then have

$$
\begin{aligned}
\prod_{n=2}^{\infty} \cos \frac{\pi}{2^{n}} &=\lim _{N \rightarrow \infty} \prod_{n=2}^{N} \cos \frac{\pi}{2^{n}}=\lim _{N \rightarrow \infty} \prod_{n=2}^{N} \frac{1}{2} \cdot \frac{\sin \frac{\pi}{2^{n-1}}}{\sin \frac{\pi}{2^{n}}} \\
&=\lim _{N \rightarrow \infty} \frac{1}{2^{N}} \frac{\sin \frac{\pi}{2}}{\sin \frac{\pi}{2^{N}}}=\frac{2}{\pi} \lim _{N \rightarrow \infty} \frac{\frac{\pi}{2^{N}}}{\sin \frac{\pi}{2^{N}}}=\frac{2}{\pi} .
\end{aligned}
$$

Thus the answer to the problem is $\frac{2}{\pi}$.

Remark. As a corollary, we obtain the formula

$$
\frac{2}{\pi}=\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{2+\sqrt{2}}}{2} \cdot \frac{\sqrt{2+\sqrt{2+\sqrt{2}}}}{2} \cdots .
$$

This formula is credited to F. Viète, although Archimedes already used this approximation of the circle by regular polygons to compute $\pi$.

694. For $k=1,2, \ldots, 59$,

$$
\begin{aligned}
1-\frac{\cos \left(60^{\circ}+k^{\circ}\right)}{\cos k^{\circ}} &=\frac{\cos k^{\circ}-\cos \left(60^{\circ}+k^{\circ}\right)}{\cos k^{\circ}}=\frac{2 \sin 30^{\circ} \sin \left(30^{\circ}+k^{\circ}\right)}{\cos k^{\circ}} \\
&=\frac{\cos \left(90^{\circ}-30^{\circ}-k^{\circ}\right)}{\cos k^{\circ}}=\frac{\cos \left(60^{\circ}-k^{\circ}\right)}{\cos k^{\circ}} .
\end{aligned}
$$

So

$$
\prod_{k=1}^{59}\left(1-\frac{\cos \left(60^{\circ}+k^{\circ}\right)}{\cos k^{\circ}}\right)=\frac{\cos 59^{\circ} \cos 58^{\circ} \cdots \cos 1^{\circ}}{\cos 1^{\circ} \cos 2^{\circ} \cdots \cos 59^{\circ}}=1 .
$$

695. We have

$$
\begin{aligned}
\left(1-\cot 1^{\circ}\right)\left(1-\cot 2^{\circ}\right) \cdots\left(1-\cot 44^{\circ}\right) \\
&=\left(1-\frac{\cos 1^{\circ}}{\sin 1^{\circ}}\right)\left(1-\frac{\cos 2^{\circ}}{\sin 2^{\circ}}\right) \cdots\left(1-\frac{\cos 44^{\circ}}{\sin 44^{\circ}}\right) \\
&=\frac{\left(\sin 1^{\circ}-\cos 1^{\circ}\right)\left(\sin 2^{\circ}-\cos 2^{\circ}\right) \cdots\left(\sin 44^{\circ}-\cos 44^{\circ}\right)}{\sin 1^{\circ} \sin 2^{\circ} \cdots \sin 44^{\circ}}
\end{aligned}
$$

Using the identity $\sin a-\cos a=\sqrt{2} \sin \left(a-45^{\circ}\right)$ in the numerators, we transform this further into

$$
\begin{gathered}
\frac{\sqrt{2} \sin \left(1^{\circ}-45^{\circ}\right) \cdot \sqrt{2} \sin \left(2^{\circ}-45^{\circ}\right) \cdots \sqrt{2} \sin \left(44^{\circ}-45^{\circ}\right)}{\sin 1^{\circ} \sin 2^{\circ} \cdots \sin 44^{\circ}} \\
=\frac{(\sqrt{2})^{44}(-1)^{44} \sin 44^{\circ} \sin 43^{\circ} \cdots \sin 1^{\circ}}{\sin 44^{\circ} \sin 43^{\circ} \cdots \sin 1^{\circ}} .
\end{gathered}
$$

After cancellations, we obtain $2^{22}$.

696. We can write

$$
\begin{aligned}
\sqrt{3}+\tan n^{\circ} &=\tan 60^{\circ}+\tan n^{\circ}=\frac{\sin 60^{\circ}}{\cos 60^{\circ}}+\frac{\sin n^{\circ}}{\cos n^{\circ}} \\
&=\frac{\sin \left(60^{\circ}+n^{\circ}\right)}{\cos 60^{\circ} \cos n^{\circ}}=2 \cdot \frac{\sin \left(60^{\circ}+n^{\circ}\right)}{\cos n^{\circ}}=2 \cdot \frac{\cos \left(30^{\circ}-n^{\circ}\right)}{\cos n^{\circ}} .
\end{aligned}
$$

And the product telescopes as follows:

$$
\prod_{n=1}^{29}\left(\sqrt{3}+\tan n^{\circ}\right)=2^{29} \prod_{n=1}^{29} \frac{\cos \left(30^{\circ}-n^{\circ}\right)}{\cos n^{\circ}}=2^{29} \cdot \frac{\cos 29^{\circ} \cos 28^{\circ} \cdots \cos 1^{\circ}}{\cos 1^{\circ} \cos 2^{\circ} \cdots \cos 29^{\circ}}=2^{29} .
$$

\section{(T. Andreescu)}

697. (a) Note that

$$
1-2 \cos 2 x=1-2\left(2 \cos ^{2} x-1\right)=3-4 \cos ^{2} x=-\frac{\cos 3 x}{\cos x} .
$$

The product becomes

$$
\left(-\frac{1}{2}\right)^{3} \frac{\cos \frac{3 \pi}{7}}{\cos \frac{\pi}{7}} \cdot \frac{\cos \frac{9 \pi}{7}}{\cos \frac{3 \pi}{7}} \cdot \frac{\cos \frac{27 \pi}{7}}{\cos \frac{9 \pi}{7}}=-\frac{1}{8} \cdot \frac{\cos \frac{27 \pi}{7}}{\cos \frac{\pi}{7}} .
$$

Taking into account that $\cos \frac{27 \pi}{7}=\cos \left(2 \pi-\frac{\pi}{7}\right)=\cos \frac{\pi}{7}$, we obtain the desired identity.

(b) Analogously,

$$
1+2 \cos 2 x=1+2\left(1-2 \sin ^{2} x\right)=3-4 \sin ^{2} x=\frac{\sin 3 x}{\sin x},
$$

and the product becomes

$$
\frac{1}{2^{4}} \frac{\sin \frac{3 \pi}{20}}{\sin \frac{\pi}{20}} \cdot \frac{\sin \frac{9 \pi}{20}}{\sin \frac{3 \pi}{30}} \cdot \frac{\sin \frac{27 \pi}{20}}{\sin \frac{9 \pi}{20}} \cdot \frac{\sin \frac{81 \pi}{20}}{\sin \frac{27 \pi}{20}}=\frac{1}{16} \frac{\sin \frac{81 \pi}{20}}{\sin \frac{\pi}{20}} .
$$

Because $\sin \frac{81 \pi}{20}=\sin \left(4 \pi+\frac{\pi}{20}\right)=\sin \frac{\pi}{20}$, this is equal to $\frac{1}{16}$.

(T. Andreescu)

698. (a) We observe that

$$
\sec x=\frac{1}{\cos x}=\frac{2 \sin x}{2 \sin x \cos x}=2 \frac{\sin x}{\sin 2 x} .
$$

Applying this to the product in question yields

$$
\prod_{n=1}^{24} \sec \left(2^{n}\right)^{\circ}=2^{24} \prod_{n=1}^{24} \frac{\sin \left(2^{n}\right)^{\circ}}{\sin \left(2^{n+1}\right)^{\circ}}=2^{24} \frac{\sin 2^{\circ}}{\sin \left(2^{25}\right)^{\circ}} .
$$

We want to show that $\sin \left(2^{25}\right)^{\circ}=\cos 2^{\circ}$. To this end, we prove that $2^{25}-2-90$ is an odd multiple of 180 . This comes down to proving that $2^{23}-23$ is an odd multiple of $45=5 \times 9$. Modulo 5 , this is $2 \cdot\left(2^{2}\right)^{11}-3=2 \cdot(-1)^{11}-3=0$, and modulo 9 , $4 \cdot\left(2^{3}\right)^{7}-5=4 \cdot(-1)^{7}-5=0$. This completes the proof of the first identity.

(b) As usual, we start with a trigonometric computation

$$
2 \cos x-\sec x=\frac{2 \cos ^{2} x-1}{\cos x}=\frac{\cos 2 x}{\cos x} .
$$

Using this, the product becomes

$$
\prod_{n=2}^{25} \frac{\cos \left(2^{n+1}\right)^{\circ}}{\cos \left(2^{n}\right)^{\circ}}=\frac{\cos \left(2^{26}\right)^{\circ}}{\cos 4^{\circ}} .
$$

The statement of the problem suggests that $\cos \left(2^{26}\right)^{\circ}=-\cos 4^{\circ}$, which is true only if $2^{26}-4$ is a multiple of 180 , but not of 360 . And indeed, $2^{26}-2^{2}=4\left(2^{24}-1\right)$, which is divisible on the one hand by $2^{4}-1$ and on the other by $2^{6}-1$. This number is therefore an odd multiple of $4 \times 5 \times 9=180$, and we are done.

(T. Andreescu) 

\section{Number Theory}

699. Because $a_{n-1} \equiv n-1(\bmod k)$, the first positive integer greater than $a_{n-1}$ that is congruent to $n$ modulo $k$ must be $a_{n-1}+1$. The $n$th positive integer greater than $a_{n-1}$ that is congruent to $n$ modulo $k$ is simply $(n-1) k$ more than the first positive integer greater than $a_{n-1}$ that satisfies this condition. Therefore, $a_{n}=a_{n-1}+1+(n-1) k$. Solving this recurrence gives

$$
a_{n}=n+\frac{(n-1) n k}{2} .
$$

(Austrian Mathematical Olympiad, 1997)

700. First, let us assume that none of the progressions contains consecutive numbers, for otherwise the property is obvious. Distributing the eight numbers among the three arithmetic progressions shows that either one of the progressions contains at least four of the numbers, or two of them contain exactly three of the numbers. In the first situation, if one progression contains $2,4,6,8$, then it consists of all positive even numbers, and we are done. If it contains $1,3,5,7$, then the other two contain $2,4,6,8$ and again we have two possibilities: either a progression contains two consecutive even numbers, whence it contains all even numbers thereafter, or one progression contains 2,6 , the other 4,8 , and hence the latter contains 1980.

Let us assume that two progressions each contain exactly three of the numbers $1,2,3,4,5,6,7,8$. The numbers 3 and 6 must belong to different progressions, for otherwise all multiples of 3 occur in one of the progressions and we are done. If 3 belongs to one of the progressions containing exactly three of the numbers, then these numbers must be $3,5,7$. But then the other two progressions contain $2,4,6,8$, and we saw before that 1980 occurs in one of them. If 6 belongs to one of the progressions containing exactly three of the numbers, then these numbers must be 4, 6, 8, and 1980 will then belong to this progression. This completes the proof.

(Austrian-Polish Mathematics Competition, 1980) 

701. From $f(1)+2 f(f(1))=8$ we deduce that $f(1)$ is an even number between 1 and 6 , that is, $f(1)=2,4$, or 6 . If $f(1)=2$ then $2+2 f(2)=8$, so $f(2)=3$. Continuing with $3+2 f(3)=11$, we obtain $f(3)=4$, and formulate the conjecture that $f(n)=n+1$ for all $n \geq 1$. And indeed, in an inductive manner we see that $f(n)=n+1$ implies $n+1+2 f(n+1)=3 n+5$; hence $f(n+1)=n+2$.

The case $f(1)=4$ gives $4+2 f(4)=8$, so $f(4)=2$. But then $2+2 f(f(4))=17$, which cannot hold for reasons of parity. Also, if $f(1)=6$, then $6+2 f(6)=8$, so $f(6)=1$. This cannot happen, because $f(6)+2 f(f(6))=1+2 \cdot 6$, which does not equal $3 \cdot 6+5$

We conclude that $f(n)=n+1, n \geq 1$, is the unique solution to the functional equation.

702. Let $g(x)=f(x)-x$. The given equation becomes $g(x)=2 g(f(x))$. Iterating, we obtain that $g(x)=2^{n} f^{(n)}(x)$ for all $x \in \mathbb{Z}$, where $f^{(n)}(x)$ means $f$ composed $n$ times with itself. It follows that for every $x \in \mathbb{Z}, g(x)$ is divisible by all powers of 2 , so $g(x)=0$. Therefore, the only function satisfying the condition from the statement is $f(x)=x$ for all $x$.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by L. Funar)

703. Assume such a function exists, and define $g: \mathbb{N} \rightarrow 3 \mathbb{N}+1, g(x)=3 f(x)+1$. Then $g$ is bijective and satisfies $g(x y)=g(x) g(y)$. This implies in particular that $g(1)=1$.

We will need the following fact. If $x$ is such that $g(x)=n$, where $n=p q$, and $p, q$ are prime numbers congruent to 2 modulo 3 , then $x$ is prime. Indeed, if $x=y z, y, z \geq 2$, then $g(x)=g(y) g(z)$. This implies that $n$ can be factored as the product of two numbers in $3 \mathbb{N}+1$, which is not true.

Now choose two distinct numbers $p$ and $q$ that are congruent to 2 modulo 3 (for example, 2 and 5). Then $p q, p^{2}$, and $q^{2}$ are all in the image of $g$. Let $g(a)=p^{2}$, $g(b)=q^{2}$, and $g(c)=p q$. We have

$$
g\left(c^{2}\right)=g(c)^{2}=p^{2} q^{2}=g(a) g(b)=g(a b) .
$$

It follows that $c^{2}=a b$, with $a, b$, and $c$ distinct prime numbers, and this is impossible. Therefore, such a function $f$ does not exist.

(Balkan Mathematical Olympiad, 1991)

704. We will prove that a sequence of positive integers satisfying the double inequality from the statement terminates immediately. Precisely, we show that if $a_{1}, a_{2}, \ldots, a_{N}$ satisfy the relation from the statement for $n=1,2, \ldots, N$, then $N \leq 5$.

Arguing by contradiction, let us assume that the sequence has a sixth term $a_{6}$. Set $b_{n}=a_{n+1}-a_{n}, n=1, \ldots, 5$. The relation from the statement implies $a_{n} \geq a_{n-1}$ for $n \geq 2$, and so $b_{n}$ is a nonnegative integer for $n=1, \ldots, 5$. For $n=2,3,4$ we have 

$$
\begin{gathered}
-a_{n} \leq-b_{n}^{2} \leq-a_{n-1} \\
a_{n} \leq b_{n+1}^{2} \leq a_{n+1}
\end{gathered}
$$

Adding these two inequalities, we obtain

$$
0 \leq b_{n+1}^{2}-b_{n}^{2} \leq b_{n}+b_{n-1},
$$

or

$$
0 \leq\left(b_{n+1}-b_{n}\right)\left(b_{n+1}+b_{n}\right) \leq b_{n}+b_{n-1}
$$

Therefore, $b_{n+1} \geq b_{n}$ for $n=2,3,4$. If for $n=3$ or $n=4$ this inequality were strict, then for that specific $n$ we would have

$$
0<b_{n+1}^{2}-b_{n}^{2} \leq b_{n}+b_{n-1}<b_{n+1}+b_{n}
$$

with the impossible consequence $0<b_{n+1}-b_{n}<1$. It follows that $b_{3}=b_{4}=b_{5}$. Combining this with the inequality from the statement, namely with

$$
b_{3}^{2} \leq a_{3} \leq b_{4}^{2} \leq a_{4} \leq b_{5}^{2},
$$

we find that $a_{3}=a_{4}$. But then $b_{3}=a_{4}-a_{3}=0$, which would imply $a_{2} \leq b_{3}^{2}=0$, a contradiction. We conclude that the sequence can have at most five terms. This limit is sharp, since $a_{1}=1, a_{2}=3, a_{3}=4, a_{4}=6, a_{5}=8$ satisfies the condition from the statement.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1985 , proposed by L. Panaitopol)

705. Setting $x=y=z=0$ we find that $f(0)=3(f(0))^{3}$. This cubic equation has the unique integer solution $f(0)=0$. Next, with $y=-x$ and $z=0$ we have $f(0)=$ $(f(x))^{3}+(f(-x))^{3}+(f(0))^{3}$, which yields $f(-x)=-f(x)$ for all integers $x$; hence $f$ is an odd function. Now set $x=1, y=z=0$ to obtain $f(1)=(f(1))^{3}+2(f(0))^{3}$; hence $f(1)=f(1)^{3}$. Therefore, $f(1) \in\{-1,0,1\}$. Continuing with $x=y=1$ and $z=0$ and $x=y=z=1$ we find that $f(2)=2(f(1))^{3}=2 f(1)$ and $f(3)=3(f(1))^{3}=3 f(1)$. We conjecture that $f(x)=x f(1)$ for all integers $x$. We will do this by strong induction on the absolute value of $x$, and for that we need the following lemma.

Lemma. If $x$ is an integer whose absolute value is greater than 3, then $x^{3}$ can be written as the sum of five cubes whose absolute values are less than $x$.

Proof. We have

$$
\begin{array}{ll}
4^{3}=3^{3}+3^{3}+2^{3}+1^{3}+1^{3}, & 5^{3}=4^{3}+4^{3}+(-1)^{3}+(-1)^{3}+(-1)^{3}, \\
6^{3}=5^{3}+4^{3}+3^{3}+0^{3}+0^{3}, & 7^{3}=6^{3}+5^{3}+1^{3}+1^{3}+0^{3}
\end{array}
$$

and if $x=2 k+1$ with $k>3$, then

$$
x^{3}=(2 k+1)^{3}=(2 k-1)^{3}+(k+4)^{3}+(4-k)^{3}+(-5)^{3}+(-1)^{3} .
$$

In this last case it is not hard to see that $2 k-1, k+4,|4-k|, 5$, and 1 are all less than $2 k+1$. If $x>3$ is an arbitrary integer, then we write $x=m y$, where $y$ is 4,6 , or an odd number greater than 3 , and $m$ is an integer. If we express $y^{3}=y_{1}^{3}+y_{2}^{3}+y_{3}^{3}+y_{4}^{3}+y_{5}^{3}$, then $x^{3}=\left(m y_{1}\right)^{3}+\left(m y_{2}\right)^{3}+\left(m y_{3}\right)^{3}+\left(m y_{4}\right)^{3}+\left(m y_{5}\right)^{3}$, and the lemma is proved.

Returning to the problem, using the fact that $f$ is odd and what we proved before, we see that $f(x)=x f(1)$ for $|x| \leq 3$. For $x>4$, suppose that $f(y)=y f(1)$ for all $y$ with $|y|<|x|$. Using the lemma write $x^{3}=x_{1}^{3}+x_{2}^{3}+x_{3}^{3}+x_{4}^{3}+x_{5}^{3}$, where $\left|x_{i}\right|<|x|$, $i=1,2,3,4,5$. After writing

$$
x^{3}+\left(-x_{4}\right)^{3}+\left(-x_{5}\right)^{3}=x_{1}^{3}+x_{2}^{3}+x_{3}^{3},
$$

we apply $f$ to both sides and use the fact that $f$ is odd and the condition from the statement to obtain

$$
(f(x))^{3}-\left(f\left(x_{4}\right)\right)^{3}-\left(f\left(x_{5}\right)\right)^{3}=f\left(x_{1}\right)^{3}+f\left(x_{2}\right)^{3}+f\left(x_{3}\right)^{3} .
$$

The inductive hypothesis yields

$$
(f(x))^{3}-\left(x_{4} f(1)\right)^{3}-\left(x_{5} f(1)\right)^{3}=\left(x_{1} f(1)\right)^{3}+\left(x_{2} f(1)\right)^{3}+\left(x_{3} f(1)\right)^{3} ;
$$

hence

$$
(f(x))^{3}=\left(x_{1}^{3}+x_{2}^{3}+x_{3}^{3}+x_{4}^{3}+x_{5}^{3}\right)(f(1))^{3}=x^{3}(f(1))^{3} .
$$

Hence $f(x)=x f(1)$, and the induction is complete. Therefore, the only answers to the problem are $f(x)=-x$ for all $x, f(x)=0$ for all $x$, and $f(x)=x$ for all $x$. That these satisfy the given equation is a straightforward exercise.

(American Mathematical Monthly, proposed by T. Andreescu)

706. The number on the left ends in a $0,1,4,5,6$, or 9 , while the one on the right ends in a $0,2,3,5,7$, or 8 . For equality to hold, both $x$ and $z$ should be multiples of 5 , say $x=5 x_{0}$ and $z=5 z_{0}$. But then $25 x_{0}^{2}+10 y^{2}=3 \cdot 25 z^{2}$. It follows that $y$ is divisible by 5 as well, $y=5 y_{0}$. The positive integers $x_{0}, y_{0}, z_{0}$ satisfy the same equation, and continuing we obtain an infinite descent. Since this is not possible, the original equation does not have positive integer solutions.

707. It suffices to show that there are no positive solutions. Adding the two equations, we obtain

$$
6\left(x^{2}+y^{2}\right)=z^{2}+t^{2} .
$$

So 3 divides $z^{2}+t^{2}$. Since the residue of a square modulo 3 is either 0 or 1 , this can happen only if both $z$ and $t$ are divisible by 3 , meaning that $z=3 z_{1}, t=3 t_{1}$. But then

$$
6\left(x^{2}+y^{2}\right)=9\left(z_{1}^{2}+t_{1}^{2}\right),
$$

and hence $x^{2}+y^{2}$ is divisible by 3 . Again, this can happen only if $x=3 x_{1}$, and $y=3 y_{1}$, with $x_{1}, y_{1}$ positive integers. So $\left(x_{1}, y_{1}, z_{1}, t_{1}\right)$ is another solution. We construct inductively a decreasing infinite sequence of positive solutions, which, of course, cannot exist. Hence the system does not admit nontrivial solutions.

(W. Sierpiński, 250 Problems in Elementary Number Theory, Państwowe Wydawnictwo Naukowe, Warsawa, 1970)

708. Assume that the positive integers $x, y, z$ satisfy the given equation, and let $d=x y$. If $d=1$, then $x=y=1$ and $z=0$, which cannot happen. Hence $d>1$. Let $p$ be a prime divisor of $d$. Because

$$
(x+y)(x-y)=x^{2}-y^{2}=2 x y z \equiv 0(\bmod p),
$$

either $x \equiv y(\bmod p)$ or $x \equiv-y(\bmod p)$. But $p$ divides one of $x$ and $y$, so $p$ must divide the other, too. Hence $x_{1}=x / p$ and $y_{1}=y / p$ are positive integers, and $x_{1}, y_{1}, z$ satisfy the given equation as well. Repeating the argument, we construct an infinite sequence of solutions $\left(x_{n}, y_{n}, z\right), n \geq 1$, to the original equation, with $x_{1}>x_{2}>x_{3}>\cdots$. This is, of course, impossible; hence the equation has no solutions.

(T. Andreescu, D. Andrica, An Introduction to Diophantine Equations, GIL, 2002) 

709. If $\left(a_{n}^{2}\right)_{n}$ is an infinite arithmetic progression, then

$$
a_{k+1}^{2}-a_{k}^{2}=a_{k}^{2}-a_{k-1}^{2}, \quad \text { for } k \geq 2 .
$$

Such an arithmetic progression must be increasing, so $a_{k+1}+a_{k}>a_{k}+a_{k-1}$. Combining the two relations, we obtain $a_{k+1}-a_{k}<a_{k}-a_{k-1}$, for all $k \geq 2$. We have thus obtained an infinite descending sequence of positive integers

$$
a_{2}-a_{1}>a_{3}-a_{2}>a_{4}-a_{3}>\cdots .
$$

Clearly, such a sequence cannot exist. Hence there is no infinite arithmetic progression whose terms are perfect squares.

Remark. In fact, much more is true. No four perfect squares can form an arithmetic progression.

(T.B. Soulami, Les olympiades de mathématiques: Réflexes et stratégies, Ellipses, 1999) 

710. Assume that the property does not hold, and fix $a$. Only finitely many numbers of the form $f(a+k)$ can be less than $a$, so we can choose $r$ such that $f(a+n r)>f(a)$ for all $n$. By our assumption $f\left(a+2^{m+1} r\right)<f\left(a+2^{m} r\right)$ for all $m$, for otherwise $a$ and $d=2^{m} r$ would satisfy the desired property. We have constructed an infinite descending sequence of positive integers, a contradiction. Hence the conclusion.

(British Mathematical Olympiad, 2003)

711. We will apply Fermat's infinite descent method to the prime factors of $n$.

Let $p_{1}$ be a prime divisor of $n$, and $q$ the smallest positive integer for which $p_{1}$ divides $2^{q}-1$. From Fermat's little theorem it follows that $p_{1}$ also divides $2^{p_{1}-1}-1$. Hence $q \leq p_{1}-1<p_{1}$.

Let us prove that $q$ divides $n$. If not, let $n=k q+r$, where $0<r<q$. Then

$$
\begin{aligned}
2^{n}-1 &=2^{k q} \cdot 2^{r}-1=\left(2^{q}\right)^{k} \cdot 2^{r}-1=\left(2^{q}-1+1\right)^{k} \cdot 2^{r}-1 \\
&=\sum_{j=1}^{k}\left(\begin{array}{l}
k \\
j
\end{array}\right)\left(2^{q}-1\right)^{j} \cdot 2^{r}-1 \equiv 2^{r}-1\left(\bmod p_{1}\right) .
\end{aligned}
$$

It follows that $p_{1}$ divides $2^{r}-1$, contradicting the minimality of $q$. Hence $q$ divides $n$, and $1<q<p_{1}$. Let $p_{2}$ be a prime divisor of $q$. Then $p_{2}$ is also a divisor of $n$, and $p_{2}<p_{1}$. Repeating the argument, we construct an infinite sequence of prime divisors of $n, p_{1}>p_{2}>\cdots$, which is impossible. Hence the conclusion.

(1st W.L. Putnam Mathematical Competition, 1939)

712. The divisibility condition can be written as

$$
k(a b+a+b)=a^{2}+b^{2}+1,
$$

where $k$ is a positive integer. The small values of $k$ are easy to solve. For example, $k=1$ yields $a b+a+b=a^{2}+b^{2}+1$, which is equivalent to $(a-b)^{2}+(a-1)^{2}+(b-1)^{2}=0$, whose only solution is $a=b=1$. Also, for $k=2$ we have $2 a b+2 a+2 b=a^{2}+b^{2}+1$. This can be rewritten either as $4 a=(b-a-1)^{2}$ or as $4 b=(b-a+1)^{2}$, showing that both $a$ and $b$ are perfect squares. Assuming that $a \leq b$, we see that $(b-a-1)-(b-a+1)=2$, and hence $a$ and $b$ are consecutive squares. We obtain as an infinite family of solutions the pairs of consecutive perfect squares.

Now let us examine the case $k \geq 3$. This is where we apply Fermat's infinite descent method. Again we assume that $a \leq b$. A standard approach is to interpret the divisibility condition as a quadratic equation in $b$ :

$$
b^{2}-k(a+1) b+\left(a^{2}-k a+1\right)=0 .
$$

Because one of the roots, namely $b$, is an integer, the other root must be an integer, too (the sum of the roots is $k(a+1)$ ). Thus we may substitute the pair $(a, b)$ by the smaller pair $(r, a)$, provided that $0<r<a$. Let us verify first that $0<r$. Assume the contrary. Since $b r=a^{2}-k a+1$, we must have $a^{2}-k a+1 \leq 0$. The equality case is impossible, since $a(k-a)=1$ cannot hold if $k \geq 3$. If $a^{2}-k a+1<0$, the original divisibility condition implies $b(b-a k-k)=a k-a^{2}-1>0$, hence $b-a k-k>0$. But then $b(b-a k-k)>$ $(a k+k) \cdot 1>a k-a^{2}-1$, a contradiction. This proves that $r$ is positive. From the fact that $b r=a^{2}-k a+1<a^{2}$ and $b \geq a$, it follows that $r<a$. Successively, we obtain the sequence of pairs of solutions to the original problem $\left(a_{1}, b_{1}\right)=(a, b),\left(a_{2}, b_{2}\right)=(r, a)$, $\left(a_{3}, b_{3}\right), \ldots$, with $a_{i} \leq b_{i}$ and $a_{1}>a_{2}>a_{3}>\cdots, b_{1}>b_{2}>b_{3}>\cdots$, which of course is impossible. This shows that the ratio of $a^{2}+b^{2}+1$ to $a b+a+b$ cannot be greater than or equal to 3 , and so the answer to the problem consists of the pair $(1,1)$ together with all pairs of consecutive perfect squares.

\section{(Mathematics Magazine)}

713. We argue by contradiction: assuming the existence of one triple that does not satisfy the property from the statement, we construct an infinite decreasing sequence of such triples. So let $\left(x_{0}, y_{0}, z_{0}\right)$ be a triple such that $x_{0} y_{0}-z_{0}^{2}=1$, but for which there do not exist nonnegative integers $a, b, c, d$ such that $x_{0}=a^{2}+b^{2}, y_{0}=c^{2}+d^{2}$, and $z_{0}=a c+b d$. We can assume that $x_{0} \leq y_{0}$, and also $x_{0} \geq 2$, for if $x_{0}=1$, then $x_{0}=1^{2}+0^{2}, y_{0}=z_{0}^{2}+1^{2}$, and $z_{0}=z_{0} \cdot 1+0 \cdot 1$. We now want to construct a new triple $\left(x_{1}, y_{1}, z_{1}\right)$ satisfying $x_{1}^{2} y_{1}^{2}-z_{1}^{2}=1$ such that $x_{1}+y_{1}+z_{1}<x_{0}+y_{0}+z_{0}$. To this end, set $z_{0}=x_{0}+u$. Then

$$
\begin{aligned}
1 &=x_{0} y_{0}-\left(x_{0}+u\right)^{2}=x_{0} y_{0}-x_{0}^{2}-2 x_{0} u+u^{2} \\
&=x_{0}\left(y-x_{0}-2 u\right)-u^{2}=x_{0}\left(x_{0}+y_{0}-2 z_{0}\right)-\left(z_{0}-x_{0}\right)^{2} .
\end{aligned}
$$

A good candidate for the new triple is $\left(x_{1}, y_{1}, z_{1}\right)$ with $x_{1}=\min \left(x_{0}, x_{0}+y_{0}-2 z_{0}\right)$, $y_{1}=\max \left(x_{0}, x_{0}+y_{0}-2 z_{0}\right), z_{1}=z_{0}-x_{0}$. Note that $x_{1}+y_{1}+z_{1}=x_{0}+y_{0}-z_{0}<$ $x_{0}+y_{0}+z_{0}$.

First, let us verify that $x_{1}, y_{1}, z_{1}$ are positive. From

$$
z_{0}^{2}=x_{0} y_{0}-1<x_{0} y_{0} \leq\left(\frac{x_{0}+y_{0}}{2}\right)^{2}
$$

we deduce that $x_{0}+y_{0}>2 z_{0}$, which means that $x_{0}+y_{0}-2 z_{0}>0$. It follows that both $x_{1}$ and $y_{1}$ are positive. Also,

$$
z_{0}^{2}=x_{0} y_{0}-1 \geq x_{0}^{2}-1,
$$

which implies $\left(z_{0}-x_{0}\right)\left(z_{0}+x_{0}\right) \geq-1$. Since $z_{0}+x_{0} \geq 3$, this can happen only if $z_{0} \geq x_{0}$. Equality would yield $x_{0}\left(y_{0}-x_{0}\right)=1$, which cannot hold in view of the assumption $x_{0} \geq 2$. Hence $z_{1}=z_{0}-x_{0}>0$. If the new triple satisfied the condition from the statement, we would be able to find nonnegative integers $m, n, p, q$ such that 

$$
x_{0}=m^{2}+n^{2}, \quad x_{0}+y_{0}-2 z_{0}=p^{2}+q^{2}, \quad z_{0}-x_{0}=m p+n q .
$$

In that case,

$$
y_{0}=p^{2}+q^{2}+2 z_{0}-x_{0}=p^{2}+q^{2}+2 m p+2 n q+m^{2}+n^{2}=(m+p)^{2}+(n+q)^{2}
$$

and

$$
z_{0}=m(m+p)+n(n+q),
$$

contradicting our assumption.

We therefore can construct inductively an infinite sequence of triples of positive numbers $\left(x_{n}, y_{n}, z_{n}\right), n \geq 0$, none of which admits the representation from the statement, and such that $x_{n}+y_{n}+z_{n}>x_{n+1}+y_{n+1}+z_{n+1}$ for all $n$. This is of course impossible, and the claim is proved.

(short list of the 20th International Mathematical Olympiad, 1978)

714. First solution: Choose $k$ such that

$$
\lfloor x\rfloor+\frac{k}{n} \leq x<\lfloor x\rfloor+\frac{k+1}{n} .
$$

Then $\left\lfloor x+\frac{j}{n}\right\rfloor$ is equal to $\lfloor x\rfloor$ for $j=0,1, \ldots, n-k-1$, and to $\lfloor x\rfloor+1$ for $x=$ $n-k, \ldots, n-1$. It follows that the expression on the left is equal to $n\lfloor x\rfloor+k$. Also, $\lfloor n x\rfloor=n\lfloor x\rfloor+k$, which shows that the two sides of the identity are indeed equal.

Second solution: Define $f: \mathbb{R} \rightarrow \mathbb{N}$,

$$
f(x)=\lfloor x\rfloor+\left\lfloor x+\frac{1}{n}\right\rfloor+\cdots+\left\lfloor x+\frac{n-1}{n}\right\rfloor-\lfloor n x\rfloor .
$$

We have

$$
f\left(x+\frac{1}{n}\right)=\left\lfloor x+\frac{1}{n}\right\rfloor+\cdots+\left\lfloor x+\frac{n-1}{n}\right\rfloor+\left\lfloor x+\frac{n}{n}\right\rfloor-\lfloor n x+1\rfloor=f(x) .
$$

Therefore, $f$ is periodic, with period $\frac{1}{n}$. Also, since $f(x)=0$ for $x \in\left[0, \frac{1}{n}\right)$, it follows that $f$ is identically 0 , and the identity is proved.

(Ch. Hermite)

715. Denote the sum in question by $S_{n}$. Observe that

$$
\begin{aligned}
S_{n}-S_{n-1} &=\left\lfloor\frac{x}{n}\right\rfloor+\left\lfloor\frac{x+1}{n}\right\rfloor+\cdots+\left\lfloor\frac{x+n-1}{n}\right\rfloor \\
&=\left\lfloor\frac{x}{n}\right\rfloor+\left\lfloor\frac{x}{n}+\frac{1}{n}\right\rfloor+\cdots+\left\lfloor\frac{x}{n}+\frac{n-1}{n}\right\rfloor,
\end{aligned}
$$

and, according to Hermite's identity,

$$
S_{n}-S_{n-1}=\left\lfloor n \frac{x}{n}\right\rfloor=\lfloor x\rfloor .
$$

Because $S_{1}=\lfloor x\rfloor$, it follows that $S_{n}=n\lfloor x\rfloor$ for all $n \geq 1$.

(S. Savchev, T. Andreescu, Mathematical Miniatures, MAA, 2002)

716. Set $k=\lfloor\sqrt{n}\rfloor$. We want to prove that

$$
k=\left\lfloor\sqrt{n}+\frac{1}{\sqrt{n}+\sqrt{n+2}}\right\rfloor,
$$

which amounts to proving the double inequality

$$
k \leq \sqrt{n}+\frac{1}{\sqrt{n}+\sqrt{n+2}}<k+1 .
$$

The inequality on the left is obvious. For the other, note that $k \leq \sqrt{n}<k+1$, which implies $k^{2} \leq n \leq(k+1)^{2}-1$. Using this we can write

$$
\begin{aligned}
\sqrt{n}+\frac{1}{\sqrt{n}+\sqrt{n+2}} &=\sqrt{n}+\frac{\sqrt{n+2}-\sqrt{n}}{2}=\frac{\sqrt{n+2}+\sqrt{n}}{2} \\
& \leq \frac{\sqrt{(k+1)^{2}+1}+\sqrt{(k+1)^{2}-1}}{2}<k+1 .
\end{aligned}
$$

The last inequality in this sequence needs to be explained. Rewriting it as

$$
\frac{1}{2} \sqrt{(k+1)^{2}+1}+\frac{1}{2} \sqrt{(k+1)^{2}-1}<\sqrt{(k+1)^{2}},
$$

we recognize Jensen's inequality for the (strictly) concave function $f(x)=\sqrt{x}$. This completes the solution.

(Gh. Eckstein)

717. We apply the identity proved in the introduction to the function $f:[1, n] \rightarrow[1, \sqrt{n}]$, $f(x)=\sqrt{x}$. Because $n\left(G_{f}\right)=\lfloor\sqrt{n}\rfloor$, the identity reads

$$
\sum_{k=1}^{n}\lfloor\sqrt{k}\rfloor+\sum_{k=1}^{\lfloor\sqrt{n}\rfloor}\left\lfloor k^{2}\right\rfloor-\lfloor\sqrt{n}\rfloor=n\lfloor\sqrt{n}\rfloor .
$$

Hence the desired formula is

$$
\sum_{k=1}^{n}\lfloor\sqrt{k}\rfloor=(n+1) a-\frac{a(a+1)(2 a+1)}{6} .
$$

(Korean Mathematical Olympiad, 1997)

718. The function $f:\left[1, \frac{n(n+1)}{2}\right] \rightarrow \mathbb{R}$,

$$
f(x)=\frac{-1+\sqrt{1+8 x}}{2},
$$

is, in fact, the inverse of the increasing bijective function $g:[1, n] \rightarrow\left[1, \frac{n(n+1)}{2}\right]$,

$$
g(x)=\frac{x(x+1)}{2} .
$$

We apply the identity proved in the introduction to $g$ in order to obtain

$$
\sum_{k=1}^{n}\left\lfloor\frac{k(k+1)}{2}\right\rfloor+\sum_{k=1}^{\frac{n(n+1)}{2}}\left\lfloor\frac{-1+\sqrt{1+8 k}}{2}\right\rfloor-n=\frac{n^{2}(n+1)}{2} .
$$

Note that $\frac{k(k+1)}{2}$ is an integer for all $k$, and so

$$
\begin{aligned}
\sum_{k=1}^{n}\left\lfloor\frac{k(k+1)}{2}\right\rfloor &=\sum_{k=1}^{n} \frac{k(k+1)}{2}=\frac{1}{2} \sum_{k=1}^{n}\left(k^{2}+k\right)=\frac{n(n+1)}{4}+\frac{n(n+1)(2 n+1)}{12} \\
&=\frac{n(n+1)(n+2)}{6} .
\end{aligned}
$$

The identity follows.

719. The property is clearly satisfied if $a=b$ or if $a b=0$. Let us show that if neither of these is true, then $a$ and $b$ are integers.

First, note that for an integer $x,\lfloor 2 x\rfloor=2\lfloor x\rfloor$ if $x-\lfloor x\rfloor \in\left[0, \frac{1}{2}\right)$ and $\lfloor 2 x\rfloor=2\lfloor x\rfloor+1$ if $x-\lfloor x\rfloor \in\left[\frac{1}{2}, 1\right)$. Let us see which of the two holds for $a$ and $b$. If $\lfloor 2 a\rfloor=2\lfloor a\rfloor+1$, then

$$
a\lfloor 2 b\rfloor=b\lfloor 2 a\rfloor=2\lfloor a\rfloor b+b=2 a\lfloor b\rfloor+b .
$$

This implies $\lfloor 2 b\rfloor=2\lfloor b\rfloor+\frac{b}{a}$, and so $\frac{b}{a}$ is either 0 or 1 , which contradicts our working hypothesis. Therefore, $\lfloor 2 a\rfloor=2\lfloor a\rfloor$ and also $\lfloor 2 b\rfloor=2\lfloor b\rfloor$. This means that the fractional parts of both $a$ and $b$ are less than $\frac{1}{2}$. With this as the base case, we will prove by induction that $\left\lfloor 2^{m} a\right\rfloor=2^{m}\lfloor a\rfloor$ and $\left\lfloor 2^{m} b\right\rfloor=2^{m}\lfloor b\rfloor$ for all $m \geq 1$.

The inductive step works as follows. Assume that the property is true for $m$ and let us prove it for $m+1$. If $\left\lfloor 2^{m+1} a\right\rfloor=2\left\lfloor 2^{m} a\right\rfloor$, we are done. If $\left\lfloor 2^{m+1} a\right\rfloor=2\left\lfloor 2^{m} a\right\rfloor+1$, then

$$
a\left\lfloor 2^{m+1} b\right\rfloor=b\left\lfloor 2^{m+1} a\right\rfloor=2\left\lfloor 2^{m} a\right\rfloor b+b=2^{m+1}\lfloor a\rfloor b+b=2^{m+1} a\lfloor b\rfloor+1 .
$$

As before, we deduce that $\left\lfloor 2^{m+1} b\right\rfloor=2^{m+1}\lfloor b\rfloor+\frac{b}{a}$. Again this is an impossibility. Hence the only possibility is that $\left\lfloor 2^{m+1} a\right\rfloor=2^{m+1}\lfloor a\rfloor$ and by a similar argument $\left\lfloor 2^{m+1} b\right\rfloor=$ $2^{m+1}\lfloor b\rfloor$. This completes the induction.

From $\left\lfloor 2^{m} a\right\rfloor=2^{m}\lfloor a\rfloor$ and $\left\lfloor 2^{m} b\right\rfloor=2^{m}\lfloor b\rfloor$ we deduce that the fractional parts of $a$ and $b$ are less than $\frac{1}{2^{m}}$. Taking $m \rightarrow \infty$, we conclude that $a$ and $b$ are integers.

(short list of the 39th International Mathematical Olympiad, 1998)

720. Ignoring the "brackets" we have

$$
\frac{p}{q}+\frac{2 p}{q}+\cdots+\frac{(q-1) p}{q}=\frac{(q-1) p}{2} .
$$

The difference between $k p / q$ and $\lfloor k p / q\rfloor$ is $r / q$, where $r$ is the remainder obtained on dividing $k p$ by $q$. Since $p$ and $q$ are coprime, $p, 2 p, \ldots,(q-1) p$ form a complete set of residues modulo $q$. So for $k=1,2, \ldots, q-1$, the numbers $k / p-\lfloor k p / q\rfloor$ are a permutation of $1,2, \ldots, q-1$. Therefore,

$$
\sum_{k=1}^{q-1}\left\lfloor\frac{k p}{q}\right\rfloor=\sum_{k=1}^{q-1} \frac{k p}{q}-\sum_{k=1}^{q-1} \frac{k}{q}=\frac{(q-1) p}{2}-\frac{q-1}{2}=\frac{(p-1)(q-1)}{2},
$$

and the reciprocity law follows.

721. The function

$$
f(x)=\lfloor n x\rfloor-\frac{\lfloor x\rfloor}{1}-\frac{\lfloor 2 x\rfloor}{2}-\frac{\lfloor 3 x\rfloor}{3}-\cdots-\frac{\lfloor n x\rfloor}{n}
$$

satisfies $f(x)=f(x+1)$ for all $x$ and $f(0)=0$. Moreover, the function is constant on subintervals of $[0,1)$ that do not contain numbers of the form $p / q, 2 \leq q \leq n$ and $1 \leq p \leq q-1$. Thus it suffices to verify the inequality for $x=p / q$, where $p$ and $q$ are coprime positive integers, $2 \leq q \leq n, 1 \leq p \leq q-1$. Subtracting the inequality from

$$
x=\frac{x}{1}+\frac{2 x}{2}+\cdots+\frac{n x}{n},
$$

we obtain the equivalent inequality for the fractional part $\{\cdot\}(\{x\}=x-\lfloor x\rfloor)$,

$$
\{n x\} \leq \frac{\{x\}}{1}+\frac{\{2 x\}}{2}+\frac{\{3 x\}}{3}+\cdots+\frac{\{n x\}}{n},
$$

which we prove for the particular values of $x$ mentioned above. If $r_{k}$ is the remainder obtained on dividing $k p$ by $q$, then $\{k x\}=\frac{r_{k}}{q}$, and so the inequality can be written as

$$
\frac{r_{n}}{q} \leq \frac{r_{1} / q}{1}+\frac{r_{2} / q}{2}+\frac{r_{3} / q}{3}+\cdots+\frac{r_{n} / q}{n},
$$

or

$$
r_{n} \leq \frac{r_{1}}{1}+\frac{r_{2}}{2}+\frac{r_{3}}{3}+\cdots+\frac{r_{n}}{n} .
$$

Truncate the sum on the right to the $(q-1)$ st term. Since $p$ and $q$ are coprime, the numbers $r_{1}, r_{2}, \ldots, r_{q-1}$ are a permutation of $1,2, \ldots, q-1$. Applying this fact and the AM-GM inequality, we obtain

$$
\frac{r_{1}}{1}+\frac{r_{2}}{2}+\frac{r_{3}}{3}+\cdots+\frac{r_{q-1}}{q-1} \geq(q-1)\left(\frac{r_{1}}{1} \cdot \frac{r_{2}}{2} \cdot \frac{r_{3}}{3} \cdots \frac{r_{q-1}}{q-1}\right)^{1 /(q-1)}=(q-1) \geq r_{n}
$$

This proves the (weaker) inequality

$$
\frac{r_{1}}{1}+\frac{r_{2}}{2}+\frac{r_{3}}{3}+\cdots+\frac{r_{n}}{n} \geq r_{n},
$$

and consequently the inequality from the statement of the problem.

(O.P. Lossers)

722. Let $x_{1}$ be the golden ratio, i.e., the (unique) positive root of the equation $x^{2}-x-1=$ 0 . We claim that the following identity holds:

$$
\left\lfloor x_{1}\left\lfloor x_{1} n+\frac{1}{2}\right\rfloor+\frac{1}{2}\right\rfloor=\left\lfloor x_{1}+\frac{1}{2}\right\rfloor+n .
$$

If this were so, then the function $f(n)=\left\lfloor x_{1} n+\frac{1}{2}\right\rfloor$ would satisfy the functional equation. Also, since $\alpha=\frac{1+\sqrt{5}}{2}>1, f$ would be strictly increasing, and so it would provide an example of a function that satisfies the conditions from the statement.

To prove the claim, we only need to show that

$$
\left[\left(x_{1}-1\right)\left[x_{1} n+\frac{1}{2}\right\rfloor+\frac{1}{2}\right\rfloor=n
$$

We have

$$
\begin{aligned}
\left\lfloor\left(x_{1}-1\right)\left[x_{1} n+\frac{1}{2}\right\rfloor+\frac{1}{2}\right\rfloor & \leq\left\lfloor\left(x_{1}-1\right)\left(x_{1} n+\frac{1}{2}\right)+\frac{1}{2}\right\rfloor \\
&=\left\lfloor x_{1} n+n-x_{1} n+\frac{x_{1}}{2}\right\rfloor=n
\end{aligned}
$$

Also,

$$
n=\left\lfloor n+\frac{2-x_{1}}{2}\right\rfloor \leq\left\lfloor\left(x_{1}-1\right)\left(x_{1} n-\frac{1}{2}\right)+\frac{1}{2}\right\rfloor \leq\left[\left(x_{1}-1\right)\left[x_{1} n+\frac{1}{2}\right\rfloor+\frac{1}{2}\right\rfloor .
$$

This proves the claim and completes the solution.

(34th International Mathematical Olympiad, 1993)

723. Suppose first that the pair $(f, g)$ is not unique and that there is a second pair of functions $\left(f^{\prime}, g^{\prime}\right)$ subject to the same conditions. Write the sets $\{f(n), n \geq 1\} \cup\{g(n), n \geq 1\}$, respectively, $\left\{f^{\prime}(n), n \geq 1\right\} \cup\left\{g^{\prime}(n), n \geq 1\right\}$, as increasing sequences, and let $n_{0}$ be the smallest number where a difference occurs in the values of $f(n)$ and $g(n)$ versus $f^{\prime}(n)$ and $g^{\prime}(n)$. Because the pairs of functions exhaust the positive integers, either $f\left(n_{1}\right)=g^{\prime}\left(n_{0}\right)$ or $f^{\prime}\left(n_{0}\right)=g\left(n_{1}\right)$. The situations are symmetric, so let us assume that the first occurs. Then

$$
f\left(n_{1}\right)=g^{\prime}\left(n_{0}\right)=f^{\prime}\left(f^{\prime}\left(k n_{0}\right)\right)+1=f\left(f\left(k n_{0}\right)\right)+1=g\left(n_{0}\right) .
$$

We stress that the third equality occurs because $f^{\prime}\left(k n_{0}\right)$ occurs earlier in the sequence (since it is smaller than $\left.f\left(n_{1}\right)\right)$, so it is equal to $f\left(k n_{0}\right)$, and the same is true for $f^{\prime}\left(f^{\prime}\left(k n_{0}\right)\right)$. But the equality $f\left(n_{1}\right)=g\left(n_{0}\right)$ is ruled out by the hypothesis, which shows that our assumption was false. Hence the pair $(f, g)$ is unique.

Inspired by the previous problems we take $\alpha$ to be the positive root of the quadratic equation $k x^{2}-k x-1=0$, and set $\beta=k \alpha^{2}$. Then $\frac{1}{\alpha}+\frac{1}{\beta}=1$, and because $k$ is an integer, both $\alpha$ and $\beta$ are irrational. By Beatty's theorem the sequences $f(n)=\lfloor\alpha n\rfloor$ and $g(n)=\lfloor\beta n\rfloor$ are strictly increasing and define a partition of the positive integers into two disjoint sets. Let us show that $f$ and $g$ satisfy the functional equation from the statement.

Because $k \alpha^{2}=k \alpha+1$,

$$
g(n)=\left\lfloor k \alpha^{2} n\right\rfloor=\lfloor(k \alpha+1) n\rfloor=\lfloor k \alpha n\rfloor+n,
$$

and we are left to prove that $\lfloor\alpha k n\rfloor+n=\lfloor\alpha\lfloor\alpha k n\rfloor\rfloor+1$, the latter being $f(f(k n))+1$. Reduce this further to

$$
\lfloor(\alpha-1)\lfloor\alpha k n\rfloor\rfloor=n-1 .
$$

Since $(\alpha-1) \alpha k=1$ and $\alpha$ is irrational, $\lfloor(\alpha-1)\lfloor\alpha k n\rfloor\rfloor<n$. Also,

$$
(\alpha-1)\lfloor\alpha k n\rfloor>(\alpha-1)(\alpha k n-1)=\left(\alpha^{2} k-\alpha k\right) n+1-\alpha=n+1-\alpha>n-1,
$$

since $\alpha<2$ (which can be checked by solving the quadratic equation that defines $\alpha$ ). Hence

$$
g(n)=\lfloor\alpha k n\rfloor+n=\lfloor\alpha\lfloor\alpha n\rfloor\rfloor+1=f(f(k n))+1,
$$

and the problem is solved. Remark. The case $k=1$ was given at the 20th International Mathematical Olympiad, 1978; the idea of the solution was taken from I.J. Schoenberg, Mathematical Time Exposures (MAA, 1982).

724. If we multiplied the fraction by 8 , we would still get an integer. Note that

$$
8 \frac{n^{3}-3 n^{2}+4}{2 n-1}=4 n^{2}-10 n-5+\frac{27}{2 n-1} .
$$

Hence $2 n-1$ must divide 27 . This happens only when $2 n-1=\pm 1, \pm 3, \pm 9, \pm 27$, that is, when $n=-13,-4,-1,1,2,5,14$. An easy check shows that for each of these numbers the original fraction is an integer.

725. The factor to be erased is 50 !. Indeed, using the equality $(2 k) !=(2 k-1) ! \cdot 2 k$, we see that

$$
\begin{aligned}
P &=(1 !)^{2} \cdot 2 \cdot(3 !)^{2} \cdot 4 \cdot(5 !)^{2} \cdot 6 \cdots(99 !)^{2} \cdot 100=(1 ! \cdot 3 ! \cdot 5 ! \cdots 99 !)^{2} \cdot 2 \cdot 4 \cdot 6 \cdots 100 \\
&=(1 ! \cdot 3 ! \cdot 5 ! \cdots 99 !)^{2} \cdot 2^{50} \cdot 50 !=\left(1 ! \cdot 3 ! \cdot 5 ! \cdots 99 ! \cdot 2^{25}\right)^{2} \cdot 50 !
\end{aligned}
$$

It is noteworthy that $P$ itself is not a perfect square, since 50 ! is not, the latter because 47 appears to the first power in 50 !.

(first stage of the Moscow Mathematical Olympiad, 1995-1996)

726. For any integer $m$, we have $\operatorname{gcd}\left(a_{m}, a_{2 m}\right)=\operatorname{gcd}(2 m, m)=m$, and so $m$ divides $a_{m}$. It follows that for any other integer $n, m$ divides $a_{n}$ if and only if it divides $\operatorname{gcd}\left(a_{m}, a_{n}\right)=$ $\operatorname{gcd}(m, n)$. Hence $a_{n}$ has exactly the same divisors as $n$, so it must equal $n$, for all $n$.

(Russian Mathematical Olympiad, 1995)

727. Because $\operatorname{gcd}(a, b)$ divides both $a$ and $b$, we can factor $n^{\operatorname{gcd}(a, b)}-1$ from both $n^{a}-1$ and $n^{b}-1$. Therefore, $n^{\operatorname{gcd}(a, b)}-1$ divides $\operatorname{gcd}\left(n^{a}-1, n^{b}-1\right)$.

On the other hand, using Euclid's algorithm we can find positive integers $x$ and $y$ such that $a x-b y=\operatorname{gcd}(a, b)$. Then $n^{a}-1$ divides $n^{a x}-1$ and $n^{b}-1$ divides $n^{b y}-1$. In order to combine these two, we use the equality

$$
n^{b y}\left(n^{\operatorname{gcd}(a, b)}-1\right)=\left(n^{a x}-1\right)-\left(n^{b x}-1\right) .
$$

Note that $\operatorname{gcd}\left(n^{a}-1, n^{b}-1\right)$ divides the right-hand side, and has no common factor with $n^{b y}$. It therefore must divide $n^{\operatorname{gcd}(a, b)}-1$. We conclude that $n^{\operatorname{gcd}(a, b)}-1=\operatorname{gcd}\left(n^{a}-\right.$ $\left.1, n^{b}-1\right)$, as desired.

728. We use the particular case $n=2$ of the previous problem as a lemma. To obtain the negative signs we incorporate $2^{a}+1$ and $2^{b}+1$ into $2^{2 a}-1$ and $2^{2 b}-1$, then apply the lemma to these two numbers. We have

$$
2^{\operatorname{gcd}(2 a, 2 b)}-1=\operatorname{gcd}\left(2^{2 a}-1,2^{2 b}-1\right)=\operatorname{gcd}\left(\left(2^{a}-1\right)\left(2^{a}+1\right),\left(2^{b}-1\right)\left(2^{b}+1\right)\right) .
$$

Because $2^{a}-1$ and $2^{a}+1$ are coprime, and so are $2^{b}-1$ and $2^{b}+1$, this is further equal to

$$
\operatorname{gcd}\left(2^{a}-1,2^{b}-1\right) \cdot \operatorname{gcd}\left(2^{a}-1,2^{b}+1\right) \cdot \operatorname{gcd}\left(2^{a}+1,2^{b}-1\right) \cdot \operatorname{gcd}\left(2^{a}+1,2^{b}+1\right)
$$

It follows that $\operatorname{gcd}\left(2^{a}+1,2^{b}+1\right)$ divides $2^{\operatorname{gcd}(2 a, 2 b)}-1$. Of course,

$$
2^{\operatorname{gcd}(2 a, 2 b)}-1=2^{2 \operatorname{gcd}(a, b)}-1=\left(2^{\operatorname{gcd}(a, b)}-1\right)\left(2^{\operatorname{gcd}(a, b)}+1\right),
$$

so $\operatorname{gcd}\left(2^{a}+1,2^{b}+1\right)$ divides the product $\left(2^{\operatorname{gcd}(a, b)}-1\right)\left(2^{\operatorname{gcd}(a, b)}+1\right)$. Again because $\operatorname{gcd}\left(2^{a}+1,2^{a}-1\right)=\operatorname{gcd}\left(2^{b}+1,2^{b}-1\right)=1$, it follows that $\operatorname{gcd}\left(2^{a}+1,2^{b}+1\right)$ and $2^{\operatorname{gcd}(a, b)}-1$ do not have common factors. We conclude that $\operatorname{gcd}\left(2^{a}+1,2^{b}+1\right)$ divides $2^{\operatorname{gcd}(a, b)}+1$

729. We compute $a_{2}=(k+1)^{2}-k(k+1)+k=(k+1)+k=a_{1}+k, a_{3}=$ $a_{2}\left(a_{2}-k\right)+k=a_{2} a_{1}+k, a_{4}=a_{3}\left(a_{3}-k\right)+k=a_{3} a_{2} a_{1}+k$, and in general if $a_{n}=a_{n-1} a_{n-2} \cdots a_{1}+k$, then

$$
a_{n+1}=a_{n}\left(a_{n}-k\right)+k=a_{n} a_{n-1} a_{n-2} \cdots a_{1}+k .
$$

Therefore, $a_{n}-k$ is divisible by $a_{m}$, for $1 \leq m<n$. On the other hand, inductively we obtain that $a_{m}$ and $k$ are relatively prime. It follows that $a_{m}$ and $a_{n}=\left(a_{n}-k\right)+k$ are also relatively prime. This completes the solution.

(Polish Mathematical Olympiad, 2002)

730. By hypothesis, all coefficients of the quadratic polynomial

$$
\begin{aligned}
P(x)=&(x+a)(x+b)(x+c)-(x-d)(x-e)(x-f) \\
=&(a+b+c+d+e+f) x^{2}+(a b+b c+c a-d e-e f-f d) x \\
&+(a b c+d e f)
\end{aligned}
$$

are divisible by $S=a+b+c+d+e+f$. Evaluating $P(x)$ at $d$, we see that $P(d)=(a+d)(b+d)(c+d)$ is a multiple of $S$. This readily implies that $S$ is composite because each of $a+d, b+d$, and $c+d$ is less than $S$.

(short list of 46th International Mathematical Olympiad, 2005)

731. The polynomial

$$
P(n)=n(n-1)^{4}+1=n^{5}-4 n^{4}+6 n^{3}-4 n^{2}+n+1
$$

does not have integer zeros, so we should be able to factor it as a product a quadratic and a cubic polynomial. This means that

$$
P(n)=\left(n^{2}+a n+1\right)\left(n^{3}+b n^{3}+c n+1\right),
$$

for some integers $a, b, c$. Identifying coefficients, we must have

$$
\begin{aligned}
a+b &=-4, \\
c+a b+1 &=6, \\
b+a c+1 &=-4, \\
a+c &=1 .
\end{aligned}
$$

From the first and last equations, we obtain $b-c=-5$, and from the second and the third, $(b-c)(a-1)=10$. It follows that $a-1=-2$; hence $a=-1, b=-4+1=-3$, $c=1+1=2$. Therefore,

$$
n(n-1)^{4}+1=\left(n^{2}-n+1\right)\left(n^{3}-3 n^{2}+2 n+1\right),
$$

a product of integers greater than 1.

\section{(T. Andreescu)}

732. Setting $n=0$ in (i) gives

$$
f(1)^{2}=f(0)^{2}+6 f(0)+1=(f(0)+3)^{2}-8 .
$$

Hence

$$
(f(0)+3)^{2}-f(1)^{2}=(f(0)+3+f(1))(f(0)+3-f(1))=4 \times 2 .
$$

The only possibility is $f(0)+3+f(1)=4$ and $f(0)+3-f(1)=2$. It follows that $f(0)=0$ and $f(1)=1$.

In general,

$$
(f(2 n+1)-f(2 n))(f(2 n+1)+f(2 n))=6 f(n)+1 .
$$

We claim that $f(2 n+1)-f(2 n)=1$ and $f(2 n+1)+f(2 n)=6 f(n)+1$. To prove our claim, let $f(2 n+1)-f(2 n)=d$. Then $f(2 n+1)+f(2 n)=d+2 f(2 n)$. Multiplying, we obtain

$$
6 f(n)+1=d(d+2 f(2 n)) \geq d(d+2 f(n)),
$$

where the inequality follows from condition (ii). Moving everything to one side, we obtain the inequality

$$
d^{2}+(2 d-6) f(n)-1 \leq 0,
$$

which can hold only if $d \leq 3$. The cases $d=2$ and $d=3$ cannot hold, because $d$ divides $6 f(n)+1$. Hence $d=1$, and the claim is proved. From it we deduce that $f$ is computed recursively by the rule 

$$
\begin{aligned}
f(2 n+1) &=3 f(n)+1, \\
f(2 n) &=3 f(n) .
\end{aligned}
$$

At this moment it is not hard to guess the explicit formula for $f$; it associates to a number in binary representation the number with the same digits but read in ternary representation. For example, $f(5)=f\left(101_{2}\right)=101_{3}=10$.

733. It is better to rephrase the problem and prove that there are infinitely many prime numbers of the form $4 m-1$. Euclid's proof of the existence of infinitely many primes, presented in the first section of the book, works in this situation, too. Assume that there exist only finitely many prime numbers of the form $4 m-1$, and let these numbers be $p_{1}, p_{2}, \ldots, p_{n}$. Consider $M=4 p_{1} p_{2} p_{3} \cdots p_{n}-1$. This number is of the form $4 m-1$, so it has a prime divisor of the same form, for otherwise $M$ would be a product of numbers of the form $4 m+1$ and itself would be of the form $4 m+1$. But $M$ is not divisible by any of the primes $p_{1}, p_{2}, \ldots, p_{n}$, so it must be divisible by some other prime of the form $4 m-1$. This contradicts our assumption that $p_{1}, p_{2}, \ldots, p_{n}$ are all primes of the form $4 m-1$, showing that it was false. We conclude that there exist infinitely many prime numbers of the form $4 m+3, m$ an integer.

Remark. A highly nonelementary theorem of Dirichlet shows that for any two coprime numbers $a$ and $b$, the arithmetic progression $a n+b, n \geq 0$ contains infinitely many prime terms.

734. We have

$$
\begin{aligned}
\frac{m}{n} &=\frac{1}{1}-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots+\frac{1}{2 k-1}-\frac{1}{2 k} \\
&=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{2 k}-2\left(\frac{1}{2}+\frac{1}{4}+\cdots+\frac{1}{2 k}\right) \\
&=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{2 k}-\left(1+\frac{1}{2}+\cdots+\frac{1}{k}\right) \\
&=\frac{1}{k+1}+\frac{1}{k+2}+\cdots+\frac{1}{2 k-1}+\frac{1}{2 k} \\
&=\left(\frac{1}{k+1}+\frac{1}{2 k}\right)+\left(\frac{1}{k+2}+\frac{1}{2 k-1}\right)+\cdots \\
&=\frac{3 k+1}{(k+1) 2 k}+\frac{3 k+1}{(k+2)(2 k-1}+\cdots .
\end{aligned}
$$

It follows that $m(2 k) !=n(3 k+1) q$ for some positive integer $q$; hence $p=3 k+1$ divides $m(2 k)$ !. But $p$ is a prime greater than $2 k$, so it is coprime to $(2 k)$ !. Thus $p$ divides $m$, and we are done.

(Mathematical Reflections, proposed by T. Andreescu) 

735. The numbers $x$ and $y$ have the same prime factors,

$$
x=\prod_{i=1}^{k} p_{i}^{\alpha_{i}}, \quad y=\prod_{i=1}^{k} p_{i}^{\beta_{i}} .
$$

The equality from the statement can be written as

$$
\prod_{i=1}^{k} p_{i}^{\alpha_{i}(x+y)}=\prod_{i=1}^{k} p_{i}^{\beta_{i}(y-x)} ;
$$

hence $\alpha_{i}(y+x)=\beta_{i}(y-x)$ for $i=1,2, \ldots, k$. From here we deduce that $\alpha_{i}<\beta_{i}$, $i=1,2, \ldots, k$, and therefore $x$ divides $y$. Writing $y=z x$, the equation becomes $x^{x(z+1)}=(x z)^{x(z-1)}$, which implies $x^{2}=z^{z-1}$ and then $y^{2}=(x z)^{2}=z^{z+1}$. A power is a perfect square if either the base is itself a perfect square or if the exponent is even. For $z=t^{2}, t \geq 1$, we have $x=t^{t^{2}-1}, y=t^{t^{2}+1}$, which is one family of solutions. For $z-1=2 s, s \geq 0$, we obtain the second family of solutions $x=(2 s+1)^{s}, y=(2 s+1)^{s+1}$.

(Austrian-Polish Mathematics Competition, 1999, communicated by I. Cucurezeanu)

736. If $n$ is even, then we can write it as $(2 n)-n$. If $n$ is odd, let $p$ be the smallest odd prime that does not divide $n$. Then write $n=(p n)-((p-1) n)$. The number $p n$ contains exactly one more prime factor than $n$. As for $(p-1) n$, it is divisible by 2 because $p-1$ is even, while its odd factors are less than $p$, so they all divide $n$. Therefore, $(p-1) n$ also contains exactly one more prime factor than $n$, and therefore $p n$ and $(p-1) n$ have the same number of prime factors.

(Russian Mathematical Olympiad, 1999)

737. The only numbers that do not have this property are the products of two distinct primes.

Let $n$ be the number in question. If $n=p q$ with $p, q$ primes and $p \neq q$, then any cycle formed by $p, q, p q$ will have $p$ and $q$ next to each other. This rules out numbers of this form.

For any other number $n=p_{1}^{\alpha_{1}} p_{2}^{\alpha_{2}} \cdots p_{k}^{\alpha_{k}}$, with $k \geq 1, \alpha_{i} \geq 1$ for $i=1,2, \ldots, k$ and $\alpha_{1}+\alpha_{2} \geq 3$ if $k=2$, arrange the divisors of $n$ around the circle according to the following algorithm. First, we place $p_{1}, p_{2}, \ldots, p_{k}$ arranged clockwise around the circle in increasing order of their indices. Second, we place $p_{i} p_{i+1}$ between $p_{i}$ and $p_{i+1}$ for $i=1, \ldots, k-1$. (Note that the text has $p_{i+i}$, which is a typo and lets $i$ go up to $k$, which is a problem if $k=2$, since $p_{1} p_{2}$ gets placed twice.) Third, we place $n$ between $p_{k}$ and $p_{1}$. Note that at this point every pair of consecutive numbers has a common factor and each prime $p_{i}$ occurs as a common factor for some pair of adjacent numbers. Now for any remaining divisor of $n$ we choose a prime $p_{i}$ that divides it and place it between $p_{i}$ and one of its neighbors.

(USA Mathematical Olympiad, 2005, proposed by Z. Feng) 

738. The answer is negative. To motivate our claim, assume the contrary, and let $a_{0}, a_{1}, \ldots, a_{1995}=a_{0}$ be the integers. Then for $i=1,2, \ldots, 1995$, the ratio $a_{k-1} / a_{k}$ is either a prime, or the reciprocal of a prime. Suppose the former happens $m$ times and the latter $1995-m$ times. The product of all these ratios is $a_{0} / a_{1995}=1$, which means that the product of some $m$ primes equals the product of some $1995-m$ primes. This can happen only when the primes are the same (by unique factorization), and in particular they must be in the same number on both sides. But the equality $m=1995-m$ is impossible, since 1995 is odd, a contradiction. This proves our claim.

(Russian Mathematical Olympiad, 1995)

739. First solution: The cases $p=2,3,5$ are done as before. Let $p \geq 7$. The numbers $p, 2 p, \ldots, 9999999999 p$ have distinct terminating ten-digit sequences. Indeed, the difference $m p-n p=(m-n) p$ is not divisible by $10^{10}$, since $p$ is relatively prime to 10 and $m-n<10^{10}$. There are $10^{10}-1$ ten-digit terminating sequences, so all possible combinations of digits should occur. Many of these sequences consist of distinct digits, providing solutions to the problem.

Second solution: The statement is true for $p=2$ and $p=5$. Suppose that $p \neq 2$, 5. Then $p$ is relatively prime to 10 . From Fermat's little theorem, $10^{p-1} \equiv 1(\bmod p)$ and hence $10^{k(p-1)} \equiv 1(\bmod p)$ for all positive integers $k$. Let $a$ be a 10 -digit number with distinct digits, and let $a \equiv n(\bmod p)$, with $0 \leq n \leq p-1$. Since $p \geq 3,10^{6(p-1)}>10^{10}$. Therefore,

$$
N_{a}=10^{(p-n+5)(p-1)}+\cdots+10^{6(p-1)}+a \equiv 1+\cdots+1+n \equiv 0(\bmod p) .
$$

For all positive integers $k$, the numbers of the form

$$
10^{10} k p+N_{a},
$$

end in $a$ and are divisible by $p$.

(proposed by T. Andreescu for the 41st International Mathematical Olympiad, 2000, first solution by G. Galperin, second solution by Z. Feng)

740. The case $p=2$ is easy, so assume that $p$ is an odd prime. Note that if $p^{2}=a^{2}+2 b^{2}$, then $2 b^{2}=(p-a)(p+a)$. In particular, $a$ is odd. Also, $a$ is too small to be divisible by $p$. Hence $\operatorname{gcd}(p-a, p+a)=\operatorname{gcd}(p-a, 2 p)=2$. By changing the sign of $a$ we may assume that $p-a$ is not divisible by 4 , and so we must have $|p+a|=m^{2}$ and $|p-a|=2 n^{2}$ for some integers $m$ and $n$.

Because $|a|<p$, both $p+a$ and $p-a$ are actually positive, so $p+a=m^{2}$ and $p-a=2 n^{2}$. We obtain $2 p=m^{2}+2 n^{2}$. This can happen only if $m$ is even, in which case $p=n^{2}+2\left(\frac{m}{2}\right)^{2}$, as desired.

(Romanian Mathematical Olympiad, 1997) 

741. Note that if $d$ is a divisor of $n$, then so is $\frac{n}{d}$. So the sum $s$ is given by

$$
s=\sum_{i=1}^{k-1} d_{i} d_{i+1}=n^{2} \sum_{i=1}^{k-1} \frac{1}{d_{i} d_{i+1}} \leq n^{2} \sum_{i=1}^{k-1}\left(\frac{1}{d_{i}}-\frac{1}{d_{i+1}}\right)<\frac{n^{2}}{d_{1}}=n^{2} .
$$

For the second part, note also that $d_{2}=p, d_{k-1}=\frac{n}{p}$, where $p$ is the least prime divisor of $n$. If $n=p$, then $k=2$, and $s=p$, which divides $n^{2}$. If $n$ is composite, then $k>2$, and $S>d_{k-1} d_{k}=\frac{n^{2}}{p}$. If such an $s$ were a divisor of $n^{2}$, then $\frac{n^{2}}{s}$ would also be a divisor of $n^{2}$. But $1<\frac{n^{2}}{s}<p$, which is impossible, because $p$ is the least prime divisor of $n^{2}$. Hence the given sum is a divisor of $n^{2}$ if and only if $n$ is a prime.

(43rd International Mathematical Olympiad, 2002, proposed by M. Manea (Romania))

742. We look instead at composite odd positive numbers. Each such number can be written as $(2 a+3)(2 b+3)$, for $a$ and $b$ nonnegative integers. In fact, $n$ is composite if and only if it can be written this way. We only need to write this product as a difference of two squares. And indeed,

$$
(2 a+3)(2 b+3)=(a+b+3)^{2}-(a-b)^{2} .
$$

Thus we can choose $f(a, b)=(a+b+3)^{2}$ and $g(a, b)=(a-b)^{2}$.

(Nea Mărin)

743. Arguing by contradiction, assume that there is some $k, 0 \leq k \leq n-2$, such that $k^{2}+k+n$ is not prime. Choose $s$ to be the smallest number with this property, and let $p$ be the smallest prime divisor of $s^{2}+s+n$. First, let us notice that $p$ is rather small, in the sense that $p \leq 2 s$. For if $p \geq 2 s+1$, then

$$
\begin{aligned}
s^{2}+s+n & \geq p^{2} \geq(2 s+1)^{2}=s^{2}+s+3 s^{2}+3 s+1 \geq s^{2}+s+n+3 s+1 \\
&>s^{2}+s+n,
\end{aligned}
$$

which is because $s>\sqrt{\frac{\pi}{3}}$. This is clearly impossible, which proves our claim.

It follows that either $p=s-k$ or $p=s+k+1$ for some $0 \leq k \leq s-1$. But then for this $k$,

$$
s^{2}+s+n-k^{2}-k-n=(s-k)(s+k+1) .
$$

Because $p$ divides $s^{2}+s+n$ and the product $(s-k)(s+k+1)$, it must also divide $k^{2}+k+n$. Now, this number cannot be equal to $p$, because $s-k<n-k<k^{2}+k+n$ and $s+k+1<n-1+k+1<k^{2}+k+n$. It follows that the number $k^{2}+k+n$ is composite, contradicting the minimality of $s$. Hence the conclusion.

Remark. Euler noticed that 41 has the property that $k^{2}+k+41$ is a prime number for all $0 \leq k \leq 39$. Yet $40^{2}+40+41=41^{2}$ is not prime! 

744. There are clearly more 2's than 5's in the prime factorization of $n$ !, so it suffices to solve the equation

$$
\left\lfloor\frac{n}{5}\right\rfloor+\left\lfloor\frac{n}{5^{2}}\right\rfloor+\left\lfloor\frac{n}{5^{3}}\right\rfloor+\cdots=1000 .
$$

On the one hand,

$$
\left\lfloor\frac{n}{5}\right\rfloor+\left\lfloor\frac{n}{5^{2}}\right\rfloor+\left\lfloor\frac{n}{5^{3}}\right\rfloor+\cdots<\frac{n}{5}+\frac{n}{5^{2}}+\frac{n}{5^{3}}+\cdots=\frac{n}{5} \cdot \frac{1}{1-\frac{1}{5}}=\frac{n}{4},
$$

and hence $n>4000$. On the other hand, using the inequality $\lfloor a\rfloor>a-1$, we have

$$
\begin{aligned}
1000 &>\left(\frac{n}{5}-1\right)+\left(\frac{n}{5^{2}}-1\right)+\left(\frac{n}{5^{3}}-1\right)+\left(\frac{n}{5^{4}}-1\right)+\left(\frac{n}{5^{5}}-1\right) \\
&=\frac{n}{5}\left(1+\frac{1}{5}+\frac{1}{5^{2}}+\frac{1}{5^{3}}+\frac{1}{5^{4}}\right)-5=\frac{n}{5} \cdot \frac{1-\left(\frac{1}{5}\right)^{5}}{1-\frac{1}{5}}-5,
\end{aligned}
$$

so

$$
n<\frac{1005 \cdot 4 \cdot 3125}{3124}<4022 .
$$

We have narrowed down our search to $\{4001,4002, \ldots, 4021\}$. Checking each case with Polignac's formula, we find that the only solutions are $n=4005,4006,4007$, 4008, and 4009.

745. Polignac's formula implies that the exponent of the number 2 in $n !$ is

$$
\left\lfloor\frac{n}{2}\right\rfloor+\left\lfloor\frac{n}{2^{2}}\right\rfloor+\left\lfloor\frac{n}{2^{3}}\right\rfloor+\cdots .
$$

Because

$$
\frac{n}{2}+\frac{n}{2^{2}}+\frac{n}{2^{3}}+\cdots=n
$$

and not all terms in this infinite sum are integers, it follows that $n$ is strictly greater than the exponent of 2 in $n$ !, and the claim is proved.

(Mathematics Competition, Soviet Union, 1971)

746. Let $p$ be a prime number. The power of $p$ in $\operatorname{lcm}\left(1,2, \ldots,\left\lfloor\frac{n}{i}\right\rfloor\right)$ is equal to $k$ if and only if

$$
\left\lfloor\frac{n}{p^{k+1}}\right\rfloor<i \leq\left\lfloor\frac{n}{p^{k}}\right\rfloor .
$$

Hence the power of $p$ in the expression on the right-hand side is 

$$
\sum_{k \geq 1} k\left(\left\lfloor\frac{n}{p^{k}}\right\rfloor-\left\lfloor\frac{n}{p^{k+1}}\right\rfloor\right)=\sum_{k \geq 1}(k-(k-1))\left\lfloor\frac{n}{p^{k}}\right\rfloor=\sum_{k \geq 1}\left\lfloor\frac{n}{p^{k}}\right\rfloor .
$$

By Polignac's formula this is the exponent of $p$ in $n$ ! and we are done.

(64th W.L. Putnam Mathematical Competition, 2003)

747. First solution: We will show that for any prime number $p$ the power to which it appears in the numerator is greater than or equal to the power to which it appears in the denominator, which solves the problem.

Assume that $p$ appears to the power $\alpha$ in $n$ and to the power $\beta$ in $m, \alpha \geq \beta \geq 0$. Then among the inequalities

$$
\left\lfloor\frac{n}{p^{k}}\right\rfloor \geq\left\lfloor\frac{m}{p^{k}}\right\rfloor+\left\lfloor\frac{n-m}{p^{k}}\right\rfloor, \quad k=1,2, \ldots
$$

those with $\beta<k \leq \alpha$ are strict. Using this fact when applying Polignac's formula to $n$ !, $m$ !, and $(n-m)$ !, we deduce that the power of $p$ in $\left(\begin{array}{c}n \\ m\end{array}\right)$ is at least $\alpha-\beta$. Of course, the power of $p$ in $\operatorname{gcd}(m, n)$ is $\beta$. Hence $p$ appears to a nonnegative power in

$$
\frac{\operatorname{gcd}(m, n)}{n}\left(\begin{array}{l}
n \\
m
\end{array}\right),
$$

and we are done.

Second solution: A solution that does not involve prime numbers is also possible. Since $\operatorname{gcd}(m, n)$ is an integer linear combination of $m$ and $n$, it follows that

$$
\frac{\operatorname{gcd}(m, n)}{n}\left(\begin{array}{l}
n \\
m
\end{array}\right)
$$

is an integer linear combination of the integers

$$
\frac{m}{n}\left(\begin{array}{l}
n \\
m
\end{array}\right)=\left(\begin{array}{l}
n-1 \\
m-1
\end{array}\right) \quad \text { and } \quad \frac{n}{n}\left(\begin{array}{l}
n \\
m
\end{array}\right)=\left(\begin{array}{l}
n \\
m
\end{array}\right),
$$

and hence is itself an integer.

(61st W.L. Putnam Mathematical Competition, 2000)

748. Let $p$ be a prime divisor of $k$. Then $p \leq n$, so $p$ is also a divisor of $n$ !. Denote the powers of $p$ in $k$ by $\alpha$ and in $n$ ! by $\beta$. The problem amounts to showing that $\alpha \leq \beta$ for all prime divisors $p$ of $k$.

By Polignac's formula, the power of $p$ in $n$ ! is

$$
\beta=\sum_{i=1}^{\infty}\left\lfloor\frac{n}{p^{i}}\right\rfloor .
$$

Of course, the sum terminates at the $m$ th term, where $m$ is defined by $p^{m} \leq n<p^{m+1}$.

Write $\gamma=\left\lfloor\frac{\alpha}{2}\right\rfloor$, so that $\alpha$ equals either $2 \gamma$ or $2 \gamma+1$. From the hypothesis,

$$
n^{2} \geq 4 k \geq 4 p^{\alpha},
$$

and hence $n \geq 2 p^{\alpha / 2} \geq 2 p^{\gamma}$. Since $n<p^{m+1}$, this leads to $p^{m+1-\gamma}>2$. It means that if $p=2$, then $\gamma<m$, and if $p \geq 3$, then $\gamma \leq m$.

If $p=2$, we will show that $\beta \geq m+\gamma$, from which it will follow that $\beta \geq 2 \gamma+1 \geq \alpha$. The coefficient of 2 in $n !$ is

$$
\left\lfloor\frac{n}{2}\right\rfloor+\left\lfloor\frac{n}{2^{2}}\right\rfloor+\cdots+\left\lfloor\frac{n}{2^{m}}\right\rfloor .
$$

All terms in this sum are greater than or equal to 1 . Moreover, we have seen that $n \geq 2 \cdot 2^{\gamma}$, so the first term is greater than or equal to $2^{\gamma}$, and so this sum is greater than or equal to $2^{\gamma}+m-1$. It is immediate that this is greater than or equal to $\gamma+m$ for any $\gamma \geq 1$.

If $p \geq 3$, we need to show that

$$
\left\lfloor\frac{n}{p}\right\rfloor+\left\lfloor\frac{n}{p^{2}}\right\rfloor+\cdots+\left\lfloor\frac{n}{p^{m}}\right\rfloor \geq m+\gamma+1 .
$$

This time $m \geq \gamma$, and so $m+\gamma+1 \geq \gamma+\gamma+1 \geq \alpha$. Again, since $n \geq 2 p^{\gamma}$, the first term of the left-hand side is greater than or equal to $2 p^{\gamma-1}$. So the inequality can be reduced to $2 p^{\gamma-1}+m-1 \geq m+\gamma+1$, or $2 p^{\gamma-1} \geq \gamma+2$. This again holds true for any $p \geq 3$ and $\gamma \geq 2$. For $\gamma=1$, if $\alpha=2$, then we have $2 p^{\gamma-1}+m-1 \geq m+\gamma \geq \alpha$. If $\alpha=3$, then $n^{2} \geq 2 p^{3}$ implies $n \geq 2\lfloor\sqrt{p}\rfloor p \geq 3 p$, and hence the first term in the sum is greater than or equal to 3, so again it is greater than or equal to $\alpha$.

We have thus showed that any prime appears to a larger power in $n$ ! than in $k$, which means that $k$ divides $n !$ !

(Austrian-Polish Mathematics Competition, 1986)

749. Define

$$
E(a, b)=a^{3} b-a b^{3}=a b(a-b)(a+b) .
$$

Since if $a$ and $b$ are both odd, then $a+b$ is even, it follows that $E(a, b)$ is always even. Hence we only have to prove that among any three integers we can find two, $a$ and $b$, with $E(a, b)$ divisible by 5 . If one of the numbers is a multiple of 5 , the property is true. If not, consider the pairs $\{1,4\}$ and $\{2,3\}$ of residue classes modulo 5 . By the pigeonhole principle, the residues of two of the given numbers belong to the same pair. These will be $a$ and $b$. If $a \equiv b$ (mod 5), then $a-b$ is divisible by 5 , and so is $E(a, b)$. If not, then by the way we defined our pairs, $a+b$ is divisible by 5 , and so again $E(a, b)$ is divisible by 5 . The problem is solved.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1980, proposed by I. Tomescu) 

750. Observe that $2002=10^{3}+10^{3}+1^{3}+1^{3}$, so that

$$
\begin{aligned}
2002^{2002} &=2002^{2001} \cdot 2002=\left((2002)^{667}\right)^{3}\left(10^{3}+10^{3}+1^{3}+1^{3}\right) \\
&=\left(10 \cdot 2002^{667}\right)^{3}+\left(10 \cdot 2002^{667}\right)^{3}+\left(2002^{667}\right)^{3}+\left(2002^{667}\right)^{3} .
\end{aligned}
$$

This proves the first claim. For the second, note that modulo 9, a perfect cube can be only $\pm 1$ or 0 . Therefore, the sum of the residues modulo 9 of three perfect cubes can be only $0, \pm 1, \pm 2$, or $\pm 3$. We verify that

$$
2002^{2002} \equiv 4^{2002} \equiv\left(4^{3}\right)^{667} \cdot 4 \equiv 1 \cdot 4 \equiv 4(\bmod 9) .
$$

It is easy now to see that $2002^{2002}$ cannot be written as the sum of three cubes. (communicated by V.V. Acharya)

751. Denote the perfect square by $k^{2}$ and the digit that appears in the last four positions by $a$. Then $k^{2} \equiv a \cdot 1111(\bmod 10000)$. Perfect squares end in $0,1,4,5,6$, or 9 , so $a$ can only be one of these digits.

Now let us examine case by case. If $a=0$, we are done. The cases $a \in\{1,5,9\}$ can be ruled out by working modulo 8 . Indeed, the quadratic residues modulo 8 are 0 , 1, and 4 , while as $a$ ranges over the given set, $a \cdot 1111$ has the residues 7 or 3 .

The cases $a=2$ or 4 are ruled out by working modulo 16 , since neither $4 \cdot 1111 \equiv$ $12(\bmod 16)$ nor $6 \cdot 1111 \equiv 10(\bmod 16)$ is a quadratic residue modulo 16.

752. Reducing modulo 4 , the right-hand side of the equation becomes equal to 2 . So the left-hand side is not divisible by 4 , which means that $x=1$. If $y>1$, then reducing modulo 9 we find that $z$ has to be divisible by 6 . A reduction modulo 6 makes the lefthand side 0 , while the right-hand side would be $1+(-1)^{z}=2$. This cannot happen. Therefore, $y=1$, and we obtain the unique solution $x=y=z=1$.

(Matematika v Škole (Mathematics in Schools), 1979, proposed by I. Mihailov)

753. Note that a perfect square is congruent to 0 or to 1 modulo 3 . Using this fact we can easily prove by induction that $a_{n} \equiv 2(\bmod 3)$ for $n \geq 1$. Since $2 \cdot 2 \equiv 1(\bmod 3)$, the question has a negative answer.

(Indian International Mathematical Olympiad Training Camp, 2005)

754. By hypothesis, there exist integers $t$ and $N$ such that $a N+b=t^{k}$. Choose $m$ arbitrary positive integers $s_{1}, s_{2}, \ldots, s_{m}$, and consider the number

$$
s=\left(a s_{1}+t\right)^{k}+\sum_{j=2}^{m}\left(a s_{j}\right)^{k} .
$$

Then

$$
s \equiv t^{k} \equiv a N+b \equiv b(\bmod a) .
$$

Since $s \equiv b(\bmod a)$, there exists $n$ such that $s=a n+b$, and so $s$ is a term of the arithmetic progression that can be written as a sum of $m k$ th powers of integers. Varying the parameters $s_{1}, s_{2}, \ldots, s_{n}$, we obtain infinitely many terms with this property.

(proposed by E. Just for Mathematics Magazine)

755. Denote the sum from the statement by $S_{n}$. We will prove a stronger inequality, namely,

$$
S_{n}>\frac{n}{2}\left(\log _{2} n-4\right) .
$$

The solution is based on the following obvious fact: no odd number but 1 divides $2^{n}$ evenly. Hence the residue of $2^{n}$ modulo such an odd number is nonzero. From here we deduce that the residue of $2^{n}$ modulo a number of the form $2^{m}(2 k+1), k>1$, is at least $2^{m}$. Indeed, if $2^{n-m}=(2 k+1) q+r$, with $1 \leq r<2 k+1$, then $2^{n}=2^{m}(2 k+1) q+2^{m} r$, with $2^{m}<2^{m} r<2^{m}(2 k+1)$. And so $2^{m} r$ is the remainder obtained by dividing $2^{n}$ by $2^{m}(2 k+1)$

Therefore, $S_{n} \geq 1 \times$ (the number of integers of the form $2 k+1, k>1$, not exceeding $n)+2 \times($ the number of integers of the form $2(2 k+1), k>1$, not exceeding $n)+2^{2} \times($ the number of integers of the form $2^{2}(2 k+1), k>1$, not exceeding $\left.n\right)+\cdots$.

Let us look at the $(j+1)$ st term in this estimate. This term is equal to $2^{j}$ multiplied by the number of odd numbers between 3 and $\frac{n}{2^{j}}$, and the latter is at least $\frac{1}{2}\left(\frac{n}{2^{j}}-3\right)$. We deduce that

$$
S_{n} \geq \sum_{j} 2^{j} \frac{n-3 \cdot 2^{j}}{2^{j+1}}=\sum_{j} \frac{1}{2}\left(n-3 \cdot 2^{j}\right),
$$

where the sums stop when $2^{j} \cdot 3>n$, that is, when $j=\left\lfloor\log _{2} \frac{n}{3}\right\rfloor$. Setting $l=\left\lfloor\log _{2} \frac{n}{3}\right\rfloor$, we have

$$
S_{n} \geq(l+1) \frac{n}{2}-\frac{3}{2} \sum_{j=0}^{l} 2^{i}>(l+1) \frac{n}{2}-\frac{3 \cdot 2^{l+1}}{2} .
$$

Recalling the definition of $l$, we conclude that

$$
S_{n}>\frac{n}{2} \log _{2} \frac{n}{3}-n=\frac{n}{2}\left(\log _{2} \frac{n}{3}-2\right)>\frac{n}{2}\left(\log _{2} n-4\right),
$$

and the claim is proved. The inequality from the statement follows from the fact that for $n>1000, \frac{1}{2}\left(\log _{2} n-4\right)>\frac{1}{2}\left(\log _{2} 1000-4\right)>2$.

(Kvant (Quantum), proposed by A. Kushnirenko, solution by D. Grigoryev)

756. First, observe that all terms of the progression must be odd. Let $p_{1}<p_{2}<\cdots<p_{k}$ be the prime numbers less than $n$. We prove the property true for $p_{i}$ by induction on $i$. For $i=1$ the property is obviously true, since $p_{1}=2$ and the consecutive terms of the progression are odd numbers. Assume the property is true for $p_{1}, p_{2}, \ldots, p_{i-1}$ and let us prove it for $p_{i}$.

Let $a, a+d, a+2 d, \ldots, a+(n-1) d$ be the arithmetic progression consisting of prime numbers. Using the inequality $d \geq p_{1} p_{2} \cdots p_{i-1}>p_{i}$, we see that if a term of the progression is equal to $p_{i}$, then this is exactly the first term (in the special case of $p_{2}=3$, for which the inequality does not hold, the claim is also true because 3 is the first odd prime). But if $a=p_{i}$, then $a+p_{i} d$, which is a term of the progression, is divisible by $p_{i}$, and the problem states that this number is prime. This means that $a \neq p_{i}$, and consequently the residues of the numbers $a, a+d, \ldots, a+\left(p_{i}-1\right) d$ modulo $p_{i}$ range over $\left\{1,2, \ldots, p_{i}-1\right\}$. By the pigeonhole principle, two of these residues must be equal, i.e.,

$$
a+s d \equiv a+t d\left(\bmod p_{i}\right),
$$

for some $0 \leq i<j \leq p_{i}-1$. Consequently, $a+s d-a-t d=(s-t) d$ is divisible by $p_{i}$, and since $|s-t|<p_{i}$, it follows that $d$ is divisible by $p_{i}$. This completes the induction, and with it the solution to the problem.

(G. Cantor)

757. We reduce everything modulo 3 ; thus we work in the ring of polynomials with $\mathbb{Z}_{3}$ coefficients. The coefficients of both $P(x)$ and $Q(x)$ are congruent to 1 , so the reduced polynomials are $\widehat{P}(x)=\frac{x^{m+1}-1}{x-1}$ and $\widehat{Q}(x)=\frac{x^{n+1}-1}{x-1}$. The polynomial $\widehat{P}(x)$ still divides $\widehat{Q}(x)$; therefore $x^{m+1}-1$ divides $x^{n+1}-1$.

Let $g$ be the greatest common divisor of $m+1$ and $n+1$. Then there exist positive integers $a$ and $b$ such that $a(m+1)-b(n+1)=g$. The polynomial $x^{m+1}-1$ divides $x^{a(m+1)}-1$, while the polynomial $x^{n+1}-1$ divides $x^{b(n+1)}-1$ and so does $x^{m+1}-1$. It follows that $x^{m+1}-1$ divides

$$
x^{a(m+1)}-1-\left(x^{b(n+1)}-1\right)=x^{b(n+1)}\left(x^{a(m+1)-b(n+1)}-1\right)=x^{b(n+1)}\left(x^{g}-1\right) .
$$

Hence $x^{m+1}-1$ divides $x^{g}-1$. Because $g$ divides $m+1$, this can happen only if $g=m+1$. Therefore, $m+1$ is a divisor of $n+1$, and we are done.

(Romanian Mathematical Olympiad, 2002)

758. We use complex coordinates, and for this, let

$$
\epsilon=\cos \frac{2 \pi}{n}+i \sin \frac{2 \pi}{n} \text {. }
$$

The vertices of the equiangular polygon should have coordinates

$$
\sum_{i=0}^{k} \sigma(i) \epsilon^{i}, \quad k=1,2, \ldots, n-1,
$$

where $\sigma$ is a certain permutation of $1,2, \ldots, n$. The sides are parallel to the rays $\sigma(k) \epsilon^{k}$, so the angle between two consecutive sides is indeed $\frac{2 \pi}{n}$, except for maybe the first and the last! For these two sides to form the appropriate angle, the equality

$$
\sum_{i=0}^{n-1} \sigma(i) \epsilon^{i}=0
$$

must hold. We are supposed to find a permutation $\sigma$ for which this relation is satisfied. It is here that residues come into play.

Let $n=a b$ with $a$ and $b$ coprime. Represent the $n$th roots of unity as

$$
\epsilon^{a j+b k}, \quad j=0,1, \ldots, b-1, \quad k=0,1, \ldots, a-1 .
$$

Note that there are $a b=n$ such numbers altogether, and no two coincide, for if $a j+b k \equiv$ $a j^{\prime}+b k^{\prime}(\bmod n)$, then $a\left(j-j^{\prime}\right) \equiv b\left(k^{\prime}-k\right)(\bmod n)$, which means that $j-j^{\prime}$ is divisible by $b$ and $k-k^{\prime}$ is divisible by $a$, and so $j=j^{\prime}$ and $k=k^{\prime}$. Thus we have indeed listed all $n$th roots of unity.

Order the roots of unity in the lexicographic order of the pairs $(j, k)$. This defines the permutation $\sigma$. We are left with proving that

$$
\sum_{j=0}^{b-1} \sum_{k=0}^{a-1}(a j+k) \epsilon^{a j+b k}=0 .
$$

And indeed,

$$
\sum_{j=0}^{b-1} \sum_{k=0}^{a-1}(a j+k) \epsilon^{a j+b k}=\sum_{j=0}^{b-1} a j \epsilon^{a j} \sum_{k=0}^{a-1}\left(\epsilon^{b}\right)^{k}+\sum_{k=0}^{a-1} k \epsilon^{b k} \sum_{k=0}^{b-1}\left(\epsilon^{a}\right)^{j}=0 .
$$

759. Let $S$ be the set of all primes with the desired property. We claim that $S=$ $\{2,3,5,7,13\}$.

It is easy to verify that these primes are indeed in $S$. So let us consider a prime $p$ in $S, p>7$. Then $p-4$ can have no factor $q$ larger than 4 , for otherwise $p-\left\lfloor\frac{p}{q}\right\rfloor q=4$. Since $p-4$ is odd, $p-4=3^{a}$ for some $a \geq 2$. For a similar reason, $p-8$ cannot have prime factors larger than 8 , and so $p-8=3^{a}-4=5^{b} 7^{c}$. Reducing the last equality modulo 24 , we find that $a$ is even and $b$ is odd.

If $c \neq 0$, then $p-9=5^{b} 7^{c}-1=2^{d}$. Here we used the fact that $p-9$ has no prime factor exceeding 8 and is not divisible by 3,5 , or 7 . Reduction modulo 7 shows that the last equality is impossible, for the powers of 2 are 1,2 , and 4 modulo 7 . Hence $c=0$ and $3^{a}-4=5^{b}$, which, since $3^{a / 2}-2$ and $3^{a / 2}+2$ are relatively prime, gives $3^{a / 2}-2=1$ and $3^{a / 2}+2=5^{b}$. Thus $a=2, b=1$, and $p=13$. This proves the claim.

(American Mathematical Monthly, 1987, proposed by M. Cipu and M. Deaconescu, solution by L. Jones) 

760. Note that

$$
n=1+10+\cdots+10^{p-2}=\frac{10^{p-1}-1}{10-1} .
$$

By Fermat's little theorem the numerator is divisible by $p$, while the denominator is not. Hence the conclusion.

761. We have the factorization

$$
16320=2^{6} \cdot 3 \cdot 5 \cdot 17 .
$$

First, note that $p^{a b}-1=\left(p^{a}\right)^{b}-1$ is divisible by $p^{a}-1$. Hence $p^{32}-1$ is divisible by $p^{2}-1, p^{4}-1$, and $p^{16}-1$. By Fermat's little theorem, $p^{2}-1=p^{3-1}-1$ is divisible by $3, p^{4}-1=p^{5-1}-1$ is divisible by 5 , and $p^{16}-1=p^{17-1}-1$ is divisible by 17 . Here we used the fact that $p$, being prime and greater than 17, is coprime to 3, 5, and 17 .

We are left to show that $p^{32}-1$ is divisible by $2^{6}$. Of course, $p$ is odd, say $p=2 m+1$, $m$ an integer. Then $p^{32}-1=(2 m+1)^{32}-1$. Expanding with Newton's binomial formula, we get

$$
(2 m)^{32}+\left(\begin{array}{c}
32 \\
1
\end{array}\right)(2 m)^{31}+\cdots+\left(\begin{array}{c}
32 \\
2
\end{array}\right)(2 m)^{2}+\left(\begin{array}{c}
32 \\
1
\end{array}\right)(2 m) .
$$

In this sum all but the last five terms contain a power of two greater than or equal to 6 . On the other hand, it is easy to check that in

$$
\left(\begin{array}{c}
32 \\
5
\end{array}\right)(2 m)^{5}+\left(\begin{array}{c}
132 \\
4
\end{array}\right)(2 m)^{4}+\left(\begin{array}{c}
32 \\
3
\end{array}\right)(2 m)^{3}+\left(\begin{array}{c}
32 \\
2
\end{array}\right)(2 m)^{2}+\left(\begin{array}{c}
32 \\
1
\end{array}\right)(2 m)
$$

the first binomial coefficient is divisible by 2 , the second by $2^{2}$, the third by $2^{3}$, the fourth by $2^{4}$, and the fifth by $2^{5}$. So this sum is divisible by $2^{6}$, and hence $(2 m+1)^{32}-1=p^{32}-1$ is itself divisible by $2^{6}$. This completes the solution.

(Gazeta Matematică (Mathematics Gazette, Bucharest), proposed by I. Tomescu)

762. If $x$ is a solution to the equation from the statement, then using Fermat's little theorem, we obtain

$$
1 \equiv x^{p-1} \equiv a^{\frac{p-1}{2}}(\bmod p) .
$$

If $m$ is an integer, then every odd prime factor $p$ of $m^{2}+1$ must be of the form $4 m+1$, with $m$ an integer. Indeed, in this case because $m^{2} \equiv-1(\bmod p)$, and by what we just proved,

$$
(-1)^{\frac{p-1}{2}}=1,
$$

which means that $p-1$ is divisible by 4 . Now assume that there are only finitely many primes of the form $4 m+1, m$ an integer, say $p_{1}, p_{2}, \ldots, p_{n}$. The number $\left(2 p_{1} p_{2} \ldots p_{n}\right)^{2}+1$ has only odd prime factors, and these must be of the form $4 m+1, m$ an integer. Yet these are none of $p_{1}, p_{2}, \ldots, p_{n}$, a contradiction. Hence the conclusion.

763. Assume a solution $(x, y)$ exists. If $y$ were even, then $y^{3}+7$ would be congruent to 3 modulo 4 . But a square cannot be congruent to 3 modulo 4 . Hence $y$ must be odd, say $y=2 k+1$. We have

$$
x^{2}+1=y^{3}+2^{3}=(y+2)\left[(y-1)^{2}+3\right]=(y+2)\left(4 k^{2}+3\right) .
$$

We deduce that $x^{2}+1$ is divisible by a number of the form $4 m+3$, namely, $4 k^{2}+3$. It must therefore be divisible by a prime number of this form. But we have seen in the previous problem that this is impossible. Hence the equation has no solutions.

\section{(V.A. Lebesgue)}

764. Assume that the equation admits a solution $(x, y)$. Let $p$ be the smallest prime number that divides $n$. Because $(x+1)^{n}-x^{n}$ is divisible by $p$, and $x$ and $x+1$ cannot both be divisible by $p$, it follows that $x$ and $x+1$ are relatively prime to $p$. By Fermat's little theorem, $(x+1)^{p-1} \equiv 1 \equiv x^{p-1}(\bmod p)$. Also, $(x+1)^{n} \equiv x^{n}(\bmod p)$ by hypothesis.

Additionally, because $p$ is the smallest prime dividing $n$, the numbers $p-1$ and $n$ are coprime. By the fundamental theorem of arithmetic, there exist integers $a$ and $b$ such that $a(p-1)+b n=1$. It follows that

$$
x+1=(x+1)^{a(p-1)+b n} \equiv x^{a(p-1)+b n} \equiv x(\bmod p),
$$

which is impossible. Hence the equation has no solutions.

\section{(I. Cucurezeanu)}

765. We construct the desired subsequence $\left(x_{n}\right)_{n}$ inductively. Suppose that the prime numbers that appear in the prime factor decompositions of $x_{1}, x_{2}, \ldots, x_{k-1}$ are $p_{1}, p_{2}, \ldots, p_{m}$. Because the terms of the sequence are odd, none of these primes is equal to 2 . Define

$$
x_{k}=2^{\left(p_{1}-1\right)\left(p_{2}-1\right) \cdots\left(p_{m}-1\right)}-3 .
$$

By Fermat's little theorem, $2^{\left(p_{1}-1\right)\left(p_{2}-1\right) \cdots\left(p_{m}-1\right)}-1$ is divisible by each of the numbers $p_{1}, p_{2}, \ldots, p_{n}$. It follows that $x_{k}$ is not divisible by any of these primes. Hence $x_{k}$ is relatively prime to $x_{1}, x_{2}, \ldots, x_{k-1}$, and thus it can be added to the sequence. This completes the solution.

766. The recurrence is linear. Using the characteristic equation we find that $x_{n}=A$. $2^{n}+B \cdot 3^{n}$, where $A=3 x_{0}-x_{1}$ and $B=x_{1}-2 x_{0}$. We see that $A$ and $B$ are integers.

Now let us assume that all but finitely many terms of the sequence are prime. Then $A, B \neq 0$, and 

$$
\lim _{n \rightarrow \infty} x_{n}=\lim _{n \rightarrow \infty} 3^{n}\left(A\left(\frac{2}{3}\right)^{n}+B\right)=\infty .
$$

Let $n$ be sufficiently large that $x_{n}$ is a prime number different from 2 and 3 . Then for $k \geq 1$

$$
x_{n+k(p-1)}=A \cdot 2^{n+k(p-1)}+B \cdot 3^{n+k(p-1)}=A \cdot 2^{n} \cdot\left(2^{p-1}\right)^{k}+B \cdot 3^{n} \cdot\left(3^{p-1}\right)^{k} .
$$

By Fermat's little theorem, this is congruent to $A \cdot 2^{n}+B \cdot 3^{n}$ modulo $p$, hence to $x_{n}$ which is divisible by $p$. So the terms of the subsequence $x_{n+k(p-1)}, k \geq 1$, are divisible by $p$, and increase to infinity. This can happen only if the terms become composite at some point, which contradicts our assumption. Hence the conclusion.

767. All congruences in this problem are modulo 13 . First, let us show that for $0 \leq k<12$,

$$
\sum_{x=0}^{12} x^{k} \equiv 0(\bmod 13) .
$$

The case $k=0$ is obvious, so let us assume $k>0$. First, observe that 2 is a primitive root modulo 13 , meaning that $2^{m}, m \geq 1$, exhausts all nonzero residues modulo 13 . So on the one hand, $2^{k} \not \equiv 1$ for $1 \leq k<12$, and on the other hand, the residue classes $2,4,6, \ldots, 24$ are a permutation of the residue classes $1,2, \ldots, 12$. We deduce that

$$
\sum_{x=0}^{12} x^{k} \equiv \sum_{x=0}^{12}(2 x)^{k}=2^{k} \sum_{x=0}^{12} x^{k}
$$

and because $2^{k} \not \equiv 1$, we must have $\sum_{x=0}^{12} x^{k} \equiv 0$.

Now let $S=\left\{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \mid 0 \leq x_{i} \leq 12\right\}$. Because $|S|=13^{n}$ is divisible by 13 , it suffices to show that the number of $n$-tuples $\left(x_{1}, \ldots, x_{n}\right) \in S$ such that $f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \not \equiv 0$ is divisible by 13 . Consider the sum

$$
\sum_{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in S}\left(f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\right)^{12} .
$$

This sum is congruent modulo 13 to the number of $n$-tuples $\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in S$ such that $f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \not \equiv 0$, since by Fermat's little theorem,

$$
\left(f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\right)^{12} \equiv \begin{cases}1 & \text { if } f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \neq 0, \\ 0 & \text { if } f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \equiv 0 .\end{cases}
$$

On the other hand, $\left(f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\right)^{12}$ can be expanded as

$$
\left(f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\right)^{12}=\sum_{j=1}^{m} c_{j} \prod_{j=1}^{n} x_{i}^{\alpha_{j i}},
$$

for some integers $m, c_{j}, \alpha_{j i}$. Because $f$ is a polynomial of total degree less than $n$, we have $\alpha_{j 1}+\alpha_{j 2}+\cdots+\alpha_{j n}<12 n$ for every $j$, so for each $j$ there exists $i$ such that $\alpha_{j i}<12$. Using what we proved above, we obtain for $1 \leq j \leq m$,

$$
\sum_{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in S} c_{j} \prod_{i=1}^{n} x_{i}^{\alpha_{j i}}=c_{j} \prod_{i=1}^{n} \sum_{x_{i}=0}^{12} x_{i}^{\alpha_{j i}} \equiv 0,
$$

since one of the sums in the product is congruent to 0 . Therefore,

$$
\sum_{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in S}\left(f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\right)^{12}=\sum_{\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in S} \sum_{j=1}^{m} c_{j} \prod_{i=1}^{n} x_{i}^{\alpha_{j i}} \equiv 0 .
$$

This implies that the number of $n$-tuples $\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ in $S$ with the property that $f\left(x_{1}, x_{2}, \ldots, x_{n}\right) \not \equiv 0(\bmod 13)$ is divisible by 13 , and we are done.

(Turkish Mathematical Olympiad, 1998)

768. We have $12321=(111)^{2}=3^{2} \times 37^{2}$. It becomes natural to work modulo 3 and modulo 37. By Fermat's little theorem,

$$
a^{2} \equiv 1(\bmod 3),
$$

and since we must have $a^{k} \equiv-1(\bmod 3)$, it follows that $k$ is odd. Fermat's little theorem also gives

$$
a^{36} \equiv 1(\bmod 37) .
$$

By hypothesis $a^{k} \equiv-1(\bmod 37)$. By the fundamental theorem of arithmetic there exist integers $x$ and $y$ such that $k x+36 y=\operatorname{gcd}(k, 36)$. Since the $\operatorname{gcd}(k, 36)$ is odd, $x$ is odd. We obtain that

$$
a^{\operatorname{gcd}(k, 36)} \equiv a^{k x+36 y} \equiv(-1) \cdot 1=-1(\bmod 37) .
$$

Since $\operatorname{gcd}(k, 36)$ can be 1,3 , or 9 , we see that $a$ must satisfy $a \equiv-1, a^{3} \equiv-1$, or $a^{9} \equiv-1$ modulo 37 . Thus $a$ is congruent to $-1$ modulo 3 and to $3,4,11,21,25,27,28$, 30 , or 36 modulo 37 . These residue classes modulo 37 are precisely those for which $a$ is a perfect square but not a perfect fourth power. Note that if these conditions are satisfied, then $a^{k} \equiv-1(\bmod 3 \times 37)$, for some odd integer $k$.

How do the $3^{2}$ and $37^{2}$ come into the picture? The algebraic identity

$$
x^{n}-y^{n}=(x-y)\left(x^{n-1}+x^{n-2} y+\cdots+x y^{n-2}+y^{n-1}\right)
$$

shows that if $x \equiv y(\bmod n)$, then $x^{n} \equiv y^{n}\left(\bmod n^{2}\right)$. Indeed, modulo $n$, the factors on the right are 0 , respectively, $n x^{n-1}$, which is again 0 . We conclude that if $a$ is a perfect square but not a fourth power modulo 37, and is $-1$ modulo 3 , then $a^{k} \equiv-1(\bmod 3 \times 37)$ and $a^{k \times 3 \times 37} \equiv-1\left(\bmod 3^{2} \times 37^{2}\right)$. The answer to the problem is the residue classes

$$
11,41,62,65,77,95,101,104,110
$$

modulo 111 .

(Indian Team Selection Test for the International Mathematical Olympiad, 2004, proposed by S.A. Katre)

769. If $n+1$ is composite, then each prime divisor of $(n+1)$ ! is less than $n$, which also divides $n$ !. Then it does not divide $n !+1$. In this case the greatest common divisor is 1 .

If $n+1$ is prime, then by the same argument the greatest common divisor can only be a power of $n+1$. Wilson's theorem implies that $n+1$ divides $n !+1$. However, $(n+1)^{2}$ does not divide $(n+1)$ !, and thus the greatest common divisor is $(n+1)$.

(Irish Mathematical Olympiad, 1996)

770. We work modulo 7. None of the six numbers is divisible by 7 , since otherwise the product of the elements in one set would be divisible by 7 , while the product of the elements in the other set would not.

By Wilson's theorem, the product of the six consecutive numbers is congruent to $-1$ modulo 7. If the partition existed, denote by $x$ the product of the elements in one set. Then

$$
x^{2}=n(n+1) \cdots(n+5) \equiv-1(\bmod 7) .
$$

But this is impossible since $-1$ is not a quadratic residue modulo 7 .

(12th International Mathematical Olympiad, 1970)

771. Consider all pairs of numbers $i$ and $j$ with $i j \equiv a(\bmod p)$. Because the equation $x^{2} \equiv a(\bmod p)$ has no solutions, $i$ is always different from $j$. Since every nonzero element is invertible in $\mathbb{Z}_{p}$, the pairs exhaust all residue classes modulo $p$. Taking the product of all such pairs, we obtain

$$
a^{\frac{p-1}{2}} \equiv(p-1) !(\bmod p),
$$

which by Wilson's theorem is congruent to $-1$, as desired.

772. We claim that if $p \equiv 1(\bmod 4)$, then $x=\left(\frac{p-1}{2}\right)$ ! is a solution to the equation $x^{2} \equiv-1(\bmod p)$. Indeed, by Wilson's theorem,

$$
\begin{aligned}
-1 & \equiv(p-1) !=1 \cdot 2 \cdots\left(\frac{p-1}{2}\right)\left(\frac{p+1}{2}\right) \cdots(p-1) \\
& \equiv 1 \cdot 2 \cdots\left(\frac{p-1}{2}\right)\left(p-\frac{p-1}{2}\right) \cdot(p-1) \equiv(-1)^{\frac{p-1}{2}}\left[\left(\frac{p-1}{2}\right) !\right]^{2}(\bmod p) .
\end{aligned}
$$

Hence

$$
\left[\left(\frac{p-1}{2}\right) !\right]^{2} \equiv-1(\bmod p),
$$

as desired.

To show that the equation has no solution if $p \equiv 3(\bmod 4)$, assume that such a solution exists. Call it $a$. Using Fermat's little theorem, we obtain

$$
1 \equiv a^{p-1} \equiv a^{2 \cdot \frac{p-1}{2}} \equiv(-1)^{\frac{p-1}{2}}=-1(\bmod p) .
$$

This is impossible. Hence the equation has no solution.

773. Multiplying the obvious congruences

$$
\begin{aligned}
& 1 \equiv-(p-1)(\bmod p) \text {, } \\
& 2 \equiv-(p-2)(\bmod p) \text {, } \\
& n-1 \equiv-(p-n+1)(\bmod p),
\end{aligned}
$$

we obtain

$$
(n-1) ! \equiv(-1)^{n-1}(p-1)(p-2) \cdots(p-n+1)(\bmod p) .
$$

Multiplying both sides by $(p-n)$ ! further gives

$$
(p-n) !(n-1) ! \equiv(-1)^{n-1}(p-1) !(\bmod p) .
$$

Because by Wilson's theorem $(p-1) ! \equiv-1(\bmod p)$, this becomes

$$
(p-n) !(n-1) ! \equiv(-1)^{n}(\bmod p),
$$

as desired.

\section{(A. Simionov)}

774. Because the common difference of the progression is not divisible by $p$, the numbers $a_{1}, a_{2}, \ldots, a_{p}$ represent different residue classes modulo $p$. One of them, say $a_{i}$, is divisible by $p$, and the others give the residues $1,2, \ldots, p-1$ in some order. Applying Wilson's theorem, we have

$$
\frac{a_{1} a_{2} \cdots a_{p}}{a_{i}} \equiv(p-1) ! \equiv-1(\bmod p) ;
$$

hence $a_{1} a_{2} \cdots \frac{a_{p}}{a_{i}}+1$ is divisible by $p$. Since $a_{i}$ is divisible by $p$, we find that $a_{1} a_{2} \cdots a_{p}+$ $a_{i}$ is divisible by $p^{2}$, as desired.

(I. Cucurezeanu) 

775. We use strong induction. The property is true for $n=1$. Let $n=p^{\alpha} q$, where $p$ is a prime number and $q$ is relatively prime to $p$ ( $q$ is allowed to be 1). Assume that the formula holds for $q$. Any number $k$ that divides $n$ is of the form $p^{j} m$, where $0 \leq j \leq \alpha$, and $m$ divides $q$. Hence we can write

$$
\begin{aligned}
\sum_{j=0}^{\alpha} \sum_{m \mid q} \phi\left(p^{j} m\right) &=\sum_{j=0}^{\alpha} \sum_{m \mid q} \phi\left(p^{j}\right) \phi(m)=\sum_{j=0}^{\alpha} \phi\left(p^{j}\right) \sum_{m \mid q} \phi(m) \\
&=\left(1+\sum_{j=1}^{\alpha} p^{j-1}(p-1)\right) q=p^{\alpha} q=n
\end{aligned}
$$

This completes the induction.

(C.F. Gauss)

776. If $n=2^{m}, m \geq 2$, then

$$
\phi(n)=2^{m}-2^{m-1}=2^{m-1} \geq \sqrt{2^{m}}=\sqrt{n} .
$$

If $n=p^{m}$, where $m \geq 2$ and $p$ is an odd prime, then

$$
\phi(n)=p^{m-1}(p-1) \geq \sqrt{p^{m}}=\sqrt{n} .
$$

Observe, moreover, that if $n=p^{m}, m \geq 2$, where $p$ is a prime greater than or equal to 5 , then $\phi(n) \geq \sqrt{2 n}$.

Now in general, if $n$ is either odd or a multiple of 4 , then

$$
\phi(n)=\phi\left(p_{1}^{\alpha_{1}}\right) \cdots \phi\left(p_{k}^{\alpha_{k}}\right) \geq \sqrt{p_{1}^{\alpha_{1}}} \cdots \sqrt{p_{k}^{\alpha_{k}}}=\sqrt{n} .
$$

We are left with the case $n=2 t$, with $t$ odd and different from 1 or 3 . If any prime factor of $t$ is greater than or equal to 5 , then $\phi(n)=\phi(t) \geq \sqrt{2 t}$. It remains to settle the case $n=2 \cdot 3^{i}, i \geq 2$. For $i=2, \phi(18)=6>\sqrt{18}$. For $i \geq 3, \phi(n)=2 \cdot 3^{i-1}$, and the inequality reduces to $\sqrt{2} \cdot 3^{\frac{i}{2}-1}>1$, which is obvious.

777. An example is $n=15$. In that case $\phi(15)=\phi(3 \cdot 5)=2 \cdot 4=8$, and $8^{2}+15^{2}=17^{2}$. Observe that for $\alpha, \beta \geq 1$,

$$
\phi\left(3^{\alpha} \cdot 5^{\beta}\right)=3^{\alpha-1} \cdot 5^{\beta-1}(3-1)(5-1)=3^{\alpha-1} \cdot 5^{\beta-1} \cdot 8
$$

and

$$
\left(3^{\alpha-1} \cdot 5^{\beta-1} \cdot 8\right)^{2}+\left(3^{\alpha} \cdot 5^{\beta}\right)^{2}=\left(3^{\alpha-1} \cdot 5^{\beta-1} \cdot 17\right)^{2},
$$

so any number of the form $n=3^{\alpha} \cdot 5^{\beta}$ has the desired property.

778. We will prove that if $m=2 \cdot 7^{r}, r \geq 1$, then the equation $\phi(n)=m$ has no solutions. If $n=p_{1}^{\alpha_{1}} \cdots p_{k}^{\alpha_{k}}$, then

$$
\phi(n)=p_{1}^{\alpha_{1}-1} \cdots p_{k}^{\alpha_{k}-1}\left(p_{1}-1\right) \cdots\left(p_{k}-1\right) .
$$

If at least two of the primes $p_{1}, \ldots, p_{k}$ are odd, then $\phi(n)$ is divisible by 4 , so is not equal to $m$.

If $n=2^{\alpha}$, or $n=2^{\alpha} p^{\beta}$, with $\alpha>2$, then $\phi(n)$ is again divisible by 4 , so again $\phi(n) \neq m$. The only cases left are $n=2^{\alpha} p^{\beta}$, with $\alpha=0, \alpha=1$, or $\alpha=2$. In the first case,

$$
\phi(n)=p^{\beta-1}(p-1)
$$

This implies $p=7$, but even then equality cannot hold. For the other two cases,

$$
\phi(n)=2^{\alpha-1} p^{\beta-1}(p-1) .
$$

The equality $\phi(n)=m$ implies right away that $\alpha=1, p=7$, but $7^{\beta-1} \cdot 6$ cannot equal $2 \cdot 7^{r}$. Hence the conclusion.

779. Let $s=2^{\alpha} 5^{\beta} t$, where $t$ is coprime to 10 . Define

$$
n=10^{\alpha+\beta}\left(10^{\phi(t)}+10^{2 \phi(t)}+\cdots+10^{s \phi(t)}\right) .
$$

The sum of the digits of $n$ is $1+1+\cdots+1=s$. By Euler's theorem, $10^{\phi(t)} \equiv 1(\bmod t)$, and so $10^{k \phi(t)} \equiv 1(\bmod t), k=1,2, \ldots, s$. It follows that

$$
n \equiv 10^{\alpha+\beta}(1+1+\cdots+1)=s \cdot 10^{\alpha+\beta}(\bmod t),
$$

so $n$ is divisible by $t$. This number is also divisible by $2^{\alpha} 5^{\beta}$ and therefore has the desired property.

\section{(W. Sierpinski)}

780. To have few residues that are cubes, 3 should divide the Euler totient function of the number. This is the case with 7,9 , and 13 , since $\phi(7)=6, \phi(9)=6$, and $\phi(13)=6$. The cubes modulo 7 and 9 are 0,1 , and $-1$; those modulo 13 are $0,1,-1,8$, and $-8$.

So let us assume that the equation admits a solution $x, z$. Reducing modulo 7 , we find that $x=3 k+2$, with $k$ a positive integer. The equation becomes $4 \cdot 8^{k}+3=z^{3}$. A reduction modulo 9 implies that $k$ is odd, $k=2 n+1$, and the equation further changes into $32 \cdot 64^{n}+3=z^{3}$. This is impossible modulo 13 . Hence, no solutions.

\section{(I. Cucurezeanu)}

781. First solution: Here is a proof by induction on $n$. The case $n=1$ is an easy check. Let us verify the inductive step from $n$ to $n+1$. We transform the left-hand side as

$$
\sum_{k=1}^{n+1} \phi(k)\left\lfloor\frac{n+1}{k}\right\rfloor=\sum_{k=1}^{n+1} \phi(k)\left\lfloor\frac{n}{k}\right\rfloor+\sum_{k=1}^{n+1} \phi(k)\left(\left\lfloor\frac{n+1}{k}\right\rfloor-\left\lfloor\frac{n}{k}\right\rfloor\right) \text {. }
$$

The last term in the first sum can be ignored since it is equal to zero. To evaluate the second sum, we observe that

$$
\left\lfloor\frac{n+1}{k}\right\rfloor-\left\lfloor\frac{n}{k}\right\rfloor= \begin{cases}1 & \text { if } k \text { divides } n, \\ 0 & \text { otherwise. }\end{cases}
$$

Therefore,

$$
\sum_{k=1}^{n+1} \phi(k)\left\lfloor\frac{n+1}{k}\right\rfloor=\sum_{k=1}^{n} \phi(k)\left\lfloor\frac{n}{k}\right\rfloor+\sum_{k \mid n+1} \phi(k) .
$$

Using the induction hypothesis and Gauss' identity $\sum_{k \mid n} \phi(k)=n$, we find that this is equal to $\frac{n(n+1)}{2}+(n+1)$, which is further equal to the desired answer $\frac{(n+1)(n+2)}{2}$. This completes the induction, and the solution to the problem.

Second solution: Using the Gauss identity for Euler's totient function (the first problem in this section), we can write

$$
\frac{n(n+1)}{2}=\sum_{m=1}^{n} m=\sum_{m=1}^{n} \sum_{k \mid m} \phi(k)=\sum_{k=1}^{n} \phi(k) \sum_{m=1}^{\lfloor n / k\rfloor} 1 .
$$

This is clearly equal to the left-hand side of the identity from the statement, and we are done.

(M.O. Drimbe, 200 de Identitaţi şi Inegalitaţi cu "Partea Întreagă (200 Identities and Inequalities about the “Greatest Integer Function'), GIL, 2004, second solution by R. Stong)

782. We may assume $\operatorname{gcd}(a, d)=1, d \geq 1, a>d$. Since $a^{\phi(d)} \equiv 1(\bmod d)$, it follows that $a^{k \phi(d)} \equiv 1(\bmod d)$ for all integers $k$. Hence for all $k \geq 1$,

$$
a^{k \phi(d)}=1+m_{k} d,
$$

for some positive integers $m_{k}$. If we let $n_{k}=a m_{k}, k \geq 1$, then

$$
a+n_{k} d=a^{k \phi(d)+1},
$$

so the prime factors of $a+n_{k} d, k \geq 1$, are exactly those of $a$.

(G. Pólya, G. Szegó, Aufgaben und Lehrsätze aus der Analysis, Springer-Verlag, 1964)

783. The customer picks a number $k$ and transmits it securely to the bank using the algorithm described in the essay. Using the two large prime numbers $p$ and $q$, the bank finds $m$ such that $k m \equiv 1(\bmod (p-1)(q-1))$. If $\alpha$ is the numerical information that the customer wants to receive, the bank computes $\alpha^{m}(\bmod n)$, then transmits the answer $\beta$ to the customer. The customer computes $\beta^{k}(\bmod n)$. By Euler's theorem, this is $\alpha$. Success!

784. As before, let $p$ and $q$ be two large prime numbers known by the United Nations experts alone. Let also $k$ be an arbitrary secret number picked by these experts with the property that $\operatorname{gcd}(k,(p-1)(q-1))=1$. The number $n=p q$ and the inverse $m$ of $k$ modulo $\phi(n)=(p-1)(q-1)$ are provided to both the country under investigation and to the United Nations.

The numerical data $\alpha$ that comprises the findings of the team of experts is raised to the power $k$, then reduced modulo $n$. The answer $\beta$ is handed over to the country. Computing $\beta^{m}$ modulo $n$, the country can read the data. But it cannot encrypt fake data, since it does not know the number $k$.

785. We are to find the smallest positive solution to the system of congruences

$$
\begin{aligned}
&x \equiv 1(\bmod 60), \\
&x \equiv 0(\bmod 7) .
\end{aligned}
$$

The general solution is $7 b_{1}+420 t$, where $b_{1}$ is the inverse of 7 modulo 60 and $t$ is an integer. Since $b_{1}$ is a solution to the Diophantine equation $7 b_{1}+60 y=1$, we find it using Euclid's algorithm. Here is how to do it: $60=8 \cdot 7+4,7=1 \cdot 4+3,4=1 \cdot 3+1$. Then

$$
\begin{aligned}
1 &=4-1 \cdot 3=4-1 \cdot(7-1 \cdot 4)=2 \cdot 4-7=2 \cdot(60-8 \cdot 7)-7 \\
&=2 \cdot 60-17 \cdot 7
\end{aligned}
$$

Hence $b_{1}=-17$, and the smallest positive number of the form $7 b_{1}+420 t$ is $-7 \cdot 17+$ $420 \cdot 1=301$.

(Brahmagupta)

786. Let $p_{1}, p_{2}, \ldots, p_{2 n}$ be different primes. By the Chinese Remainder Theorem there exists $x$ such that

$$
\begin{aligned}
x & \equiv 0\left(\bmod p_{1} p_{2}\right) \\
x & \equiv-1\left(\bmod p_{3} p_{4}\right), \\
& \cdots \\
x & \equiv-n+1\left(\bmod p_{2 n-1} p_{2 n}\right) .
\end{aligned}
$$

Then the numbers $x+k, 0 \leq k \leq n-1$, are each divisible by $p_{2 k+1} p_{2 k+2}$, and we are done.

Remark. This problem shows a nontrivial way in which there exist arbitrarily long arithmetic progressions containing no prime numbers. 

787. Let $m=m_{1} m_{2}$. If $x \in\{0,1, \ldots, m-1\}$ is such that $P(x) \equiv 0(\bmod m)$, then $P(x) \equiv 0\left(\bmod m_{1}\right)$. Let $a_{1}$ be the residue of $x$ modulo $m_{1}$. Then $P\left(a_{1}\right) \equiv 0\left(\bmod m_{1}\right)$. Similarly, if $a_{2}$ is the residue of $x$ modulo $m_{2}$, then $P\left(a_{2}\right) \equiv 0\left(\bmod m_{2}\right)$. Thus for each solution $x$ to $P(x) \equiv 0(\bmod m)$, we have constructed a pair $\left(a_{1}, a_{2}\right)$ with $a_{i}$ a solution to $P(x) \equiv 0\left(\bmod m_{i}\right), i=1,2$.

Conversely, given the residues $a_{i}$ such that $P\left(a_{i}\right) \equiv 0\left(\bmod m_{i}\right), i=1,2$, by the Chinese Remainder Theorem there exists a unique $x \in\{0,1, \ldots, m-1\}$ such that $x \equiv a_{i}\left(\bmod m_{i}\right), i=1,2$. Then $P(x) \equiv 0\left(\bmod m_{i}\right), i=1,2$, and consequently $P(x) \equiv 0(\bmod m)$. We have established a bijection from the set of solutions to the equation $P(x) \equiv 0(\bmod m)$ to the Cartesian product of the sets of solutions to $P(x) \equiv$ $0\left(\bmod m_{i}\right), i=1,2$. The conclusion follows.

(I. Niven, H.S. Zuckerman, H.L. Montgomery, An Introduction to the Theory of Numbers, Wiley, 1991)

788. Since this is a game with finite number of possibilities, there is always a winning strategy, either for the first player, or for the second. Arguing by contradiction, let us assume that there are only finitely many $n$ 's, say $n_{1}, n_{2}, \ldots, n_{m}$ for which Bob has a winning strategy. Then for every other nonnegative integer $n$, Alice must have some move on a heap of $n$ stones leading to a position in which the second player wins. This means that any other integer $n$ is of the form $p-1+n_{k}$ for some prime $p$ and some $1 \leq k \leq m$

We will prove that this is not the case. Choose an integer $N$ greater than all the $n_{k}$ 's and let $p_{1}, p_{2}, \ldots, p_{N}$ be the first $N$ prime numbers. By the Chinese Remainder Theorem, there exists a positive integer $x$ such that

$$
\begin{aligned}
x & \equiv-1\left(\bmod p_{1}^{2}\right) \\
x & \equiv-2\left(\bmod p_{2}^{2}\right) \\
& \cdots \\
x & \equiv-N\left(\bmod p_{r}^{2}\right)
\end{aligned}
$$

Then the number $x+N+1$ is not of the form $p-1+n_{k}$, because each of the numbers $x+N+1-n_{k}-1$ is composite, being a multiple of a square of a prime number. We have reached a contradiction, which proves the desired conclusion.

(67th W.L. Putnam Mathematical Competition, 2006)

789. Let $p_{1}<p_{2}<p_{3}<\cdots$ be the sequence of all prime numbers. Set $a_{1}=2$. Inductively, for $n \geq 1$, let $a_{n+1}$ be the least integer greater than $a_{n}$ that is congruent to $-k$ modulo $p_{k+1}$, for all $k \leq n$. The existence of such an integer is guaranteed by the Chinese Remainder Theorem. Observe that for all $k \geq 0, k+a_{n} \equiv 0\left(\bmod p_{k+1}\right)$ for $n \geq k+1$. Then at most $k+1$ values in the sequence $k+a_{n}, n \geq 1$, can be prime, since from the $(k+2)$ nd term onward, the terms of the sequence are nontrivial multiples of $p_{k+1}$, and therefore must be composite. This completes the proof.

(Czech and Slovak Mathematical Olympiad, 1997)

790. We construct such a sequence recursively. Suppose that $a_{1}, a_{2}, \ldots, a_{m}$ have been chosen. Set $s=a_{1}+a_{2}+\cdots+a_{m}$, and let $n$ be the smallest positive integer that is not yet a term of the sequence. By the Chinese Remainder Theorem, there exists $t$ such that $t \equiv-s(\bmod (m+1))$, and $t \equiv-s-n(\bmod (m+2))$. We can increase $t$ by a suitably large multiple of $(m+1)(m+2)$ to ensure that it does not equal any of $a_{1}, a_{2}, \ldots, a_{m}$. Then $a_{1}, a_{2}, \ldots, a_{m}, t, n$ is also a sequence with the desired property. Indeed, $a_{1}+a_{2}+\cdots+a_{m}+t=s+t$ is divisible by $m+1$ and $a_{1}+\cdots+a_{m}+t+n=s+t+n$ is divisible by $m+2$. Continue the construction inductively. Observe that the algorithm ensures that $1, \ldots, m$ all occur among the first $2 m$ terms.

(Russian Mathematical Olympiad, 1995)

791. First, let us fulfill a simpler task, namely to find a $k$ such that $k \cdot 2^{n}+1$ is composite for every $n$ in an infinite arithmetic sequence. Let $p$ be a prime, and $b$ some positive integer. Choose $k$ such that $k \cdot 2^{b} \equiv-1(\bmod p)$ (which is possible since $2^{b}$ has an inverse modulo $p)$, and such that $k \cdot 2^{b}+1>p$. Also, let $a$ be such that $2^{a} \equiv 1(\bmod p)$. Then $k \cdot 2^{a m+b}+1$ is divisible by $p$ for all $m \geq 0$, hence is composite.

Now assume that we were able to find a finite set of triples $\left(a_{j}, b_{j}, p_{j}\right), 1 \leq j \leq s$, with $2^{a_{j}} \equiv 1\left(\bmod p_{j}\right)$ and such that for any positive integer $n$ there exist $m$ and $j$ with $n=a_{j} m+b_{j}$. We would like to determine a $k$ such that $k \cdot 2^{a_{j} m+b_{j}}+1$ is divisible by $p_{j}$, $1 \leq j \leq s, m \geq 0$. Using the Chinese Remainder Theorem we can use $k$ as a sufficiently large solution to the system of equations

$$
k \equiv-2^{-b_{j}}\left(\bmod p_{j}\right), \quad 0 \leq j \leq s .
$$

Then for every $n, k \cdot 2^{n}+1$ is divisible by one of the $p_{j}$ 's, $j=0,1, \ldots, s$, hence is composite.

An example of such a family of triples is $(2,0,3),(3,0,7),(4,1,5),(8,3,17)$, $(12,7,13),(24,23,241)$.

(W. Sierpiński, 250 Problems in Elementary Number Theory, Państwowe Wydawnictwo Naukowe, Warsawa, 1970)

792. Assume the contrary and consider a prime $p$ that does not divide $b-a$. By the Chinese Remainder Theorem we can find a positive integer $n$ such that

$$
\begin{aligned}
&n \equiv 1(\bmod p-1), \\
&n \equiv-a(\bmod p) .
\end{aligned}
$$

Then by Fermat's little theorem,

$$
a^{n}+n \equiv a+n \equiv a-a \equiv 0(\bmod p)
$$

and

$$
b^{n}+n \equiv b+n \equiv b-a(\bmod p) .
$$

It follows that $p$ divides $a^{n}+n$ but does not divide $b^{n}+n$, a contradiction. Hence $a=b$, as desired.

(short list of the 46th International Mathematical Olympiad, 2005)

793. The idea is to place $(a, b)$ at the center of a square of size $(2 n+1) \times(2 n+1)$ having the property that all lattice points in its interior and on its sides are not visible from the origin. To this end, choose $(2 n+1)^{2}$ distinct primes $p_{i j},-n \leq i, j \leq n$. Apply the Chinese Remainder Theorem to find an $a$ with $a+i \equiv 0\left(\bmod p_{i j}\right)$ for all $i, j$ and a $b$ with $b+j \equiv 0\left(\bmod p_{i j}\right)$ for all $i, j$. For any $i$ and $j, a+i$ and $b+j$ are both divisible by $p_{i j}$. Hence none of the points $(a+i, b+j)$ are visible from the origin. We conclude that any point visible from the origin lies outside the square of size $(2 n+1) \times(2 n+1)$ centered at $(a, b)$, hence at distance greater than $n$ from $(a, b)$.

(American Mathematical Monthly, 1977, proposed by A.A. Mullin)

794. This problem tests whether you really understood our discussion of the procedure of writing the elements of $\operatorname{SL}(2, \mathbb{Z})$ in terms of the generators.

Call the first matrix from the statement $\bar{S}$. This matrix is no longer in $\operatorname{SL}(2, \mathbb{Z})$ ! Let us see again where the linear equation is. The determinant of the matrix

$$
\left[\begin{array}{rr}
12 & 5 \\
7 & 3
\end{array}\right]
$$

is equal to $12 \cdot 3-7 \cdot 5=1$, so $(3,5)$ is a solution to the linear equation $12 x-7 y=1$. Note that

$$
\bar{S}\left(\begin{array}{l}
p \\
q
\end{array}\right)=\left(\begin{array}{l}
q \\
p
\end{array}\right), \quad T^{n}\left(\begin{array}{l}
p \\
q
\end{array}\right)=\left(\begin{array}{r}
p+n q \\
q
\end{array}\right) .
$$

So $\bar{S}$ flips a fraction, and $T^{k}$ adds $k$ to it. This time it is the continued fraction expansion

$$
\frac{12}{7}=1+\frac{1}{1+\frac{1}{2+\frac{1}{2}}}
$$

(no negatives !). All we need to do is start with $\bar{S}$ and apply to it $T^{2}$, then $\bar{S}$, then again $T^{2}$, and so on, following the continued fraction expansion from bottom to top. We thus obtain

$$
\left[\begin{array}{rr}
12 & 5 \\
7 & 3
\end{array}\right]=T \bar{S} T \bar{S} T^{2} \bar{S} T^{2} \bar{S}
$$

and the problem is solved.

795. Consider first the case $a=0$. Since $b y=m$ always has solutions, it follows that $b=\pm 1$. From this we deduce that $y=\pm m$. The second equation becomes a linear equation in $x, c x=n \mp d m$, which is supposed always to have an integer solution. This implies $c=\pm 1$, and hence $a d-b c=b c=\pm 1$. The same argument applies if any of $b, c$, or $d$ is 0 .

If none of them is zero, set $\Delta=a b-c d$. Again we distinguish two cases. If $\Delta=0$, then $\frac{a}{c}=\frac{b}{d}=\lambda$. Then $m=a x+b y=\lambda(c x+d y)=\lambda n$, which restricts the range of $m$ and $n$. Hence $\Delta \neq 0$.

Solving the system using Cramer's rule, we obtain

$$
x=\frac{d m-b n}{\Delta}, \quad y=\frac{a n-c m}{\Delta} .
$$

These numbers are integers for any $m$ and $n$. In particular, for $(m, n)=(1,0), x_{1}=\frac{d}{\Delta}$, $y_{1}=-\frac{c}{\Delta}$, and for $(m, n)=(0,1), x_{2}=-\frac{b}{\Delta}, y_{2}=\frac{a}{\Delta}$. The number

$$
x_{1} y_{2}-x_{2} y_{1}=\frac{a d-b c}{\Delta^{2}}=\frac{1}{\Delta}
$$

is therefore an integer. Since $\Delta$ is an integer, this can happen only if $\Delta=\pm 1$, and the problem is solved.

Remark. A linear map $T: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$ is called orientation preserving if its determinant is positive, and orientation reversing otherwise. As a consequence of what we just proved, we obtain that $\mathrm{SL}(2, \mathbb{Z})$ consists of precisely those orientation-preserving linear transformations of the plane that map $\mathbb{Z}^{2}$ onto itself.

796. Because $\operatorname{gcd}(a, b)=1$, the equation $a u-b v=1$ has infinitely many positive solutions $(u, v)$. Let $(t, z)$ be a solution. Consider now the system in $(x, y)$,

$$
\left\{\begin{array}{l}
a x-y z-c=0, \\
b x-y t+d=0 .
\end{array}\right.
$$

The determinant of its coefficient matrix is $-1$, so the system admits integer solutions. Solving, we obtain

$$
\left(\begin{array}{l}
x \\
y
\end{array}\right)=\left(\begin{array}{c}
t-z \\
b-a
\end{array}\right)\left(\begin{array}{r}
c \\
-d
\end{array}\right)=\left(\begin{array}{c}
t c+z d \\
b c+a d
\end{array}\right) .
$$

So each positive solution $(t, z)$ to the equation $a u-b v=1$ yields a positive solution ( $t c+z d, b c+a d, z, t)$ to the original system of equations. This solves the problem. 

797. At each cut we add 7 or 11 new pieces. Thus after cutting $x$ times in 8 and $y$ times in 12 we have $7 x+11 y+1$ pieces. The problem amounts to showing that the equation $7 x+11 y=n$ has nonnegative solutions for every $n \geq 60$, but no nonnegative solution for $n=59$. This is of course a corollary to Sylvester's theorem, but let us see how the proof works for this particular situation.

The numbers $11 \cdot 0,11 \cdot 1, \ldots, 11 \cdot 6$ form a complete set of residues modulo 7 . This means that for $n$ equal to one of the numbers $60=11 \cdot 6-6,61=11 \cdot 6-5, \ldots, 66=11 \cdot 6$, one can find nonnegative $x$ and $y$ such that $7 x+11 y=n$. Indeed,

$$
\begin{aligned}
&60=7 \cdot 7+11 \cdot 1, \\
&61=7 \cdot 4+11 \cdot 3, \\
&62=7 \cdot 1+11 \cdot 5, \\
&63=7 \cdot 9+11 \cdot 0, \\
&64=7 \cdot 6+11 \cdot 2, \\
&65=7 \cdot 3+11 \cdot 4, \\
&66=7 \cdot 0+11 \cdot 6 .
\end{aligned}
$$

Since if we are able to cut the sheet of paper into $n$ pieces we are also able to cut it into $n+7$, we can prove by induction that the cut is possible for any $n \geq 61$.

Let us now show that the equation $7 x+11 y=59$ has no solution. Rewrite it as $7 x+11(y-5)=4$. This implies $7 x \equiv 4(\bmod 11)$. But this means $x \equiv 10(\bmod 11)$, hence $x \geq 10$. This is impossible since $7 x+11 y=59$ implies $x \leq 8$. Hence we cannot obtain 60 pieces, and the problem is solved.

(German Mathematical Olympiad, 1970/71)

798. Multiply the geometric series

$$
\frac{1}{1-x^{a}}=1+x^{a}+x^{2 a}+\cdots \quad \text { and } \quad \frac{1}{1-x^{b}}=1+x^{b}+x^{2 b}+\cdots .
$$

The coefficient of $x^{n}$ in the product counts the number of ways exponents of the form $k a$ and $m b$ add up to $n$. And this is $s(n)$.

799. The number $n$ can be represented as $4 m, 4 m+1,4 m+2$, or $4 m+3$. The required solution is provided by one of the following identities:

$$
\begin{aligned}
4 m &=(2 m-1)+(2 m+1), \\
4 m+1 &=2 m+(2 m+1), \\
4 m+2 &=(2 m-1)+(2 m+3), \\
4 m+3 &=(2 m+1)+(2 m+2) .
\end{aligned}
$$

The two terms on the right are coprime because either they differ by 1 , or they are odd and differ by 2 or 4 . 

800. Note that for any integer $k$, we can dissect the $d$-dimensional cube into $k^{d}$ pieces. If we do this for two integers $a$ and $b$, then performing the appropriate dissections we can obtain $\left(a^{d}-1\right) x+\left(b^{d}-1\right) y+1$ cubes.

By Sylvester's theorem for coprime positive numbers $\alpha$ and $\beta$, the equation $\alpha x+\beta y=$ $n$ has nonnegative solutions provided that $n$ is sufficiently large.

To complete the solution, we just have to find $a$ and $b$ such that $a^{d}-1$ and $b^{d}-1$ are coprime. We can choose any $a$ and then let $b=a^{d}-1$. Indeed, $\left(a^{d}-1\right)^{d}-1$ differs from a power of $a^{d}-1$ by 1 , so the two numbers cannot have a common divisor.

801. There exist integers $u$ and $v$ such that the two sides in question are $a=u^{2}-v^{2}$ and $b=2 u v$. We are also told that $a+b=k^{2}$, for some integer $k$. Then

$$
\begin{aligned}
a^{3}+b^{3} &=(a+b)\left(a^{2}-a b+b^{2}\right)=k^{2}\left(\left(u^{2}-v^{2}\right)^{2}-2 u v\left(u^{2}-v^{2}\right)+4 u^{2} v^{2}\right) \\
&=k^{2}\left(u^{4}+v^{4}-2 u^{3} v+2 u v^{3}+2 u^{2} v^{2}\right)=\left[k\left(u^{2}-u v\right)\right]^{2}+\left[k\left(v^{2}+u v\right)\right]^{2},
\end{aligned}
$$

and the problem is solved.

802. We guess immediately that $x=2, y=4$, and $z=2$ is a solution because of the trigonometric triple $3,4,5$. This gives us a hint as to how to approach the problem. Checking parity, we see that $y$ has to be even. A reduction modulo 4 shows that $x$ must be even, while a reduction modulo 3 shows that $z$ must be even. Letting $x=2 m$ and $z=2 n$, we obtain a Pythagorean equation

$$
\left(3^{m}\right)^{2}+y^{2}=\left(5^{n}\right)^{2} .
$$

Because $y$ is even, in the usual parametrization of the solution we should have $3^{m}=$ $u^{2}-v^{2}$ and $5^{n}=u^{2}+v^{2}$. From $(u-v)(u+v)=3^{m}$ we find that $u-v$ and $u+v$ are powers of 3. Unless $u-v$ is $1, u=(u-v+u+v) / 2$ and $v=(u+v-u+v) / 2$ are both divisible by 3 , which cannot happen because $u^{2}+v^{2}$ is a power of 5 . So $u-v=1$, $u+v=3^{m}$, and $u^{2}+v^{2}=5^{n}$. Eliminating the parameters $u$ and $v$, we obtain the simpler equation

$$
2 \cdot 5^{n}=9^{m}+1 .
$$

First, note that $n=1$ yields the solution mentioned in the beginning. If $n>1$, then looking at the equation modulo 25 , we see that $m$ has to be an odd multiple of 5 , say $m=5(2 k+1)$. But then

$$
2 \cdot 5^{n}=\left(9^{5}\right)^{2 k+1}+1=\left(9^{5}+1\right)\left(\left(9^{5}\right)^{2 k}-\left(9^{5}\right)^{2 k-1}+\cdots+1\right),
$$

which implies that $2 \cdot 5^{n}$ is a multiple of $9^{5}+1=2 \cdot 5^{2} \cdot 1181$. This is of course impossible; hence the equation does not have other solutions.

(I. Cucurezeanu) 

803. The last digit of a perfect square cannot be 3 or 7 . This implies that $x$ must be even, say $x=2 x^{\prime}$. The condition from the statement can be written as

$$
\left(2^{x^{\prime}}\right)^{2}+\left(5^{y}\right)^{2}=z^{2},
$$

for integers $x^{\prime}, y$, and $z$. It follows that there exist integers $u$ and $v$ such that $5^{y}=u^{2}-v^{2}$ and $2^{x^{\prime}}=2 u v$ (looking at parity, we rule out the case $5^{y}=2 u v$ and $2^{x^{\prime}}=u^{2}-v^{2}$ ). From the first equality we see that any common factor of $u$ and $v$ is a power of 5 . From the second we find that $u$ and $v$ are powers of 2. Thus $u=2^{x^{\prime}-1}$ and $v=1$. It follows that $x^{\prime}$ and $y$ satisfy the simpler Diophantine equation

$$
5^{y}=2^{2 x^{\prime}-2}-1 .
$$

But then $5^{y}=\left(2^{x^{\prime}-1}-1\right)\left(2^{x^{\prime}-1}+1\right)$, and the factors on the right differ by 2 , which cannot happen since no powers of 5 differ by 2 . Hence no such numbers can exist.

804. Here is how to transform the equation from the statement into a Pythagorean equation:

$$
\begin{aligned}
x^{2}+y^{2} &=1997(x-y), \\
2\left(x^{2}+y^{2}\right) &=2 \cdot 1997(x-y), \\
(x+y)^{2}+(x-y)^{2}-2 \cdot 1997(x-y) &=0, \\
(x+y)^{2}+(1997-x+y)^{2} &=1997^{2} .
\end{aligned}
$$

Because $x$ and $y$ are positive integers, $0<x+y<1997$, and for the same reason $0<1997-x+y<1997$. The problem reduces to solving the Pythagorean equation $a^{2}+b^{2}=1997^{2}$ in positive integers. Since 1997 is prime, the greatest common divisor of $a$ and $b$ is 1 . Hence there exist coprime positive integers $u>v$ with the greatest common divisor equal to 1 such that

$$
1997=u^{2}+v^{2}, \quad a=2 u v, \quad b=u^{2}-v^{2} .
$$

Because $u$ is the larger of the two numbers, $\frac{1997}{2}<u^{2}<1997$; hence $33 \leq u \leq 44$. There are 12 cases to check. Our task is simplified if we look at the equality $1997=u^{2}+v^{2}$ and realize that neither $u$ nor $v$ can be divisible by 3 . Moreover, looking at the same equality modulo 5 , we find that $u$ and $v$ can only be 1 or $-1$ modulo 5 . We are left with the cases $m=34,41$, or 44 . The only solution is $(m, n)=(34,29)$. Solving $x+y=2 \cdot 34 \cdot 29$ and $1997-x+y=34^{2}-29^{2}$, we obtain $x=1827, y=145$. Solving $x+y=34^{2}-29^{2}$, $1997-x+y=2 \cdot 34 \cdot 29$, we obtain $(x, y)=(170,145)$. These are the two solutions to the equation.

(Bulgarian Mathematical Olympiad, 1997) 

805. One can verify that $x=2 m^{2}+1$ and $y=2 m$ is a solution. (Diophantus)

806. We will search for numbers $x$ and $y$ for which $2^{x^{2}}=a^{2}$ and $2^{y^{2}}=2 a$, so that $1+2^{x^{2}}+2^{y^{2}}=(a+1)^{2}$. Then $x=2 z$ for some positive integer $z$, and

$$
a=2^{2 z^{2}}=2^{y^{2}-1} .
$$

This leads to the Pell equation

$$
y^{2}-2 z^{2}=1 .
$$

This equation has infinitely many solutions, given by

$$
y_{n}+z_{n} \sqrt{2}=(3+2 \sqrt{2})^{n},
$$

and we are done.

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by M. Burtea)

807. The Pell equation $x^{2}-2 y^{2}=1$ has infinitely many solutions. Choose $n=x^{2}-1$. Then $n=y^{2}+y^{2}, n+1=x^{2}+0^{2}$, and $n+2=x^{2}+1^{2}$, and we are done.

(61st W.L. Putnam Mathematical Competition, 2000)

808. In other words, the problem asks us to show that the Diophantine equation $x^{2}-2=7^{y}$ has no positive solutions. A reduction modulo 8 makes the right-hand side equal to $(-1)^{y}$, while the left-hand side could only be equal to $-2,-1,2$. This means that $y$ must be odd, $y=2 z+1$, with $z$ an integer.

Multiplying by $7^{y}=7^{2 z+1}$ and completing the square, we obtain the equivalent equation

$$
\left(7^{2 z+1}+1\right)^{2}-7\left(7^{z} x\right)^{2}=1 .
$$

Let us analyze the associated Pell equation

$$
X^{2}-7 Y^{2}=1 .
$$

Its fundamental solution is $X_{1}=8, Y_{1}=3$, and its general solution is given by

$$
X_{k}+Y_{k} \sqrt{7}=(8+3 \sqrt{7})^{k}, \quad k=1,2, \ldots
$$

Substituting $X=7^{2 z+1}+1$ and $Y=7^{z} x$, we obtain

$$
7^{2 z+1}+1=8^{k}+\left(\begin{array}{l}
k \\
2
\end{array}\right) 8^{k-2} \cdot 3^{2} \cdot 7+\left(\begin{array}{l}
k \\
4
\end{array}\right) 8^{k-4} \cdot 3^{4} \cdot 7^{2}+\cdots,
$$



$$
7^{z}=\left(\begin{array}{l}
k \\
1
\end{array}\right) 8^{k-1} \cdot 3+\left(\begin{array}{c}
k \\
3
\end{array}\right) 8^{k-3} \cdot 3^{3} \cdot 7+\left(\begin{array}{c}
k \\
5
\end{array}\right) 8^{k-5} \cdot 3^{5} \cdot 7^{2}+\cdots
$$

Let us compare the power of 7 in $k=\left(\begin{array}{l}k \\ 1\end{array}\right)$ with the power of 7 in $\left(\begin{array}{c}k \\ 2 m+1\end{array}\right) 7^{m}, m>1$. Writ$\operatorname{ing}\left(\begin{array}{c}k \\ 2 m+1\end{array}\right) 7^{m}=\frac{7^{m} k(k-1) \cdots(k-2 m-1)}{1 \cdot 2 \cdots k}$, we see that the power of 7 in the numerator grows faster than it can be canceled by the denominator. Consequently, in the second equality from above, the power of 7 in the first term is less than in the others. We thus obtain that $7^{z}$ divides $k$. But then $8^{k}>8^{7^{z}}>7^{2 z+1}$, and the first inequality could not hold. This shows that the equation has no solutions.

\section{(I. Cucurezeanu)}

809. Expanding the cube, we obtain the equivalent equation $3 x^{2}+3 x+1=y^{2}$. After multiplying by 4 and completing the square, we obtain $(2 y)^{2}-3(2 x+1)^{2}=1$, a Pell equation, namely, $u^{2}-3 v^{2}=1$ with $u$ even and $v$ odd. The solutions to this equation are generated by $u_{n} \pm v_{n} \sqrt{3}=(2 \pm \sqrt{3})^{n}$, and the parity restriction shows that we must select every other solution. So the original equation has infinitely many solutions generated by

$$
2 y_{n} \pm\left(2 x_{n}+1\right) \sqrt{3}=(2 \pm \sqrt{3})(5 \pm 4 \sqrt{3})^{n},
$$

or, explicitly,

$$
\begin{aligned}
&x_{n}=\frac{(2+\sqrt{3})(5+4 \sqrt{3})^{n}-(2-\sqrt{3})(5-4 \sqrt{3})^{n}-1}{2}, \\
&y_{n}=\frac{(2+\sqrt{3})(5+4 \sqrt{3})^{n}+(2-\sqrt{3})(5-4 \sqrt{3})^{n}}{2} .
\end{aligned}
$$

810. One family of solutions is of course $(n, n), n \in \mathbb{N}$. Let us see what other solutions the equation might have. Denote by $t$ the greatest common divisor of $x$ and $y$, and let $u=\frac{x}{t}, v=\frac{y}{t}$. The equation becomes $t^{5}(u-v)^{5}=t^{3}\left(u^{3}-v^{3}\right)$. Hence

$$
t^{2}(u-v)^{4}=\frac{u^{3}-v^{3}}{u-v}=u^{2}+u v+v^{2}=(u-v)^{2}+3 u v
$$

or $(u-v)^{2}\left[t^{2}(u-v)^{2}-1\right]=3 u v$. It follows that $(u-v)^{2}$ divides $3 u v$, and since $u$ and $v$ are relatively prime and $u>v$, this can happen only if $u-v=1$. We obtain the equation $3 v(v+1)=t^{2}-1$, which is the same as

$$
(v+1)^{3}-v^{3}=t^{2}
$$

This was solved in the previous problem. The solutions to the original equation are then given by $x=(v+1) t, y=v t$, for any solution $(v, t)$ to this last equation.

\section{(A. Rotkiewicz)}

811. It is easy to guess that $(x, y, z, t)=(10,10,-1,0)$ is a solution. Because quadratic Diophantine equations are usually simpler than cubic equations, we try to reduce the given equation to a quadratic. We do this by perturbing the particular solution that we already know.

We try to find numbers $u$ and $v$ such that $\left(10+u, 10-u,-\frac{1}{2}+v,-\frac{1}{2}-v\right)$ is a solution. Of course, $v$ has to be a half-integer, so it is better to replace it by $\frac{w}{2}$, where $w$ is an odd integer. The equation becomes

$$
\left(2000+u^{2}\right)-\frac{1+3 w^{2}}{4}=1999,
$$

which is the same as

$$
w^{2}-80 u^{2}=1 .
$$

This is a Pell equation. The smallest solution is $\left(w_{1}, u_{1}\right)=(9,1)$, and the other positive solutions are generated by

$$
w_{n}+u_{n} \sqrt{80}=\left(w_{1}+u_{1} \sqrt{80}\right)^{n} .
$$

This gives rise to the recurrence

$$
\left(w_{n+1}, u_{n+1}\right)=\left(9 w_{n}+80 u_{n}, w_{n}+9 u_{n}\right), \quad n \geq 1 .
$$

It is now easy to prove by induction that all the $w_{n}$ 's are odd, and hence any solution $\left(w_{n}, u_{n}\right)$ to Pell's equation yields the solution

$$
\left(x_{n}, y_{n}, z_{n}, t_{n}\right)=\left(10+u_{n}, 10-u_{n},-\frac{1}{2}+\frac{w_{n}}{2},-\frac{1}{2}-\frac{w_{n}}{2}\right)
$$

to the original equation.

(Bulgarian Mathematical Olympiad, 1999)

812. Consider first the case that $n$ is even, $n=2 k, k$ an integer. We have

$$
(\sqrt{m}+\sqrt{m-1})^{2 k}=(2 m-1+2 \sqrt{m(m-1)})^{k} .
$$

The term on the right-hand side generates the solution to Pell's equation

$$
X^{2}-m(m-1) Y^{2}=1 .
$$

If for a certain $n,\left(X_{n}, Y_{n}\right)$ is the corresponding solution, then choose $p=X_{n}^{2}$. Since $p-1=X_{n}^{2}-1=m(m-1) Y_{n}^{2}$, it follows that

$$
(\sqrt{m}+\sqrt{m-1})^{2 k}=(2 m-1+2 \sqrt{m(m-1)})^{k}=X_{n}+Y_{n} \sqrt{m(m-1)}
$$



$$
=\sqrt{p}+\sqrt{p-1},
$$

as desired.

This now suggests the path we should follow in the case that $n$ is odd. Write

$$
(\sqrt{m}+\sqrt{m-1})^{n}=U_{n} \sqrt{m}+V_{n} \sqrt{m-1} .
$$

This time, $\left(U_{n}, V_{n}\right)$ is a solution to the generalized Pell equation

$$
m U^{2}-(m-1) V^{2}=1 .
$$

In a similar manner we choose $p=m U_{n}^{2}$ and obtain the desired identity.

(I. Tomescu, Problems in Combinatorics, Wiley, 1985)

813. First solution: This solution is based on an idea that we already encountered in the section on factorizations and divisibility. Solving for $y$, we obtain

$$
y=-\frac{x^{2}+4006 x+2003^{2}}{3 x+4006} .
$$

To make the expression on the right easier to handle we multiply both sides by 9 and write

$$
9 y=-3 x-8012-\frac{2003^{2}}{3 x+4006} .
$$

If $(x, y)$ is an integer solution to the given equation, then $3 x+4006$ divides $2003^{2}$. Because 2003 is a prime number, we have $3 x+4006 \in\left\{\pm 1, \pm 2003, \pm 2003^{2}\right\}$. Working modulo 3 we see that of these six possibilities, only $1,-2003$, and $2003^{2}$ yield integer solutions for $x$. We deduce that the equation from the statement has three solutions: $(-1334,-446224),(-2003,0)$, and $(1336001,-446224)$.

Second solution: Rewrite the equation as

$$
(3 x+4006)(3 x+9 y+8012)=-2003^{2} .
$$

This yields a linear system

$$
\begin{aligned}
3 x+4006 &=d, \\
3 x+9 y+8012 &=-\frac{2003^{2}}{d},
\end{aligned}
$$

where $d$ is a divisor of $-2003^{2}$. Since 2003 is prime, one has to check the cases $d=$ $\pm 1, \pm 2003, \pm 2003^{2}$, which yield the above solutions.

(American Mathematical Monthly, proposed by Wu Wei Chao) 

814. Divide through by $x^{2} y^{2}$ to obtain the equivalent equation

$$
\frac{1}{y^{2}}+\frac{1}{x y}+\frac{1}{x^{2}}=1 .
$$

One of the denominators must be less than or equal to 3. The situations $x=1$ and $y=1$ are ruled out. Thus we can have only $x y=2$ or 3 . But then again either $x$ or $y$ is 1 , which is impossible. Hence the equation has no solutions.

815. Note that $2002=3^{4}+5^{4}+6^{4}$. It suffices to consider

$$
x_{k}=3 \cdot 2002^{k}, \quad y_{k}=5 \cdot 2002^{k}, \quad z_{k}=6 \cdot 2002^{k}, \quad w_{k}=4 k+1,
$$

with $k$ a positive integer. Indeed,

$$
x_{k}^{4}+y_{k}^{4}+z_{k}^{4}=\left(3^{4}+5^{4}+6^{4}\right) 2002^{4 k}=2002^{4 k+1},
$$

for all $k \geq 1$

816. If $x \leq y \leq z$, then since $4^{x}+4^{y}+4^{z}$ is a perfect square, it follows that the number $1+4^{y-x}+4^{z-x}$ is also a perfect square. Then there exist an odd integer $t$ and a positive integer $m$ such that

$$
1+4^{y-x}+4^{z-x}=\left(1+2^{m} t\right)^{2} .
$$

It follows that

$$
4^{y-x}\left(1+4^{z-x}\right)=2^{m+1} t\left(1+2^{m-1} t\right) ;
$$

hence $m=2 y-2 x-1$. From $1+4^{z-x}=t+2^{m-1} t^{2}$, we obtain

$$
t-1=4^{y-x-1}\left(4^{z-2 y+x+1}-t^{2}\right)=4^{y-x-1}\left(2^{z-2 y+x+1}+t\right)\left(2^{z-2 y+x+1}-t\right) .
$$

Since $2^{z-2 y+x+1}+t>t$, this equality can hold only if $t=1$ and $z=2 y-x-1$. The solutions are of the form $(x, y, 2 y-x-1)$ with $x, y$ nonnegative integers.

817. With the substitution $u=2 x+3, v=2 y+3, w=2 z+3$, the equation reads

$$
u^{2}+v^{2}+w^{2}=7 .
$$

By eliminating the denominators, it is equivalent to show that the equation

$$
U^{2}+V^{2}+W^{2}=7 T^{2}
$$

has no integer solution $(U, V, W, T) \neq(0,0,0,0)$. Assuming the contrary, pick a solution for which $|U|+|V|+|W|+|T|$ is minimal. Reducing the equality modulo 4 , we find that $|U|,|V|,|W|,|T|$ is even, hence $\left(\frac{U}{2}, \frac{V}{2}, \frac{W}{2}, \frac{T}{2}\right)$ is also a solution, contradicting minimality. Hence the equation does not have solutions.

(Bulgarian Mathematical Olympiad, 1997)

818. Clearly, $y=0$ does not yield a solution, while $x=y=1$ is a solution. We show that there are no solutions with $y \geq 2$. Since in this case $7^{x}$ must give residue 4 when taken modulo 9 , it follows that $x \equiv 2(\bmod 4)$. In particular, we can write $x=2 n$, so that

$$
3^{y}=7^{2 n}-4=\left(7^{n}+2\right)\left(7^{n}-2\right) .
$$

Both factors on the right must be powers of 3, but no two powers of 3 differ by 4 . Hence there are no solutions other than $x=y=1$.

(Indian Mathematical Olympiad, 1995)

819. First solution: One can see immediately that $x=1$ is a solution. Assume that there exists a solution $x>1$. Then $x$ ! is even, so $3^{x !}$ has residue 1 modulo 4 . This implies that the last digit of the number $2^{3^{x !}}$ is 2 , so the last digit of $3^{2^{x !}}=2^{3^{x !}}+1$ is 3 . But this is impossible because the last digit of an even power of 3 is either 1 or 9 . Hence $x=1$ is the only solution.

Second solution: We will prove by induction the inequality

$$
3^{2^{x !}}<2^{3^{x !}},
$$

for $x \geq 2$. The base case $x=2$ runs as follows: $3^{2^{2}}=3^{4}=81<512=2^{9}=2^{3^{2}}$. Assume now that $3^{2^{x !}}<2^{3^{x !}}$ and let us show that $3^{2^{(x+1) !}}<2^{3^{(x+1) !}}$.

Raising the inequality $3^{2^{x !}}<2^{3 x^{x !}}$ to the power $2^{x ! \cdot x}$, we obtain

$$
\left(3^{2^{x !}}\right)^{2^{2 ! ! x}}<\left(2^{3^{x !}}\right)^{2^{x ! \cdot x}}<\left(2^{3^{x !}}\right)^{3^{x ! \cdot x}} .
$$

Therefore, $3^{2^{(x+1) !}}<2^{3^{(x+1) !}}$, and the inequality is proved. The inequality we just proved shows that there are no solutions with $x \geq 2$. We are done.

Remark. The proof by induction can be avoided if we perform some computations. Indeed, the inequality can be reduced to

$$
3^{2^{x !}}<2^{3^{x !}}
$$

and then to

$$
x !<\frac{\log \log 3-\log \log 2}{\log 3-\log 2}=1.13588 \ldots
$$

(Romanian Mathematical Olympiad, 1985) 

820. First solution: The solutions are

$$
(v+1, v, 1,1), \text { for all } v ; \quad(2,1,1, y), \text { for all } y ; \quad(2,3,2,1),(3,2,2,3) .
$$

To show that these are the only solutions, we consider first the simpler case $v=$ $u+1$. Then $u^{x}-(u+1)^{y}=1$. Considering this equation modulo $u$, we obtain $-1 \equiv u^{x}-(u+1)^{y}=1(\bmod u)$. So $u=1$ or 2 . The case $u=1$ is clearly impossible, since then $v^{y}=0$, so we have $u=2, v=3$. We are left with the simpler equation $2^{x}-3^{y}=1$. Modulo 3 it follows that $x$ is even, $x=2 x^{\prime}$. The equality $2^{2 x^{\prime}}-1=\left(2^{x^{\prime}}-1\right)\left(2^{x^{\prime}}+1\right)=3^{y}$ can hold only if $x^{\prime}=1$ (the only consecutive powers of 3 that differ by 2 are 1 and 3). So $x=2, y=1$, and we obtain the solution $(2,3,2,1)$.

Now suppose that $u=v+1$. If $v=1$, then $u=2, x=1$, and $y$ is arbitrary. So we have found the solution $(2,1,2, y)$. If $v=2$, the equation reduces to $3^{x}-2^{y}=1$. If $y \geq 2$, then modulo 4 we obtain that $x$ is even, $x=2 x^{\prime}$, and so $3^{2 x^{\prime}}-1=\left(3^{x^{\prime}}-1\right)\left(3^{x^{\prime}}+\right.$ 1) $=2^{y}$. Two consecutive powers of 2 differ by 2 if they are 2 and 4 . We find that either $x=y=1$ or $x=2, y=3$. This gives the solutions $(2,1,1,1)$ and $(3,2,2,3)$.

So let us assume $v \geq 3$. The case $y=1$ gives the solutions $(v+1, v, 1,1)$. If $y>1$, then $v^{2}$ divides $v^{y}$, so $1 \equiv(v+1)^{x} \equiv 0+\left(\begin{array}{l}x \\ 1\end{array}\right) v+1\left(\bmod v^{2}\right)$, and therefore $v$ divides $x$. Considering the equation modulo $v+1$, we obtain $1 \equiv(v+1)^{x}-v^{y} \equiv$ $-(-1)^{y}(\bmod (v+1))$. Since $v+1>2,1 \not \equiv-1(\bmod (v+1))$, so $y$ must be odd. Now if $x=1$, then $v^{y}=v$, so $v=1$, giving again the family of solutions $(v+1, v, 1,1)$. So assume $x>1$. Then $(v+1)^{2}$ divides $(v+1)^{x}$, so

$$
\begin{aligned}
1 & \equiv(v+1)^{x}-v^{y} \equiv-(v+1-1)^{y} \\
& \equiv 0-\left(\begin{array}{l}
y \\
1
\end{array}\right)(v+1)(-1)^{y-1}-(-1)^{y} \\
& \equiv-y(v+1)+1\left(\bmod (v+1)^{2}\right)
\end{aligned}
$$

Hence $v+1$ divides $y$. Since $y$ is odd, $v+1$ is odd and $v$ is even. Since $v$ divides $x$, $x$ is also even. Because $v$ is even and $v \geq 3$, it follows that $v \geq 4$. We will need the following result.

Lemma. If $a$ and $q$ are odd, if $1 \leq m<t$, and if $a^{2^{m} q} \equiv 1\left(\bmod 2^{t}\right)$, then $a \equiv$ $\pm 1\left(\bmod 2^{t-m}\right)$.

Proof. First, let us prove the property for $q=1$. We will do it by induction on $m$. For $m=1$ we have $a^{2}=(a-1)(a+1)$, so one of the factors is divisible by $2^{t-1}$. Assume that the property is true for $m-1$ and let us prove it for $m$. Factoring, we obtain $\left(a^{2^{m-1}}+1\right)\left(a^{2^{m-1}}-1\right)$. For $m \geq 2$, the first factor is 2 modulo 4 , hence $a^{2^{m-1}}$ is 1 modulo $2^{t-1}$. From the induction hypothesis it follows that $a \equiv \pm 1\left(\bmod 2^{t-m}\right)$ (note that $t-m=(t-1)-(m-1))$. For arbitrary $q$, from what we have proved so far it follows that $a^{q} \equiv \pm 1\left(\bmod 2^{t-m}\right)$. Because $\phi\left(2^{t-m}\right)=2^{t-m-1}$, by Euler's theorem $a^{2^{t-m-1}} \equiv 1\left(\bmod 2^{t-m}\right)$. Since $q$ is odd, we can find a positive integer $c$ such that $c q \equiv 1\left(\bmod 2^{t-m-1}\right)$. Then $a \equiv a^{c q} \equiv$ $(\pm 1)^{c} \equiv \pm 1\left(\bmod 2^{t-m}\right)$, and the lemma is proved.

Let us return to the problem. Let $x=2^{m} q$, where $m \geq 1$ and $q$ is odd. Because $(v+1)^{x}-v^{y}=1$, clearly $y \geq x$. We have shown that $v+1$ divides $y$, so $y \geq v+1$. Let us prove that $y \geq 2 m+1$. Indeed, if $m \leq 2$ this holds since $y \geq v+1 \geq 5 \geq 2 m+1$; otherwise, $y \geq x=2^{m} q \geq 2^{m} \geq 2 m+1$.

Looking at the equation modulo $2^{y}$, we have $(v+1)^{2^{m} q} \equiv 1\left(\bmod 2^{y}\right)$, because $2^{y}$ divides $v^{y}$. By the lemma this implies that $v+1 \equiv \pm 1\left(\bmod 2^{y-m}\right)$. But $v+1 \equiv$ $1\left(\bmod 2^{y-m}\right)$ would imply that $2^{m+1}$ divides $v$, which is impossible since $v$ divides $x$. Therefore, $v+1 \equiv-1\left(\bmod 2^{y-m}\right)$ and $v \equiv-2\left(\bmod 2^{y-m}\right)$. In particular, $v \geq 2^{y-m}-2$, so $y \geq 2^{y-m}-1$. But since $y \geq 2 m+1$ and $y \geq 5$, it follows that $2^{y-m}-1>y$, a contradiction. This shows that there are no other solutions.

Second solution: Begin as before until we reduce to the case $u=v+1$ and $v \geq 3$. Then we use the following lemma.

Lemma. Suppose $p^{s} \geq 3$ is a prime power, $r \geq 1$, and $a \equiv 1\left(\bmod p^{s}\right)$, but not $\bmod p^{s+1}$. If $a^{k} \equiv 1\left(\bmod p^{r+s}\right)$, then $p^{r}$ divides $k$.

Proof. Write $a=1+c p^{s}+d p^{s+1}$, where $1 \leq c \leq p-1$. Then we compute $a^{k} \equiv$ $1+k c p^{s}\left(\bmod p^{s+1}\right)$, and

$$
a^{p}=1+c p^{s+1}+d p^{s+2}+\left(\begin{array}{l}
p \\
2
\end{array}\right) p^{2 s}(c+d p)+\left(\begin{array}{l}
p \\
3
\end{array}\right) p^{3 s}(c+d p)^{3}+\cdots .
$$

Since either $s \geq 2$ or $p$ is odd, $p^{s+2}$ divides $\left(\begin{array}{c}p \\ 2\end{array}\right) p^{2 s}$; hence the fourth term is zero $\bmod p^{s+2}$. Since $s+2 \leq 3 s$, the latter terms are also zero $\bmod p^{s+2}$; hence $a^{p} \equiv$ $1\left(\bmod p^{s+1}\right)$, but not $\bmod p^{s+2}$.

We now proceed by induction on $r$. Since $r \geq 1$, the first equation above shows that $p$ divides $k$, which is the base case. For the inductive step, we note that the second calculation above lets us apply the previous case to $\left(a^{p}\right)^{k / p}$.

To use this lemma, let $p^{s} \geq 3$ be the highest power of the prime $p$ that divides $v$. Then $u=v+1 \equiv 1\left(\bmod p^{s}\right)$, but not $\bmod p^{s+1}$, and $u^{x}=v^{y}+1 \equiv 1\left(\bmod p^{s y}\right)$. Hence by the lemma, $p^{s(y-1)}$ divides $x$, and in particular, $x \geq p^{s(y-1)} \geq 3^{y-1}$. Thus either $x>y$ or $y=1$.

Similarly, let $q^{t} \geq 3$ be the highest power of the prime $q$ that divides $u$. Then $(-v)=1-u \equiv 1\left(\bmod q^{t}\right)$, but not $\bmod q^{t+1}$. Since $(-v)^{y} \equiv 1\left(\bmod q^{t}\right)$ and $(-v)^{y}=(-1)^{y}-(-1)^{y} u^{x} \equiv(-1)^{y}\left(\bmod q^{t}\right)$, we see that $y$ is even. Hence $(-v)^{y}=$ $1-u^{x} \equiv 1\left(\bmod q^{t x}\right)$. Thus by the lemma, $q^{t(x-1)}$ divides $y$, and in particular, $y \geq$ $q^{t(x-1)} \geq 3^{x-1}$, so either $y>x$ or $x=1$. Combining these, we see that we must have either $x=1$ or $y=1$. Either of these implies the other and gives the solution $(v+1, v, 1,1)$.

Remark. Catalan conjectured in 1844 a more general fact, namely that the Diophantine equation $u^{x}-v^{y}=1$ subject to the condition $x, y \geq 2$ has the unique solution $3^{2}-2^{3}=1$. This would mean that 8 and 9 are the only consecutive powers. Catalan's conjecture was proved by P. Mihăilescu in 2002.

(Kvant (Quantum), first solution by R. Barton, second solution by R. Stong) 

\section{Combinatorics and Probability}

821. The relation from the statement implies

$$
(A \cap X) \cup(B \cap X)=A \cap B .
$$

Applying de Morgan's law, we obtain

$$
(A \cup B) \cap X=A \cap B .
$$

But the left-hand side is equal to $(A \cup B \cup X) \cap X$, and this is obviously equal to $X$. Hence $X=A \cap B$.

(Russian Mathematics Competition, 1977)

822. This is an easy application of the pigeonhole principle. Let $n$ be the number of vertices. Associate to each vertex the set of vertices connected to it by edges. There are $n$ such sets, and each of them has at most $n-1$ elements. Hence there are two sets with the same number of elements. Their corresponding vertices are endpoints of the same number of edges.

823. We prove the property by induction on the number of elements of the set. For a set with one element the property clearly holds. Let us assume that we could find the required list $A_{1}, A_{2}, \ldots, A_{2^{n}}$ of the subsets of the set with $n$ elements, $n \geq 1$. Add the element $x$ to obtain a set with $n+1$ elements. The list for this new set is

$$
A_{1}, A_{2}, \ldots, A_{2^{n}}, A_{2^{n}} \cup\{x\}, \ldots, A_{2} \cup\{x\}, A_{1} \cup\{x\},
$$

and the induction is complete.

824. Note that the product of the three elements in each of the sets $\{1,4,9\},\{2,6,12\}$, $\{3,5,15\}$, and $\{7,8,14\}$ is a square. Hence none of these sets is a subset of $M$. Because they are disjoint, it follows that $M$ has at most $15-4=11$ elements.

Since 10 is not an element of the aforementioned sets, if $10 \notin M$, then $M$ has at most 10 elements. Suppose $10 \in M$. Then none of $\{2,5\},\{6,15\},\{1,4,9\}$, and $\{7,8,14\}$ is a subset of $M$. If $\{3,12\} \not \subset M$, it follows again that $M$ has at most 10 elements. If $\{3,12\} \subset M$, then none of $\{1\},\{4\},\{9\},\{2,6\},\{5,15\}$, and $\{7,8,14\}$ is a subset of $M$, and then $M$ has at most 9 elements. We conclude that $M$ has at most 10 elements in any case.

Finally, it is easy to verify that the subset

$$
M=\{1,4,5,6,7,10,11,12,13,14\}
$$

has the desired property. Hence the maximum number of elements in $M$ is 10 .

(short list of the 35th International Mathematical Olympiad, 1994, proposed by Bulgaria)

825. Fix $A \in \mathcal{F}$ and consider the function $f: \mathcal{P}(S) \rightarrow \mathcal{P}(S)$ on the subsets of $S$, $f(X)=X \Delta A$. Because

$$
\begin{aligned}
f(f(X)) &=(X \Delta A) \Delta A=((X \Delta A) \backslash A) \cup(A \backslash(X \Delta A)) \\
&=(X \backslash A) \cup(X \cap A)=X,
\end{aligned}
$$

$f$ is one-to-one. Therefore, $f(\mathcal{F})$ has at least $m$ elements. The conclusion follows.

(I. Tomescu, Problems in Combinatorics, Wiley, 1985)

826. If all functions $f_{n}, n=1,2,3, \ldots$, are onto, then the property is obvious. We will reduce the general situation to this particular one. For some $k$ and $n$, define

$$
B_{n, k}=\left(f_{n} \circ f_{n+1} \circ \cdots \circ f_{n+k-1}\right)\left(A_{n+k}\right) .
$$

We have the descending sequence of sets

$$
A_{n} \supset B_{n, 1} \supset B_{n, 2} \supset \cdots .
$$

Because all these sets are finite, the sequence is stationary, so there exists $k_{0}$ such that $B_{n, k}=B_{n, k+1}$, for $k \geq k_{0}$. Let $B_{n}=B_{n, k_{0}}$. It is not hard to see that $f_{n}\left(B_{n+1}\right)=B_{n}$, and in this way we obtain a sequence of sets and surjective maps. For these the property holds; hence it holds for the original sets as well.

(C. Năstăsescu, C. Niţ̆a, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogiç., Bucharest, 1983)

827. For a person $X$ we will denote by $m_{X}$ the number of people he knows. Let $A$ and $B$ be two people who know each other. We denote by $M_{A}$ and $M_{B}$ the set of acquaintances of $A$, respectively, $B$. By hypothesis $M_{A}$ and $M_{B}$ are disjoint. If $X \in M_{A}$, then $X$ has exactly one acquaintance in $M_{B}$. Indeed, either $X=A$, in which case he only knows $B$ in $M_{B}$, or $X \neq A$, in which case he does not know $B$, so he has exactly one common acquaintance with $B$. This latter person is the only one he knows in $M_{B}$. Similarly, any person in $M_{B}$ has exactly one acquaintance in $M_{A}$. This allows us to establish a bijection between $M_{A}$ and $M_{B}$, and conclude that $m_{A}=m_{B}$.

Finally, if $A$ and $B$ do not know each other, then they have a common acquaintance $C$. The above argument shows that $m_{A}=m_{C}=m_{B}$, and we are done.

\section{(Kvant (Quantum)}

828. We set $f^{0}=1_{A}, f^{n+1}=f^{n} \circ f, n \geq 0$. Define on $A$ the relation $x \sim y$ if there exist $m$ and $n$ such that $f^{n}(x)=f^{m}(y)$. One verifies immediately that $\sim$ is an equivalence relation, and that equivalence classes are invariant under $f$. An equivalence class resembles a spiral galaxy, with a cycle into which several branches enter. Such an equivalence class is illustrated in Figure 94, where the dots are elements of $E$ and the arrows describe the action of $f$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-738.jpg?height=366&width=511&top_left_y=824&top_left_x=612)

Figure 94

Thus $f$ defines a directed graph whose connected components are the equivalence classes. We color the vertices of this graph by $0,1,2,3$ according to the following rule. All fixed points are colored by 0 . Each cycle is colored alternately $1,2,1,2, \ldots$ with its last vertex colored by 3 . Finally, each branch is colored alternately so that no consecutive vertices have the same color. The coloring has the property that adjacent vertices have different colors. If we let $A_{i}$ consist of those elements of $A$ colored by $i, i=0,1,2,3$, then these sets have the required property. The construction works also in the case that the cycle has length one, that is, when it is a fixed points of $f$. Note that in general the partition is not unique.

This argument can be easily adapted to the case in which $A$ is infinite. All cycles are finite and they are taken care of as in the case of a finite set. The coloring can be done provided that we can choose one element from each cycle to start with, thus we have to assume the axiom of choice. This axiom states that given a family of sets one can choose one element from each of them. Now let us consider an equivalence class as defined above, and look at the dynamic process of repeated applications of $f$. It either ends in $A_{0}$ or in a cycle, or it continues forever. In the equivalence class we pick a reference point $x_{0}$, which is either the point where the equivalence class enters $A_{0}$ or a cycle, or otherwise is an arbitrary point. Either $x_{0}$ has been colored, by 0 or as part of a cycle, or if not, we color it by the color of our choice. Say the color of $x_{0}$ is $i$, and let $j$ and $k$ be two other colors chosen from 1,2 , and 3. If $x \sim x_{0}$ then $f^{n}(x)=f^{m}\left(x_{0}\right)$ for some integers $m$ and $n$. For that particular $x$, choose $m$ and $n$ to be minimal with this property. Color $x$ by $j$ if $m-n$ is even, and by $k$ if $m-n$ is odd.

Note that $x$ and $f(x)$ cannot have the same color, for otherwise in the equalities $f^{n}(x)=f^{m}\left(x_{0}\right)$ and $f^{n+1}(x)=f^{m^{\prime}}\left(x_{0}\right)$ the minimality of $m$ and $m^{\prime}$ implies that $m=m^{\prime}$, and then $n-m$ and $n+1-m$ would have the same parity, which is impossible. Again, the coloring partitions $A$ into four sets with the desired properties.

829. We solve the more general case of the permutations of the first $2 n$ positive integers, $n \geq 1$. The average of the sum

$$
\sum_{k=1}^{n}\left|a_{2 k-1}-a_{2 k}\right|
$$

is just $n$ times the average value of $\left|a_{1}-a_{2}\right|$, because the average value of $\left|a_{2 i-1}-a_{2 i}\right|$ is the same for all $i=1,2, \ldots, n$. When $a_{1}=k$, the average value of $\left|a_{1}-a_{2}\right|$ is

$$
\begin{aligned}
\frac{(k-1)+(k-2)+\cdots+1+1+2+\cdots+(2 n-k)}{2 n-1} \\
=& \frac{1}{2 n-1}\left[\frac{k(k-1)}{2}+\frac{(2 n-k)(2 n-k+1)}{2}\right] \\
=& \frac{k^{2}-(2 n+1) k+n(2 n+1)}{2 n-1} .
\end{aligned}
$$

It follows that the average value of the sum is

$$
\begin{aligned}
n \cdot \frac{1}{2 n} & \sum_{k=1}^{2 n} \frac{k^{2}-(2 n+1) k+n(2 n+1)}{2 n-1} \\
&=\frac{1}{4 n-2}\left[\frac{2 n(2 n+1)(4 n+1)}{6}-(2 n+1) \frac{2 n(2 n+1)}{2}+2 n^{2}(2 n+1)\right] \\
&=\frac{n(2 n+1)}{3} .
\end{aligned}
$$

For our problem $n=5$ and the average of the sums is $\frac{55}{3}$.

(American Invitational Mathematics Examination, 1996)

830. The condition from the statement implies that any such permutation has exactly two disjoint cycles, say $\left(a_{i_{1}}, \ldots, a_{i_{r}}\right)$ and $\left(a_{i_{r+1}}, \ldots, a_{i_{6}}\right)$. This follows from the fact that in order to transform a cycle of length $r$ into the identity $r-1$, transpositions are needed. Moreover, we can only have $r=5,4$, or 3 .

When $r=5$, there are $\left(\begin{array}{l}6 \\ 1\end{array}\right)$ choices for the number that stays unpermuted. There are $(5-1) !$ possible cycles, so in this case we have $6 \times 4 !=144$ possibilities. When $r=4$, there are $\left(\begin{array}{l}6 \\ 4\end{array}\right)$ ways to split the numbers into the two cycles (two cycles are needed and not just one). One cycle is a transposition. There are $(4-1) !=6$ choices for the other. Hence in this case the number is 90 . Note that here exactly four transpositions are needed.

Finally, when $r=3$, then there are $\left(\begin{array}{l}6 \\ 3\end{array}\right) \times(3-1) ! \times(3-1) !=40$ cases. Therefore, the answer to the problem is $144+90+40=274$.

(Korean Mathematical Olympiad, 1999)

831. We would like to find a recursive scheme for $f(n)$. Let us attempt the less ambitious goal of finding a recurrence relation for the number $g(n)$ of permutations of the desired form satisfying $a_{n}=n$. In that situation either $a_{n-1}=n-1$ or $a_{n-1}=n-2$, and in the latter case we necessarily have $a_{n-2}=n-1$ and $a_{n-3}=n-3$. We obtain the recurrence relation

$$
g(n)=g(n-1)+g(n-3), \quad \text { for } n \geq 4 .
$$

In particular, the values of $g(n)$ modulo 3 are $1,1,1,2,0,1,0,0, \ldots$ repeating with period 8.

Now let $h(n)=f(n)-g(n)$. We see that $h(n)$ counts permutations of the desired form with $n$ occurring in the middle, sandwiched between $n-1$ and $n-2$. Removing $n$ leaves an acceptable permutation, and any acceptable permutation on $n-1$ symbols can be so produced, except those ending in $n-4, n-2, n-3, n-1$. So for $h(n)$, we have the recurrence

$$
h(n)=h(n-1)+g(n-1)-g(n-4)=h(n-1)+g(n-2), \quad \text { for } n \geq 5 .
$$

A routine check shows that $h(n)$ modulo 3 repeats with period 24.

We find that $f(n)$ repeats with period equal to the least common multiple of 8 and 24 , which is 24 . Because $1996 \equiv 4(\bmod 24)$, we have $f(1996) \equiv f(4)=4(\bmod 3)$. So $f$ (1996) is not divisible by 3 .

(Canadian Mathematical Olympiad, 1996)

832. To solve this problem we will apply Sturm's principle, a method discussed in Section 2.1.6. The fact is that as $\sigma$ ranges over all permutations, there are $n$ ! sums of the form

$$
\sum_{i=1}^{n}\left(x_{i}-y_{\sigma(i)}\right)^{2},
$$

and one of them must be the smallest. If $\sigma$ is not the identity permutation, then it must contain an inversion, i.e., a pair $(i, j)$ with $i<j$ and $\sigma(i)>\sigma(j)$. We have

$$
\left(x_{i}-y_{\sigma(i)}\right)^{2}+\left(x_{j}-y_{\sigma(j)}\right)^{2}-\left(x_{i}-y_{\sigma(j)}\right)^{2}-\left(x_{j}-y_{\sigma(i)}\right)^{2}=\left(x_{j}-x_{i}\right)\left(y_{\sigma(i)}-y_{\sigma(j)}\right) \text {. }
$$

This product is positive, so by exchanging $y_{\sigma(i)}$ and $y_{\sigma(j)}$ we decrease the sum. This means that this permutation does not minimize the sum. Therefore, the sum is minimal for the identity permutation. The inequality follows.

833. Let $N(\sigma)$ be the number we are computing. Denote by $N_{i}(\sigma)$ the average number of large integers $a_{i}$. Taking into account the fact that after choosing the first $i-1$ numbers, the $i$ th is completely determined by the condition of being large, for any choice of the first $i-1$ numbers there are $(n-i+1)$ ! choices for the last $n-i+1$, from which $(n-i)$ ! contain a large integer in the $i$ th position. We deduce that $N_{i}(\sigma)=\frac{1}{n-i+1}$. The answer to the problem is therefore

$$
N(\sigma)=\sum_{i=1}^{n} N_{i}(\sigma)=1+\frac{1}{2}+\cdots+\frac{1}{n} .
$$

(19th W.L. Putnam Mathematical Competition, 1958)

834. We will show that $\sigma$ is the identity permutation. Assume the contrary and let $\left(i_{1}, i_{2}, \ldots, i_{k}\right)$ be a cycle, i.e., $\sigma\left(i_{1}\right)=i_{2}, \sigma\left(i_{2}\right)=i_{3}, \ldots, \sigma\left(i_{k}\right)=i_{1}$. We can assume that $i_{1}$ is the smallest of the $i_{j}$ 's, $j=1,2, \ldots, k$. From the hypothesis,

$$
a_{i_{1}} a_{i_{2}}=a_{i_{1}} a_{\sigma\left(i_{1}\right)}<a_{i_{k}} a_{\sigma\left(i_{k}\right)}=a_{i_{k}} a_{i_{1}},
$$

so $a_{i_{2}}<a_{i k}$ and therefore $i_{2}<i_{k}$. Similarly,

$$
a_{i_{2}} a_{i_{3}}=a_{i_{2}} a_{\sigma\left(i_{2}\right)}<a_{i_{k}} a_{\sigma\left(i_{k}\right)}=a_{i_{k}} a_{i_{1}},
$$

and since $a_{i_{2}}>a_{i_{1}}$ it follows that $a_{i_{3}}<a_{i_{k}}$, so $i_{3}<i_{k}$. Inductively, we obtain that $i_{j}<i_{k}, j=1,2, \ldots, k-1$. But then

$$
a_{i_{k-1}} a_{i_{k}}=a_{i_{k-1}} a_{\sigma\left(i_{k-1}\right)}<a_{i_{k}} a_{\sigma\left(i_{k}\right)}=a_{i_{k}} a_{i_{1}},
$$

hence $i_{k-1}<i_{1}$, a contradiction. This proves that $\sigma$ is the identity permutation, and we are done.

(C. Năstăsescu, C. Niţă, M. Brandiburu, D. Joiţa, Exerciţii şi Probleme de Algebră (Exercises and Problems in Algebra), Editura Didactică şi Pedagogică, Bucharest, 1983)

835. Let $S=\{1,2, \ldots, 2004\}$. Write the permutation as a function $f: S \rightarrow S$, $f(n)=a_{n}, n=1,2, \ldots, 2004$. We start by noting three properties of $f$ :

(i) $f(i) \neq i$ for any $i$,

(ii) $f(i) \neq f(j)$ if $i \neq j$,

(iii) $f(i)=j$ implies $f(j)=i$. The first two properties are obvious, while the third requires a proof. Arguing by contradiction, let us assume that $f(i)=j$ but $f(j) \neq i$. We discuss first the case $j>i$. If we let $k=j-i$, then $f(i)=i+k$. Since $k=|f(i)-i|=|f(j)-j|$ and $f(j) \neq i$, it follows that $f(j)=i+2 k$, i.e., $f(i+k)=i+2 k$. The same reasoning yields $f(i+2 k)=i+k$ or $i+3 k$. Since we already have $f(i)=i+k$, the only possibility is $f(i+2 k)=i+3 k$. And the argument can be repeated to show that $f(i+n k)=i+(n+1) k$ for all $n$. However, this then forces $f$ to attain ever increasing values, which is impossible since its range is finite. A similar argument takes care of the case $j<i$. This proves (iii).

The three properties show that $f$ is an involution on $S$ with no fixed points. Thus $f$ partitions $S$ into 1002 distinct pairs $(i, j)$ with $i=f(j)$ and $j=f(i)$. Moreover, the absolute value of the difference of the elements in any pair is the same. If $f(1)-1=k$ then $f(2)=k+1, \ldots, f(k)=2 k$, and since $f$ is an involution, the values of $f$ on $k+1, k+2, \ldots, 2 k$ are already determined, namely $f(k+1)=1, f(k+2)=$ $2, \ldots, f(2 k)=k$. So the first block of $2 k$ integers is invariant under $f$. Using similar reasoning, we obtain $f(2 k+1)=3 k+1, f(2 k+2)=3 k+2, \ldots, f(3 k)=4 k, f(3 k+$ $1)=2 k+1, \ldots, f(4 k)=3 k$. So the next block of $2 k$ integers is invariant under $f$. Continuing this process, we see that $f$ partitions $S$ into blocks of $2 k$ consecutive integers that are invariant under $f$. This can happen only if $2 k$ divides 2004 , hence if $k$ divides 1002. Furthermore, for each such $k$ we can construct $f$ following the recipe given above. Hence the number of such permutations equals the number of divisors of 1002 , which is 8.

(Australian Mathematical Olympiad, 2004, solution by L. Field)

836. Expanding $|\sigma(k)-k|$ as $\pm \sigma(k) \pm k$ and reordering, we see that

$$
|\sigma(1)-1|+|\sigma(2)-2|+\cdots+|\sigma(n)-n|=\pm 1 \pm 1 \pm 2 \pm 2 \pm \cdots \pm n \pm n,
$$

for some choices of signs. The maximum of $|\sigma(1)-1|+|\sigma(2)-2|+\cdots+|\sigma(n)-n|$ is reached by choosing the smaller of the numbers to be negative and the larger to be positive, and is therefore equal to

$$
\begin{gathered}
2\left(-1-2-\cdots-\frac{n-1}{2}\right)-\frac{n+1}{2}+\frac{n+1}{2}+2\left(\frac{n+3}{2}+\cdots+n\right) \\
=-\left(1+\frac{n-1}{2}\right) \frac{n-1}{2}+\left(\frac{n+3}{2}+n\right) \frac{n-1}{2}=\frac{n^{2}-1}{2} .
\end{gathered}
$$

Therefore, in order to have $|\sigma(1)-1|+\cdots+|\sigma(n)-n|=\frac{n^{2}-1}{2}$, we must have

$$
\left\{\sigma(1), \ldots, \sigma\left(\frac{n-1}{2}\right)\right\} \subset\left\{\frac{n+1}{2}, \frac{n+3}{2}, \ldots, n\right\}
$$

and 

$$
\left\{\sigma\left(\frac{n+3}{2}\right), \sigma\left(\frac{n+5}{2}\right), \ldots, \sigma(n)\right\} \subset\left\{1,2, \ldots, \frac{n+1}{2}\right\} .
$$

Let $\sigma\left(\frac{n+1}{2}\right)=k$. If $k \leq \frac{n+1}{2}$, then

$$
\left\{\sigma(1), \ldots, \sigma\left(\frac{n-1}{2}\right)\right\}=\left\{\frac{n+3}{2}, \frac{n+5}{2}, \ldots, n\right\}
$$

and

$$
\left\{\sigma\left(\frac{n+3}{2}\right), \sigma\left(\frac{n+5}{2}\right), \ldots, \sigma(n)\right\}=\left\{1,2, \ldots, \frac{n+1}{2}\right\}-\{k\} .
$$

If $k \geq \frac{n+1}{2}$, then

$$
\left\{\sigma(1), \ldots, \sigma\left(\frac{n-1}{2}\right)\right\}=\left\{\frac{n+1}{2}, \frac{n+3}{2}, \ldots, n\right\}-\{k\}
$$

and

$$
\left\{\sigma\left(\frac{n+3}{2}\right), \sigma\left(\frac{n+5}{2}\right), \ldots, \sigma(n)\right\}=\left\{1,2, \ldots, \frac{n-1}{2}\right\} .
$$

For any value of $k$, there are $\left[\left(\frac{n-1}{2}\right) !\right]^{2}$ choices for the remaining values of $\sigma$, so there are

$$
n\left[\left(\frac{n-1}{2}\right) !\right]^{2}
$$

such permutations.

\section{(T. Andreescu)}

837. Let $f(n)$ be the desired number. We count immediately $f(1)=2, f(2)=4$. For the general case we argue inductively. Assume that we already have constructed $n$ circles. When adding the $(n+1)$ st, it intersects the other circles in $2 n$ points. Each of the $2 n$ arcs determined by those points splits some region in two. This produces the recurrence relation $f(n+1)=f(n)+2 n$. Iterating, we obtain

$$
f(n)=2+2+4+6+\cdots+2(n-1)=n^{2}-n+2
$$

(25th W.L. Putnam Mathematical Competition, 1965)

838. Again we try to derive a recursive formula for the number $F(n)$ of regions. But this time counting the number of regions added by a new sphere is not easy at all. The previous problem comes in handy. The first $n$ spheres determine on the $(n+1)$ st exactly $n^{2}-n+2$ regions. This is because the conditions from the statement give rise on the last sphere to a configuration of circles in which any two, but no three, intersect. And this is the only condition that we used in the solution to the previous problem. Each of the $n^{2}-n+2$ spherical regions divides some spatial region into two parts. This allows us to write the recursive formula

$$
F(n+1)=F(n)+n^{2}-n+2, \quad F(1)=2 .
$$

Iterating, we obtain

$$
\begin{aligned}
F(n) &=2+4+8+\cdots+\left[(n-1)^{2}-(n-1)+2\right]=\sum_{k=1}^{n-1}\left(k^{2}-k+2\right) \\
&=\frac{n^{3}-3 n^{2}+8 n}{3}
\end{aligned}
$$

839. Choose three points $A, B, C$ of the given set that lie on the boundary of its convex hull. There are $\left(\begin{array}{c}n-3 \\ 2\end{array}\right)$ ways to select two more points from the set. The line $D E$ cuts two of the sides of the triangle $A B C$, say, $A B$ and $A C$. Then $B, C, D, E$ form a convex quadrilateral. Making all possible choices of the points $D$ and $E$, we obtain $\left(\begin{array}{c}n-3 \\ 2\end{array}\right)$ convex quadrilaterals.

(11th International Mathematical Olympiad, 1969)

840. The grid is made up of $\frac{n(n+1)}{2}$ small equilateral triangles of side length 1 . In each of these triangles, at most 2 segments can be marked, so we can mark at most $\frac{2}{3} \cdot \frac{3 n(n+1)}{2}=$ $n(n+1)$ segments in all. Every segment points in one of three directions, so we can achieve the maximum $n(n+1)$ by marking all the segments pointing in two of the three directions.

(Russian Mathematical Olympiad, 1999)

841. Assume by way of contradiction that the distance between any two points is greater than or equal to 1 . Then the spheres of radius $\frac{1}{2}$ with centers at these 1981 points have disjoint interiors, and are included in the cube of side length 10 determined by the six parallel planes to the given cube's faces and situated in the exterior at distance $\frac{1}{2}$. It follows that the sum of the volumes of the 1981 spheres is less than the volume of the cube of side 10 , meaning that

$$
1981 \cdot \frac{4 \pi \cdot\left(\frac{1}{2}\right)^{3}}{3}=1981 \cdot \frac{\pi}{6}>1000,
$$

a contradiction. This completes the proof.

Remark. If we naively divide each side of the cube into $\lfloor\sqrt[3]{1981}\rfloor=12$ congruent segments, we obtain $12^{3}=1728$ small cubes of side $\frac{9}{12}=\frac{3}{4}$. The pigeonhole principle guarantees that some small cube contains two of the points, but unfortunately the upper bound that we get for the distance between the two points is $\frac{3}{4} \sqrt[3]{3}$, which is greater than 1 .

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu) 

842. We examine separately the cases $n=3,4$, 5. A triangle can have at most one right angle, a quadrilateral four, and a pentagon three (if four angles of the pentagon were right, the fifth would have to be equal to $\left.180^{\circ}\right)$.

Let us consider an $n$-gon with $n \geq 6$ having $k$ internal right angles. Because the other $n-k$ angles are less than $360^{\circ}$ and because the sum of all angles is $(n-2) \cdot 180^{\circ}$, the following inequality holds:

$$
(n-k) \cdot 360^{\circ}+k \cdot 90^{\circ}>(n-2) \cdot 180^{\circ} .
$$

This readily implies that $k<\frac{2 n+4}{3}$, and since $k$ and $n$ are integers, $k \leq\left\lfloor\frac{2 n}{3}\right\rfloor+1$.

We will prove by induction on $n$ that this upper bound can be reached. The base cases $n=6,7,8$ are shown in Figure 95 .
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-745.jpg?height=180&width=940&top_left_y=840&top_left_x=398)

Figure 95

We assume that the construction is done for $n$ and prove that it can be done for $n+3$. For our method to work, we assume in addition that at least one internal angle is greater than $180^{\circ}$. This is the case with the polygons from Figure 95 . For the inductive step we replace the internal angle greater than $180^{\circ}$ as shown in Figure 96. This increases the angles by 3 and the right angles by 2 . The new figure still has an internal angle greater than $180^{\circ}$, so the induction works. This construction proves that the bound can be reached.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-745.jpg?height=192&width=621&top_left_y=1481&top_left_x=557)

Figure 96

(short list of the 44th International Mathematical Olympiad, 2003)

843. It seems that the situation is complicated by successive colorings. But it is not! Observe that each time the moving circle passes through the original position, a new point will be colored. But this point will color the same points on the fixed circle. In short, only the first colored point on one circle contributes to newly colored points on the other; all other colored points follow in its footsteps. So there will be as many colored points on the small circle as there are points of coordinate $2 \pi k, k$ an integer, on the segment $[0,200 \pi \sqrt{2}]$. Their number is 

$$
\left\lfloor\frac{200 \pi \sqrt{2}}{2 \pi}\right\rfloor=\lfloor 100 \sqrt{2}\rfloor=141 \text {. }
$$

(Ukrainian Mathematical Olympiad)

844. The solution is based on the pigeonhole principle. Let us assume that the sum of lengths of the chords is greater than or equal to $k \pi$. Then the sum of the lengths of the arcs subtended by these chords is greater than $k \pi$. Add to these arcs their reflections about the center of the circle. The sum of the lengths of all arcs is greater than $2 k \pi$, so there exists a point covered by at least $k+1$ arcs. The diameter through that point intersects at least $k+1$ chords, contradicting our assumption. Hence the conclusion.

(Kvant (Quantum), proposed by A.T. Kolotov)

845. The center of the desired circle must lie at distance at least 1 from the boundary of the square. We will be able to find it somewhere inside the square whose sides are parallel to those of the initial square and at distance 1 from them. The side length of this smaller square is 36.

The locus of all points that lie at distance less than 1 from a convex polygonal surface $P$ is a polygonal surface $Q$ with sides parallel to those of $P$ and whose corners are rounded. The areas of $P$ and $Q$ are related by

$$
S[Q]=S[P]+(\text { perimeter of } P) \times 1+\pi .
$$

This is because the circular sectors from the corners of $Q$ complete themselves to a disk of radius 1 .

So the locus of the points at distance less than 1 from a polygon of area at most $\pi$ and perimeter at most $2 \pi$ is less than or equal to $\pi+2 \pi+\pi=4 \pi$. It follows that the area of the region of all points that are at distance less than 1 from any of the given 100 polygons is at most $400 \pi$. But

$$
400 \pi \leq 400 \cdot 3.2=40 \cdot 32=36^{2}-4^{2}<36^{2} .
$$

So the set of these points does not cover entirely the interior of the square of side length 36. Pick a point that is not covered; the unit disk centered at that point is disjoint from any of the polygons, as desired.

(M. Pimsner, S. Popa, Probleme de geometrie elementară (Problems in elementary geometry), Editura Didactică şi Pedagogică, Bucharest, 1979)

846. Place $n$ disks of radius 1 with the centers at the given $n$ points. The problem can be reformulated in terms of these disks as follows.

Alternative problem. Given $n \geq 3$ disks in the plane such that any 3 intersect, show that the intersection of all disks is nontrivial. This is a well-known property, true in $d$-dimensional space, where "disks" becomes "balls" and the number 3 is replaced by $d+1$. The case $d=1$ is rather simple. Translating the problem for the real axis, we have a finite family of intervals $\left[a_{i}, b_{i}\right], 1 \leq i \leq n$, such that any two intersect. Then $a_{i}<b_{j}$ for any $i, j$, and hence

$$
\left[\max a_{i}, \min b_{j}\right] \subset \cap_{i}\left[a_{i}, b_{i}\right],
$$

proving the claim. In general, we proceed by induction on $d$. Assume that the property is not true, and select the $d$-dimensional balls (disks in the two-dimensional case) $B_{1}, B_{2}, \ldots, B_{k-1}, B_{k}$ such that

$$
B_{1} \cap B_{2} \cap \cdots \cap B_{k-1}=G \neq \emptyset \quad \text { and } \quad B_{1} \cap B_{2} \cap \cdots \cap B_{k-1} \cap B_{k}=\emptyset .
$$

Let $H$ be a hyperplane (line in the two-dimensional case) that separates $G$ from $B_{k}$. Since $B_{k}$ intersects each of the balls $B_{1}, B_{2}, \ldots, B_{k-1}$, the sets $X_{i}=B_{i} \cap H, i=1,2, \ldots, k-1$, are nonempty. Moreover, since by hypothesis $B_{k}$ and any $d$ of the other $k-1$ balls have nontrivial intersection, any collection of $d$ sets $X_{i}$ has nontrivial intersection. But then, by the induction hypothesis, all $X_{i}$ have nontrivial intersection. Therefore,

$$
H \cap B_{1} \cap B_{2} \cap \cdots \cap B_{k-1} \neq \emptyset,
$$

i.e., $H \cap G \neq \emptyset$, a contradiction. Our assumption was false, which proves the inductive step. So the property is true in general, in particular in the two-dimensional case.

847. The problem is solved once we show that the faces of this polyhedron can be colored black and white such that neighboring faces have different colors. Indeed, the edges of the polygonal section will themselves be colored in such a way that consecutive edges have different colors, and this can be done only if the number of edges is even.

To prove the claim, we will slightly generalize it; namely, we show that if in a planar graph every vertex belongs to an even number of edges, then the faces of the graph and its exterior can be colored black and white such that neighboring regions are of different colors. Once we allow edges to bend, and faces to be bigons, we can induct on the number of faces.

The base case consists of a face bounded by two edges, for which the property obviously holds. Assume that the property holds true for all graphs with at most $k$ faces and let us prove it for an arbitrary graph with $k+1$ faces. Choose a face of the graph, which may look as in Figure 97. Shrink it to a point. Color the new graph as permitted by the inductive hypothesis. Blow up the face back into the picture. Because an even number of edges meet at each vertex, all the faces that share an edge with the chosen one are colored by the same color (when moving clockwise around the chosen face we get from one neighboring face to the next in an even number of steps). Hence the face can be given the opposite color. This completes the argument.

(Kvant (Quantum) 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-748.jpg?height=543&width=657&top_left_y=241&top_left_x=539)

Figure 97

848. For finding the upper bound we employ Euler's formula. View the configuration as a planar graph, and complete as many curved edges as possible, until a triangulation of the plane is obtained. If $V=n$ is the number of vertices, $E$ the number of edges and $F$ the number of faces (with the exterior counted among them), then $V-E+F=2$, so $E-F=n+2$. On the other hand, since every edge belongs to two faces and every face has three edges, $2 E=3 F$. Solving, we obtain $E=3 n-6$. Deleting the "alien" curved edges, we obtain the inequality $E \leq 3 n-6$. That the bound can be reached is demonstrated in Figure 98.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-748.jpg?height=319&width=564&top_left_y=1302&top_left_x=590)

Figure 98

(German Mathematical Olympiad, 1976)

849. If this were possible, then the configuration would determine a planar graph with $V=6$ vertices (the 3 neighbors and the 3 wells) and $E=9$ edges (the paths). Each of its $F$ faces would have 4 or more edges because there is no path between wells or between neighbors. So

$$
F \leq \frac{2}{4} E=\frac{9}{2} .
$$

On the other hand, by Euler's relation we have 

$$
F=2+E-V=5 .
$$

We have reached a contradiction, which shows that the answer to the problem is negative. 

850. With the standard notation, we are given that $F \geq 5$ and $E=\frac{3 V}{2}$. We will show that not all faces of the polyhedron are triangles. Otherwise, $E=\frac{3 F}{2}$ and Euler's formula yields $F-\frac{3 F}{2}+F=2$, that is, $F=4$, contradicting the hypothesis.

We will indicate now the game strategy for the two players. The first player writes his/her name on a face that is not a triangle; call this face $A_{1} A_{2} \ldots A_{n}, n \geq 4$. The second player, in an attempt to obstruct the first, will sign a face that has as many common vertices with the face signed by the first as possible, thus claiming a face that shares an edge with the one chosen by the first player. Assume that the second player signed a face containing the edge $A_{1} A_{2}$. The first player will now sign a face containing the edge $A_{3} A_{4}$. Regardless of the play of the second player, the first can sign a face containing either $A_{3}$ or $A_{4}$, and wins!

(64th W.L. Putnam Mathematical Competition, 2003, proposed by T. Andreescu)

851. Start with Euler's relation $V-E+F=2$, and multiply it by $2 \pi$ to obtain $2 \pi V-$ $2 \pi E+2 \pi F=4 \pi$. If $n_{k}, k \geq 3$, denotes the number of faces that are $k$-gons, then $F=n_{3}+n_{4}+n_{5}+\cdots$. Also, counting edges by the faces, and using the fact that each edge belongs to two faces, we have $2 E=3 n_{3}+4 n_{4}+5 n_{5}+\cdots$. Euler's relation becomes

$$
2 \pi V-\pi\left(n_{3}+2 n_{4}+3 n_{5}+\cdots\right)=4 \pi .
$$

Because the sum of the angles of a $k$-gon is $(k-2) \pi$, the sum in the above relation is equal to $\Sigma$. Hence the conclusion.

Remark. In general, if a polyhedron $P$ resembles a sphere with $g$ handles, then $2 \pi V-$ $\Sigma=2 \pi(2-2 g)$. As mentioned before, the number $2-2 g$, denoted by $\chi(P)$, is called the Euler characteristic of the polyhedron. The difference between $2 \pi$ and the sum of the angles around a vertex is the curvature $K_{v}$ at that vertex. Our formula then reads

$$
\sum_{v} K_{v}=2 \pi \chi(P) .
$$

This is the piecewise linear version of the Gauss-Bonnet theorem.

In the differential setting, the Gauss-Bonnet theorem is expressed as

$$
\int_{S} K d A=2 \pi \chi(S),
$$

or in words, the integral of the Gaussian curvature over a closed surface $S$ is equal to the Euler characteristic of the surface multiplied by $2 \pi$. This means that no matter how we deform a surface, although locally its Gaussian curvature will change, the total curvature remains unchanged. 

852. (a) We use an argument by contradiction. The idea is to start with Euler's formula

$$
V-E+F=2
$$

and obtain a relation that is manifestly absurd. By our assumption each vertex belongs to at least 6 edges. Counting the vertices by the edges, we obtain $2 E$ (each edge has two vertices). But we overcounted the vertices at least 6 times. Hence $2 E \geq 6 \mathrm{~V}$. Similarly, counting faces by the edges and using the fact that each face has at least three edges, we obtain $2 E \geq 3 F$. We thus have

$$
2=V-E+F \leq \frac{1}{3} E-E+\frac{2}{3} E=0,
$$

an absurdity. It follows that our assumption was false, and hence there is a vertex belonging to at most five edges.

(b) We use the first part. To the map we associate a connected planar graph $G$. The vertices of $G$ are the regions. The edges cross the boundary arcs (see Figure 99). For a border consisting of consecutive segments that separates two neighboring regions we add just one edge! The constructed graph satisfies the conditions from part (a). We claim that it can be colored by 5 colors so that whenever two vertices are joined by an edge, they have different colors.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-750.jpg?height=348&width=553&top_left_y=1163&top_left_x=591)

Figure 99

We prove the claim by induction on the number of vertices. The result is obvious if $G$ has at most 5 vertices. Now assume that the coloring exists for any graph with $V-1$ vertices and let us prove that it exists for graphs with $V$ vertices.

By (a), there is a vertex $v$ that has at most 5 adjacent vertices. Remove $v$ and the incident edges, and color the remaining graph by 5 colors. The only situation that poses difficulties for extending the coloring to $v$ is if $v$ has exactly 5 adjacent vertices and they are colored by different colors. Call these vertices $w_{1}, w_{2}, w_{3}, w_{4}, w_{5}$ in clockwise order, and assume they are colored $A, B, C, D, E$, respectively. Look at the connected component containing $w_{1}$ of the subgraph of $G$ consisting of only those vertices colored by $A$ and $C$. If $w_{3}$ does not belong to this component, switch the colors $A$ and $C$ on this component, and then color $v$ by $A$. Now let us examine the case in which $w_{3}$ belongs to this component. There is a path of vertices colored by $A$ and $C$ that connects $w_{1}$ and $w_{3}$. 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-751.jpg?height=479&width=513&top_left_y=251&top_left_x=611)

Figure 100

Next, let us focus on $w_{2}$ and $w_{4}$ (Figure 100). The only case in which we would not know how to perform the coloring is again the one in which there is a path of vertices colored by $B$ and $D$ that joins $w_{2}$ to $w_{4}$. Add $v$ to the two paths (from $w_{1}$ to $w_{3}$ and from $w_{2}$ to $w_{4}$ ) to obtain two cycles. Because of how we ordered the $w_{i}$ 's and because the graph is planar, the two cycles will intersect at a vertex that must be simultaneously colored by one of $A$ or $C$ and by one of $B$ or $D$. This is impossible, so this situation cannot occur. This completes the solution.

Remark. The famous four color theorem states that four colors suffice. This was first conjectured by F. Guthrie in 1853, and proved by K. Appel and W. Haken in 1977 with the aid of a computer. The above five-color theorem was proved in 1890 by P.J. Heawood using ideas of A. Kempe.

853. We will prove a more precise result. To this end, we need to define one more type of singularity. A vertex is called a (multi)saddle of index $-k, k \geq 1$, if it belongs to some incoming and to some outgoing edge, and if there are $k+1$ changes from incoming to outgoing edges in making a complete turn around the vertex. The name is motivated by the fact that if the index is $-1$, then the arrows describe the way liquid flows on a horse saddle. Figure 101 depicts a saddle of index $-2$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-751.jpg?height=307&width=384&top_left_y=1796&top_left_x=680)

Figure 101 Call a vertex that belongs only to outgoing edges a source, a vertex that belongs only to incoming edges a sink, and a face whose edges form a cycle a circulation. Denote by $n_{1}$ the number of sources, by $n_{2}$ the number of sinks, by $n_{3}$ the number of circulations, and by $n_{4}$ the sum of the indices of all (multi)saddles.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-752.jpg?height=391&width=729&top_left_y=487&top_left_x=503)

Figure 102

We refer everything to Figure 102 . We start with the count of vertices by incoming edges; thus for each incoming edge we count one vertex. Sources are not counted. With the standard notation, if we write

$$
E=V-n_{1},
$$

we have overcounted on the left-hand side. To compensate this, let us count vertices by faces. Each face that is not a circulation has two edges pointing toward the same vertex. In that case, for that face we count that vertex. All faces but the circulations count, and for vertices that are not singularities this takes care of the overcount. So we can improve our "equality" to

$$
E=V-n_{1}+F-n_{3} .
$$

Each sink is overcounted by 1 on the right. We improve again to

$$
E=V-n_{1}+F-n_{3}-n_{2} \text {. }
$$

Still, the right-hand side undercounts saddles, and each saddle is undercounted by the absolute value of its index. We finally reach equality with

$$
E=V-n_{1}+F-n_{3}-n_{2}+\left|n_{4}\right|=V+F-n_{1}-n_{2}-n_{3}-n_{4} .
$$

Using Euler's formula, we obtain

$$
n_{1}+n_{2}+n_{3}+n_{4}=V-E+F=2 .
$$

Because $n_{4} \leq 0$, we have $n_{1}+n_{2}+n_{3} \geq 2$, which is what we had to prove. Remark. The polyhedron can be thought of as a discrete approximation of a surface. The orientation of edges is the discrete analogue of a smooth vector field on the surface. The number $n_{1}+n_{2}+n_{3}+n_{4}$ is called the total index of the vector field. The result we just proved shows that if the polyhedron resembles a (triangulated) sphere, the total index of any vector field is 2 . This is a particular case of the Poincaré-Hopf index theorem, which in its general setting states that given a smooth vector field with finitely many zeros on a compact, orientable manifold, the total index of the vector field is equal to the Euler characteristic of the manifold.

854. Figure 103 shows that this number is greater than or equal to 5.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-753.jpg?height=329&width=380&top_left_y=748&top_left_x=684)

Figure 103

Let us show that any coloring by two colors of the edges of a complete graph with 6 vertices has a monochromatic triangle. Assume the contrary. By the pigeonhole principle, 3 of the 5 edges starting at some point have the same color (see Figure 104). Each pair of such edges forms a triangle with another edge. By hypothesis, this third edge must be of the other color. The three pairs produce three other edges that are of the same color and form a triangle. This contradicts our assumption. Hence any coloring of a complete graph with six vertices contains a monochromatic triangle. We conclude that $n=5$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-753.jpg?height=295&width=511&top_left_y=1524&top_left_x=612)

Figure 104

Remark. This shows that the Ramsey number $R(3,3)$ is equal to 6 .

855. Let $n=R(p-1, q)+R(p, q-1)$. We will prove that for any coloring of the edges of a complete graph with $n$ vertices by red or blue, there is a red complete subgraph with $p$ vertices or a blue complete subgraph with $q$ vertices. Fix a vertex $x$ and consider the $n-1$ edges starting at $x$. Among them there are either $R(p-1, q)$ red edges, or $R(p, q-1)$ blue edges. Without loss of generality, we may assume that the first case is true, and let $X$ be the set of vertices connected to $x$ by red edges. The complete graph on $X$ has $R(p-1, q)$ vertices. It either has a blue complete subgraph with $q$ edges, in which case we are done, or it has a red complete subgraph with $p-1$ edges, to which we add the red edges joining $x$ to $X$ to obtain a red complete subgraph with $p$ edges of the original graph. This proves $R(p, q) \leq R(p-1, q)+R(p, q-1)$.

To prove the upper bound for the Ramsey numbers we argue by induction on $p+q$. The base case consists of all configurations with $p=2$ or $q=2$, in which case $R(p, 2)=$ $R(2, p)=p=\left(\begin{array}{c}p \\ p-1\end{array}\right)$, since any graph with $p$ vertices either has an edge colored red, or is entirely colored blue. Let us assume that the inequality is true for all $p, q \geq 2$, $p+q=n$. Either $p=2$, or $q=2$, or otherwise

$$
\begin{aligned}
R(p, q) & \leq R(p-1, q)+R(p, q-1) \leq\left(\begin{array}{c}
p+q-3 \\
p-2
\end{array}\right)+\left(\begin{array}{c}
p+q-3 \\
p-1
\end{array}\right) \\
&=\left(\begin{array}{c}
p+q-2 \\
p-1
\end{array}\right) .
\end{aligned}
$$

(P. Erdős, G. Szekeres)

856. We prove the property by induction on $k$. First, observe that

$$
\lfloor k ! e\rfloor=\frac{k !}{1}+\frac{k !}{1 !}+\frac{k !}{2 !}+\cdots+\frac{k !}{k !} .
$$

For $k=2,\lfloor k ! e\rfloor+1=6$, and the property was proved in the previous problem. Assume that the property is true for a complete graph replaced with $\lfloor(k-1) ! e\rfloor+1$ vertices colored by $k-1$ colors, and let us prove it for a complete graph with $\lfloor k ! e\rfloor+1$ vertices colored by $k$ colors. Choose a vertex $v$ of the graph. By the pigeonhole principle, $v$ is connected to $\lfloor(\lfloor k ! e\rfloor+1) / k\rfloor+1$ vertices by edges of the same color $c$. Note that

$$
\begin{aligned}
\left\lfloor\frac{\lfloor k ! e\rfloor+1}{k}\right\rfloor+1 &=\left\lfloor\frac{1}{k}\left(\frac{k !}{1}+\frac{k !}{1 !}+\frac{k !}{2 !}+\cdots+\frac{k !}{k !}\right)\right\rfloor+1 \\
&=\frac{(k-1) !}{1}+\frac{(k-1) !}{1 !}+\frac{(k-1) !}{2 !}+\cdots+\frac{(k-1) !}{(k-1) !}+1 \\
&=\lfloor(k-1) ! e\rfloor+1 .
\end{aligned}
$$

If two of these vertices are connected by an edge of color $c$, then a $c$-colored triangle is formed. If not, the complete graph on these $\lfloor(k-1) ! e\rfloor+1$ vertices is colored by the remaining $k-1$ colors, and by the induction hypothesis a monochromatic triangle is formed. This completes the proof.

Remark. This proves that the $k$-color Ramsey number $R(3,3, \ldots, 3)$ is bounded from above by $\lfloor k ! e\rfloor+1$.

(F.P. Ramsey) 

857. Yet another Olympiad problem related to Schur numbers. We can reformulate the problem as follows:

Show that if the set $\{1,2, \ldots, 1978\}$ is partitioned into six sets, then in one of these sets there are $a, b, c$ (not necessarily distinct) such that $a+b=c$.

The germs of the solution have already been glimpsed in the Bielorussian problem from the introduction. Observe that by the pigeonhole principle, one of the six sets, say $A$, has at least $\left\lfloor\frac{1978}{6}\right\rfloor+1=330$ elements; call them $a_{1}<a_{2}<\cdots<a_{330}$. If any of the 329 differences

$$
b_{1}=a_{330}-a_{329}, b_{2}=a_{330}-a_{328}, \ldots, b_{329}=a_{330}-a_{1}
$$

is in $A$, then we are done, because $a_{330}-a_{m}=a_{n}$ means $a_{m}+a_{n}=a_{330}$. So let us assume that none of these differences is in $A$. Then one of the remaining sets, say $B$, contains at least $\left\lfloor\frac{329}{5}\right\rfloor+1=66$ of these differences. By eventually renumbering them, we may assume that they are $b_{1}<b_{2}<\cdots<b_{66}$. We repeat the argument for the common differences

$$
c_{1}=b_{66}-b_{65}, c_{2}=b_{66}-b_{64}, \ldots, c_{65}=b_{66}-b_{1} .
$$

Note that

$$
c_{j}=b_{66}-b_{66-j}=\left(a_{330}-a_{m}\right)-\left(a_{330}-a_{n}\right)=a_{n}-a_{m} .
$$

So if one of the $c_{j}$ 's is in $A$ or $B$, then we are done. Otherwise, there is a fourth set $D$, which contains $\left\lfloor\frac{65}{4}\right\rfloor+1=17$ of the $c_{j}$ 's. We repeat the argument and conclude that either one of the sets $A, B, C, D$ contains a Schur triple, or there is a fifth set $E$ containing $\left\lfloor\frac{17}{3}\right\rfloor+1=6$ of the common differences $d_{k}=c_{17}-c_{17-k}$. Again either we find a Schur triple in $A, B, C$, or $D$, or there is a set $E$ containing $\left\lfloor\frac{5}{2}\right\rfloor+1=3$ of the five differences $e_{i}=d_{5}-d_{5-k}$. If any of the three differences $e_{2}-e_{1}, e_{3}-e_{2}, e_{3}-e_{1}$ belongs to $A, B, C, D, E$, then we have found a Schur triple in one of these sets. Otherwise, they are all in the sixth set $F$, and we have found a Schur triple in $F$.

Remark. Look at the striking similarity with the proof of Ramsey's theorem, which makes the object of the previous problem. And indeed, Ramsey's theorem can be used to prove Schur's theorem in the general case: $S(n)$ is finite and is bounded above by the $k$-color Ramsey number $R(3,3, \ldots, 3)$.

Here is how the proof runs. Think of the partition of the set of the first $N$ positive integers into $n$ subsets as a coloring $c:\{1,2, \ldots, N\} \rightarrow\{1,2, \ldots, n\}$. Consider the complete graph with vertices $1,2, \ldots, N$ and color its edges so that for $i>j,(i, j)$ is colored by $c(i-j)$. If $N \geq R(3,3, \ldots, 3)$ (the $k$-color Ramsey number), then there is a monochromatic triangle. If $i<j<k$ are the vertices of this triangle, then the numbers $x=j-i, y=k-j$, and $z=k-i$ form a Schur triple. The fact that they have the same color means that they belong to the same set of the partition. The theorem is proved.

(20th International Mathematical Olympiad, 1978)

858. First solution: We will prove that the maximum value of $n$ is 11 . Figure 105 describes an arrangement of 12 dominoes such that no additional domino can be placed on the board. Therefore, $n \leq 11$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-756.jpg?height=354&width=362&top_left_y=600&top_left_x=684)

Figure 105

Let us show that for any arrangement of 11 dominoes on the board one can add one more domino. Arguing by contradiction, let us assume that there is a way of placing 11 dominoes on the board so that no more dominoes can be added. In this case there are $36-22=14$ squares not covered by dominoes.

Denote by $S_{1}$ the upper $5 \times 6$ subboard, by $S_{2}$ the lower $1 \times 6$ subboard, and by $S_{3}$ the lower $5 \times 6$ subboard of the given chessboard as shown in Figure 106 .

Because we cannot place another domino on the board, at least one of any two neighboring squares is covered by a domino. Hence there are at least three squares in $S_{2}$ that are covered by dominoes, and so in $S_{2}$ there are at most three uncovered squares. If $A$ denotes the set of uncovered squares in $S_{1}$, then $|A| \geq 14-3=11$.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-756.jpg?height=360&width=866&top_left_y=1542&top_left_x=435)

Figure 106

Let us also denote by $B$ the set of dominoes that lie completely in $S_{3}$. We will construct a one-to-one map $f: A \rightarrow B$. First, note that directly below each square $s$ in $S_{1}$ there is a square $t$ of the chessboard (see Figure 107). If $s$ is in $A$, then $t$ must be covered by a domino $d$ in $B$, since otherwise we could place a domino over $s$ and $t$. We define $f(s)=d$. If $f$ were not one-to-one, that is, if $f\left(s_{1}\right)=f\left(s_{2}\right)=d$, for some $s_{1}, s_{2} \in A$, then $d$ would cover squares directly below $s_{1}$ and $s_{2}$ as described in Figure 107. Then $s_{1}$ and $s_{2}$ must be neighbors, so a new domino can be placed to cover them. We conclude that $f$ is one-to-one, and hence $|A| \leq|B|$. It follows that $|B| \geq 11$. But there are only 11 dominoes, so $|B|=11$. This means that all 11 dominoes lie completely in $S_{3}$ and the top row is not covered by any dominoes! We could then put three more dominoes there, contradicting our assumption on the maximality of the arrangement. Hence the assumption was wrong; one can always add a domino to an arrangement of 11 dominoes. The answer to the problem is therefore $n=11$.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-757.jpg?height=358&width=784&top_left_y=705&top_left_x=481)

Figure 107

Second solution: Suppose we have an example with $k$ dominoes to which no more can be added. Let $X$ be the number of pairs of an uncovered square and a domino that covers an adjacent square. Let $m=36-2 k$ be the number of uncovered squares, let $m_{\partial}$ be the number of uncovered squares that touch the boundary (including corner squares), and $m_{c}$ the number of uncovered corner squares. Since any neighbor of an uncovered square must be covered by some domino, we have $X=4 m-m_{\partial}-m_{c}$. Similarly, let $k_{\partial}$ be the number of dominoes that touch the boundary and $k_{c}$ the number of dominoes that contain a corner square. A domino in the center of the board can have at most four unoccupied neighbors, for otherwise, we could place a new domino adjacent to it. Similarly, a domino that touches the boundary can have at most three unoccupied neighbors, and a domino that contains a corner square can have at most two unoccupied neighbors. Hence $X \leq 4 k-k_{\partial}-k_{c}$. Also, note that $k_{\partial} \geq m_{\partial}$, since as we go around the boundary we can never encounter two unoccupied squares in a row, and $m_{c}+k_{c} \leq 4$, since there are only four corners. Thus $4 m-m_{\partial}-m_{c}=X \leq 4 k-k_{\partial}-k_{c}$ gives $4 m-4 \leq 4 k$; hence $35-2 k \leq k$ and $3 k \geq 35$. Thus $k$ must be at least 12 . This argument also shows that on an $n \times n$ board, $3 k^{2} \geq n^{2}-1$.

(T. Andreescu, Z. Feng, 102 Combinatorial Problems, Birkhäuser, 2000, second solution by R. Stong)

859. Let

$$
I_{k}=\int_{0}^{\frac{\pi}{2}}(2 \sin \theta)^{2 k} d \theta, \quad k \geq 0 .
$$

Integrating by parts, we obtain

$$
\begin{aligned}
I_{k} &=\int_{0}^{\frac{\pi}{2}}(2 \sin \theta)^{2 k-1}(2 \sin \theta) d \theta \\
&=\left.(2 \sin \theta)^{2 k}(-2 \cos \theta)\right|_{0} ^{\frac{\pi}{2}}+\int_{0}^{\frac{\pi}{2}}(2 k-1)(2 \sin \theta)^{2 k-2} 4 \cos ^{2} \theta d \theta \\
&=(2 k-1) \int_{0}^{\frac{\pi}{2}}(2 \sin \theta)^{2 k-2}\left(4-4 \sin ^{2} \theta\right) d \theta \\
&=4(2 k-1) I_{k-1}-(2 k-1) I_{k} .
\end{aligned}
$$

Hence $I_{k}=\frac{4 k-2}{k} I_{k-1}, k \geq 1$. Comparing this with

$$
\left(\begin{array}{c}
2 k \\
k
\end{array}\right)=\frac{(2 k)(2 k-1)(2 k-2) !}{k^{2}((k-1) !)^{2}}=\frac{4 k-2}{k}\left(\begin{array}{c}
2 k-2 \\
k
\end{array}\right),
$$

we see that it remains to check the equality $\frac{2}{\pi} I_{0}=1$, and that is obvious.

860. We compute

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-758.jpg?height=288&width=851&top_left_y=1112&top_left_x=442)

Also,

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-758.jpg?height=288&width=502&top_left_y=1491&top_left_x=621)

In general,

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-758.jpg?height=302&width=633&top_left_y=1873&top_left_x=551)

This formula follows inductively from the combinatorial identity

$$
\left(\begin{array}{l}
m \\
m
\end{array}\right)+\left(\begin{array}{c}
m+1 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
m+p \\
m
\end{array}\right)=\left(\begin{array}{c}
m+p+1 \\
m+1
\end{array}\right)
$$

which holds for $m, p \geq 0$. This identity is quite straightforward and can be proved using Pascal's triangle as follows:

$$
\begin{aligned}
\left(\begin{array}{l}
m \\
m
\end{array}\right)+\left(\begin{array}{c}
m+1 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
m+p \\
m
\end{array}\right) &=\left(\begin{array}{l}
m+1 \\
m+1
\end{array}\right)+\left(\begin{array}{c}
m+1 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
m+p \\
m
\end{array}\right) \\
&=\left(\begin{array}{c}
m+2 \\
m+1
\end{array}\right)+\left(\begin{array}{c}
m+2 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
m+p \\
m
\end{array}\right) \\
&=\left(\begin{array}{c}
m+3 \\
m+1
\end{array}\right)+\left(\begin{array}{c}
m+3 \\
m
\end{array}\right)+\cdots+\left(\begin{array}{c}
m+p \\
m
\end{array}\right) \\
&=\cdots=\left(\begin{array}{c}
m+p \\
m+1
\end{array}\right)+\left(\begin{array}{c}
m+p \\
m
\end{array}\right)=\left(\begin{array}{c}
m+p+1 \\
m+1
\end{array}\right) .
\end{aligned}
$$

861. The general term of the Fibonacci sequence is given by the Binet formula

$$
F_{n}=\frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}\right)^{n}-\left(\frac{1-\sqrt{5}}{2}\right)^{n}\right], \quad n \geq 0 .
$$

Note that because $F_{0}=0$, we can start the summation at the 0th term. We therefore have

$$
\begin{aligned}
\sum_{i=0}^{n} F_{i}\left(\begin{array}{c}
n \\
i
\end{array}\right) &=\frac{1}{\sqrt{5}}\left[\sum_{i=0}^{n}\left(\begin{array}{c}
n \\
i
\end{array}\right)\left(\frac{1+\sqrt{5}}{2}\right)^{i}-\sum_{i=0}^{n}\left(\begin{array}{c}
n \\
i
\end{array}\right)\left(\frac{1-\sqrt{5}}{2}\right)^{i}\right] \\
&=\frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}+1\right)^{n}-\left(\frac{1-\sqrt{5}}{2}+1\right)^{n}\right] \\
&=\frac{1}{\sqrt{5}}\left[\left(\frac{3+\sqrt{5}}{2}\right)^{n}-\left(\frac{3-\sqrt{5}}{2}\right)^{n}\right]
\end{aligned}
$$

But

$$
\frac{3 \pm \sqrt{5}}{2}=\left(\frac{1 \pm \sqrt{5}}{2}\right)^{2} \text {. }
$$

So the sum is equal to

$$
\frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}\right)^{2 n}-\left(\frac{1-\sqrt{5}}{2}\right)^{2 n}\right]
$$

and this is $F_{2 n}$. The identity is proved.

(E. Cesàro)

862. Note that for $k=0,1, \ldots, n$,

$$
\left(a_{k+1}+a_{n-k+1}\right)(n+1)=2 S_{n+1} .
$$

If we add the two equal sums $\sum_{k}\left(\begin{array}{l}n \\ k\end{array}\right) a_{k+1}$ and $\sum_{k}\left(\begin{array}{c}n \\ n-k\end{array}\right) a_{n-k+1}$, we obtain

$$
\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(a_{k+1}+a_{n-k+1}\right)=\frac{2 S_{n+1}}{n+1} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)=\frac{2^{n+1}}{n+1} S_{n+1} .
$$

The identity follows.

863. Newton's binomial expansion can be used to express our sum in closed form as

$$
S_{n}=\frac{1}{4}\left[(2+\sqrt{3})^{2 n+1}+(2-\sqrt{3})^{2 n+1}\right] .
$$

The fact that $S_{n}=(k-1)^{2}+k^{2}$ for some positive integer $k$ is equivalent to

$$
2 k^{2}-2 k+1-S_{n}=0 .
$$

View this as a quadratic equation in $k$. Its discriminant is

$$
\Delta=4\left(2 S_{n}-1\right)=2\left[(2+\sqrt{3})^{2 n+1}+(2-\sqrt{3})^{2 n+1}-2\right] .
$$

Is this a perfect square? The numbers $(2+\sqrt{3})$ and $(2-\sqrt{3})$ are one the reciprocal of the other, and if they were squares, we would have a perfect square. In fact, $(4 \pm 2 \sqrt{3})$ are the squares of $(1 \pm \sqrt{3})$. We find that

$$
\Delta=\left(\frac{(1+\sqrt{3})^{2 n+1}+(1-\sqrt{3})^{2 n+1}}{2^{n}}\right)^{2} .
$$

Solving the quadratic equation, we find that

$$
\begin{aligned}
k &=\frac{1}{2}+\frac{(1+\sqrt{3})^{2 n+1}+(1-\sqrt{3})^{2 n+1}}{2^{2 n+2}} \\
&=\frac{1}{2}+\frac{1}{4}\left[(1+\sqrt{3})(2+\sqrt{3})^{n}+(1-\sqrt{3})(2-\sqrt{3})^{n}\right] .
\end{aligned}
$$

This is clearly a rational number, but is it an integer? The numbers $2+\sqrt{3}$ and $2-\sqrt{3}$ are the roots of the equation

$$
\lambda^{2}-4 \lambda+1=0,
$$

which can be interpreted as the characteristic equation of a recursive sequence $x_{n+1}-$ $4 x_{n}+x_{n-1}=0$. Given that the general formula of the terms of the sequence is $(1+$ $\sqrt{3})(2+\sqrt{3})^{n}+(1-\sqrt{3})(2-\sqrt{3})^{n}$, we also see that $x_{0}=2$ and $x_{1}=10$. An induction based on the recurrence relation shows that $x_{n}$ is divisible by 2 but not by 4 . It follows that $k$ is an integer and the problem is solved.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1999, proposed by D. Andrica)

864. We have

$$
\begin{aligned}
a_{n}+b_{n} \sqrt[3]{2}+c_{n} \sqrt[3]{4} &=\frac{\sqrt[3]{2}(1+\sqrt[3]{2}+\sqrt[3]{4})^{n}}{(\sqrt[3]{2})^{n}}=2^{-\frac{n}{3}}(\sqrt[3]{2}+\sqrt[3]{4}+2)^{n} \\
&=2^{-\frac{n}{3}}(1+(1+\sqrt[3]{2}+\sqrt[3]{4}))^{n}=2^{-\frac{n}{3}} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(a_{k}+b_{k} \sqrt[3]{2}+c_{k} \sqrt[3]{4}\right) .
\end{aligned}
$$

Hence

$$
a_{n}+b_{n} \sqrt[3]{2}+c_{n} \sqrt[3]{4}=2^{-\frac{n}{3}} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) a_{k}+2^{-\frac{n}{3}} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) b_{k} \sqrt[3]{2}+2^{-\frac{n}{3}} \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right) c_{k} \sqrt[3]{4} .
$$

The conclusion follows from the fact that $2^{-n / 3}$ is an integer if $n$ is divisible by 3 , is an integer times $\sqrt[3]{4}$ if $n$ is congruent to 1 modulo 3 , and is an integer times $\sqrt[3]{2}$ if $n$ is congruent to 2 modulo 3 .

(Revista Matematică din Timişoara (Timişoara Mathematics Gazette), proposed by T. Andreescu and D. Andrica)

865. First solution: We prove the formula by induction on $n$. The case $n=1$ is straightforward. Now let us assume that the formula holds for $n$ and let us prove it for $n+1$. Using the induction hypothesis, we can write

$$
\begin{aligned}
{[x+y]_{n+1} } &=(x+y-n)[x+y]_{n}=(x+y-n) \sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{n-k}[y]_{k} \\
&=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)((x-k)+(y-n+k))[x]_{k}[y]_{n-k} \\
&=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)(x-k)[x]_{k}[y]_{n-k}+\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)(y-(n-k))[x]_{k}[y]_{n-k} \\
&=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{k+1}[y]_{n-k}+\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{k}[y]_{n-k+1} \\
&=\sum_{k=1}^{n+1}\left(\begin{array}{c}
n \\
k-1
\end{array}\right)[x]_{k}[y]_{n-k+1}+\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{k}[y]_{n-k+1}
\end{aligned}
$$



$$
=\sum_{k=0}^{n+1}\left(\left(\begin{array}{l}
n \\
k
\end{array}\right)+\left(\begin{array}{c}
n \\
k-1
\end{array}\right)\right)[x]_{k}[y]_{n-k+1}=\sum_{k=0}^{n+1}\left(\begin{array}{c}
n+1 \\
k
\end{array}\right)[x]_{k}[y]_{n+1-k} .
$$

The induction is complete.

Second solution: The identity can also be proved by computing $\left(\frac{d}{d t}\right)^{n} t^{x+y}$ in two different ways. First,

$$
\left(\frac{d}{d t}\right)^{n} t^{x+y}=(x+y)(x+y-1) \cdots(x+y-n+1) t^{x+y-n}=[x+y]_{n} t^{x+y-n} .
$$

Second, by the Leibniz rule,

$$
\left(\frac{d}{d t}\right)^{n}\left(t^{x} \cdot t^{y}\right)=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(\left(\frac{d}{d t}\right)^{k} t^{x}\right)\left(\left(\frac{d}{d t}\right)^{n-k} t^{y}\right)=\sum_{k=0}^{n}\left(\begin{array}{l}
n \\
k
\end{array}\right)[x]_{k}[y]_{n-k} t^{x+y-n} .
$$

The conclusion follows.

866. The binomial formula $(Q+P)^{n}=\sum_{k=0}^{n}\left(\begin{array}{l}n \\ k\end{array}\right){ }_{q} Q^{k} P^{n-k}$ is of no use because the variables $Q$ and $P$ do not commute, so we cannot set $P=-Q$. The solution relies on the $q$-Pascal triangle. But the $q$-Pascal triangle is written as

$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)_{q}=q^{k}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)_{q}+\left(\begin{array}{l}
n-1 \\
k-1
\end{array}\right)_{q} .
$$

With the standard convention that $\left(\begin{array}{l}n \\ k\end{array}\right)_{q}=0$ if $k<0$ or $k>n$, we have

$$
\begin{aligned}
\sum_{k}(-1)^{k} q^{\frac{k(k-1)}{2}}\left(\begin{array}{l}
n \\
k
\end{array}\right)_{q} &=\sum_{k}(-1)^{k} q^{\frac{k(k-1)}{2}}\left(q^{k}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)_{q}+\left(\begin{array}{c}
n-1 \\
k-1
\end{array}\right)_{q}\right)_{q} \\
&=\sum_{k}(-1)^{k} q^{\frac{k(k+1)}{2}}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right)_{q}-\sum_{k}(-1)^{k-1} q^{\frac{k(k-1)}{2}}\left(\begin{array}{l}
n-1 \\
k-1
\end{array}\right)_{q} .
\end{aligned}
$$

Now just shift the index in the second $\operatorname{sum} k \rightarrow k+1$ to obtain the difference of two equal sums. The identity follows.

867. Let $G(x)=\sum_{n} y_{n} x^{n}$ be the generating function of the sequence. It satisfies the functional equation

$$
(1-a x) G(x)=1+b x+b x^{2}+\cdots=\frac{1}{1-b x}
$$

We find that

$$
G(x)=\frac{1}{(1-a x)(1-b x)}=\frac{A}{1-a x}+\frac{B}{1-b x}=\sum_{n}\left(A a^{n}+B b^{n}\right) x^{n}
$$

for some $A$ and $B$. It follows that $y_{n}=A a^{n}+B b^{n}$, and because $y_{0}=1$ and $y_{1}=a+b$, $A=\frac{a}{a-b}$ and $B=-\frac{b}{a-b}$. The general term of the sequence is therefore

$$
\frac{1}{a-b}\left(a^{n+1}-b^{n+1}\right) .
$$

868. The first identity is obtained by differentiating $(x+1)^{n}=\sum_{k=1}^{n}\left(\begin{array}{c}n \\ k\end{array}\right) x^{k}$, then setting $x=1$. The answer is $n 2^{n-1}$. The second identity is obtained by integrating the same equality and then setting $x=1$, in which case the answer is $\frac{2^{n+1}}{n+1}$.

869. The identity in part (a) is the Vandermonde formula. It is proved using the generating function of the binomial coefficients, by equating the coefficients of $x^{k}$ on the two sides of the equality $(x+1)^{m+n}=(x+1)^{m}(x+1)^{n}$.

The identity in part (b) is called the Chu-Vandermonde formula. This time the generating function in question is $(Q+P)^{n}$, where $Q$ and $P$ are the noncommuting variables that describe the time evolution of the position and the momentum of a quantum particle. They are noncommuting variables satisfying $P Q=q Q P$, the exponential form of the Heisenberg uncertainty principle. The Chu-Vandermonde formula is obtained by identifying the coefficients of $Q^{k} P^{m+n-k}$ on the two sides of the equality

$$
(Q+P)^{m+n}=(Q+P)^{m}(Q+P)^{n} .
$$

Observe that the powers of $q$ arise when we switch $P$ 's and $Q$ 's as follows:

$$
\begin{aligned}
\left(\begin{array}{c}
m \\
j
\end{array}\right)_{q} Q^{j} P^{m-j}\left(\begin{array}{c}
n \\
k-j
\end{array}\right)_{q} Q^{k-j} P^{n-k+j} &=\left(\begin{array}{c}
m \\
j
\end{array}\right)_{q}\left(\begin{array}{c}
n \\
k-j
\end{array}\right)_{q} Q^{j} P^{m-j} Q^{k-j} P^{n-k+j} \\
&=q^{(m-j)(k-j)}\left(\begin{array}{c}
m \\
j
\end{array}\right)_{q}\left(\begin{array}{c}
n \\
k-j
\end{array}\right) Q_{q} Q^{k} P^{m+n-k} .
\end{aligned}
$$

870. The sum is equal to the coefficient of $x^{n}$ in the expansion of

$$
x^{n}(1-x)^{n}+x^{n-1}(1-x)^{n}+\cdots+x^{n-m}(1-x)^{n} .
$$

This expression is equal to

$$
x^{n-m} \cdot \frac{1-x^{m+1}}{1-x}(1-x)^{n},
$$

which can be written as $\left(x^{n-m}-x^{n+1}\right)(1-x)^{n-1}$. Hence the sum is equal to $(-1)^{m}\left(\begin{array}{c}n-1 \\ m\end{array}\right)$ if $m<n$, and to 0 if $m=n$.

871. The sum from the statement is equal to the coefficient of $x^{k}$ in the expansion of $(1+x)^{n}+(1+x)^{n+1}+\cdots+(1+x)^{n+m}$. This expression can be written in compact form as 

$$
\frac{1}{x}\left((1+x)^{n+m+1}-(1+x)^{n}\right) .
$$

We deduce that the sum is equal to $\left(\begin{array}{c}n+m+1 \\ k+1\end{array}\right)-\left(\begin{array}{c}n \\ k+1\end{array}\right)$ for $k<n$ and to $\left(\begin{array}{c}n+m+1 \\ n+1\end{array}\right)$ for $k=n$. 

872. The generating function of the Fibonacci sequence is $\phi(x)=\frac{1}{1-x-x^{2}}$. Expanding like a geometric series, we obtain

$$
\frac{1}{1-x-x^{2}}=\frac{1}{1-x(1+x)}=1+x(1+x)+x^{2}(1+x)^{2}+\cdots+x^{n}(1+x)^{n}+\cdots .
$$

The coefficient of $x^{n}$ is on the one hand $F_{n}$ and on the other hand $\left(\begin{array}{c}n \\ 0\end{array}\right)+\left(\begin{array}{c}n-1 \\ 1\end{array}\right)+\left(\begin{array}{c}n-2 \\ 2\end{array}\right)+\cdots$. The identity follows.

873. We introduce some additional parameters and consider the expansion

$$
\begin{aligned}
&\frac{1}{\left(1-a_{1} x\right)\left(1-a_{2} x^{2}\right)\left(1-a_{3} x^{3}\right) \cdots} \\
&=\left(1+a_{1} x+a_{1}^{2} x^{2}+\cdots\right)\left(1+a_{2} x^{2}+a_{2}^{2} x^{4}+\cdots\right)\left(1+a_{3} x^{3}+a_{3}^{2} x^{6}+\cdots\right) \cdots \\
&=1+a_{1} x+\left(a_{1}^{2}+a_{2}\right) x^{2}+\cdots+\left(a_{1}^{\lambda_{1}} a_{2}^{\lambda_{2}} \cdots a_{k}^{\lambda_{k}}+\cdots\right) x^{n}+\cdots
\end{aligned}
$$

The term $a_{1}^{\lambda_{1}} a_{2}^{\lambda_{2}} \cdots a_{k}^{\lambda_{k}}$ that is part of the coefficient of $x^{n}$ has the property that $\lambda_{1}+2 \lambda_{2}+$ $\cdots+k \lambda_{k}=n$; hence it defines a partition of $n$, namely,

$$
n=\underbrace{1+1+\cdots+1}_{\lambda_{1}}+\underbrace{2+2+\cdots+2}_{\lambda_{2}}+\cdots+\underbrace{k+k+\cdots+k}_{\lambda_{k}} .
$$

So the terms that appear in the coefficient of $x^{n}$ generate all partitions of $n$. Setting $a_{1}=a_{2}=a_{3}=\cdots=1$, we obtain for the coefficient of $x^{n}$ the number $P(n)$ of the partitions of $n$. And we are done.

874. The argument of the previous problem can be applied mutatis mutandis to show that the number of ways of writing $n$ as a sum of odd positive integers is the coefficient of $x^{n}$ in the expansion of

$$
\frac{1}{(1-x)\left(1-x^{3}\right)\left(1-x^{5}\right)\left(1-x^{7}\right) \cdots},
$$

while the number of ways of writing $n$ as a sum of distinct positive integers is the coefficient of $x^{n}$ in

$$
(1+x)\left(1+x^{2}\right)\left(1+x^{3}\right)\left(1+x^{4}\right) \cdots
$$

We have

$$
\begin{aligned}
\frac{1}{(1-x)\left(1-x^{3}\right)\left(1-x^{5}\right)\left(1-x^{7}\right) \cdots} &=\frac{1-x^{2}}{1-x} \cdot \frac{1-x^{4}}{1-x^{2}} \cdot \frac{1-x^{6}}{1-x^{3}} \cdot \frac{1-x^{8}}{1-x^{4}} \cdot \frac{1-x^{10}}{1-x^{5}} \cdots \\
&=(1+x)\left(1+x^{2}\right)\left(1+x^{3}\right)\left(1+x^{4}\right) \cdots
\end{aligned}
$$

This proves the desired equality. Remark. This property is usually phrased as follows: Prove that the number of partitions of $n$ into distinct parts is equal to the number of partitions of $n$ into odd parts.

(L. Euler)

875. The number of subsets with the sum of the elements equal to $n$ is the coefficient of $x^{n}$ in the product

$$
G(x)=(1+x)\left(1+x^{2}\right) \cdots\left(1+x^{p}\right) .
$$

We are asked to compute the sum of the coefficients of $x^{n}$ for $n$ divisible by $p$. Call this number $s(p)$. There is no nice way of expanding the generating function; instead we compute $s(p)$ using particular values of $G$. It is natural to try $p$ th roots of unity.

The first observation is that if $\xi$ is a $p$ th root of unity, then $\sum_{k=1}^{p} \xi^{p}$ is zero except when $\xi=1$. Thus if we sum the values of $G$ at the $p$ th roots of unity, only those terms with exponent divisible by $p$ will survive. To be precise, if $\xi$ is a $p$ th root of unity different from 1, then

$$
\sum_{k=1}^{p} G\left(\xi^{k}\right)=p s(p) .
$$

We are left with the problem of computing $G\left(\xi^{k}\right), k=1,2, \ldots, p$. For $k=p$, this is just $2^{p}$. For $k=1,2, \ldots, p-1$,

$$
\begin{aligned}
G\left(\xi^{k}\right) &=\prod_{j=1}^{p}\left(1+\xi^{k j}\right)=\prod_{j=1}^{p}\left(1+\xi^{j}\right)=(-1)^{p} \prod_{j=1}^{p}\left((-1)-\xi^{j}\right)=(-1)^{p}\left((-1)^{p}-1\right) \\
&=2
\end{aligned}
$$

We therefore have $p s(p)=2^{p}+2(p-1)=2^{p}+2 p-2$. The answer to the problem is $s(p)=\frac{2^{p}-2}{p}+2$. The expression is an integer because of Fermat's little theorem.

(T. Andreescu, Z. Feng, A Path to Combinatorics for Undergraduates, Birkhäuser $2004)$

876. We introduce the generating function

$$
G_{n}(x)=\left(x+\frac{1}{x}\right)\left(x^{2}+\frac{1}{x^{2}}\right) \cdots\left(x^{n}+\frac{1}{x^{n}}\right) .
$$

Then $S(n)$ is the term not depending on $x$ in $G_{n}(x)$. If in the expression

$$
\left(x+\frac{1}{x}\right)\left(x^{2}+\frac{1}{x^{2}}\right) \cdots\left(x^{n}+\frac{1}{x^{n}}\right)=S(n)+\sum_{k \neq 0} c_{k} x^{k}
$$

we set $x=e^{i t}$ and then integrate between 0 and $2 \pi$, we obtain 

$$
\int_{0}^{2 \pi}(2 \cos t)(2 \cos 2 t) \cdots(2 \cos n t) d t=2 \pi S(n)+0
$$

whence the desired formula

$$
S(n)=\frac{2^{n-1}}{\pi} \int_{0}^{2 \pi} \cos t \cot 2 t \cdots \cos n t d t
$$

(communicated by D. Andrica)

877. Let us assume that $n$ is not a power of 2 . We consider a more exotic kind of generating function where the sequence is encoded in the exponents, not in the coefficients:

$$
f(x)=x^{a_{1}}+x^{a_{2}}+\cdots+x^{a_{n}} \quad \text { and } \quad g(x)=x^{b_{1}}+x^{b_{2}}+\cdots+x^{b_{n}}
$$

In fact, these are the generating functions of the characteristic functions of the sets $A$ and B. By assumption,

$$
f^{2}(x)-f\left(x^{2}\right)=2 \sum_{i<j} x^{a_{i}+a_{j}}=2 \sum_{i<j} x^{b_{i}+b_{j}}=g^{2}(x)-g\left(x^{2}\right)
$$

Therefore,

$$
(f(x)-g(x))(f(x)+g(x))=f\left(x^{2}\right)-g\left(x^{2}\right)
$$

Let $h(x)=f(x)-g(x)$ and $p(x)=f(x)+g(x)$. We want to prove that if $n$ is not a power of 2 , then $h$ is identically 0 . Note that $h(1)=0$. We will prove by strong induction that all derivatives of $h$ at 1 are zero, which will make the Taylor series of $h$ identically zero. Note that

$$
h^{\prime}(x) p(x)+h(x) p^{\prime}(x)=2 x h^{\prime}\left(x^{2}\right),
$$

and so $h^{\prime}(1) p(1)=2 h^{\prime}(1)$. Since $p(1)=f(1)+g(1)=2 n$, which is not a power of 2 , it follows that $h^{\prime}(1)=0$. Assuming that all derivatives of $h$ of order less than $k$ at 1 are zero, by differentiating the functional equation $k$ times and substituting $x=1$, we obtain

$$
h^{(k)}(1) p(1)=2^{k} h^{(k)}(1) .
$$

Hence $h^{(k)}(1)=0$. This completes the induction, leading to a contradiction. It follows that $n$ is a power of 2 , as desired.

(communicated by A. Neguţ)

878. We use the same generating functions as in the previous problem. So to the set $A_{n}$ we associate the function 

$$
a_{n} x=\sum_{a=1}^{\infty} c_{a} x^{a}
$$

with $c_{a}=1$ if $a \in A_{n}$ and $c_{a}=0$ if $a \notin A_{n}$. To $B_{n}$ we associate the function $b_{n}(x)$ in a similar manner. These functions satisfy the recurrence $a_{1}(x)=0, b_{1}(x)=1$,

$$
\begin{aligned}
a_{n+1}(x) &=x b_{n}(x) \\
b_{n+1} & \equiv a_{n}(x)+b_{n}(x)(\bmod 2)
\end{aligned}
$$

From now on we understand all equalities modulo 2. Let us restrict our attention to the sequence of functions $b_{n}(x), n=1,2, \ldots$ It satisfies $b_{1}(x)=b_{2}(x)=1$,

$$
b_{n+1}(x)=b_{n}(x)+x b_{n-1}(x)
$$

We solve this recurrence the way one usually solves second-order recurrences, namely by finding two linearly independent solutions $p_{1}(x)$ and $p_{2}(x)$ satisfying

$$
p_{i}(x)^{n+1}=p_{i}(x)^{n}+x p_{i}(x)^{n-1}, \quad i=1,2 .
$$

Again the equality is to be understood modulo 2. The solutions $p_{1}(x)$ and $p_{2}(x)$ are formal power series whose coefficients are residue classes modulo 2 . They satisfy the "characteristic" equation

$$
p(x)^{2}=p(x)+x
$$

which can be rewritten as

$$
p(x)(p(x)+1)=x
$$

So $p_{1}(x)$ and $p_{2}(x)$ can be chosen as the factors of this product, and thus we may assume that $p_{1}(x)=x h(x)$ and $p_{2}(x)=1+p_{1}(x)$, where $h(x)$ is again a formal power series. Writing $p_{1}(x)=\sum \alpha_{a} x^{a}$ and substituting in the characteristic equation, we find that $\alpha_{1}=1, \alpha_{2 k}=\alpha_{k}^{2}$, and $\alpha_{2 k+1}=0$ for $k>1$. Therefore,

$$
p_{1}(x)=\sum_{k=0}^{\infty} x^{2^{k}}
$$

Since $p_{1}(x)+p_{2}(x)=p_{1}(x)^{2}+p_{2}(x)^{2}=1$, it follows that in general,

$$
b_{n}(x)=p_{1}(x)^{n}+p_{2}(x)^{n}=\left(\sum_{k=0}^{\infty} x^{2^{k}}\right)^{n}+\left(1+\sum_{k=0}^{\infty} x^{2^{k}}\right)^{n}, \quad \text { for } n \geq 1 .
$$

We emphasize again that this is to be considered modulo 2. In order for $b_{n}(x)$ to be identically equal to 1 modulo 2 , we should have

$$
\left(\left(\sum_{k=0}^{\infty} x^{2^{k}}\right)+1\right)^{n} \equiv\left(\sum_{k=0}^{\infty} x^{2^{k}}\right)^{n}+1(\bmod 2) .
$$

This obviously happens if $n$ is a power of 2 , since all binomial coefficients in the expansion are even.

If $n$ is not a power of 2 , say $n=2^{i}(2 j+1), j \geq 1$, then the smallest $m$ for which $\left(\begin{array}{l}n \\ m\end{array}\right)$ is odd is $2^{j}$. The left-hand side will contain an $x^{2^{j}}$ with coefficient equal to 1 , while the smallest nonzero power of $x$ on the right is $n$. Hence in this case equality cannot hold.

We conclude that $B_{n}=\{0\}$ if and only if $n$ is a power of 2 .

(Chinese Mathematical Olympiad)

879. We will count the number of committees that can be chosen from $n$ people, each committee having a president and a vice-president.

Choosing first a committee of $k$ people, the president and the vice-president can then be elected in $k(k-1)$ ways. It is necessary that $k \geq 2$. The committees with president and vice-president can therefore be chosen in

$$
1 \cdot 2\left(\begin{array}{l}
n \\
2
\end{array}\right)+2 \cdot 3\left(\begin{array}{l}
n \\
3
\end{array}\right)+\cdots+(n-1) \cdot n\left(\begin{array}{l}
n \\
n
\end{array}\right)
$$

ways.

But we can start by selecting first the president and the vice-president, and then adding the other members to the committee. From the $n$ people, the president and the vice-president can be selected in $n(n-1)$ ways. The remaining members of the committee can be selected in $2^{n-2}$ ways, since they are some subset of the remaining $n-2$ people. We obtain

$$
1 \cdot 2\left(\begin{array}{l}
n \\
2
\end{array}\right)+2 \cdot 3\left(\begin{array}{l}
n \\
3
\end{array}\right)+\cdots+(n-1) \cdot n\left(\begin{array}{l}
n \\
n
\end{array}\right)=n(n-1) 2^{n-2} .
$$

880. Rewrite the identity as

$$
\sum_{k=1}^{n} k\left(\begin{array}{l}
n \\
k
\end{array}\right)\left(\begin{array}{c}
n \\
n-k
\end{array}\right)=n\left(\begin{array}{c}
2 n-1 \\
n-1
\end{array}\right) .
$$

We claim that both sides count the number of $n$-member committees with a physicist president that can be elected from a group of $n$ mathematicians and $n$ physicists. Indeed, on the left-hand side we first elect $k$ physicists and $n-k$ mathematicians, then elect the president among the $k$ physicists, and do this for all $k$. On the right-hand side we first elect the president and then elect the other members of the committee from the remaining $2 n-1$ people.

881. We will prove that both terms of the equality count the same thing. To this end, we introduce two disjoint sets $M$ and $N$ containing $m$, respectively, $n$ elements.

For the left-hand side, choose first $k$ elements in $M$. This can be done in $\left(\begin{array}{l}m \\ k\end{array}\right)$ ways. Now add these $k$ elements to $N$ and choose $m$ elements from the newly obtained set. The number of ordered pairs of sets $(X, Y)$ with $X \subset M, Y \subset N \cup X,|X|=k$, and $|Y|=m$ is equal to $\left(\begin{array}{c}m \\ k\end{array}\right)\left(\begin{array}{c}n+k \\ m\end{array}\right)$. Varying $k$, we obtain, for the total number of pairs $(X, Y)$,

$$
\sum_{k=m}^{\frac{n-1}{2}}\left(\begin{array}{c}
n \\
2 k+1
\end{array}\right)\left(\begin{array}{l}
k \\
m
\end{array}\right) .
$$

The same problem can be solved differently, namely choosing $Y$ first. If we fix the cardinality of $Y \cap N$, say $|Y \cap N|=j, 0 \leq j \leq m$, then $|Y \cap M|=m-j$, and so there are $\left(\begin{array}{c}n \\ j\end{array}\right)\left(\begin{array}{c}m \\ m-j\end{array}\right)$ ways to choose $Y$. Now $X$ contains the set $Y \cap M$, the union with some (arbitrary) subset of $M \backslash Y$. There are $j$ elements in $M \backslash Y$, so there are $2^{j}$ possible choices for $X$. Consequently, the number of pairs with the desired property is

$$
\sum_{j=0}^{m}\left(\begin{array}{l}
n \\
j
\end{array}\right)\left(\begin{array}{l}
m \\
j
\end{array}\right) 2^{j} .
$$

Setting the two numbers equal yields the identity from the statement.

(I. Tomescu, Problems in Combinatorics, Wiley, 1985)

882. We prove the identity by counting, in two different ways, the cardinality of the set of words of length $n$ using the alphabet $\{A, B, C\}$ and satisfying the condition that precisely $k$ of the letters are $A$, and all of the letters $B$ must be among the first $m$ letters as read from the left.

The first count is according to the number of $B$ 's. Place $m$ symbols $X$ in a row and following them $n-m$ symbols $Y$ :

$$
\underbrace{X X \ldots X X}_{m} \underbrace{Y Y \ldots Y Y}_{n-m} .
$$

Choose $i$ of the $X$ 's (in $\left(\begin{array}{c}m \\ i\end{array}\right)$ ways), and replace them by $B$ 's. Choose $k$ of the $n-i$ remaining symbols (in $\left(\begin{array}{c}n-i \\ k\end{array}\right)$ ways), and replace them by $A$ 's. Any remaining $X$ 's or $Y$ 's are now replaced by $C$ 's. We have constructed $\left(\begin{array}{c}m \\ i\end{array}\right)\left(\begin{array}{c}n-i \\ k\end{array}\right)$ words satisfying the conditions. Summing over $i$, we have the sum on the left.

The second count is according to the number of $A$ 's among the first $m$ letters of the word. We start with the same sequence of $X$ 's and $Y$ 's as before. Choose $i$ of the $m X$ 's (in $\left(\begin{array}{c}m \\ i\end{array}\right)$ ways), replace each of them by $A$ and replace each of the other $m-i X$ 's by $B$ of $C$ (this can be done in $2^{m-i}$ ways). Then choose $k-i$ of the $n-m Y$ 's (in $\left(\begin{array}{c}n-m \\ k-i\end{array}\right)$ ways) and replace each of them by $A$, and replace the remaining $Y$ 's by $C$. We have constructed $\left(\begin{array}{c}m \\ i\end{array}\right)\left(\begin{array}{c}n-m \\ k-i\end{array}\right) 2^{m-i}$ words satisfying the conditions. Summing over $i$, we obtain the right-hand side of the identity.

(Mathematics Magazine, the case $m=k-1$ proposed by D. Callan, generalization and solution by W. Moser)

883. For a counting argument to work, the identity should involve only integers. Thus it is sensible to write it as

$$
\sum_{k=0}^{q} 2^{q-k}\left(\begin{array}{c}
p+k \\
k
\end{array}\right)+\sum_{k=0}^{p} 2^{p-k}\left(\begin{array}{c}
q+k \\
k
\end{array}\right)=2^{p+q+1} .
$$

This looks like the count of the elements of a set partitioned into two subsets. The righthand side counts the number of subsets of a set with $p+q+1$ elements. It is better to think of it as the number of elements of $\{0,1\}^{n}$. We partition this set into two disjoint sets $A$ and $B$ such that $A$ is the set of $n$-tuples with at least $p+1$ entries equal to 1 , and $B$, its complement, is the set of $n$-tuples with at least $q+1$ entries equal to 0 . If the position of the $(p+1)$ st 1 is $p+k+1,0 \leq k \leq q$, then there are $\left(\begin{array}{c}p+k \\ p\end{array}\right)=\left(\begin{array}{c}p+k \\ k\end{array}\right)$ ways of choosing the positions of the first $p$ ones. Several subsequent coordinates can also be set to 1 , and this can be done in $2^{q-k}$ ways. It follows that $2^{q-k}\left(\begin{array}{c}p+k \\ k\end{array}\right)$ elements in $A$ have the $(p+1)$ st 1 in position $p+k+1$. Therefore, the first sum counts the elements of $A$. Similarly, the second sum counts the elements of $B$, and the conclusion follows.

(French contest, 1985, solution from T.B. Soulami, Les olympiades de mathématiques: Réflexes et stratégies, Ellipses, 1999)

884. A group of $2 n+1$ people, consisting of $n$ male/female couples and one extra male, wish to split into two teams. Team 1 should have $n$ people, consisting of $\left\lfloor\frac{n}{2}\right\rfloor$ women and $\left\lfloor\frac{n+1}{2}\right\rfloor$ men, while Team 2 should have $n+1$ people, consisting of $\left\lceil\frac{n}{2}\right\rceil$ women and $\left\lceil\frac{n+1}{2}\right\rceil$ men, where $\lceil x\rceil$ denotes the least integer greater than or equal to $x$. The number of ways to do this is counted by the first team, and is $c_{n} c_{n+1}$.

There is a different way to count this, namely by the number $k$ of couples that are split between the two teams. The single man joins Team 1 if and only if $k$ and $n$ have opposite parity. The split couples can be chosen in $\left(\begin{array}{l}n \\ k\end{array}\right)$ ways. From the remaining $n-k$ couples, the number to join Team 1 is $\left\lfloor\frac{n-k}{2}\right\rfloor$, which can be chosen in $c_{n-k}$ ways. Since these couples contribute $\left\lfloor\frac{n-k}{2}\right\rfloor$ women to Team 1, the number of women from the $k$ split couples that join Team 1 must be $\left\lfloor\frac{n}{2}\right\rfloor-\left\lfloor\frac{n-k}{2}\right\rfloor$, which equals either $\left\lfloor\frac{k}{2}\right\rfloor$ for $n$ odd or $\left\lceil\frac{k}{2}\right\rceil$ for $n$ even. Since $\left(\begin{array}{c}k \\ \lfloor k / 2\rfloor\end{array}\right)=\left(\begin{array}{c}k \\ {[k / 2\rceil}\end{array}\right)$, these women can be chosen in $c_{k}$ ways. Thus the left side also counts the choices.

(American Mathematical Monthly, proposed by D.M. Bloom, solution by Ch.N. Swanson) 

885. We count the points of integer coordinates in the rectangle

$$
1 \leq x \leq p^{\prime}, \quad 1 \leq y \leq q^{\prime} .
$$

Their total number is $p^{\prime} q^{\prime}$. Now let us look at the expression in the first set of parentheses. The terms count the number of points with integer coordinates that lie below the line $y=\frac{q}{p} x$ and on the lines $x=1, x=2, \ldots, x=p^{\prime}$. Here it is important to remark that since $p$ and $q$ are coprime, none of these points lie on the line $y=\frac{q}{p} x$. Similarly, the expression in the second parentheses counts the number of points with integer coordinates that lie above the line $y=\frac{q}{p} x$ and on the lines $y=1, y=2, \ldots, y=q^{\prime}$. These are all the points of the rectangle. That there are no others follows from the inequalities

$$
\left\lfloor\frac{p^{\prime} q}{p}\right\rfloor \leq q^{\prime} \quad \text { and } \quad\left\lfloor\frac{q^{\prime} p}{q}\right\rfloor \leq p^{\prime} .
$$

Indeed,

$$
\left\lfloor\frac{p^{\prime} q}{p}\right\rfloor=\left\lfloor\frac{p^{\prime}\left(2 q^{\prime}+1\right)}{2 p^{\prime}+1}\right\rfloor=\left\lfloor\frac{q^{\prime}+\frac{1}{2}}{1+\frac{1}{2 p^{\prime}}}\right\rfloor \leq\left\lfloor q^{\prime}+\frac{1}{2}\right\rfloor=q^{\prime},
$$

and the other inequality is similar.

Thus both sides of the identity in question count the same points, so they are equal. (G. Eisenstein)

886. First solution: For each pair of students, consider the set of those problems not solved by them. There are $\left(\begin{array}{c}200 \\ 2\end{array}\right)$ such sets, and we have to prove that at least one of them is empty.

For each problem there are at most 80 students who did not solve it. From these students at most $\left(\begin{array}{c}80 \\ 2\end{array}\right)=3160$ pairs can be selected, so the problem can belong to at most 3160 sets. The 6 problems together can belong to at most $6 \cdot 3160$ sets.

Hence at least $19900-18960=940$ sets must be empty, and the conclusion follows.

Second solution: Since each of the six problems was solved by at least 120 students, there were at least 720 correct solutions in total. Since there are only 200 students, there is some student who solved at least four problems. If a student solved five or six problems, we are clearly done. Otherwise, there is a student who solved exactly four. Since the two problems he missed were solved by at least 120 students, there must be a student (in fact, at least 40) who solved both of them.

(9th International Mathematical Competition for University Students, 2002)

887. First solution: We prove the formula by induction on $m$. For $m=1$ it clearly is true, since there is only one solution, $x_{1}=n$. Assume that the formula is valid when the number of unknowns is $k \leq m$, and let us prove it for $m+1$ unknowns. Write the equation as 

$$
x_{1}+x_{2}+\cdots+x_{m}=n-x_{m+1} .
$$

As $x_{m+1}$ ranges between 0 and $n$, the right-hand sides assumes all values between 0 and $n$. Using the induction hypothesis for all these cases and summing up, we find that the total number of solutions is

$$
\sum_{r=0}^{n}\left(\begin{array}{c}
m+r-1 \\
m-1
\end{array}\right) .
$$

As before, this sums up to $\left(\begin{array}{c}m+n \\ m\end{array}\right)$, proving the formula for $m+1$ unknowns. This completes the solution.

Second solution: Let $y_{i}=x_{i}+1$. Then $y_{1}, \ldots, y_{m}$ is a solution in positive integers to the equation $y_{1}+y_{2}+\cdots+y_{m}=n+m$. These solutions were counted in one of the examples discussed at the beginning of this section.

888. Since each tennis player played $n-1$ games, $x_{i}+y_{i}=n-1$ for all $i$. Altogether there are as many victories as losses; hence $x_{1}+x_{2}+\cdots+x_{n}=y_{1}+y_{2}+\cdots+y_{n}$. We have

$$
\begin{aligned}
x_{1}^{2}+x_{2}^{2} &+\cdots+x_{n}^{2}-y_{1}^{2}-y_{2}^{2}-\cdots-y_{n}^{2}=\left(x_{1}^{2}-y_{1}^{2}\right)+\left(x_{2}^{2}-y_{2}^{2}\right)+\cdots+\left(x_{n}^{2}-y_{n}^{2}\right) \\
&=\left(x_{1}+y_{1}\right)\left(x_{1}-y_{1}\right)+\left(x_{2}+y_{2}\right)\left(x_{2}-y_{2}\right)+\cdots+\left(x_{n}+y_{n}\right)\left(x_{n}-y_{n}\right) \\
&=(n-1)\left(x_{1}-y_{1}+x_{2}-y_{2}+\cdots+x_{n}-y_{n}\right) \\
&=(n-1)\left(x_{1}+x_{2}+\cdots+x_{n}-y_{1}-y_{2}-\cdots-y_{n}\right)=0,
\end{aligned}
$$

and we are done.

(L. Panaitopol, D. Şerbănescu, Probleme de Teoria Numerelor şi Combinatorica pentru Juniori (Problems in Number Theory and Combinatorics for Juniors), GIL, 2003)

889. Let $B=\left\{b_{1}, b_{2}, \ldots, b_{p}\right\}$ be the union of the ranges of the two functions. For $b_{i} \in B$, denote by $n_{b_{i}}$ the number of elements $x \in A$ such that $f(x)=b_{i}$, and by $k_{b_{i}}$ the number of elements $x \in A$ such that $g(x)=b_{i}$. Then the number of pairs $(x, y) \in A \times A$ for which $f(x)=g(x)=b_{i}$ is $n_{b_{i}} k_{b_{i}}$, the number of pairs for which $f(x)=f(y)=b_{i}$ is $n_{b_{i}}^{2}$, and the number of pairs for which $g(x)=g(y)=b_{i}$ is $k_{b_{i}}^{2}$. Summing over $i$, we obtain

$$
\begin{aligned}
m &=n_{b_{1}} k_{b_{1}}+n_{b_{2}} k_{b_{2}}+\cdots+n_{b_{p}} k_{b_{p}}, \\
n &=n_{b_{1}}^{2}+n_{b_{2}}^{2}+\cdots+n_{b_{p}}^{2}, \\
k &=k_{b_{1}}^{2}+k_{b_{2}}^{2}+\cdots+k_{b_{p}}^{2}
\end{aligned}
$$

The inequality from the statement is a consequence of the inequality $2 a b \leq a^{2}+b^{2}$. (T.B. Soulami, Les Olympiades de Mathématiques: Réflexes et stratégies, Ellipses, 1999) 


890. Let $a<b<c<d$ be the members of a connected set $S$. Because $a-1$ does not belong to the set, it follows that $a+1 \in S$, hence $b=a+1$. Similarly, since $d+1 \notin S$, we deduce that $d-1 \in S$; hence $c=d-1$. Therefore, a connected set has the form $\{a, a+1, d-1, d\}$, with $d-a>2$.

(a) There are 10 connected subsets of the set $\{1,2,3,4,5,6,7\}$, namely,

$$
\begin{aligned}
&\{1,2,3,4\} ;\{1,2,4,5\} ;\{1,2,5,6\} ;\{1,2,6,7\}, \\
&\{2,3,4,5\} ;\{2,3,5,6\} ;\{2,3,6,7\}\{3,4,5,6\} ;\{2,4,6,7\} ; \text { and }\{4,5,6,7\} .
\end{aligned}
$$

(b) Call $D=d-a+1$ the diameter of the set $\{a, a+1, d-1, d\}$. Clearly, $D>3$ and $D \leq n-1+1=n$. For $D=4$ there are $n-3$ connected sets, for $D=5$ there are $n-4$ connected sets, and so on. Adding up yields

$$
C_{n}=1+2+3+\cdots+n-3=\frac{(n-3)(n-2)}{2},
$$

which is the desired formula.

(Romanian Mathematical Olympiad, 2006)

891. The solution involves a counting argument that shows that the total number of colorings exceeds those that make some 18-term arithmetic sequence monochromatic.

There are $2^{2005}$ colorings of a set with 2005 elements by two colors. The number of colorings that make a fixed 18-term sequence monochromatic is $2^{2005-17}$, since the terms not belonging to the sequence can be colored without restriction, while those in the sequence can be colored either all black or all white.

How many 18-term arithmetic sequences can be found in the set $\{1,2, \ldots, 2005\}$ ? Such a sequence $a, a+r, a+2 r, \ldots, a+17 r$ is completely determined by $a$ and $r$ subject to the condition $a+17 r \leq 2005$. For every $a$ there are $\left\lfloor\frac{2005-a}{17}\right\rfloor$ arithmetic sequences that start with $a$. Altogether, the number of arithmetic sequences does not exceed

$$
\sum_{a=1}^{2005} \frac{2005-a}{17}=\frac{2004 \cdot 2005}{2 \cdot 17} .
$$

So the total number of colorings that makes an arithmetic sequence monochromatic does not exceed

$$
2^{2005-17} \cdot \frac{2004 \cdot 2005}{34},
$$

which is considerably smaller than $2^{2005}$. The conclusion follows.

(communicated by A. Neguţ)

892. Let us consider the collection of all subsets with 2 elements of $A_{1}, A_{2}, \ldots, A_{m}$. We thus have a collection of $6 \mathrm{~m}$ subsets with two elements of $A$. But the number of distinct subsets of cardinal 2 in $A$ is 4950 . By the pigeonhole principle, there exist distinct elements $x, y \in A$ that belong to at least 49 subsets. Let these subsets be $A_{1}, A_{2}, \ldots, A_{49}$. Then the conditions of the problem imply that the union of these subsets has $2+49 \times 2=100$ elements, so the union is $A$. However, the union of any 48 subsets among the 49 has at most $2+2 \times 48=98$ elements, and therefore it is different from $A$.

\section{(G. Dospinescu)}

893. First, it is not hard to see that a configuration that maximizes the number of partitions should have no three collinear points. After examining several cases we guess that the maximal number of partitions is $\left(\begin{array}{l}n \\ 2\end{array}\right)$. This is exactly the number of lines determined by two points, and we will use these lines to count the number of partitions. By pushing such a line slightly so that the two points lie on one of its sides or the other, we obtain a partition. Moreover, each partition can be obtained this way. There are $2\left(\begin{array}{l}n \\ 2\end{array}\right)$ such lines, obtained by pushing the lines through the $n$ points to one side or the other. However, each partition is counted at least twice this way, except for the partitions that come from the sides of the polygon that is the convex hull of the $n$ points, but those can be paired with the partitions that cut out one vertex of the convex hull from the others. Hence we have at most $2\left(\begin{array}{l}n \\ 2\end{array}\right) / 2=\left(\begin{array}{l}n \\ 2\end{array}\right)$ partitions.

Equality is achieved when the points form a convex $n$-gon, in which case $\left(\begin{array}{l}n \\ 2\end{array}\right)$ counts the pairs of sides that are intersected by the separating line.

(67th W.L. Putnam Mathematical Competition, 2006)

894. First solution: Consider the set of differences $D=\{x-y \mid x, y \in A\}$. It contains at most $101 \times 100+1=10101$ elements. Two sets $A+t_{i}$ and $A+t_{j}$ have nonempty intersection if and only if $t_{i}-t_{j}$ is in $D$. We are supposed to select the 100 elements in such a way that no two have the difference in $D$. We do this inductively.

First, choose one arbitrary element. Then assume that $k$ elements have been chosen, $k \leq 99$. An element $x$ that is already chosen prevents us from selecting any element from the set $x+D$. Thus after $k$ elements are chosen, at most $10101 k \leq 10101 \times 99=999999$ elements are forbidden. This allows us to choose the $(k+1)$ st element, and induction works. With this the problem is solved.

Second solution: This solution can be improved if we look instead at the set of positive differences $P=\{x-y \mid x, y \in A, x \geq y\}$. The set $P$ has $\left(\begin{array}{c}101 \\ 2\end{array}\right)+1=5051$ elements. The inductive construction has to be slightly modified, by choosing at each step the smallest element that is not forbidden. In this way we can obtain far more elements than the required 100. In fact, in the general situation, the argument proves that if $A$ is a $k$-element subset of $S=\{1,2, \ldots, n\}$ and $m$ is a positive integer such that $n>(m-1)\left(\left(\begin{array}{c}k \\ 2\end{array}\right)+1\right)$, then there exist $t_{1}, t_{2}, \ldots, t_{m} \in S$ such that the sets $A_{j}=\left\{x+t_{j} \mid x \in A\right\}, j=1,2, \ldots, m$, are pairwise disjoint.

(44th International Mathematical Olympiad, 2003, proposed by Brazil) 

895. (a) For fixed $x \in A$, denote by $k(x)$ the number of sets $B \in \mathcal{F}$ that contain $x$. List these sets as $B_{1}, B_{2}, \ldots, B_{k(x)}$. Then $B_{1} \backslash\{x\}, B_{2} \backslash\{x\}, \ldots, B_{k(x)} \backslash\{x\}$ are disjoint subsets of $A \backslash\{x\}$. Since each $B_{i} \backslash\{x\}$ has $n-1$ elements, and $A \backslash\{x\}$ has $n^{2}-1$ elements, $k(x) \leq \frac{n^{2}-1}{n-1}=n+1$. Repeating the argument for all $x \in A$ and adding, we obtain

$$
\sum_{x \in A} k(x) \leq n^{2}(n+1) .
$$

But

$$
\sum_{x \in A} k(x)=\sum_{B \in \mathcal{F}}|B|=n|\mathcal{F}| .
$$

Therefore, $n|\mathcal{F}| \leq n^{2}(n+1)$, which implies $|\mathcal{F}| \leq n^{2}+n$, proving (a).

For (b) arrange the elements $1,2, \ldots, 9$ in a matrix

$$
\begin{aligned}
&123 \\
&456 \\
&789
\end{aligned}
$$

and choose the sets of $\mathcal{F}$ as the rows, columns, and the "diagonals" that appear in the expansion of the $3 \times 3$ determinant:

$$
\begin{aligned}
&\{1,2,3\},\{4,5,6\},\{7,8,9\},\{1,4,7\},\{2,5,8\},\{3,6,9\}, \\
&\{1,5,9\},\{2,6,7\},\{3,4,8\},\{3,5,7\},\{2,4,9\},\{1,6,8\} .
\end{aligned}
$$

It is straightforward to check that they provide the required counterexample.

(Romanian Team Selection Test for the International Mathematical Olympiad, 1985)

896. At every cut the number of pieces grows by 1 , so after $n$ cuts we will have $n+1$ pieces.

Let us evaluate the total number of vertices of the polygons after $n$ cuts. After each cut the number of vertices grows by 2 if the cut went through two vertices, by 3 if the cut went through a vertex and a side, or by 4 if the cut went through two sides. So after $n$ cuts there are at most $4 n+4$ vertices.

Assume now that after $N$ cuts we have obtained the one hundred polygons with 20 sides. Since altogether there are $N+1$ pieces, besides the one hundred polygons there are $N+1-100$ other pieces. Each of these other pieces has at least 3 vertices, so the total number of vertices is $100 \cdot 20+(N-99) \cdot 3$. This number does not exceed $4 N+4$. Therefore,

$$
4 N+4 \geq 100 \cdot 20+(N-99) \cdot 3=3 N+1703 .
$$

We deduce that $N \geq 1699$. We can obtain one hundred polygons with twenty sides by making 1699 cuts in the following way. First, cut the square into 100 rectangles ( 99 cuts needed). Each rectangle is then cut through 16 cuts into a polygon with twenty sides and some triangles. We have performed a total of $99+100 \cdot 16=1699$ cuts.

(Kvant (Quantum), proposed by I. Bershtein)

897. We give a proof by contradiction. Let us assume that the conclusion is false. We can also assume that no problem was solved by at most one sex. Denote by $b_{i}$ and $g_{i}$ the number of boys, respectively, girls, that solved problem $i$, and by $p$ the total number of problems. Then since $b_{i}, g_{i} \geq 1$, it follows that $\left(b_{i}-2\right)\left(g_{i}-2\right) \leq 1$, which is equivalent to

$$
b_{i} g_{i} \leq 2\left(b_{i}+g_{i}\right)-3 .
$$

Let us sum this over all problems. Note that condition (ii) implies that $441 \leq \sum b_{i} g_{i}$. We thus have

$$
441 \leq \sum b_{i} g_{i} \leq 2\left(b_{i}+g_{i}\right)-3 \leq 2(6 \cdot 21+6 \cdot 21)-3 p=504-3 p .
$$

This implies that $p \leq 21$, so 21 is an upper bound for $p$.

We now do a different count of the problems that will produce a lower bound for $p$. Pairing a girl with each of the 21 boys, and using the fact that she solved at most six problems, by the pigeonhole principle we conclude that some problem was solved by that girl and 4 of the boys. By our assumption, there are at most two girls who solved that problem. This argument works for any girl, which means that there are at least 11 problems that were solved by at least 4 boys and at most 2 girls. Symmetrically, 11 other problems were solved by at least 4 girls and at most 2 boys. This shows that $p \geq 22$, a contradiction. The problem is solved.

(42nd International Mathematical Olympiad, 2001)

898. First, let us forget about the constraint and count the number of paths from $(0,0)$ and $(m, n)$ such that at each step one of the coordinates increases by 1 . There are a total of $m+n$ steps, out of which $n$ go up. These $n$ can be chosen in $\left(\begin{array}{c}m+n \\ n\end{array}\right)$ ways from the total of $m+n$. Therefore, the number of paths is $\left(\begin{array}{c}m+n \\ n\end{array}\right)$.

How many of these go through $(p, q)$ ? There are $\left(\begin{array}{c}p+q \\ q\end{array}\right)$ paths from $(0,0)$ to $(p, q)$ and $\left(\begin{array}{c}m+n-p-q \\ n-q\end{array}\right)$ paths from $(p, q)$ to $(m, n)$. Hence

$$
\left(\begin{array}{c}
p+q \\
q
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-p-q \\
n-q
\end{array}\right)
$$

of all the paths pass through $(p, q)$. And, of course,

$$
\left(\begin{array}{c}
r+s \\
s
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-r-s \\
n-s
\end{array}\right)
$$

paths pass through $(r, s)$. To apply the inclusion-exclusion principle, we also need to count the number of paths that go simultaneously through $(p, q)$ and $(r, s)$. This number is

$$
\left(\begin{array}{c}
p+q \\
q
\end{array}\right) \cdot\left(\begin{array}{c}
r+s-p-q \\
s-q
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-r-s \\
n-s
\end{array}\right) .
$$

Hence, by the inclusion-exclusion principle, the number of paths avoiding $(p, q)$ and $(r, s)$ is

$$
\begin{aligned}
\left(\begin{array}{c}
m+n \\
n
\end{array}\right) &-\left(\begin{array}{c}
p+q \\
q
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-p-q \\
n-q
\end{array}\right)-\left(\begin{array}{c}
r+s \\
s
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-r-s \\
n-s
\end{array}\right) \\
&+\left(\begin{array}{c}
p+q \\
q
\end{array}\right) \cdot\left(\begin{array}{c}
r+s-p-q \\
s-q
\end{array}\right) \cdot\left(\begin{array}{c}
m+n-r-s \\
n-s
\end{array}\right) .
\end{aligned}
$$

899. Let $E=\{1,2, \ldots, n\}$ and $F=\{1,2, \ldots, p\}$. There are $p^{n}$ functions from $E$ to $F$. The number of surjective functions is $p^{n}-N$, where $N$ is the number of functions that are not surjective. We compute $N$ using the inclusion-exclusion principle.

Define the sets

$$
A_{i}=\{f: E \rightarrow F \mid i \notin f(E)\} .
$$

Then

$$
N=\left|\cup_{i=1}^{p} A_{i}\right|=\sum_{i}\left|A_{i}\right|-\sum_{i \neq j}\left|A_{i} \cap A_{j}\right|+\cdots+(-1)^{p-1}\left|\cap_{i=1}^{p} A_{i}\right| .
$$

But $A_{i}$ consists of the functions from $E$ to $F \backslash\{i\}$; hence $\left|A_{i}\right|=(p-1)^{n}$. Similarly, for all $k, 2 \leq k \leq p-1, A_{i_{1}} \cap A_{i_{2}} \cap \cdots \cap A_{i_{k}}$ is the set of functions from $E$ to $F \backslash\left\{i_{1}, i_{2}, \ldots, i_{k}\right\}$; hence $\left|A_{i_{1}} \cap A_{i_{2}} \cap \cdots \cap A_{i_{k}}\right|=(p-k)^{n}$. Also, note that for a certain $k$, there are $\left(\begin{array}{l}p \\ k\end{array}\right)$ terms of the form $\left|A_{i_{1}} \cap A_{i_{2}} \cap \cdots \cap A_{i_{k}}\right|$. It follows that

$$
N=\left(\begin{array}{l}
p \\
1
\end{array}\right)(p-1)^{n}-\left(\begin{array}{l}
p \\
2
\end{array}\right)(p-2)^{n}+\cdots+(-1)^{p-1}\left(\begin{array}{c}
p \\
p-1
\end{array}\right) .
$$

We conclude that the total number of surjections from $E$ to $F$ is

$$
p^{n}-\left(\begin{array}{l}
p \\
1
\end{array}\right)(p-1)^{n}+\left(\begin{array}{l}
p \\
2
\end{array}\right)(p-2)^{n}-\cdots+(-1)^{p}\left(\begin{array}{c}
p \\
p-1
\end{array}\right) .
$$

900. We count instead the permutations that are not derangements. Denote by $A_{i}$ the set of permutations $\sigma$ with $\sigma(i)=i$. Because the elements in $A_{i}$ have the value at $i$ already prescribed, it follows that $\left|A_{i}\right|=(n-1)$ !. And for the same reason, $\left|A_{i_{1}} \cup A_{i_{2}} \cup \cdots \cup A_{i_{k}}\right|=$ $(n-k)$ ! for any distinct $i_{1}, i_{2}, \ldots, i_{k}, 1 \leq k \leq n$. Applying the inclusion-exclusion principle, we find that 

$$
\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right|=\left(\begin{array}{l}
n \\
1
\end{array}\right)(n-1) !-\left(\begin{array}{l}
n \\
2
\end{array}\right)(n-2) !+\cdots+(-1)^{n}\left(\begin{array}{l}
n \\
n
\end{array}\right) 1 !
$$

The number of derangements is therefore $n !-\left|A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right|$, which is

$$
n !-\left(\begin{array}{l}
n \\
1
\end{array}\right)(n-1) !+\left(\begin{array}{l}
n \\
2
\end{array}\right)(n-2) !-\cdots+(-1)^{n}\left(\begin{array}{l}
n \\
n
\end{array}\right) 0 !
$$

This number can also be written as

$$
n !\left[1-\frac{1}{1 !}+\frac{1}{2 !}-\cdots+\frac{(-1)^{n}}{n !}\right]
$$

This number is approximately equal to $\frac{n !}{e}$.

901. For a vertex $x$, denote by $A_{x}$ the set of vertices connected to $x$ by an edge. Assume that $\left|A_{x}\right| \geq\left\lfloor\frac{n}{2}\right\rfloor+1$ for all vertices $x$.

Now choose two vertices $x$ and $y$ such that $y \in A_{x}$. Counting with the inclusionexclusion principle, we get

$$
\left|A_{x} \cup A_{y}\right|=\left|A_{x}\right|+\left|A_{y}\right|-\left|A_{x} \cap A_{y}\right|
$$

Rewrite this as

$$
\left|A_{x} \cap A_{y}\right|=\left|A_{x}\right|+\left|A_{y}\right|-\left|A_{x} \cup A_{y}\right|
$$

From the fact that $\left|A_{x} \cup A_{y}\right| \leq n$ we find that $\left|A_{x} \cap A_{y}\right|$ is greater than or equal to

$$
2\left\lfloor\frac{n}{2}\right\rfloor+2-n \geq 1
$$

If follows that the set $A_{x} \cap A_{y}$ contains some vertex $z$, and so $x, y, z$ are the vertices of a triangle.

(D. Buşneag, I. Maftei, Teme pentru cercurile şi concursurile de matematic $\breve{a}$ (Themes for mathematics circles and contests), Scrisul Românesc, Craiova)

902. If the $m$-gon has three acute angles, say at vertices $A, B, C$, then with a fourth vertex $D$ they form a cyclic quadrilateral $A B C D$ that has three acute angles, which is impossible. Similarly, if the $m$-gon has two acute angles that do not share a side, say at vertices $A$ and $C$, then they form with two other vertices $B$ and $D$ of the $m$-gon a cyclic quadrilateral $A B C D$ that has two opposite acute angles, which again is impossible. Therefore, the $m$-gon has either exactly one acute angle, or has two acute angles and they share a side.

To count the number of such $m$-gons we employ the principle of inclusion and exclusion. Thus we first find the number of $m$-gons with at least one acute angle, then subtract the number of $m$-gons with two acute angles (which were counted twice the first time). If the acute angle of the $m$-gon is $A_{k} A_{1} A_{k+r}$, the condition that this angle is acute translates into $r \leq n$. The other vertices of the $m$-gon lie between $A_{k}$ and $A_{k+r}$; hence $m-2 \leq r$, and these vertices can be chosen in $\left(\begin{array}{c}r-1 \\ m-3\end{array}\right)$ ways. Note also that $1 \leq k \leq 2 n-r$. Thus the number of $m$-gons with an acute angle at $A_{1}$ is

$$
\begin{aligned}
\sum_{r=m-2}^{n} \sum_{k=1}^{2 n-r}\left(\begin{array}{c}
r-1 \\
m-3
\end{array}\right) &=2 n \sum_{m-2}^{n}\left(\begin{array}{c}
r-1 \\
m-3
\end{array}\right)-\sum_{r=m-2}^{n} r\left(\begin{array}{c}
r-1 \\
m-3
\end{array}\right) \\
&=2 n\left(\begin{array}{c}
n \\
m-2
\end{array}\right)-(m-2)\left(\begin{array}{c}
n+1 \\
m-1
\end{array}\right)
\end{aligned}
$$

There are as many polygons with an acute angle at $A_{2}, A_{3}, \ldots, A_{2 n+1}$.

To count the number of $m$-gons with two acute angles, let us first assume that these acute angles are $A_{s} A_{1} A_{k}$ and $A_{1} A_{k} A_{r}$. The other vertices lie between $A_{r}$ and $A_{s}$. We have the restrictions $2 \leq k \leq 2 n-m+3, n+2 \leq r<s \leq k+n$ if $k \leq n$ and no restriction on $r$ and $s$ otherwise. The number of such $m$-gons is

$$
\begin{aligned}
\sum_{k=1}^{n}\left(\begin{array}{c}
k-1 \\
m-2
\end{array}\right)+\sum_{k=n+1}^{2 n+1-(m-2)}\left(\begin{array}{c}
2 n+1-k \\
m-2
\end{array}\right) &=\sum_{k=m-1}^{n}\left(\begin{array}{c}
k-1 \\
m-2
\end{array}\right)+\sum_{s=m-2}^{n}\left(\begin{array}{c}
s \\
m-2
\end{array}\right) \\
&=\left(\begin{array}{c}
n+1 \\
m-1
\end{array}\right)+\left(\begin{array}{c}
n \\
m-1
\end{array}\right)
\end{aligned}
$$

This number has to be multiplied by $2 n+1$ to take into account that the first acute vertex can be at any other vertex of the regular $n$-gon.

We conclude that the number of $m$-gons with at least one acute angle is

$$
(2 n+1)\left(2 n\left(\begin{array}{c}
n \\
m-2
\end{array}\right)-(m-1)\left(\begin{array}{c}
n+1 \\
m-1
\end{array}\right)-\left(\begin{array}{c}
n \\
m-1
\end{array}\right)\right) .
$$

903. Denote by $U_{n}$ the set of $z \in S^{1}$ such that $f^{n}(z)=z$. Because $f^{n}(z)=z^{m^{n}}, U_{n}$ is the set of the roots of unity of order $m^{n}-1$. In our situation $n=1989$, and we are looking for those elements of $U_{1989}$ that do not have period less than 1989. The periods of the elements of $U_{1989}$ are divisors of 1989. Note that $1989=3^{2} \times 13 \times 17$. The elements we are looking for lie in the complement of $U_{1989 / 3} \cup U_{1989 / 13} \cup U_{1989 / 17}$. Using the inclusion-exclusion principle, we find that the answer to the problem is

$$
\begin{aligned}
\left|U_{1989}\right| &-\left|U_{1989 / 3}\right|-\left|U_{1989 / 13}\right|-\left|U_{1989 / 17}\right|+\left|U_{1989 / 3} \cap U_{1898 / 13}\right|+\left|U_{1989 / 3} \cap U_{1989 / 17}\right| \\
&+\left|U_{1989 / 13} \cap U_{1989 / 17}\right|+\left|U_{1989 / 3} \cap U_{1989 / 13} \cap U_{1989 / 17}\right|,
\end{aligned}
$$

i.e.,

$$
\left|U_{1989}\right|-\left|U_{663}\right|-\left|U_{153}\right|-\left|U_{117}\right|+\left|U_{51}\right|+\left|U_{39}\right|+\left|U_{9}\right|-\left|U_{3}\right| .
$$

This number is equal to

$$
m^{1989}-m^{663}-m^{153}-m^{117}+m^{51}+m^{39}+m^{9}-m^{3},
$$

since the $-1$ 's in the formula for the cardinalities of the $U_{n}$ 's cancel out.

(Chinese Mathematical Olympiad, 1989)

904. Here we apply a "multiplicative" inclusion-exclusion formula for computing the least common multiple of several integers, which states that the least common multiple $\left[x_{1}, x_{2}, \ldots, x_{n}\right]$ of the numbers $x_{1}, x_{2}, \ldots, x_{n}$ is equal to

$$
x_{1} x_{2} \cdots x_{n} \frac{1}{\left(x_{1}, x_{2}\right)\left(x_{1}, x_{3}\right) \cdots\left(x_{n-1}, x_{n}\right)}\left(x_{1}, x_{2}, x_{3}\right) \cdots\left(x_{n-2}, x_{n-1}, x_{n}\right) \cdots .
$$

For three numbers, this formula reads

$$
[a, b, c]=a b c \frac{1}{(a, b)(b, c)(a, c)}(a, b, c),
$$

while for two numbers, it reads

$$
[a, b]=a b \frac{1}{(a, b)} .
$$

Let us combine the two. Square the first formula; then substitute the products $a b, b c$, and $c a$ using the second. In detail,

$$
\begin{aligned}
{[a, b, c]^{2} } &=a b \cdot b c \cdot c a \frac{1}{(a, b)^{2}(b, c)^{2}(c, a)^{2}}(a, b, c)^{2} \\
&=[a, b][b, c][c, a](a, b)(b, c)(c, a) \frac{1}{(a, b)^{2}(b, c)^{2}(c, a)^{2}}(a, b, c)^{2} \\
&=[a, b][b, c][c, a] \frac{(a, b, c)^{2}}{(a, b)(b, c)(c, a)} .
\end{aligned}
$$

The identity follows.

905. We solve the problem for the general case of a rectangular solid of width $w$, length $l$, and height $h$, where $w, l$, and $h$ are positive integers. Orient the solid in space so that one vertex is at $O=(0,0,0)$ and the opposite vertex is at $A=(w, l, h)$. Then $O A$ is the diagonal of the solid.

The diagonal is transversal to the planes determined by the faces of the small cubes, so each time it meets a face, edge, or vertex, it leaves the interior of one cube and enters the interior of another. Counting by the number of interiors of small cubes that the diagonal leaves, we find that the number of interiors that $O A$ intersects is equal to the number of points on $O A$ having at least one integer coordinate. We count these points using the inclusion-exclusion principle. The first coordinate of the current point $P=(t w, t l, t h), 0<t \leq 1$, on the diagonal is a positive integer for exactly $w$ values of $t$, namely, $t=\frac{1}{w}, \frac{2}{2}, \ldots, \frac{w}{w}$. The second coordinate is an integer for $l$ values of $t$, and the third coordinate is an integer for $h$ values of $t$. However, the sum $w+l+h$ doubly counts the points with two integer coordinates, and triply counts the points with three integer coordinates. The first two coordinates are integers precisely when $t=\frac{k}{\operatorname{gcd}(w, l)}$, for some integer $k, 1 \leq k \leq \operatorname{gcd}(w, l)$. Similarly, the second and third coordinates are positive integers for $\operatorname{gcd}(l, h)$, respectively, $\operatorname{gcd}(h, w)$ values of $t$, and all three coordinates are positive integers for $\operatorname{gcd}(w, l, h)$ values of $t$.

The inclusion-exclusion principle shows that the diagonal passes through the interiors of

$$
w+l+h-\operatorname{gcd}(w, l)-\operatorname{gcd}(l, h)-\operatorname{gcd}(h, w)+\operatorname{gcd}(w, l, h)
$$

small cubes. For $w=150, l=324, h=375$ this number is equal to 768 .

(American Invitational Mathematics Examination, 1996)

906. Because the 1997 roots of the equation are symmetrically distributed in the complex plane, there is no loss of generality to assume that $v=1$. We are required to find the probability that

$$
|1+w|^{2}=|(1+\cos \theta)+i \sin \theta|^{2}=2+2 \cos \theta \geq 2+\sqrt{3} .
$$

This is equivalent to $\cos \theta \geq \frac{1}{2} \sqrt{3}$, or $|\theta| \leq \frac{\pi}{6}$. Because $w \neq 1, \theta$ is of the form $\pm \frac{2 k \pi}{1997} k$, $1 \leq k \leq\left\lfloor\frac{1997}{12}\right\rfloor$. There are $2 \cdot 166=332$ such angles, and hence the probability is $\frac{332}{1996}=\frac{83}{499} \approx 0.166$

(American Invitational Mathematics Examination, 1997)

907. It is easier to compute the probability that no two people have the same birthday. Arrange the people in some order. The first is free to be born on any of the 365 days. But only 364 dates are available for the second, 363 for the third, and so on. The probability that no two people have the same birthday is therefore

$$
\frac{364}{365} \cdot \frac{363}{365} \cdots \frac{365-n+1}{365}=\frac{365 !}{(365-n) ! 365^{n}} .
$$

And the probability that two people have the same birthday is

$$
1-\frac{365 !}{(365-n) ! 365^{n}} .
$$

Remark. Starting with $n=23$ the probability becomes greater than $\frac{1}{2}$, while when $n>365$ the probability is clearly 1 by the pigeonhole principle. 

908. Denote by $P(n)$ the probability that a bag containing $n$ distinct pairs of tiles will be emptied, $n \geq 2$. Then $P(n)=Q(n) P(n-1)$ where $Q(n)$ is the probability that two of the first three tiles selected make a pair. The latter one is

$$
\begin{aligned}
Q(n) &=\frac{\text { number of ways to select three tiles, two of which match }}{\text { number of ways to select three tiles }} \\
&=\frac{n(2 n-2)}{\left(\begin{array}{c}
2 n \\
3
\end{array}\right)}=\frac{3}{2 n-1} .
\end{aligned}
$$

The recurrence

$$
P(n)=\frac{3}{2 n-1} P(n-1)
$$

yields

$$
P(n)=\frac{3^{n-2}}{(2 n-1)(2 n-3) \cdots 5} P(2) .
$$

Clearly, $P(2)=1$, and hence the answer to the problem is

$$
P(6)=\frac{3^{4}}{11 \cdot 9 \cdot 7 \cdot 5}=\frac{9}{385} \approx 0.023 .
$$

(American Invitational Mathematics Examination, 1994)

909. Because there are two extractions each of with must contain a certain ball, the total number of cases is $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)^{2}$. The favorable cases are those for which the balls extracted the second time differ from those extracted first (except of course the chosen ball). For the first extraction there are $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)$ cases, while for the second there are $\left(\begin{array}{c}n-m \\ m-1\end{array}\right)$, giving a total number of cases $\left(\begin{array}{c}n-1 \\ m-1\end{array}\right)\left(\begin{array}{c}n-m \\ m-1\end{array}\right)$. Taking the ratio, we obtain the desired probability as

$$
P=\frac{\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)\left(\begin{array}{c}
n-m \\
m-1
\end{array}\right)}{\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)}=\frac{\left(\begin{array}{c}
n-m \\
m-1
\end{array}\right)}{\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)} .
$$

(Gazeta Matematic $\breve{a}$ (Mathematics Gazette, Bucharest), proposed by C. Marinescu)

910. First, observe that since at least one ball is removed during each stage, the process will eventually terminate, leaving no ball or one ball in the bag. Because red balls are removed 2 at a time and since we start with an odd number of red balls, the number of red balls in the bag at any time is odd. Hence the process will always leave red balls in the bag, and so it must terminate with exactly one red ball. The probability we are computing is therefore 1 .

(Mathematics and Informatics Quarterly, proposed by D. Macks) 

911. Consider the dual cube to the octahedron. The vertices $A, B, C, D, E, F, G$, $H$ of this cube are the centers of the faces of the octahedron (here $A B C D$ is a face of the cube and $(A, G),(B, H),(C, E),(D, F)$ are pairs of diagonally opposite vertices). Each assignment of the numbers $1,2,3,4,5,6,7$, and 8 to the faces of the octahedron corresponds to a permutation of $A B C D E F G H$, and thus to an octagonal circuit of these vertices. The cube has 16 diagonal segments that join nonadjacent vertices. The problem requires us to count octagonal circuits that can be formed by eight of these diagonals.

Six of these diagonals are edges of the tetrahedron $A C F H$, six are edges of the tetrahedron $D B E G$, and four are long diagonals, joining opposite vertices of the cube. Notice that each vertex belongs to exactly one long diagonal. It follows that an octagonal circuit must contain either 2 long diagonals separated by 3 tetrahedron edges (Figure 108a), or 4 long diagonals (Figure 108b) alternating with tetrahedron edges.
![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-783.jpg?height=330&width=820&top_left_y=872&top_left_x=462)

Figure 108

When forming a (skew) octagon with 4 long diagonals, the four tetrahedron edges need to be disjoint; hence two are opposite edges of $A C F H$ and two are opposite edges of $D B E G$. For each of the three ways to choose a pair of opposite edges from the tetrahedron $A C F H$, there are two possible ways to choose a pair of opposite edges from tetrahedron $D B E G$. There are $3 \cdot 2=6$ octagons of this type, and for each of them, a circuit can start at 8 possible vertices and can be traced in two different ways, making a total of $6 \cdot 8 \cdot 2=96$ permutations.

An octagon that contains exactly two long diagonals must also contain a three-edge path along the tetrahedron $A C F H$ and a three-edge path along tetrahedron the $D B E G$. A three-edge path along the tetrahedron the $A C F H$ can be chosen in $4 !=24$ ways. The corresponding three-edge path along the tetrahedron $D B E G$ has predetermined initial and terminal vertices; it thus can be chosen in only 2 ways. Since this counting method treats each path as different from its reverse, there are $8 \cdot 24 \cdot 2=384$ permutations of this type.

In all, there are $96+384=480$ permutations that correspond to octagonal circuits formed exclusively from cube diagonals. The probability of randomly choosing such a permutation is $\frac{480}{8 !}=\frac{1}{84}$.

(American Invitational Mathematics Examination, 2001) 

912. The total number of permutations is of course $n$ !. We will count instead the number of permutations for which 1 and 2 lie in different cycles.

If the cycle that contains 1 has length $k$, we can choose the other $k-1$ elements in $\left(\begin{array}{c}n-2 \\ k-1\end{array}\right)$ ways from the set $\{3,4, \ldots, n\}$. There exist $(k-1)$ ! circular permutations of these elements, and $(n-k)$ ! permutations of the remaining $n-k$ elements. Hence the total number of permutations for which 1 and 2 belong to different cycles is equal to

$$
\sum_{k=1}^{n-1}\left(\begin{array}{l}
n-2 \\
k-1
\end{array}\right)(k-1) !(n-k) !=(n-2) ! \sum_{k=1}^{n-1}(n-k)=(n-2) ! \frac{n(n-1)}{2}=\frac{n !}{2} .
$$

It follows that exactly half of all permutations contain 1 and 2 in different cycles, and so half contain 1 and 2 in the same cycle. The probability is $\frac{1}{2}$.

(I. Tomescu Problems in Combinatorics, Wiley, 1985)

913. There are $\left(\begin{array}{l}n \\ k\end{array}\right)$ ways in which exactly $k$ tails appear, and in this case the difference is $n-2 k$. Hence the expected value of $|H-T|$ is

$$
\frac{1}{2^{n}} \sum_{k=0}^{n}|n-2 k|\left(\begin{array}{l}
n \\
k
\end{array}\right) .
$$

Evaluate the sum as follows:

$$
\begin{aligned}
\frac{1}{2^{n}} \sum_{m=0}^{n}|n-2 m|\left(\begin{array}{c}
n \\
m
\end{array}\right) &=\frac{1}{2^{n-1}} \sum_{m=0}^{\lfloor n / 2\rfloor}(n-2 m)\left(\begin{array}{c}
n \\
m
\end{array}\right) \\
&=\frac{1}{2^{n-1}}\left(\sum_{m=0}^{\lfloor n / 2\rfloor}(n-m)\left(\begin{array}{c}
n \\
m
\end{array}\right)-\sum_{m=0}^{\lfloor n / 2\rfloor} m\left(\begin{array}{c}
n \\
m
\end{array}\right)\right) \\
&=\frac{1}{2^{n-1}}\left(\sum_{m=0}^{\lfloor n / 2\rfloor} n\left(\begin{array}{c}
n-1 \\
m
\end{array}\right)-\sum_{m=1}^{\lfloor n / 2\rfloor} n\left(\begin{array}{c}
n-1 \\
m-1
\end{array}\right)\right) \\
&=\frac{n}{2^{n-1}}\left(\begin{array}{c}
n-1 \\
\left\lfloor\frac{n}{2}\right\rfloor
\end{array}\right) .
\end{aligned}
$$

(35th W.L. Putnam Mathematical Competition, 1974)

914. Use $n$ cards with the numbers $1,2, \ldots, n$ on them. Shuffle the cards and stack them with the numbered faces down. Then pick cards from the top of this pack, one at a time. We say that a matching occurs at the $i$ th draw if the number on the card drawn is $i$. The probability that no matching occurs is

$$
\sum_{i=0}^{n} \frac{(-1)^{i}}{i !}=p(n),
$$

which follows from the deragements formula (see Section 6.2.4.). The probability that exactly $k$ matches occur is

$$
\left(\begin{array}{l}
n \\
k
\end{array}\right) \frac{p(n-k)(n-k) !}{n !}=\frac{1}{k !} p(n-k)=\frac{1}{k !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !} .
$$

Denote by $X$ the number of matchings in this $n$-card game. The expected value of $X$ is

$$
E(X)=\sum_{k=0}^{n} k P(X=k)=\sum_{k=0}^{n} k \frac{1}{k !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !}=\sum_{k=1}^{n} \frac{1}{(k-1) !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !},
$$

because

$$
P(X=k)=\frac{1}{k !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !} .
$$

Let us compute $E(X)$ differently. Set

$$
X_{i}= \begin{cases}1 & \text { if there is a match at the } i \text { th draw, } \\ 0 & \text { if there is no match at the } i \text { th draw. }\end{cases}
$$

Then

$$
E(X)=E\left(X_{1}+\cdots+X_{n}\right)=\sum_{i=1}^{n} E\left(X_{i}\right)=n \frac{1}{n}=1,
$$

because

$$
E\left(X_{i}\right)=1 \cdot P\left(X_{i}=1\right)=\frac{(n-1) !}{n !}=\frac{1}{n} .
$$

Combining the two, we obtain

$$
\sum_{k=1}^{n} \frac{1}{(k-1) !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !}=1,
$$

which proves the first identity. The proof of the second identity is similar. We have

$$
E\left(X^{2}\right)=E\left(\left(\sum_{i=1}^{n} X_{i}\right)^{2}\right)=\sum_{i=1}^{n} E\left(X_{i}^{2}\right)+2 \sum_{i<j} E\left(X_{i} X_{j}\right)
$$

But 

$$
E\left(X_{i}^{2}\right)=E\left(X_{i}\right)=\frac{1}{n} \quad \text { and } \quad E\left(X_{i} X_{j}\right)=1 \cdot 1 \cdot P\left(X_{i}=1, X_{j}=1\right)=\frac{1}{n(n-1)} .
$$

Hence $E\left(X^{2}\right)=1+1=2$.

On the other hand,

$$
E\left(X^{2}\right)=\sum_{k=1}^{n} k^{2} \frac{1}{k !} \sum_{i=0}^{n-k} \frac{(-1)^{i}}{i !},
$$

which proves the second identity.

(proposed for the USA Mathematical Olympiad by T. Andreescu)

915. Denote by $A_{i}$ the event "the student solves correctly exactly $i$ of the three proposed problems, '' $i=0,1,2,3$. The event $A$ whose probability we are computing is

$$
A=A_{2} \cup A_{3} \text {, }
$$

and its probability is

$$
P(A)=P\left(A_{2}\right)+P\left(A_{3}\right),
$$

since $A_{2}$ and $A_{3}$ exclude each other.

Because the student knows how to solve half of all the problems,

$$
P\left(A_{0}\right)=P\left(A_{3}\right) \quad \text { and } \quad P\left(A_{1}\right)=P\left(A_{2}\right) .
$$

The equality

$$
P\left(A_{0}\right)+P\left(A_{1}\right)+P\left(A_{2}\right)+P\left(A_{3}\right)=1
$$

becomes

$$
2\left[P\left(A_{2}\right)+P\left(A_{3}\right)\right]=1 .
$$

It follows that the probability we are computing is

$$
P(A)=P\left(A_{2}\right)+P\left(A_{3}\right)=\frac{1}{2} .
$$

(N. Negoescu, Probleme cu... Probleme (Problems with... Problems), Editura Facla, 1975)

916. For the solution we will use Bayes' theorem for conditional probabilities. We denote by $P(A)$ the probability that the event $A$ holds, and by $P\left(\frac{B}{A}\right)$ the probability that the event $B$ holds given that $A$ in known to hold. Bayes' theorem states that 

$$
P(B / A)=\frac{P(B)}{P(A)} \cdot P(A / B) .
$$

For our problem $A$ is the event that the mammogram is positive and $B$ the event that the woman has breast cancer. Then $P(B)=0.01$, while $P(A / B)=0.60$. We compute $P(A)$ from the formula

$$
P(A)=P(A / B) P(B)+P(A / \operatorname{not} B) P(\text { not } B)=0.6 \cdot 0.01+0.07 \cdot 0.99=0.0753 .
$$

The answer to the question is therefore

$$
P(B / A)=\frac{0.01}{0.0753} \cdot 0.6=0.0795 \approx 0.08
$$

The chance that the woman has breast cancer is only $8 \%$ !

917. We call a successful string a sequence of $H$ 's and $T$ 's in which $H H H H H$ appears before $T T$ does. Each successful string must belong to one of the following three types:

(i) those that begin with $T$, followed by a successful string that begins with $H$;

(ii) those that begin with $H, H H, H H H$, or $H H H H$, followed by a successful string that begins with $T$;

(iii) the string $H H H H H$.

Let $P_{H}$ denote the probability of obtaining a successful string that begins with $H$, and let $P_{T}$ denote the probability of obtaining a successful string that begins with $T$. Then

$$
\begin{aligned}
P_{T} &=\frac{1}{2} P_{H}, \\
P_{H} &=\left(\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}\right) P_{T}+\frac{1}{32} .
\end{aligned}
$$

Solving these equations simultaneously, we find that

$$
P_{H}=\frac{1}{17} \quad \text { and } \quad P_{T}=\frac{1}{34} .
$$

Hence the probability of obtaining five heads before obtaining two tails is $\frac{3}{34}$.

(American Invitational Mathematics Examination, 1995)

918. Let us denote the events $x=70^{\circ}, y=70^{\circ}, \max \left(x^{\circ}, y^{\circ}\right)=70^{\circ}, \min \left(x^{\circ}, y^{\circ}\right)=70^{\circ}$ by $A, B, C, D$, respectively. We see that $A \cup B=C \cup D$ and $A \cap B=C \cap D$. Hence

$P(A)+P(B)=P(A \cup B)+P(A \cap B)=P(C \cup D)+P(C \cap D)=P(C)+P(D)$.

Therefore, $P(D)=P(A)+P(B)-P(C)$, that is, 

$$
\begin{aligned}
P\left(\min \left(x^{\circ}, y^{\circ}\right)\right.&\left.=70^{\circ}\right)=P\left(x^{\circ}=70^{\circ}\right)+P\left(y^{\circ}=70^{\circ}\right)-P\left(\max \left(x^{\circ}, y^{\circ}\right)=70^{\circ}\right) \\
&=a+b-c .
\end{aligned}
$$

(29th W.L. Putnam Mathematical Competition, 1968)

919. In order for $n$ black marbles to show up in $n+x$ draws, two independent events should occur. First, in the initial $n+x-1$ draws exactly $n-1$ black marbles should be drawn. Second, in the $(n+x)$ th draw a black marble should be drawn. The probability of the second event is simply $q$. The probability of the first event is computed using the Bernoulli scheme; it is equal to

$$
\left(\begin{array}{c}
n+x-1 \\
x
\end{array}\right) p^{x} q^{n-1} .
$$

The answer to the problem is therefore

$$
\left(\begin{array}{c}
n+m-1 \\
m
\end{array}\right) p^{m} q^{n-1} q=\left(\begin{array}{c}
n+m-1 \\
m
\end{array}\right) p^{m} q^{n} .
$$

(Romanian Mathematical Olympiad, 1971)

920. First solution: Denote by $p_{1}, p_{2}, p_{3}$ the three probabilities. By hypothesis,

$$
\begin{aligned}
&P(X=0)=\prod_{i}\left(1-p_{i}\right)=1-\sum_{i} p_{i}+\sum_{i \neq j} p_{i} p_{j}-p_{1} p_{2} p_{3}=\frac{2}{5}, \\
&P(X=1)=\sum_{\{i, j, k\}=\{1,2,3\}} p_{i}\left(1-p_{j}\right)\left(1-p_{k}\right)=\sum_{i} p_{i}-2 \sum_{i \neq j} p_{i} p_{j}+3 p_{1} p_{2} p_{3}=\frac{13}{30}, \\
&P(X=2)=\sum_{\{i, j, k\}=\{1,2,3\}} p_{i} p_{j}\left(1-p_{k}\right)=\sum_{i \neq j} p_{i} p_{j}-3 p_{1} p_{2} p_{3}=\frac{3}{20}, \\
&P(X=3)=p_{1} p_{2} p_{3}=\frac{1}{60} .
\end{aligned}
$$

This is a linear system in the unknowns $\sum_{i} p_{i}, \sum_{i \neq j} p_{i} p_{j}$, and $p_{1} p_{2} p_{3}$ with the solution

$$
\sum_{i} p_{i}=\frac{47}{60}, \quad \sum_{i \neq j} p_{i} p_{j}=\frac{1}{5}, \quad p_{1} p_{2} p_{3}=\frac{1}{60} .
$$

It follows that $p_{1}, p_{2}, p_{3}$ are the three solutions to the equation

$$
x^{3}-\frac{47}{60} x^{2}+\frac{1}{5} x-\frac{1}{60}=0 .
$$

Searching for solutions of the form $\frac{1}{q}$ with $q$ dividing 60, we find the three probabilities to be equal to $\frac{1}{3}, \frac{1}{4}$, and $\frac{1}{5}$. Second solution: Using the Poisson scheme

$$
\left(p_{1} x+1-p_{1}\right)\left(p_{2} x+1-p_{2}\right)\left(p_{3} x+1-p_{3}\right)=\frac{2}{5}+\frac{13}{30} x+\frac{3}{20} x^{2}+\frac{1}{60} x^{3},
$$

we deduce that $1-\frac{1}{p_{i}}, i=1,2,3$, are the roots of $x^{3}+9 x^{2}+26 x+24=0$ and $p_{1} p_{2} p_{3}=\frac{1}{60}$. The three roots are $-2,-3,-4$, which again gives $p_{i}$ 's equal to $\frac{1}{3}, \frac{1}{4}$, and $\frac{1}{5}$.

(N. Negoescu, Probleme cu... Probleme (Problems with... Problems), Editura Facla, 1975)

921. Set $q_{i}=1-p_{i}, i=1,2, \ldots, n$, and consider the generating function

$$
Q(x)=\prod_{i=1}^{n}\left(p_{i} x+q_{i}\right)=Q_{0}+Q_{1} x+\cdots+Q_{n} x^{n} .
$$

The probability for exactly $k$ of the independent events $A_{1}, A_{2}, \ldots, A_{n}$ to occur is equal to the coefficient of $x^{k}$ in $Q(x)$, hence to $Q_{k}$. The probability $P$ for an odd number of events to occur is thus equal to $Q_{1}+Q_{3}+\cdots$. Let us compute this number in terms of $p_{1}, p_{2}, \ldots, p_{n}$.

We have

$$
Q(1)=Q_{0}+Q_{1}+\cdots+Q_{n} \quad \text { and } \quad Q(-1)=Q_{0}-Q_{1}+\cdots+(-1)^{n} Q_{n} \text {. }
$$

Therefore,

$$
P=\frac{Q(1)-Q(-1)}{2}=\frac{1}{2}\left(1-\prod_{i=1}^{n}\left(1-2 p_{i}\right)\right) .
$$

(Romanian Mathematical Olympiad, 1975)

922. It is easier to compute the probability of the contrary event, namely that the batch passes the quality check. Denote by $A_{i}$ the probability that the $i$ th checked product has the desired quality standard. We then have to compute $P\left(\cap_{i=1}^{5} A_{i}\right)$. The events are not independent, so we use the formula

$$
\begin{aligned}
P\left(\cap_{i=1}^{5} A_{i}\right)=& P\left(A_{1}\right) P\left(A_{2} / A_{1}\right)\left(A_{3} / A_{1} \cap A_{2}\right) P\left(A_{4} / A_{1} \cap A_{2} \cap A_{3}\right) \\
& \times P\left(A_{5} / A_{1} \cap A_{2} \cap A_{3} \cap A_{4}\right) .
\end{aligned}
$$

We find successively $P\left(A_{1}\right)=\frac{95}{100}, P\left(A_{2} / A_{1}\right)=\frac{94}{99}$ (because if $A_{1}$ occurs then we are left with 99 products out of which 94 are good $), P\left(A_{3} / A_{1} \cap A_{2}\right)=\frac{93}{98}, P\left(A_{4} / A_{1} \cap A_{2} \cap A_{3}\right)=$ $\frac{92}{97}, P\left(A_{5} / A_{1} \cap A_{2} \cap A_{3} \cap A_{4}\right)=\frac{91}{96}$. The answer to the problem is 

$$
1-\frac{95}{100} \cdot \frac{94}{99} \cdot \frac{93}{98} \cdot \frac{92}{97} \cdot \frac{91}{96} \approx 0.230 .
$$

923. We apply Bayes' formula. Let $B$ be the event that the plane flying out of Eulerville is a jet plane and $A_{1}$, respectively, $A_{2}$, the events that the plane flying between the two cities is a jet, respectively, a propeller plane. Then

$$
P\left(A_{1}\right)=\frac{2}{3}, \quad P\left(A_{2}\right)=\frac{1}{3}, \quad P\left(B / A_{1}\right)=\frac{2}{7}, \quad P\left(B / A_{2}\right)=\frac{1}{7} .
$$

Bayes formula gives

$$
P\left(A_{2} / B\right)=\frac{P\left(A_{2}\right) P\left(B / A_{2}\right)}{P\left(A_{1}\right) P\left(B / A_{1}\right)+P\left(A_{2}\right) P\left(B / A_{2}\right)}=\frac{\frac{1}{3} \cdot \frac{1}{7}}{\frac{2}{3} \cdot \frac{2}{7}+\frac{1}{3} \cdot \frac{1}{7}}=\frac{1}{5} .
$$

Thus the answer to the problem is $\frac{1}{5}$.

Remark. Without the farmer seeing the jet plane flying out of Eulerville, the probability would have been $\frac{1}{3}$. What you know affects your calculation of probabilities.

924. We find instead the probability $P(n)$ for no consecutive heads to appear in $n$ throws. We do this recursively. If the first throw is tails, which happens with probability $\frac{1}{2}$, then the probability for no consecutive heads to appear afterward is $P(n-1)$. If the first throw is heads, the second must be tails, and this configuration has probability $\frac{1}{4}$. The probability that no consecutive heads appear later is $P(n-2)$. We obtain the recurrence

$$
P(n)=\frac{1}{2} P(n-1)+\frac{1}{4} P(n-2),
$$

with $P(1)=1$, and $P(2)=\frac{3}{4}$. Make this relation more homogeneous by substituting $x_{n}=2^{n} P(n)$. We recognize the recurrence for the Fibonacci sequence $x_{n+1}=x_{n}+x_{n-1}$, with the remark that $x_{1}=F_{3}$ and $x_{2}=F_{4}$. It follows that $x_{n}=F_{n+2}, P(n)=\frac{F_{n+2}}{2^{n}}$, and the probability required by the problem is $P(n)=1-\frac{F_{n+2}}{2^{n}}$.

(L.C. Larson, Problem-Solving Through Problems, Springer-Verlag, 1990)

925. Fix $N=m+n$, the total amount of money, and vary $m$. Denote by $P(m)$ the probability that $A$ wins all the money when starting with $m$ dollars. Clearly, $P(0)=0$ and $P(N)=1$. We want a recurrence relation for $P(m)$.

Assume that $A$ starts with $k$ dollars. During the first game, $A$ can win, lose, or the game can be a draw. If $A$ wins this game, then the probability of winning all the money afterward is $P(k+1)$. If $A$ loses, the probability of winning in the end is $P(k-1)$. Finally, if the first game is a draw, nothing changes, so the probability of $A$ winning in the end remains equal to $P(k)$. These three situations occur with probabilities $p, q, r$, respectively; hence 

$$
P(k)=p P(k+1)+q P(k-1)+r P(k) .
$$

Taking into account that $p+q+r=1$, we obtain the recurrence relation

$$
p P(k+1)-(p+q) P(k)+q P(k-1)=0 .
$$

The characteristic equation of this recurrence is $p \lambda^{2}-(p+q) \lambda+q=0$. There are two cases. The simpler is $p=q$. Then the equation has the double root $\lambda=1$, in which case the general term is a linear function in $k$. Since $P(0)=0$ and $P(N)=1$, it follows that $P(m)=\frac{m}{N}=\frac{m}{n+m}$. If $p \neq q$, then the distinct roots of the equation are $\lambda_{1}=1$ and $\lambda_{2}=\frac{q}{p}$, and the general term must be of the form $P(k)=c_{1}+c_{2}\left(\frac{q}{p}\right)^{k}$. Using the known values for $k=0$ and $N$, we compute

$$
c_{1}=-c_{2}=\frac{1}{1-\left(\frac{q}{p}\right)^{N}} .
$$

Hence the required probability is

$$
\frac{m}{m+n} \text { if } p=q \quad \text { and } \quad \frac{1-\left(\frac{q}{p}\right)^{m}}{1-\left(\frac{q}{p}\right)^{m+n}} \text { if } p \neq q .
$$

(K.S. Williams, K. Hardy, The Red Book of Mathematical Problems, Dover, Mineola, NY, 1996)

926. Seeking a recurrence relation, we denote by $E(m, n)$ this expected length. What happens, then, after one toss? Half the time you win, and then the parameters become $m+1, n-1$; the other half of the time you lose, and the parameters become $m-1, n+1$. Hence the recurrence

$$
E(m, n)=1+\frac{1}{2} E(m-1, n+1)+\frac{1}{2} E(m+1, n-1),
$$

the 1 indicating the first toss. Of course, this assumes $m, n>0$. The boundary conditions are that $E(0, n)=0$ and $E(m, 0)=0$, and these, together with the recurrence formula, do determine uniquely the function $E(m, n)$.

View $E(m, n)$ as a function of one variable, say $n$, along the line $m+n=$ constant. Solving the inhomogeneous second-order recurrence, we obtain $E(m, n)=m n$. Alternately, the recursive formula says that the second difference is the constant $(-2)$, and so $E(m, n)$ is a quadratic function. Vanishing at the endpoints forces it to be $\mathrm{cmn}$, and direct evaluation shows that $c=1$.

(D.J. Newman, A Problem Seminar, Springer-Verlag)

927. Let $x$ and $y$ be the two numbers. The set of all possible outcomes is the unit square

$$
D=\{(x, y) \mid 0 \leq x \leq 1,0 \leq y \leq 1\} .
$$

The favorable cases consist of the region

$$
D_{f}=\left\{(x, y) \in D \mid x+y \leq 1, x y \leq \frac{2}{9}\right\} .
$$

This is the set of points that lie below both the line $f(x)=1-x$ and the hyperbola $g(x)=\frac{2}{9 x}$. equal to

The required probability is $P=\frac{\operatorname{Area}\left(D_{f}\right)}{\operatorname{Area}(D)}$. The area of $D$ is 1 . The area of $D_{f}$ is

$$
\int_{0}^{1} \min (f(x), g(x)) d x .
$$

The line and the hyperbola intersect at the points $\left(\frac{1}{3}, \frac{2}{3}\right)$ and $\left(\frac{2}{3}, \frac{1}{3}\right)$. Therefore,

$$
\operatorname{Area}\left(D_{f}\right)=\int_{0}^{1 / 3}(1-x) d x+\int_{1 / 3}^{2 / 3} \frac{2}{9 x} d x+\int_{2 / 3}^{1}(1-x) d x=\frac{1}{3}+\frac{2}{9} \ln 2 .
$$

We conclude that $P=\frac{1}{3}+\frac{2}{9} \ln 2 \approx 0.487$.

(C. Reischer, A. Sâmboan, Culegere de Probleme de Teoria Probabilitătilor şi Statistică Matematica (Collection of Problems of Probability Theory and Mathematical Statistics), Editura Didactică şi Pedagogică, Bucharest, 1972)

928. The total region is a square of side $\beta$. The favorable region is the union of the two triangular regions shown in Figure 109, and hence the probability of a favorable outcome is

$$
\frac{(\beta-\alpha)^{2}}{\beta^{2}}=\left(1-\frac{\alpha}{\beta}\right)^{2} .
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-792.jpg?height=282&width=287&top_left_y=1621&top_left_x=724)

Figure 109

(22nd W.L. Putnam Mathematical Competition, 1961)

929. Denote by $x$, respectively, $y$, the fraction of the hour when the husband, respectively, wife, arrive. The configuration space is the square 

$$
D=\{(x, y) \mid 0 \leq x \leq 1,0 \leq y \leq 1\} .
$$

In order for the two people to meet, their arrival time must lie inside the region

$$
D_{f}=\left\{(x, y)|| x-y \mid \leq \frac{1}{4}\right\} .
$$

The desired probability is the ratio of the area of this region to the area of the square.

The complement of the region consists of two isosceles right triangles with legs equal to $\frac{3}{4}$, and hence of areas $\frac{1}{2}\left(\frac{3}{4}\right)^{2}$. We obtain for the desired probability

$$
1-2 \cdot \frac{1}{2} \cdot\left(\frac{3}{4}\right)^{2}=\frac{7}{16} \approx 0.44 .
$$

\section{(B.V. Gnedenko)}

930. The set of possible events is modeled by the square [0, 24] $\times[0,24]$. It is, however, better to identify the 0th and the 24th hours, thus obtaining a square with opposite sides identified, an object that in mathematics is called a torus (which is, in fact, the Cartesian product of two circles. The favorable region is outside a band of fixed thickness along the curve $x=y$ on the torus as depicted in Figure 110. On the square model this region is obtained by removing the points $(x, y)$ with $|x-y| \leq 1$ together with those for which $|x-y-1| \leq 1$ and $|x-y+1| \leq 1$. The required probability is the ratio of the area of the favorable region to the area of the square, and is

$$
P=\frac{24^{2}-2 \cdot 24}{24^{2}}=\frac{11}{12} \approx 0.917 .
$$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-793.jpg?height=400&width=511&top_left_y=1510&top_left_x=612)

Figure 110

931. We assume that the circle of the problem is the unit circle centered at the origin $O$. The space of all possible choices of three points $P_{1}, P_{2}, P_{3}$ is the product of three circles; the volume of this space is $2 \pi \times 2 \pi \times 2 \pi=8 \pi^{3}$. Let us first measure the volume of the configurations $\left(P_{1}, P_{2}, P_{3}\right)$ such that the arc $P_{1} \widehat{P_{2}} P_{3}$ is included in a semicircle and is oriented counterclockwise from $P_{1}$ to $P_{3}$. The condition that the arc is contained in a semicircle translates to $0 \leq \angle P_{1} O P_{2} \leq \pi$ and $0 \leq \angle P_{2} O P_{3} \leq \pi-\angle P_{1} O P_{2}$ (see Figure 111). The point $P_{1}$ is chosen randomly on the circle, and for each $P_{1}$ the region of the angles $\theta_{1}$ and $\theta_{2}$ such that $0 \leq \theta_{1} \leq \pi$ and $0 \leq \theta_{1} \leq \pi-\theta_{1}$ is an isosceles right triangle with leg equal to $\pi$. Hence the region of points $\left(P_{1}, P_{2}, P_{3}\right)$ subject to the above constraints has volume $2 \pi \cdot \frac{1}{2} \pi^{2}=\pi^{3}$. There are $3 !=6$ such regions and they are disjoint. Therefore, the volume of the favorable region is $6 \pi^{3}$. The desired probability is therefore equal to $\frac{6 \pi^{3}}{8 \pi^{3}}=\frac{3}{4}$.

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-794.jpg?height=321&width=346&top_left_y=714&top_left_x=699)

Figure 111

932. The angle at the vertex $P_{i}$ is acute if and only if all other points lie on an open semicircle facing $P_{i}$. We first deduce from this that if there are any two acute angles at all, they must occur consecutively. Otherwise, the two arcs that these angles subtend would overlap and cover the whole circle, and the sum of the measures of the two angles would exceed $180^{\circ}$.

So the polygon has either just one acute angle or two consecutive acute angles. In particular, taken in counterclockwise order, there exists exactly one pair of consecutive angles the second of which is acute and the first of which is not.

We are left with the computation of the probability that for one of the points $P_{j}$, the angle at $P_{j}$ is not acute, but the following angle is. This can be done using integrals. But there is a clever argument that reduces the geometric probability to a probability with a finite number of outcomes. The idea is to choose randomly $n-1$ pairs of antipodal points, and then among these to choose the vertices of the polygon. A polygon with one vertex at $P_{j}$ and the other among these points has the desired property exactly when $n-2$ vertices lie on the semicircle to the clockwise side of $P_{j}$ and one vertex on the opposite semicircle. Moreover, the points on the semicircle should include the counterclockwisemost to guarantee that the angle at $P_{j}$ is not acute. Hence there are $n-2$ favorable choices of the total $2^{n-1}$ choices of points from the antipodal pairs. The probability for obtaining a polygon with the desired property is therefore $(n-2) 2^{-n+1}$.

Integrating over all choices of pairs of antipodal points preserves the ratio. The events $j=1,2, \ldots, n$ are independent, so the probability has to be multiplied by $n$. The answer to the problem is therefore $n(n-2) 2^{-n+1}$.

(66th W.L. Putnam Mathematical Competition, 2005, solution by C. Lin) 

933. The pair $(p, q)$ is chosen randomly from the three-dimensional domain $C \times$ int $C$, which has a total volume of $2 \pi^{2}$ (here int $C$ denotes the interior of $C$ ). For a fixed $p$, the locus of points $q$ for which $R$ does not have points outside of $C$ is the rectangle whose diagonal is the diameter through $p$ and whose sides are parallel to the coordinate axes (Figure 112). If the coordinates of $p$ are $(\cos \theta, \sin \theta)$, then the area of the rectangle is $2|\sin 2 \theta|$

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-795.jpg?height=481&width=567&top_left_y=577&top_left_x=588)

Figure 112

The volume of the favorable region is therefore

$$
V=\int_{0}^{2 \pi} 2|\sin 2 \theta| d \theta=4 \int_{0}^{\pi / 2} 2 \sin 2 \theta d \theta=8 .
$$

Hence the probability is

$$
P=\frac{8}{2 \pi^{2}}=\frac{4}{\pi^{2}} \approx 0.405 .
$$

(46th W.L. Putnam Mathematical Competition, 1985)

934. Mark an endpoint of the needle. Translations parallel to the given (horizontal) lines can be ignored; thus we can assume that the marked endpoint of the needle always falls on the same vertical. Its position is determined by the variables $(x, \theta)$, where $x$ is the distance to the line right above and $\theta$ the angle made with the horizontal (Figure 113).

The pair $(x, \theta)$ is randomly chosen from the region $[0,2) \times[0,2 \pi)$. The area of this region is $4 \pi$. The probability that the needle will cross the upper horizontal line is

$$
\frac{1}{4 \pi} \int_{0}^{\pi} \int_{0}^{\sin \theta} d x d \theta=\int_{0}^{\pi} \frac{\sin \theta}{4 \pi} d \theta=\frac{1}{2 \pi},
$$

which is also equal to the probability that the needle will cross the lower horizontal line. The probability for the needle to cross either the upper or the lower horizontal line is therefore $\frac{1}{\pi}$. This gives an experimental way of approximating $\pi$.

(G.-L. Leclerc, Comte de Buffon) 

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-796.jpg?height=241&width=492&top_left_y=259&top_left_x=626)

Figure 113

935. First solution: We will prove that the probability is $1-\frac{35}{12 \pi^{2}}$. To this end, we start with some notation and simplifications. The area of a triangle $X Y Z$ will be denoted by $A(X Y Z)$. For simplicity, the circle is assumed to have radius 1 . Also, let $E$ denote the expected value of a random variable over all choices of $P, Q, R$.

If $P, Q, R, S$ are the four points, we may ignore the case in which three of them are collinear, since this occurs with probability zero. Then the only way they can fail to form the vertices of a convex quadrilateral is if one of them lies inside the triangle formed by the other three. There are four such configurations, depending on which point lies inside the triangle, and they are mutually exclusive. Hence the desired probability is 1 minus four times the probability that $S$ lies inside triangle $P Q R$. That latter probability is simply $E(A(P Q R))$ divided by the area of the disk.

Let $O$ denote the center of the circle, and let $P^{\prime}, Q^{\prime}, R^{\prime}$ be the projections of $P, Q, R$ onto the circle from $O$. We can write

$$
A(P Q R)=\pm A(O P Q) \pm A(O Q R) \pm A(O R P)
$$

for a suitable choice of signs, determined as follows. If the points $P^{\prime}, Q^{\prime}, R^{\prime}$ lie on no semicircle, then all of the signs are positive. If $P^{\prime}, Q^{\prime}, R^{\prime}$ lie on a semicircle in that order and $Q$ lies inside the triangle $O P R$, then the sign on $A(O P R)$ is positive and the others are negative. If $P^{\prime}, Q^{\prime}, R^{\prime}$ lie on a semicircle in that order and $Q$ lies outside the triangle $O P R$, then the sign on $A(O P R)$ is negative and the others are positive.

We first calculate

$$
E(A(O P Q)+A(O Q R)+A(O R P))=3 E(A(O P Q)) .
$$

Write $r_{1}=O P, r_{2}=O Q, \theta=\angle P O Q$, so that

$$
A(O P Q)=\frac{1}{2} r_{1} r_{2} \sin \theta .
$$

The distribution of $r_{1}$ is given by $2 r_{1}$ on $[0,1]$ (e.g., by the change of variable formula to polar coordinates, or by computing the areas of annuli centered at the origin), and similarly for $r_{2}$. The distribution of $\theta$ is uniform on $[0, \pi]$. These three distributions are independent; hence

$$
E(A(O P Q))=\frac{1}{2}\left(\int_{0}^{1} 2 r^{2} d r\right)^{2}\left(\frac{1}{\pi} \int_{0}^{\pi} \sin \theta d \theta\right)=\frac{4}{9 \pi},
$$

and

$$
E(A(O P Q)+A(O Q R)+A(O R P))=\frac{4}{3 \pi} .
$$

We now treat the case in which $P^{\prime}, Q^{\prime}, R^{\prime}$ lie on a semicircle in that order. Set $\theta_{1}=\angle P O Q$ and $\theta_{2}=\angle Q O R$; then the distribution of $\theta_{1}, \theta_{2}$ is uniform on the region

$$
0 \leq \theta_{1}, \quad 0 \leq \theta_{2}, \quad \theta_{1}+\theta_{2} \leq \pi .
$$

In particular, the distribution on $\theta=\theta_{1}+\theta_{2}$ is $\frac{2 \theta}{\pi^{2}}$ on $[0, \pi]$. Set $r_{P}=O P, r_{Q}=$ $O Q, r_{R}=O R$. Again, the distribution on $r_{P}$ is given by $2 r_{P}$ on $[0,1]$, and similarly for $r_{Q}, r_{R}$; these are independent of each other and the joint distribution of $\theta_{1}, \theta_{2}$. Write $E^{\prime}(X)$ for the expectation of a random variable $X$ restricted to this part of the domain.

Let $\chi$ be the random variable with value 1 if $Q$ is inside triangle $O P R$ and 0 otherwise. We now compute

$$
E^{\prime}(A(O P R))=\frac{1}{2}\left(\int_{0}^{1} 2 r^{2} d r\right)^{2}\left(\int_{0}^{\pi} \frac{2 \theta}{\pi^{2}} \sin \theta d \theta\right)=\frac{4}{9 \pi}
$$

and

$$
\begin{aligned}
E^{\prime}(\chi A(O P R)) &=E^{\prime}\left(\frac{2 A(O P R)^{2}}{\theta}\right) \\
&=\frac{1}{2}\left(\int_{0}^{1} 2 r^{3} d r\right)^{2}\left(\int_{0}^{\pi} \frac{2 \theta}{\pi^{2}} \theta^{-1} \sin ^{2} \theta d \theta\right)=\frac{1}{8 \pi} .
\end{aligned}
$$

Also, recall that given any triangle $X Y Z$, if $T$ is chosen uniformly at random inside $X Y Z$, the expectation of $A(T X Y)$ is the area of triangle bounded by $X Y$ and the centroid of $X Y Z$, namely, $\frac{1}{3} A(X Y Z)$.

Let $\chi$ be the random variable with value 1 if $Q$ is inside triangle $O P R$ and 0 otherwise. Then

$$
\begin{aligned}
E^{\prime}(A(&O P Q)+A(O Q R)+A(O R P)-A(P Q R)) \\
&=2 E^{\prime}\left(\chi(A(O P Q)+A(O Q R))+2 E^{\prime}((1-\chi) A(O P R))\right.\\
\quad & 2 E^{\prime}\left(\frac{2}{3} \chi A(O P R)\right)+2 E^{\prime}(A(O P R))-2 E^{\prime}(\chi A(O P R))
\end{aligned}
$$



$$
=2 E^{\prime}(A(O P R))-\frac{2}{3} E^{\prime}(\chi A(O P R))=\frac{29}{36 \pi} .
$$

Finally, note that the case in which $P^{\prime}, Q^{\prime}, R^{\prime}$ lie on a semicircle in some order occurs with probability $\frac{3}{4}$. (The case in which they lie on a semicircle proceeding clockwise from $P^{\prime}$ to its antipode has probability $\frac{1}{4}$; this case and its two analogues are exclusive and exhaustive.) Hence

$$
\begin{aligned}
E(A(P Q R))=& E(A(O P Q)+A(O Q R)+A(O R P)) \\
&-\frac{3}{4} E^{\prime}(A(O P Q)+A(O Q R)+A(O R P)-A(P Q R)) \\
=& \frac{4}{3 \pi}-\frac{29}{48 \pi}=\frac{35}{48 \pi} .
\end{aligned}
$$

We conclude that the original probability is

$$
1-\frac{4 E(A(P Q R))}{\pi}=1-\frac{35}{12 \pi^{2}} .
$$

Second solution: As in the first solution, it suffices to check that for $P, Q, R$ chosen uniformly at random in the disk, $E(A(P Q R))=\frac{35}{48 \pi}$. Draw the lines $P Q, Q R, R P$, which with probability 1 divide the interior of the circle into seven regions. Set $a=$ $A(P Q R)$, let $b_{1}, b_{2}, b_{3}$ denote the areas of the other three regions sharing a side with the triangle, and let $c_{1}, c_{2}, c_{3}$ denote the areas of the other three regions. Set $A=E(a)$, $B=E\left(b_{1}\right), C=E\left(c_{1}\right)$, so that $A+3 B+3 C=\pi$.

Note that $c_{1}+c_{2}+c_{3}+a$ is the area of the region in which we can choose a fourth point $S$ such that the quadrilateral $P Q R S$ fails to be convex. By comparing expectations we find that $3 C+A=4 A$, so $A=C$ and $4 A+3 B=\pi$.

We will compute $B+2 A=B+2 C$, which is the expected area of the part of the circle cut off by a chord through two random points $D, E$, on the side of the chord not containing a third random point $F$. Let $h$ be the distance from the center $O$ of the circle to the line $D E$. We now determine the distribution of $h$.

Set $r=O D$. As seen before, the distribution of $r$ is $2 r$ on [0,1]. Without loss of generality, we may assume that $O$ is the origin and $D$ lies on the positive $x$-axis. For fixed $r$, the distribution of $h$ runs over $[0, r]$, and can be computed as the area of the infinitesimal region in which $E$ can be chosen so the chord through $D E$ has distance to $O$ between $h$ and $h+d h$, divided by $\pi$. This region splits into two symmetric pieces, one of which lies between chords making angles of $\arcsin \left(\frac{h}{r}\right)$ and $\arcsin \left(\frac{h+d h}{r}\right)$ with the $x$-axis. The angle between these is $d \theta=\frac{d h}{r^{2}-h^{2}}$. Draw the chord through $D$ at distance $h$ to $O$, and let $L_{1}, L_{2}$ be the lengths of the parts on opposite sides of $D$; then the area we are looking for is $\frac{1}{2}\left(L_{1}^{2}+L_{2}^{2}\right) d \theta$. Because

$$
\left\{L_{1}, L_{2}\right\}=\left\{\sqrt{1-h^{2}}+\sqrt{r^{2}-h^{2}}, \sqrt{1-h^{2}}-\sqrt{r^{2}-h^{2}}\right\},
$$

the area we are seeking (after doubling) is

$$
2 \frac{1+r^{2}-2 h^{2}}{\sqrt{r^{2}-h^{2}}} \text {. }
$$

Dividing by $\pi$, then integrating over $r$, we compute the distribution of $h$ to be

$$
\frac{1}{\pi} \int_{h}^{1} 2 \frac{1+r^{2}-2 h^{2}}{\sqrt{r^{2}-h^{2}}} 2 r d r=\frac{16}{3 \pi}\left(1-h^{2}\right)^{3 / 2} .
$$

Let us now return to the computation of $B+2 A$. Denote by $A(h)$ the smaller of the two areas of the disk cut off by a chord at distance $h$. The chance that the third point is in the smaller (respectively, larger) portion is $\frac{A(h)}{\pi}$ (respectively, $1-\frac{A(h)}{\pi}$ ), and then the area we are trying to compute is $\pi-A(h)$ (respectively, $A(h)$ ). Using the distribution on $h$, and the fact that

$$
A(h)=2 \int_{h}^{1} \sqrt{1-h^{2}} d h=\frac{\pi}{2}-\arcsin (h)-h \sqrt{1-h^{2}},
$$

we obtain

$$
B+2 A=\frac{2}{\pi} \int_{0}^{1} A(h)(\pi-A(h)) \frac{16}{3 \pi}\left(1-h^{2}\right)^{3 / 2} d h=\frac{35+24 \pi^{2}}{72 \pi} .
$$

Using the fact that $4 A+3 B=\pi$, we obtain $A=\frac{35}{48 \pi}$ as in the first solution.

Remark. This is a particular case of the Sylvester four-point problem, which asks for the probability that four points taken at random inside a convex domain $D$ form a nonconvex quadrilateral. Nowadays the standard method for computing this probability uses Crofton's theorem on mean values. We have seen above that when $D$ is a disk the probability is $\frac{35}{12 \pi^{2}}$. When $D$ is a triangle, square, regular hexagon, or regular octagon, the probability is, respectively, $\frac{1}{3}, \frac{11}{36}, \frac{289}{972}$, and $\frac{1181+867 \sqrt{2}}{4032+2880 \sqrt{2}}$ (cf. H. Solomon, Geometric Probability, SIAM, 1978).

(first solution by D. Kane, second solution by D. Savitt) 

\section{Index of Notation}

![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-800.jpg?height=1282&width=1101&top_left_y=851&top_left_x=193)



![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-801.jpg?height=1855&width=1223&top_left_y=245&top_left_x=193)



![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-802.jpg?height=1867&width=968&top_left_y=250&top_left_x=192)



![](https://cdn.mathpix.com/cropped/2022_10_30_5df578bdac2dccbf98f1g-803.jpg?height=457&width=931&top_left_y=250&top_left_x=193)



\section{Index}

AM-GM, see arithmetic mean-geometric mean inequality

argument by contradiction, 1

arithmetic mean-geometric mean inequality, 39

axiom of choice, 189

basis, 77

Bayes' formula, 314

Bernoulli scheme, 314

binary operation, 87

associative, 87

commutative, 87

Binet formula, 102

binomial coefficient, 294

quantum, 296

cab-bac identity, 202

Cantor set, 129

Cantor's nested intervals theorem, 116

Catalan numbers, 299

Cauchy's criterion for convergence, 109

Cauchy's equation, 189

Cauchy-Schwarz inequality, 32, 33

for integrals, 157

Cayley-Hamilton theorem, 83

Cesàro-Stolz theorem, 114

characteristic equation

of a differential equation, 195

of a sequence, 100

Chebyshev polynomial, 58

Chebyshev's inequality, 158 Chebyshev's theorem, 59

Chinese Remainder Theorem, 268

congruent, 258

conic, 212

equation of tangent line, 213

continued fraction expansion, 271, 277

coordinates

affine, 206

Cartesian, 206

complex, 209

cylindrical, 175

polar, 175

spherical, 175

coprime, 253

critical point, 134,170

Crofton's theorem, 226

cross-product, 202

area, 204

de Moivre's formula, 235

derivative, 134

partial, 168

determinant, 63

rule of Laplace, 67

Vandermonde, 63

differentiable function multivariable, 167

directrix, 212

divergence theorem, see Gauss-Ostrogradski theorem

divisor, 253

dot product, 202 eigenvalue, 79

eigenvector, 79

ellipse, 212

ellipsoid, 219

Euclid's algorithm, 271

Euclid's theorem, 1, 254

Euler's formula, 235, 289

for homogeneous functions, 168

Euler's substitutions, 217

Euler's theorem, 266

Euler's totient function, 265

exact differential equation, 192

Fermat's infinite descent principle, 248

Fermat's little theorem, 4, 261

Fibonacci sequence, 8

flux, 180

focus, 212

Fourier series, 164

Fubini's theorem, 177

function

concave, 142

continuous, 128

contractive, 110

convex, 142

differentiable, 134

harmonic, 169

Gauss-Ostrogradski theorem, 180

Gaussian integral, 177

generalized mean inequality, 147

generating function, 298

gradient, 183

graph, 282

greatest integer function, 250

Green's theorem, 179

group, 90

Abelian, 91

Klein, 91

special linear, 272

Hölder's inequality, 142

for integrals, 157

holomorphic function, 182

hyperbola, 212

hyperboloid of one sheet, 219

of two sheets, 220

identity element, 87

identity matrix, 61

inclusion-exclusion principle, 308

induction, 3

strong, 7

inductively, see induction

infinite descent, see Fermat's infinite descent principle

integral

Fresnel, 175

Gaussian, 175

integrals

computed recursively, 151

definite, 150

indefinite, 147

multivariable, 174

integrating factor, 193

intermediate value property, 131

inverse, 88

modulo $n, 258$

of a matrix, 69

invertible matrix, see inverse of a matrix

irreducible polynomial, 56

Jacobian, 174

Jensen's inequality, 146

Lagrange multipliers, 171

Leibniz formula, 151

L'Hôpital's rule, see L'Hôpital's theorem

L'Hôpital's theorem, 137

limit

of a function, 126

of a sequence, 104

linear

combination, 77

dependence, 77

independence, 77

linear Diophantine equation, 270

linear map, see linear transformation

linear transformation, 79

matrix, 61

circulant, 66 commutator, 84

rank, 77

transpose conjugate, 71

mean value theorem, 139

Minkowski's inequality, 157

mod, see modulo

modulo, 258

$n$-gon, 9

order, 14

total, 14

ordinary differential equation

first-order, 191

higher-order, 195

homogeneous, 195

inhomogeneous, 195

orthological triangles, 204

parabola, 212

paraboloid

elliptic, 220

hyperbolic, 220

Pascal's triangle, 295

Peano curve, 129

Pell's equation, 276

permutation, 283

cycle, 283

inversion, 283

signature, 283

transposition, 283

Perron-Frobenius theorem, 84

pigeonhole principle, 11

point group, 93

Poisson scheme, 314

polynomial, 45

monic, 45

prime, see prime number

prime number, 254

probability, 310

geometric, 318

Pythagorean triple, 274

quadric, 219

equation of tangent plane, 220

Ramsey number, 292 Ramsey theory, 291

rational curve, 216

regular polyhedron, 290

relatively prime, see coprime

residue, 258

residue class, see residue

Riemann sum, 153

ring, 95

Rolle's theorem, 139

root, 46

roots of unity, 236

ruled surface, 221

Schur number, 294

separation of variables, 191

sequence

Cauchy, 109

convex, 114, 143

first difference, 114

linear recursive, 100

second difference, 114

series, 117

geometric, 117

$p$-series, 117

ratio test, 118

telescopic, 120

spectral mapping theorem, 79

squeezing principle, 105

Stirling's formula, 162

Stokes' theorem, 179

Sturm's principle, 42

system of linear equations, 73

Taylor series, 159

Tonelli's theorem, 177

trace, 61

triangle inequality, 36

vector, 201

vector field

curl, 180

divergence, 180

vector space, 77 basis, 77

Viète's relations, 48

Wallis formula, 153

Weierstrass' criterion, see Weierstrass' theorem Weierstrass' theorem, 109

Wilson's theorem, 264

zero matrix, 61

zero of a polynomial, 46